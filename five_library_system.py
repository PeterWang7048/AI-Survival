#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
äº”åº“ç³»ç»Ÿ (Five Library System)
å®ç°ILAIå©´å„¿æ¨¡å‹çš„çŸ¥è¯†åŒæ­¥å’Œè§„å¾‹ç”Ÿæˆæœºåˆ¶

äº”åº“æ¶æ„ï¼š
1. ç›´æ¥ç»éªŒåº“ (Direct Experience Library) - direct_experiences.db
2. æ€»ç»éªŒåº“ (Total Experience Library) - total_experiences.db  
3. ç›´æ¥è§„å¾‹åº“ (Direct Rules Library) - direct_rules.db
4. æ€»è§„å¾‹åº“ (Total Rules Library) - total_rules.db
5. å†³ç­–åº“ (Decision Library) - decisions.db
"""

import sqlite3
import json
import hashlib
import time
import threading
import uuid
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥å¯¹è±¡å±æ€§é…ç½®
try:
    from object_attributes_config import (
        ANIMAL_CHARACTERISTICS, PLANT_CHARACTERISTICS, TOOL_CHARACTERISTICS, 
        ENVIRONMENT_TYPES, TARGET_TYPE_MAPPING, calculate_tool_effectiveness,
        get_best_tool_for_target, get_object_attributes, get_all_object_names
    )
    OBJECT_CONFIG_AVAILABLE = True
except ImportError:
    OBJECT_CONFIG_AVAILABLE = False
    logger.warning("Object attribute configuration file not found, will use default configuration")

@dataclass
class EOCATRExperience:
    """EOCATRç»éªŒæ•°æ®ç»“æ„"""
    environment: str
    object: str
    characteristics: str
    action: str
    tools: str
    result: str
    player_id: str
    timestamp: float
    success: bool = True
    metadata: Dict = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'environment': self.environment,
            'object': self.object,
            'characteristics': self.characteristics,
            'action': self.action,
            'tools': self.tools,
            'result': self.result,
            'player_id': self.player_id,
            'timestamp': self.timestamp,
            'success': self.success,
            'metadata': json.dumps(self.metadata)
        }
    
    def generate_hash(self) -> str:
        """ç”Ÿæˆç»éªŒå†…å®¹å“ˆå¸Œç”¨äºå»é‡"""
        # ä½¿ç”¨æ ¸å¿ƒå†…å®¹ç”Ÿæˆå“ˆå¸Œï¼Œæ’é™¤æ—¶é—´æˆ³å’Œç©å®¶ID
        content = (
            f"{self.environment}|{self.object}|{self.characteristics}|"
            f"{self.action}|{self.tools}|{self.result}"
        )
        return hashlib.md5(content.encode('utf-8')).hexdigest()

@dataclass
class Rule:
    """è§„å¾‹æ•°æ®ç»“æ„"""
    rule_id: str
    rule_type: str  # CN1, CN2
    conditions: Dict
    predictions: Dict
    confidence: float
    support_count: int
    contradiction_count: int
    created_time: float
    creator_id: str
    validation_status: str = 'pending'  # pending, validated, rejected
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'rule_id': self.rule_id,
            'rule_type': self.rule_type,
            'conditions': json.dumps(self.conditions),
            'predictions': json.dumps(self.predictions),
            'confidence': self.confidence,
            'support_count': self.support_count,
            'contradiction_count': self.contradiction_count,
            'created_time': self.created_time,
            'creator_id': self.creator_id,
            'validation_status': self.validation_status
        }
    
    def generate_hash(self) -> str:
        """ç”Ÿæˆè§„å¾‹å†…å®¹å“ˆå¸Œç”¨äºå»é‡"""
        content = f"{self.rule_type}|{json.dumps(self.conditions, sort_keys=True)}|{json.dumps(self.predictions, sort_keys=True)}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

@dataclass
class Decision:
    """å†³ç­–æ•°æ®ç»“æ„"""
    decision_id: str
    context: Dict  # å†³ç­–ä¸Šä¸‹æ–‡
    action: str
    confidence: float
    source: str  # 'decision_library', 'wbm_generated'
    success_count: int = 0
    failure_count: int = 0
    total_uses: int = 0
    created_time: float = field(default_factory=time.time)
    last_used: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'decision_id': self.decision_id,
            'context': json.dumps(self.context),
            'action': self.action,
            'confidence': self.confidence,
            'source': self.source,
            'success_count': self.success_count,
            'failure_count': self.failure_count,
            'total_uses': self.total_uses,
            'created_time': self.created_time,
            'last_used': self.last_used
        }
    
    def generate_hash(self) -> str:
        """ç”Ÿæˆå†³ç­–å†…å®¹å“ˆå¸Œ"""
        content = f"{json.dumps(self.context, sort_keys=True)}|{self.action}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.lock = threading.Lock()
    
    def get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path, check_same_thread=False)
        conn.row_factory = sqlite3.Row  # ä½¿ç»“æœå¯ä»¥æŒ‰åˆ—åè®¿é—®
        return conn
    
    def execute_query(self, query: str, params: tuple = ()) -> List[sqlite3.Row]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        with self.lock:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(query, params)
                return cursor.fetchall()
    
    def execute_update(self, query: str, params: tuple = ()) -> int:
        """æ‰§è¡Œæ›´æ–°æ“ä½œ"""
        with self.lock:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(query, params)
                conn.commit()
                return cursor.rowcount

class FiveLibrarySystem:
    """äº”åº“ç³»ç»Ÿæ ¸å¿ƒå®ç°"""
    
    def __init__(self, base_path: str = "five_libraries"):
        """
        åˆå§‹åŒ–äº”åº“ç³»ç»Ÿ
        
        Args:
            base_path: äº”åº“æ–‡ä»¶å­˜å‚¨åŸºç¡€è·¯å¾„
        """
        self.base_path = Path(base_path)
        self.base_path.mkdir(exist_ok=True)
        
        # äº”åº“æ•°æ®åº“è·¯å¾„
        self.db_paths = {
            'direct_experiences': self.base_path / "direct_experiences.db",
            'total_experiences': self.base_path / "total_experiences.db",
            'direct_rules': self.base_path / "direct_rules.db",
            'total_rules': self.base_path / "total_rules.db",
            'decisions': self.base_path / "decisions.db"
        }
        
        # æ•°æ®åº“ç®¡ç†å™¨
        self.db_managers = {
            name: DatabaseManager(str(path)) 
            for name, path in self.db_paths.items()
        }
        
        # ç¼“å­˜ç³»ç»Ÿ
        self.cache = {
            'experience_hashes': set(),
            'rule_hashes': set(),
            'decision_hashes': set(),
            'last_cache_update': 0
        }
        
        # âœ… æ–°å¢ï¼šåŒæ­¥çŠ¶æ€è·Ÿè¸ª
        self.sync_tracker = {
            'synced_experience_hashes': set(),  # å·²åŒæ­¥çš„ç»éªŒå“ˆå¸Œ
            'pending_sync_hashes': set(),       # å¾…åŒæ­¥çš„ç»éªŒå“ˆå¸Œ
            'last_sync_check': 0,               # ä¸Šæ¬¡åŒæ­¥æ£€æŸ¥æ—¶é—´
            'sync_batch_size': 100,  # æ€§èƒ½ä¼˜åŒ–: å¤§å¹…å¢åŠ æ‰¹é‡å¤§å°  # æ€§èƒ½ä¼˜åŒ–: å¢åŠ æ‰¹é‡å¤§å°
            'sync_interval': 300  # æ€§èƒ½ä¼˜åŒ–: å‡å°‘åŒæ­¥é¢‘ç‡ï¼ˆ5åˆ†é’Ÿï¼‰   # æ€§èƒ½ä¼˜åŒ–: å‡å°‘åŒæ­¥é¢‘ç‡ï¼ˆç§’ï¼‰
        }
        
        # å¯¹è±¡å±æ€§ç³»ç»Ÿ
        self.object_config_enabled = OBJECT_CONFIG_AVAILABLE
        if self.object_config_enabled:
            logger.info("Object attribute configuration system enabled")
            logger.info(f"Loaded {len(get_all_object_names())} object attribute configurations")
        else:
            logger.warning("Object attribute configuration system not enabled, using basic validation")
        
        # ç³»ç»Ÿé”
        self.system_lock = threading.Lock()
        
        # åˆå§‹åŒ–äº”åº“æ•°æ®åº“
        self._initialize_five_libraries()
        
        # âœ… æ–°å¢ï¼šåˆå§‹åŒ–åŒæ­¥çŠ¶æ€
        self._initialize_sync_tracker()
        
        # ğŸ”§ ä¼˜åŒ–çš„æ—¥å¿—è®°å½•å™¨
        try:
            from five_library_log_optimization import OptimizedSyncLogger
            self.sync_logger = OptimizedSyncLogger(
                aggregate_interval=30,  # 30ç§’èšåˆ
                max_individual_logs=3   # æ¯çª—å£æœ€å¤š3æ¡ä¸ªåˆ«æ—¥å¿—
            )
            logger.info("ğŸš€ Five library system log optimization enabled")
        except ImportError:
            self.sync_logger = None
            logger.info("âš ï¸ Log optimization module not found, using standard logging")
        
        logger.info(f"ğŸ›ï¸ Five library system initialization completed")
        logger.info(f"ğŸ“ Storage path: {self.base_path}")
        for name, path in self.db_paths.items():
            logger.info(f"   {name}: {path.name}")
    
    def _initialize_five_libraries(self):
        """åˆå§‹åŒ–äº”åº“æ•°æ®åº“ç»“æ„"""
        
        # 1. ç›´æ¥ç»éªŒåº“
        self._init_direct_experiences_db()
        
        # 2. æ€»ç»éªŒåº“
        self._init_total_experiences_db()
        
        # 3. ç›´æ¥è§„å¾‹åº“
        self._init_direct_rules_db()
        
        # 4. æ€»è§„å¾‹åº“
        self._init_total_rules_db()
        
        # 5. å†³ç­–åº“
        self._init_decisions_db()
        
        logger.info("âœ… Five library database structure initialization completed")
    
    def _init_direct_experiences_db(self):
        """åˆå§‹åŒ–ç›´æ¥ç»éªŒåº“"""
        db_manager = self.db_managers['direct_experiences']
        
        # åˆ›å»ºç›´æ¥ç»éªŒè¡¨
        db_manager.execute_update("""
            CREATE TABLE IF NOT EXISTS direct_experiences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content_hash TEXT UNIQUE NOT NULL,
                environment TEXT NOT NULL,
                object TEXT NOT NULL,
                characteristics TEXT NOT NULL,
                action TEXT NOT NULL,
                tools TEXT NOT NULL,
                result TEXT NOT NULL,
                player_id TEXT NOT NULL,
                timestamp REAL NOT NULL,
                success INTEGER NOT NULL,
                metadata TEXT,
                occurrence_count INTEGER DEFAULT 1,
                success_count INTEGER DEFAULT 0,
                first_discovered_by TEXT,
                first_discovered_time REAL,
                last_seen_time REAL,
                discoverers TEXT DEFAULT '[]',
                avg_success_rate REAL DEFAULT 0.0,
                created_time REAL DEFAULT (julianday('now')),
                synced_to_total INTEGER DEFAULT 0
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_hash ON direct_experiences(content_hash)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_player ON direct_experiences(player_id)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_action ON direct_experiences(action)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_sync ON direct_experiences(synced_to_total)")
    
    def _init_total_experiences_db(self):
        """åˆå§‹åŒ–æ€»ç»éªŒåº“"""
        db_manager = self.db_managers['total_experiences']
        
        # åˆ›å»ºæ€»ç»éªŒè¡¨
        db_manager.execute_update("""
            CREATE TABLE IF NOT EXISTS total_experiences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content_hash TEXT UNIQUE NOT NULL,
                environment TEXT NOT NULL,
                object TEXT NOT NULL,
                characteristics TEXT NOT NULL,
                action TEXT NOT NULL,
                tools TEXT NOT NULL,
                result TEXT NOT NULL,
                success INTEGER NOT NULL,
                occurrence_count INTEGER DEFAULT 1,
                success_count INTEGER DEFAULT 0,
                first_discovered_by TEXT,
                first_discovered_time REAL,
                last_seen_time REAL,
                discoverers TEXT,  -- JSON array of player_ids
                avg_success_rate REAL,
                confidence REAL DEFAULT 0.5,
                created_time REAL DEFAULT (julianday('now')),
                updated_time REAL DEFAULT (julianday('now'))
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_hash ON total_experiences(content_hash)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_action ON total_experiences(action)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_confidence ON total_experiences(confidence)")
    
    def _init_direct_rules_db(self):
        """åˆå§‹åŒ–ç›´æ¥è§„å¾‹åº“"""
        db_manager = self.db_managers['direct_rules']
        
        # åˆ›å»ºç›´æ¥è§„å¾‹è¡¨
        db_manager.execute_update("""
            CREATE TABLE IF NOT EXISTS direct_rules (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                rule_id TEXT UNIQUE NOT NULL,
                content_hash TEXT UNIQUE NOT NULL,
                rule_type TEXT NOT NULL,  -- CN1, CN2
                conditions TEXT NOT NULL,  -- JSON
                predictions TEXT NOT NULL,  -- JSON
                confidence REAL NOT NULL,
                support_count INTEGER DEFAULT 0,
                contradiction_count INTEGER DEFAULT 0,
                validation_count INTEGER DEFAULT 0,
                created_time REAL NOT NULL,
                creator_id TEXT NOT NULL,
                validation_status TEXT DEFAULT 'pending',
                synced_to_total INTEGER DEFAULT 0,
                last_sync_time REAL DEFAULT 0,
                last_validated REAL DEFAULT 0
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_rule_id ON direct_rules(rule_id)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_rule_hash ON direct_rules(content_hash)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_rule_type ON direct_rules(rule_type)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_rule_confidence ON direct_rules(confidence)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_direct_rule_sync ON direct_rules(synced_to_total)")
    
    def _init_total_rules_db(self):
        """åˆå§‹åŒ–æ€»è§„å¾‹åº“"""
        db_manager = self.db_managers['total_rules']
        
        # åˆ›å»ºæ€»è§„å¾‹è¡¨
        db_manager.execute_update("""
            CREATE TABLE IF NOT EXISTS total_rules (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                rule_id TEXT UNIQUE NOT NULL,
                content_hash TEXT UNIQUE NOT NULL,
                rule_type TEXT NOT NULL,  -- CN1, CN2
                conditions TEXT NOT NULL,  -- JSON
                predictions TEXT NOT NULL,  -- JSON
                confidence REAL NOT NULL,
                support_count INTEGER DEFAULT 0,
                contradiction_count INTEGER DEFAULT 0,
                validation_count INTEGER DEFAULT 0,
                occurrence_count INTEGER DEFAULT 1,
                discoverers TEXT DEFAULT '[]',  -- JSON array of player_ids
                validation_status TEXT DEFAULT 'pending',
                created_time REAL NOT NULL,
                last_updated REAL NOT NULL,
                last_validated REAL DEFAULT 0
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_rule_id ON total_rules(rule_id)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_rule_hash ON total_rules(content_hash)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_rule_type ON total_rules(rule_type)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_total_rule_confidence ON total_rules(confidence)")
    
    def _init_decisions_db(self):
        """åˆå§‹åŒ–å†³ç­–åº“"""
        db_manager = self.db_managers['decisions']
        
        # åˆ›å»ºå†³ç­–è¡¨
        db_manager.execute_update("""
            CREATE TABLE IF NOT EXISTS decisions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                decision_id TEXT UNIQUE NOT NULL,
                content_hash TEXT UNIQUE NOT NULL,
                context TEXT NOT NULL,  -- JSON
                action TEXT NOT NULL,
                confidence REAL NOT NULL,
                source TEXT NOT NULL,  -- 'decision_library', 'wbm_generated'
                success_count INTEGER DEFAULT 0,
                failure_count INTEGER DEFAULT 0,
                total_uses INTEGER DEFAULT 0,
                created_time REAL NOT NULL,
                last_used REAL NOT NULL,
                avg_success_rate REAL DEFAULT 0.0,
                emrs_score REAL DEFAULT 0.0,
                updated_time REAL DEFAULT (julianday('now'))
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_decision_id ON decisions(decision_id)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_decision_hash ON decisions(content_hash)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_decision_confidence ON decisions(confidence)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_decision_action ON decisions(action)")
        db_manager.execute_update("CREATE INDEX IF NOT EXISTS idx_decision_last_used ON decisions(last_used)")
    
    def get_system_statistics(self) -> Dict[str, Any]:
        """è·å–äº”åº“ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        try:
            # ç›´æ¥ç»éªŒåº“ç»Ÿè®¡
            result = self.db_managers['direct_experiences'].execute_query("SELECT COUNT(*) as count FROM direct_experiences")
            stats['direct_experiences'] = result[0]['count'] if result else 0
            
            # æ€»ç»éªŒåº“ç»Ÿè®¡
            result = self.db_managers['total_experiences'].execute_query("SELECT COUNT(*) as count FROM total_experiences")
            stats['total_experiences'] = result[0]['count'] if result else 0
            
            # ç›´æ¥è§„å¾‹åº“ç»Ÿè®¡
            result = self.db_managers['direct_rules'].execute_query("SELECT COUNT(*) as count FROM direct_rules")
            stats['direct_rules'] = result[0]['count'] if result else 0
            
            # æ€»è§„å¾‹åº“ç»Ÿè®¡
            result = self.db_managers['total_rules'].execute_query("SELECT COUNT(*) as count FROM total_rules")
            stats['total_rules'] = result[0]['count'] if result else 0
            
            # å†³ç­–åº“ç»Ÿè®¡
            result = self.db_managers['decisions'].execute_query("SELECT COUNT(*) as count FROM decisions")
            stats['decisions'] = result[0]['count'] if result else 0
            
            # ç¼“å­˜ç»Ÿè®¡
            stats['cache_experience_hashes'] = len(self.cache['experience_hashes'])
            stats['cache_rule_hashes'] = len(self.cache['rule_hashes'])
            stats['cache_decision_hashes'] = len(self.cache['decision_hashes'])
            
            # é«˜ç½®ä¿¡åº¦ç»Ÿè®¡
            result = self.db_managers['decisions'].execute_query("SELECT COUNT(*) as count FROM decisions WHERE confidence >= 0.7")
            stats['high_confidence_decisions'] = result[0]['count'] if result else 0
            
            result = self.db_managers['total_rules'].execute_query("SELECT COUNT(*) as count FROM total_rules WHERE confidence >= 0.6")
            stats['validated_rules'] = result[0]['count'] if result else 0
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        return stats
    
    def _update_cache(self):
        """æ›´æ–°ç¼“å­˜"""
        current_time = time.time()
        if current_time - self.cache['last_cache_update'] < 60:  # 1åˆ†é’Ÿå†…ä¸é‡å¤æ›´æ–°
            return
        
        try:
            # æ›´æ–°ç»éªŒå“ˆå¸Œç¼“å­˜
            result = self.db_managers['total_experiences'].execute_query("SELECT content_hash FROM total_experiences")
            self.cache['experience_hashes'] = {row['content_hash'] for row in result}
            
            # æ›´æ–°è§„å¾‹å“ˆå¸Œç¼“å­˜
            result = self.db_managers['total_rules'].execute_query("SELECT content_hash FROM total_rules")
            self.cache['rule_hashes'] = {row['content_hash'] for row in result}
            
            # æ›´æ–°å†³ç­–å“ˆå¸Œç¼“å­˜
            result = self.db_managers['decisions'].execute_query("SELECT content_hash FROM decisions")
            self.cache['decision_hashes'] = {row['content_hash'] for row in result}
            
            self.cache['last_cache_update'] = current_time
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç¼“å­˜å¤±è´¥: {str(e)}")

    # ==================== EOCATRç»éªŒå¤„ç†æ¨¡å— ====================
    
    def validate_eocatr_experience(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        éªŒè¯EOCATRç»éªŒçš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§
        
        Args:
            experience: EOCATRç»éªŒå¯¹è±¡
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'normalized_experience': None
        }
        
        try:
            # 1. å¿…å¡«å­—æ®µæ£€æŸ¥
            required_fields = ['environment', 'object', 'characteristics', 'action', 'tools', 'result', 'player_id']
            for field in required_fields:
                value = getattr(experience, field, None)
                if not value or (isinstance(value, str) and not value.strip()):
                    validation_result['errors'].append(f"å¿…å¡«å­—æ®µ '{field}' ä¸ºç©ºæˆ–æ— æ•ˆ")
                    validation_result['is_valid'] = False
            
            # 2. æ•°æ®ç±»å‹æ£€æŸ¥
            if not isinstance(experience.timestamp, (int, float)) or experience.timestamp <= 0:
                validation_result['errors'].append("timestamp å¿…é¡»æ˜¯æ­£æ•°")
                validation_result['is_valid'] = False
            
            if not isinstance(experience.success, bool):
                validation_result['errors'].append("success å¿…é¡»æ˜¯å¸ƒå°”å€¼")
                validation_result['is_valid'] = False
            
            if not isinstance(experience.metadata, dict):
                validation_result['errors'].append("metadata å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
                validation_result['is_valid'] = False
            
            # 3. å­—æ®µé•¿åº¦æ£€æŸ¥
            max_lengths = {
                'environment': 100,
                'object': 100, 
                'characteristics': 200,
                'action': 100,
                'tools': 100,
                'result': 200,
                'player_id': 50
            }
            
            for field, max_len in max_lengths.items():
                value = getattr(experience, field, '')
                if len(str(value)) > max_len:
                    validation_result['warnings'].append(f"å­—æ®µ '{field}' é•¿åº¦è¶…è¿‡å»ºè®®å€¼ {max_len}")
            
            # 4. å†…å®¹è§„èŒƒåŒ–
            if validation_result['is_valid']:
                normalized_exp = self._normalize_eocatr_experience(experience)
                validation_result['normalized_experience'] = normalized_exp
            
            # 5. ä¸šåŠ¡é€»è¾‘æ£€æŸ¥
            if validation_result['is_valid']:
                business_check = self._validate_business_logic(experience)
                validation_result['warnings'].extend(business_check.get('warnings', []))
                if business_check.get('errors'):
                    validation_result['errors'].extend(business_check['errors'])
                    validation_result['is_valid'] = False
            
        except Exception as e:
            validation_result['is_valid'] = False
            validation_result['errors'].append(f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        
        return validation_result
    
    def _normalize_eocatr_experience(self, experience: EOCATRExperience) -> EOCATRExperience:
        """
        è§„èŒƒåŒ–EOCATRç»éªŒæ•°æ®
        
        Args:
            experience: åŸå§‹ç»éªŒå¯¹è±¡
            
        Returns:
            è§„èŒƒåŒ–åçš„ç»éªŒå¯¹è±¡
        """
        # åˆ›å»ºè§„èŒƒåŒ–çš„ç»éªŒå‰¯æœ¬
        normalized = EOCATRExperience(
            environment=str(experience.environment).strip().lower(),
            object=str(experience.object).strip().lower(),
            characteristics=str(experience.characteristics).strip().lower(),
            action=str(experience.action).strip().lower(),
            tools=str(experience.tools).strip().lower(),
            result=str(experience.result).strip(),  # resultä¿æŒåŸå§‹å¤§å°å†™
            player_id=str(experience.player_id).strip(),
            timestamp=float(experience.timestamp),
            success=bool(experience.success),
            metadata=dict(experience.metadata) if experience.metadata else {}
        )
        
        # æ·»åŠ è§„èŒƒåŒ–æ—¶é—´æˆ³
        normalized.metadata['normalized_time'] = time.time()
        normalized.metadata['original_timestamp'] = experience.timestamp
        
        return normalized
    
    def _validate_business_logic(self, experience: EOCATRExperience) -> Dict[str, List[str]]:
        """
        éªŒè¯ä¸šåŠ¡é€»è¾‘è§„åˆ™
        
        Args:
            experience: ç»éªŒå¯¹è±¡
            
        Returns:
            åŒ…å«errorså’Œwarningsçš„å­—å…¸
        """
        result = {'errors': [], 'warnings': []}
        
        # 1. ç¯å¢ƒ-å¯¹è±¡ç»„åˆåˆç†æ€§æ£€æŸ¥
        valid_combinations = {
            'forest': ['tree', 'strawberry', 'mushroom', 'animal', 'water'],
            'cave': ['crystal', 'ore', 'bat', 'treasure'],
            'river': ['fish', 'water', 'stone'],
            'mountain': ['ore', 'crystal', 'eagle', 'snow']
        }
        
        env = str(experience.environment).lower()
        obj = str(experience.object).lower()
        
        if env in valid_combinations and obj not in valid_combinations[env]:
            result['warnings'].append(f"ç¯å¢ƒ '{env}' ä¸­å‡ºç° '{obj}' å¯èƒ½ä¸å¸¸è§")
        
        # 2. è¡ŒåŠ¨-å·¥å…·ç»„åˆæ£€æŸ¥
        action_tool_pairs = {
            'collect': ['basket', 'bag', 'hands'],
            'attack': ['sword', 'bow', 'magic', 'hands'],
            'explore': ['torch', 'map', 'compass', 'none'],
            'craft': ['hammer', 'anvil', 'workbench', 'hands']
        }
        
        action = str(experience.action).lower()
        tool = str(experience.tools).lower()
        
        if action in action_tool_pairs and tool not in action_tool_pairs[action]:
            result['warnings'].append(f"è¡ŒåŠ¨ '{action}' ä½¿ç”¨å·¥å…· '{tool}' å¯èƒ½ä¸åˆé€‚")
        
        # 3. ç»“æœåˆç†æ€§æ£€æŸ¥
        if experience.success:
            if 'fail' in str(experience.result).lower() or 'error' in str(experience.result).lower():
                result['warnings'].append("æˆåŠŸæ ‡è®°ä¸ºTrueä½†ç»“æœæè¿°åŒ…å«å¤±è´¥ä¿¡æ¯")
        else:
            if 'success' in str(experience.result).lower():
                result['warnings'].append("æˆåŠŸæ ‡è®°ä¸ºFalseä½†ç»“æœæè¿°åŒ…å«æˆåŠŸä¿¡æ¯")
        
        # 4. æ—¶é—´æˆ³åˆç†æ€§æ£€æŸ¥
        current_time = time.time()
        if experience.timestamp > current_time + 3600:  # æœªæ¥1å°æ—¶ä»¥ä¸Š
            result['errors'].append("æ—¶é—´æˆ³ä¸èƒ½æ˜¯æœªæ¥æ—¶é—´")
        elif experience.timestamp < current_time - 86400 * 365:  # 1å¹´ä»¥å‰
            result['warnings'].append("æ—¶é—´æˆ³è¿‡äºä¹…è¿œ")
        
        return result
    
    def check_experience_duplication(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        æ£€æŸ¥ç»éªŒæ˜¯å¦é‡å¤
        
        Args:
            experience: ç»éªŒå¯¹è±¡
            
        Returns:
            å»é‡æ£€æŸ¥ç»“æœ
        """
        duplication_result = {
            'is_duplicate': False,
            'duplicate_source': None,  # 'direct', 'total', 'cache'
            'existing_record': None,
            'content_hash': None,
            'similarity_score': 0.0
        }
        
        try:
            # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
            content_hash = experience.generate_hash()
            duplication_result['content_hash'] = content_hash
            
            # 1. é¦–å…ˆæ£€æŸ¥ç¼“å­˜
            self._update_cache()
            if content_hash in self.cache['experience_hashes']:
                duplication_result['is_duplicate'] = True
                duplication_result['duplicate_source'] = 'cache'
                return duplication_result
            
            # 2. æ£€æŸ¥æ€»ç»éªŒåº“
            total_result = self.db_managers['total_experiences'].execute_query(
                "SELECT * FROM total_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if total_result:
                duplication_result['is_duplicate'] = True
                duplication_result['duplicate_source'] = 'total'
                duplication_result['existing_record'] = dict(total_result[0])
                return duplication_result
            
            # 3. æ£€æŸ¥ç›´æ¥ç»éªŒåº“
            direct_result = self.db_managers['direct_experiences'].execute_query(
                "SELECT * FROM direct_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if direct_result:
                duplication_result['is_duplicate'] = True
                duplication_result['duplicate_source'] = 'direct'
                duplication_result['existing_record'] = dict(direct_result[0])
                return duplication_result
            
            # 4. æ¨¡ç³Šç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
            similarity_check = self._check_experience_similarity(experience)
            duplication_result['similarity_score'] = similarity_check['max_similarity']
            
            if similarity_check['max_similarity'] > 0.9:  # 90%ç›¸ä¼¼åº¦é˜ˆå€¼
                duplication_result['is_duplicate'] = True
                duplication_result['duplicate_source'] = 'similarity'
                duplication_result['existing_record'] = similarity_check['most_similar_record']
            
        except Exception as e:
            logger.error(f"âŒ å»é‡æ£€æŸ¥å¤±è´¥: {str(e)}")
        
        return duplication_result
    
    def _check_experience_similarity(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        æ£€æŸ¥ç»éªŒç›¸ä¼¼åº¦
        
        Args:
            experience: ç»éªŒå¯¹è±¡
            
        Returns:
            ç›¸ä¼¼åº¦æ£€æŸ¥ç»“æœ
        """
        similarity_result = {
            'max_similarity': 0.0,
            'most_similar_record': None,
            'similar_records': []
        }
        
        try:
            # æŸ¥è¯¢ç›¸åŒactionçš„ç»éªŒè¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒ
            similar_experiences = self.db_managers['total_experiences'].execute_query(
                "SELECT * FROM total_experiences WHERE action = ? LIMIT 50", 
                (experience.action,)
            )
            
            for record in similar_experiences:
                similarity = self._calculate_experience_similarity(experience, record)
                
                if similarity > similarity_result['max_similarity']:
                    similarity_result['max_similarity'] = similarity
                    similarity_result['most_similar_record'] = dict(record)
                
                if similarity > 0.7:  # 70%ä»¥ä¸Šç›¸ä¼¼åº¦è®°å½•
                    similarity_result['similar_records'].append({
                        'record': dict(record),
                        'similarity': similarity
                    })
        
        except Exception as e:
            logger.error(f"âŒ ç›¸ä¼¼åº¦æ£€æŸ¥å¤±è´¥: {str(e)}")
        
        return similarity_result
    
    def _calculate_experience_similarity(self, exp1: EOCATRExperience, exp2_record) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªç»éªŒçš„ç›¸ä¼¼åº¦
        
        Args:
            exp1: ç»éªŒå¯¹è±¡1
            exp2_record: ç»éªŒè®°å½•2ï¼ˆæ•°æ®åº“è®°å½•ï¼Œå¯èƒ½æ˜¯sqlite3.Rowæˆ–dictï¼‰
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0-1.0)
        """
        try:
            # å­—æ®µæƒé‡
            field_weights = {
                'environment': 0.2,
                'object': 0.2,
                'characteristics': 0.15,
                'action': 0.25,
                'tools': 0.1,
                'result': 0.1
            }
            
            total_similarity = 0.0
            
            for field, weight in field_weights.items():
                val1 = str(getattr(exp1, field, '')).lower().strip()
                
                # å…¼å®¹sqlite3.Rowå’Œdictä¸¤ç§ç±»å‹
                if hasattr(exp2_record, 'keys'):  # dict-like
                    val2 = str(exp2_record.get(field, '') if hasattr(exp2_record, 'get') else exp2_record[field]).lower().strip()
                else:  # sqlite3.Row
                    val2 = str(exp2_record[field] if field in exp2_record.keys() else '').lower().strip()
                
                if val1 == val2:
                    field_similarity = 1.0
                elif val1 in val2 or val2 in val1:
                    field_similarity = 0.7
                else:
                    field_similarity = 0.0
                
                total_similarity += field_similarity * weight
            
            return total_similarity
            
        except Exception as e:
            logger.error(f"âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return 0.0
    
    def format_experience_for_storage(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–ç»éªŒæ•°æ®ç”¨äºå­˜å‚¨
        
        Args:
            experience: ç»éªŒå¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–åçš„å­˜å‚¨æ•°æ®
        """
        try:
            # åŸºç¡€æ•°æ®è½¬æ¢
            storage_data = experience.to_dict()
            
            # æ·»åŠ å­˜å‚¨ç›¸å…³å­—æ®µ
            storage_data['content_hash'] = experience.generate_hash()
            storage_data['storage_timestamp'] = time.time()
            
            # å¤„ç†metadata
            if isinstance(storage_data['metadata'], str):
                # å¦‚æœå·²ç»æ˜¯JSONå­—ç¬¦ä¸²ï¼ŒéªŒè¯å…¶æœ‰æ•ˆæ€§
                try:
                    json.loads(storage_data['metadata'])
                except json.JSONDecodeError:
                    storage_data['metadata'] = json.dumps({})
            else:
                storage_data['metadata'] = json.dumps(storage_data['metadata'])
            
            # æ•°æ®ç±»å‹è½¬æ¢
            storage_data['success'] = int(storage_data['success'])
            storage_data['timestamp'] = float(storage_data['timestamp'])
            
            return storage_data
            
        except Exception as e:
            logger.error(f"âŒ ç»éªŒæ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            return {}

    # ==================== å»é‡åŒæ­¥æ¨¡å— ====================
    
    def add_experience_to_direct_library(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        æ·»åŠ ç»éªŒåˆ°ç›´æ¥ç»éªŒåº“
        
        Args:
            experience: EOCATRç»éªŒå¯¹è±¡
            
        Returns:
            æ·»åŠ ç»“æœå­—å…¸
        """
        add_result = {
            'success': False,
            'action': None,  # 'added', 'updated', 'rejected'
            'reason': None,
            'experience_id': None,
            'content_hash': None,
            'sync_required': False
        }
        
        try:
            # 1. éªŒè¯ç»éªŒ
            validation_result = self.validate_eocatr_experience(experience)
            if not validation_result['is_valid']:
                add_result['action'] = 'rejected'
                add_result['reason'] = f"éªŒè¯å¤±è´¥: {', '.join(validation_result['errors'])}"
                # å³ä½¿éªŒè¯å¤±è´¥ï¼Œä¹Ÿå°è¯•ç”Ÿæˆcontent_hashç”¨äºè°ƒè¯•
                try:
                    add_result['content_hash'] = experience.generate_hash()
                except:
                    add_result['content_hash'] = None
                return add_result
            
            # ä½¿ç”¨è§„èŒƒåŒ–åçš„ç»éªŒ
            normalized_exp = validation_result['normalized_experience']
            content_hash = normalized_exp.generate_hash()
            add_result['content_hash'] = content_hash
            
            # 2. æ£€æŸ¥ç›´æ¥ç»éªŒåº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            existing_direct = self.db_managers['direct_experiences'].execute_query(
                "SELECT * FROM direct_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if existing_direct:
                # æ›´æ–°ç°æœ‰è®°å½•
                record_id = existing_direct[0]['id']
                self.db_managers['direct_experiences'].execute_update("""
                    UPDATE direct_experiences 
                    SET occurrence_count = occurrence_count + 1,
                        success_count = success_count + ?,
                        last_seen_time = ?,
                        discoverers = CASE 
                            WHEN discoverers LIKE '%"' || ? || '"%' THEN discoverers
                            ELSE json_insert(discoverers, '$[#]', ?)
                        END,
                        avg_success_rate = CAST(success_count + ? AS FLOAT) / (occurrence_count + 1)
                    WHERE id = ?
                """, (
                    int(normalized_exp.success), normalized_exp.timestamp, 
                    normalized_exp.player_id, normalized_exp.player_id,
                    int(normalized_exp.success), record_id
                ))
                
                add_result['success'] = True
                add_result['action'] = 'updated'
                add_result['experience_id'] = record_id
                add_result['sync_required'] = True
                
            else:
                # æ·»åŠ æ–°è®°å½•
                storage_data = self.format_experience_for_storage(normalized_exp)
                
                result = self.db_managers['direct_experiences'].execute_update("""
                    INSERT INTO direct_experiences 
                    (content_hash, environment, object, characteristics, action, tools, result,
                     player_id, timestamp, success, metadata, occurrence_count, success_count,
                     first_discovered_by, first_discovered_time, last_seen_time, discoverers, avg_success_rate)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    storage_data['content_hash'],
                    storage_data['environment'], storage_data['object'], storage_data['characteristics'],
                    storage_data['action'], storage_data['tools'], storage_data['result'],
                    storage_data['player_id'], storage_data['timestamp'], storage_data['success'],
                    storage_data['metadata'], 1, int(normalized_exp.success),
                    storage_data['player_id'], storage_data['timestamp'], storage_data['timestamp'],
                    f'["{storage_data["player_id"]}"]', float(normalized_exp.success)
                ))
                
                add_result['success'] = True
                add_result['action'] = 'added'
                add_result['experience_id'] = result
                add_result['sync_required'] = True
            
            # 3. æ›´æ–°ç¼“å­˜
            self.cache['experience_hashes'].add(content_hash)
            
            # ğŸ”§ ä¼˜åŒ–: é™ä½é‡å¤æ—¥å¿—çš„çº§åˆ«
            if add_result['action'] == 'added':
                logger.info(f"âœ¨ New experience added to direct library: {content_hash[:16]}...")
            else:
                logger.debug(f"ğŸ”„ Experience updated: {content_hash[:16]}... ({add_result.get('occurrence_count', 1)}th time)")
            
        except Exception as e:
            add_result['action'] = 'rejected'
            add_result['reason'] = f"æ·»åŠ å¤±è´¥: {str(e)}"
            # ç¡®ä¿content_hashå­—æ®µå­˜åœ¨ï¼Œå³ä½¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹
            if 'content_hash' not in add_result:
                try:
                    add_result['content_hash'] = normalized_exp.generate_hash() if 'normalized_exp' in locals() else None
                except:
                    add_result['content_hash'] = None
            logger.error(f"âŒ æ·»åŠ ç»éªŒåˆ°ç›´æ¥åº“å¤±è´¥: {str(e)}")
        
        # âœ… ä¿®æ”¹ï¼šæ™ºèƒ½åŒæ­¥æœºåˆ¶
        if add_result['success'] and add_result.get('content_hash'):
            self._smart_sync_experience(add_result['content_hash'], add_result['action'])

        return add_result
    
    def sync_experience_to_total_library(self, content_hash: str) -> Dict[str, Any]:
        """
        å°†ç»éªŒä»ç›´æ¥ç»éªŒåº“åŒæ­¥åˆ°æ€»ç»éªŒåº“
        
        Args:
            content_hash: ç»éªŒå†…å®¹å“ˆå¸Œ
            
        Returns:
            åŒæ­¥ç»“æœå­—å…¸
        """
        sync_result = {
            'success': False,
            'action': None,  # 'merged', 'updated', 'created', 'skipped'
            'reason': None,
            'total_occurrence_count': 0,
            'total_success_count': 0,
            'discoverer_count': 0
        }
        
        try:
            # 1. è·å–ç›´æ¥ç»éªŒåº“ä¸­çš„è®°å½•
            direct_records = self.db_managers['direct_experiences'].execute_query(
                "SELECT * FROM direct_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if not direct_records:
                sync_result['action'] = 'skipped'
                sync_result['reason'] = 'ç›´æ¥ç»éªŒåº“ä¸­æœªæ‰¾åˆ°è®°å½•'
                return sync_result
            
            direct_record = direct_records[0]
            
            # 2. æ£€æŸ¥æ€»ç»éªŒåº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            total_records = self.db_managers['total_experiences'].execute_query(
                "SELECT * FROM total_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if total_records:
                # åˆå¹¶åˆ°ç°æœ‰è®°å½•
                total_record = total_records[0]
                
                # è§£æå‘ç°è€…åˆ—è¡¨
                try:
                    direct_discoverers = json.loads(direct_record['discoverers'])
                    total_discoverers = json.loads(total_record['discoverers'])
                except (json.JSONDecodeError, TypeError):
                    direct_discoverers = [direct_record['first_discovered_by']]
                    total_discoverers = [total_record['first_discovered_by']]
                
                # åˆå¹¶å‘ç°è€…åˆ—è¡¨
                merged_discoverers = list(set(direct_discoverers + total_discoverers))
                
                # è®¡ç®—åˆå¹¶åçš„ç»Ÿè®¡æ•°æ®
                new_occurrence_count = total_record['occurrence_count'] + direct_record['occurrence_count']
                new_success_count = total_record['success_count'] + direct_record['success_count']
                new_avg_success_rate = new_success_count / new_occurrence_count if new_occurrence_count > 0 else 0.0
                
                # æ›´æ–°æ€»ç»éªŒåº“è®°å½•
                self.db_managers['total_experiences'].execute_update("""
                    UPDATE total_experiences 
                    SET occurrence_count = ?,
                        success_count = ?,
                        last_seen_time = CASE 
                            WHEN ? > last_seen_time THEN ? 
                            ELSE last_seen_time 
                        END,
                        discoverers = ?,
                        avg_success_rate = ?,
                        confidence = CASE 
                            WHEN ? >= 10 THEN 0.9
                            WHEN ? >= 5 THEN 0.8
                            WHEN ? >= 3 THEN 0.7
                            ELSE 0.6
                        END
                    WHERE content_hash = ?
                """, (
                    new_occurrence_count, new_success_count,
                    direct_record['last_seen_time'], direct_record['last_seen_time'],
                    json.dumps(merged_discoverers), new_avg_success_rate,
                    new_occurrence_count, new_occurrence_count, new_occurrence_count,
                    content_hash
                ))
                
                sync_result['action'] = 'merged'
                sync_result['total_occurrence_count'] = new_occurrence_count
                sync_result['total_success_count'] = new_success_count
                sync_result['discoverer_count'] = len(merged_discoverers)
                
            else:
                # åˆ›å»ºæ–°çš„æ€»ç»éªŒåº“è®°å½•
                confidence = 0.9 if direct_record['occurrence_count'] >= 10 else \
                           0.8 if direct_record['occurrence_count'] >= 5 else \
                           0.7 if direct_record['occurrence_count'] >= 3 else 0.6
                
                self.db_managers['total_experiences'].execute_update("""
                    INSERT INTO total_experiences 
                    (content_hash, environment, object, characteristics, action, tools, result,
                     success, occurrence_count, success_count, first_discovered_by, 
                     first_discovered_time, last_seen_time, discoverers, avg_success_rate, confidence)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    direct_record['content_hash'],
                    direct_record['environment'], direct_record['object'], direct_record['characteristics'],
                    direct_record['action'], direct_record['tools'], direct_record['result'],
                    direct_record['success'], direct_record['occurrence_count'], direct_record['success_count'],
                    direct_record['first_discovered_by'], direct_record['first_discovered_time'],
                    direct_record['last_seen_time'], direct_record['discoverers'],
                    direct_record['avg_success_rate'], confidence
                ))
                
                sync_result['action'] = 'created'
                sync_result['total_occurrence_count'] = direct_record['occurrence_count']
                sync_result['total_success_count'] = direct_record['success_count']
                
                # è§£æå‘ç°è€…æ•°é‡
                try:
                    discoverers = json.loads(direct_record['discoverers'])
                    sync_result['discoverer_count'] = len(discoverers)
                except (json.JSONDecodeError, TypeError):
                    sync_result['discoverer_count'] = 1
            
            sync_result['success'] = True
            
            # ğŸ”§ ä¼˜åŒ–: ä½¿ç”¨æ™ºèƒ½æ—¥å¿—è®°å½•
            if hasattr(self, 'sync_logger'):
                self.sync_logger.log_sync_result(sync_result, content_hash)
            else:
                # é™çº§å¤„ç†ï¼šåªè®°å½•é‡è¦ä¿¡æ¯
                if sync_result['action'] in ['failed', 'created']:
                    logger.info(f"âœ… Experience sync: {sync_result['action']} - {content_hash[:16]}...")
                else:
                    logger.debug(f"âœ… Experience sync: {sync_result['action']} - {content_hash[:16]}...")
            
        except Exception as e:
            sync_result['action'] = 'failed'
            sync_result['reason'] = f"åŒæ­¥å¤±è´¥: {str(e)}"
            logger.error(f"âŒ ç»éªŒåŒæ­¥å¤±è´¥: {str(e)}")
        
        return sync_result
    
    def batch_sync_experiences(self, limit: int = 100) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥ç›´æ¥ç»éªŒåº“åˆ°æ€»ç»éªŒåº“
        
        Args:
            limit: æ¯æ¬¡åŒæ­¥çš„æœ€å¤§è®°å½•æ•°
            
        Returns:
            æ‰¹é‡åŒæ­¥ç»“æœ
        """
        batch_result = {
            'success': False,
            'total_processed': 0,
            'successful_syncs': 0,
            'failed_syncs': 0,
            'sync_details': [],
            'summary': {}
        }
        
        try:
            # è·å–éœ€è¦åŒæ­¥çš„ç»éªŒï¼ˆæŒ‰æœ€åæ›´æ–°æ—¶é—´æ’åºï¼‰
            pending_experiences = self.db_managers['direct_experiences'].execute_query("""
                SELECT content_hash, last_seen_time 
                FROM direct_experiences 
                ORDER BY last_seen_time DESC 
                LIMIT ?
            """, (limit,))
            
            batch_result['total_processed'] = len(pending_experiences)
            
            # ç»Ÿè®¡è®¡æ•°å™¨
            action_counts = {'merged': 0, 'created': 0, 'skipped': 0, 'failed': 0}
            
            for record in pending_experiences:
                content_hash = record['content_hash']
                sync_result = self.sync_experience_to_total_library(content_hash)
                
                if sync_result['success']:
                    batch_result['successful_syncs'] += 1
                    action_counts[sync_result['action']] += 1
                else:
                    batch_result['failed_syncs'] += 1
                    action_counts['failed'] += 1
                
                batch_result['sync_details'].append({
                    'content_hash': content_hash[:16] + '...',
                    'action': sync_result['action'],
                    'success': sync_result['success'],
                    'reason': sync_result.get('reason'),
                    'occurrence_count': sync_result.get('total_occurrence_count', 0),
                    'discoverer_count': sync_result.get('discoverer_count', 0)
                })
            
            batch_result['summary'] = action_counts
            batch_result['success'] = batch_result['failed_syncs'] == 0
            
            logger.info(f"ğŸ“Š Batch sync completed: {batch_result['successful_syncs']}/{batch_result['total_processed']} successful")
            
        except Exception as e:
            batch_result['reason'] = f"æ‰¹é‡åŒæ­¥å¤±è´¥: {str(e)}"
            logger.error(f"âŒ æ‰¹é‡åŒæ­¥å¤±è´¥: {str(e)}")
        
        return batch_result
    
    def resolve_sync_conflicts(self, content_hash: str) -> Dict[str, Any]:
        """
        è§£å†³åŒæ­¥å†²çª
        
        Args:
            content_hash: å†²çªçš„ç»éªŒå“ˆå¸Œ
            
        Returns:
            å†²çªè§£å†³ç»“æœ
        """
        conflict_result = {
            'success': False,
            'conflict_type': None,  # 'data_mismatch', 'timestamp_conflict', 'discoverer_conflict'
            'resolution_action': None,  # 'merge_favor_total', 'merge_favor_direct', 'manual_review'
            'details': {}
        }
        
        try:
            # è·å–ç›´æ¥åº“å’Œæ€»åº“çš„è®°å½•
            direct_record = self.db_managers['direct_experiences'].execute_query(
                "SELECT * FROM direct_experiences WHERE content_hash = ?", (content_hash,)
            )
            total_record = self.db_managers['total_experiences'].execute_query(
                "SELECT * FROM total_experiences WHERE content_hash = ?", (content_hash,)
            )
            
            if not direct_record or not total_record:
                conflict_result['conflict_type'] = 'missing_record'
                conflict_result['resolution_action'] = 'manual_review'
                return conflict_result
            
            direct_rec = direct_record[0]
            total_rec = total_record[0]
            
            # æ£€æŸ¥æ•°æ®ä¸åŒ¹é…
            core_fields = ['environment', 'object', 'characteristics', 'action', 'tools', 'result']
            data_mismatches = []
            
            for field in core_fields:
                if direct_rec[field] != total_rec[field]:
                    data_mismatches.append({
                        'field': field,
                        'direct_value': direct_rec[field],
                        'total_value': total_rec[field]
                    })
            
            if data_mismatches:
                conflict_result['conflict_type'] = 'data_mismatch'
                conflict_result['details']['mismatches'] = data_mismatches
                conflict_result['resolution_action'] = 'manual_review'
                return conflict_result
            
            # æ£€æŸ¥æ—¶é—´æˆ³å†²çª
            if direct_rec['first_discovered_time'] < total_rec['first_discovered_time']:
                conflict_result['conflict_type'] = 'timestamp_conflict'
                conflict_result['resolution_action'] = 'merge_favor_direct'
                conflict_result['details']['time_diff'] = total_rec['first_discovered_time'] - direct_rec['first_discovered_time']
            
            # æ£€æŸ¥å‘ç°è€…å†²çª
            try:
                direct_discoverers = set(json.loads(direct_rec['discoverers']))
                total_discoverers = set(json.loads(total_rec['discoverers']))
                
                if direct_discoverers != total_discoverers:
                    conflict_result['conflict_type'] = 'discoverer_conflict'
                    conflict_result['resolution_action'] = 'merge_favor_total'
                    conflict_result['details']['direct_discoverers'] = list(direct_discoverers)
                    conflict_result['details']['total_discoverers'] = list(total_discoverers)
                    conflict_result['details']['unique_to_direct'] = list(direct_discoverers - total_discoverers)
                    conflict_result['details']['unique_to_total'] = list(total_discoverers - direct_discoverers)
            
            except (json.JSONDecodeError, TypeError):
                conflict_result['conflict_type'] = 'discoverer_format_error'
                conflict_result['resolution_action'] = 'manual_review'
            
            # å¦‚æœæ²¡æœ‰å‘ç°å†²çªï¼Œæ ‡è®°ä¸ºæˆåŠŸ
            if not conflict_result['conflict_type']:
                conflict_result['success'] = True
                conflict_result['resolution_action'] = 'no_conflict'
            
        except Exception as e:
            conflict_result['conflict_type'] = 'resolution_error'
            conflict_result['details']['error'] = str(e)
            logger.error(f"âŒ å†²çªè§£å†³å¤±è´¥: {str(e)}")
        
        return conflict_result
    
    def get_sync_statistics(self) -> Dict[str, Any]:
        """
        è·å–åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒæ­¥ç»Ÿè®¡æ•°æ®
        """
        stats = {
            'direct_library': {},
            'total_library': {},
            'sync_status': {},
            'performance_metrics': {}
        }
        
        try:
            # ç›´æ¥ç»éªŒåº“ç»Ÿè®¡
            direct_stats = self.db_managers['direct_experiences'].execute_query("""
                SELECT 
                    COUNT(*) as total_experiences,
                    SUM(occurrence_count) as total_occurrences,
                    SUM(success_count) as total_successes,
                    AVG(avg_success_rate) as avg_success_rate,
                    COUNT(DISTINCT first_discovered_by) as unique_discoverers,
                    MIN(first_discovered_time) as earliest_discovery,
                    MAX(last_seen_time) as latest_activity
                FROM direct_experiences
            """)[0]
            
            stats['direct_library'] = dict(direct_stats)
            
            # æ€»ç»éªŒåº“ç»Ÿè®¡
            total_stats = self.db_managers['total_experiences'].execute_query("""
                SELECT 
                    COUNT(*) as total_experiences,
                    SUM(occurrence_count) as total_occurrences,
                    SUM(success_count) as total_successes,
                    AVG(avg_success_rate) as avg_success_rate,
                    AVG(confidence) as avg_confidence,
                    COUNT(DISTINCT first_discovered_by) as unique_discoverers,
                    MIN(first_discovered_time) as earliest_discovery,
                    MAX(last_seen_time) as latest_activity
                FROM total_experiences
            """)[0]
            
            stats['total_library'] = dict(total_stats)
            
            # åŒæ­¥çŠ¶æ€åˆ†æ
            # æ£€æŸ¥æœ‰å¤šå°‘ç›´æ¥åº“è®°å½•è¿˜æœªåœ¨æ€»åº“ä¸­
            try:
                unsynced_count = self.db_managers['direct_experiences'].execute_query("""
                    SELECT COUNT(*) as count
                    FROM direct_experiences d
                    WHERE d.content_hash NOT IN (
                        SELECT content_hash FROM total_experiences
                    )
                """)[0]['count']
            except Exception:
                # å¦‚æœè·¨åº“æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ–¹æ³•
                direct_hashes = set(row['content_hash'] for row in self.db_managers['direct_experiences'].execute_query(
                    "SELECT content_hash FROM direct_experiences"
                ))
                total_hashes = set(row['content_hash'] for row in self.db_managers['total_experiences'].execute_query(
                    "SELECT content_hash FROM total_experiences"
                ))
                unsynced_count = len(direct_hashes - total_hashes)
            
            stats['sync_status'] = {
                'unsynced_experiences': unsynced_count,
                'sync_coverage': 1.0 - (unsynced_count / max(stats['direct_library']['total_experiences'], 1)),
                'needs_sync': unsynced_count > 0
            }
            
            # æ€§èƒ½æŒ‡æ ‡
            stats['performance_metrics'] = {
                'direct_to_total_ratio': stats['direct_library']['total_experiences'] / max(stats['total_library']['total_experiences'], 1),
                'occurrence_efficiency': stats['total_library']['total_occurrences'] / max(stats['direct_library']['total_occurrences'], 1),
                'discovery_consolidation': stats['total_library']['unique_discoverers'] / max(stats['direct_library']['unique_discoverers'], 1)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–åŒæ­¥ç»Ÿè®¡å¤±è´¥: {str(e)}")
            stats['error'] = str(e)
        
        return stats

    # ==================== BPMæ€’æ”¾æ¨¡å— ====================
    
    def generate_candidate_rules_from_experiences(self, min_support: int = 3, min_confidence: float = 0.6) -> Dict[str, Any]:
        """
        ä»æ€»ç»éªŒåº“ç”Ÿæˆå€™é€‰è§„å¾‹
        
        Args:
            min_support: æœ€å°æ”¯æŒåº¦ï¼ˆç»éªŒå‡ºç°æ¬¡æ•°ï¼‰
            min_confidence: æœ€å°ç½®ä¿¡åº¦
            
        Returns:
            è§„å¾‹ç”Ÿæˆç»“æœ
        """
        generation_result = {
            'success': False,
            'cn1_rules_generated': 0,
            'cn2_rules_generated': 0,
            'total_rules_generated': 0,
            'processing_time': 0.0,
            'rule_details': [],
            'statistics': {}
        }
        
        start_time = time.time()
        
        try:
            # è·å–é«˜è´¨é‡ç»éªŒæ•°æ®
            high_quality_experiences = self.db_managers['total_experiences'].execute_query("""
                SELECT * FROM total_experiences 
                WHERE occurrence_count >= ? AND confidence >= ?
                ORDER BY occurrence_count DESC, avg_success_rate DESC
            """, (min_support, min_confidence))
            
            logger.info(f"ğŸ” æ‰¾åˆ° {len(high_quality_experiences)} æ¡é«˜è´¨é‡ç»éªŒç”¨äºè§„å¾‹ç”Ÿæˆ")
            
            # ç”ŸæˆCN1è§„å¾‹ï¼ˆå•æ¡ä»¶é¢„æµ‹ï¼‰
            cn1_rules = self._generate_cn1_rules(high_quality_experiences, min_support, min_confidence)
            generation_result['cn1_rules_generated'] = len(cn1_rules)
            
            # ç”ŸæˆCN2è§„å¾‹ï¼ˆå¤šæ¡ä»¶é¢„æµ‹ï¼‰
            cn2_rules = self._generate_cn2_rules(high_quality_experiences, min_support, min_confidence)
            generation_result['cn2_rules_generated'] = len(cn2_rules)
            
            # åˆå¹¶æ‰€æœ‰è§„å¾‹
            all_rules = cn1_rules + cn2_rules
            generation_result['total_rules_generated'] = len(all_rules)
            generation_result['rule_details'] = all_rules
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            generation_result['statistics'] = self._calculate_rule_generation_stats(all_rules, high_quality_experiences)
            
            generation_result['success'] = True
            generation_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… è§„å¾‹ç”Ÿæˆå®Œæˆ: CN1={len(cn1_rules)}, CN2={len(cn2_rules)}, æ€»è®¡={len(all_rules)}")
            
        except Exception as e:
            generation_result['error'] = str(e)
            logger.error(f"âŒ è§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return generation_result
    
    def _generate_cn1_rules(self, experiences: List, min_support: int, min_confidence: float) -> List[Dict]:
        """
        ç”ŸæˆCN1è§„å¾‹ï¼ˆå•æ¡ä»¶é¢„æµ‹ï¼‰
        
        Args:
            experiences: ç»éªŒæ•°æ®åˆ—è¡¨
            min_support: æœ€å°æ”¯æŒåº¦
            min_confidence: æœ€å°ç½®ä¿¡åº¦
            
        Returns:
            CN1è§„å¾‹åˆ—è¡¨
        """
        cn1_rules = []
        
        # å®šä¹‰å¯èƒ½çš„æ¡ä»¶å­—æ®µå’Œé¢„æµ‹å­—æ®µ
        condition_fields = ['environment', 'object', 'characteristics', 'action', 'tools']
        prediction_fields = ['result', 'success']
        
        # ä¸ºæ¯ä¸ªæ¡ä»¶å­—æ®µç”Ÿæˆè§„å¾‹
        for condition_field in condition_fields:
            # ç»Ÿè®¡æ¡ä»¶å€¼çš„åˆ†å¸ƒ
            condition_stats = {}
            
            for exp in experiences:
                condition_value = exp[condition_field]
                if condition_value not in condition_stats:
                    condition_stats[condition_value] = {
                        'total_count': 0,
                        'success_count': 0,
                        'results': {},
                        'experiences': []
                    }
                
                stats = condition_stats[condition_value]
                stats['total_count'] += exp['occurrence_count']
                stats['success_count'] += exp['success_count']
                stats['experiences'].append(exp)
                
                # ç»Ÿè®¡ç»“æœåˆ†å¸ƒ
                result = exp['result']
                if result not in stats['results']:
                    stats['results'][result] = {'count': 0, 'success_rate': 0.0}
                stats['results'][result]['count'] += exp['occurrence_count']
                stats['results'][result]['success_rate'] = exp['avg_success_rate']
            
            # ä¸ºæ¯ä¸ªæ¡ä»¶å€¼ç”Ÿæˆè§„å¾‹
            for condition_value, stats in condition_stats.items():
                if stats['total_count'] >= min_support:
                    # ç”ŸæˆæˆåŠŸç‡é¢„æµ‹è§„å¾‹
                    success_rate = stats['success_count'] / stats['total_count'] if stats['total_count'] > 0 else 0.0
                    
                    if success_rate >= min_confidence or success_rate <= (1 - min_confidence):
                        cn1_rule = self._create_cn1_rule(
                            condition_field, condition_value, 'success', success_rate >= 0.5,
                            success_rate, stats['total_count'], stats['experiences']
                        )
                        cn1_rules.append(cn1_rule)
                    
                    # ç”Ÿæˆæœ€å¯èƒ½ç»“æœé¢„æµ‹è§„å¾‹
                    if stats['results']:
                        most_common_result = max(stats['results'].items(), key=lambda x: x[1]['count'])
                        result_name, result_stats = most_common_result
                        result_confidence = result_stats['count'] / stats['total_count']
                        
                        if result_confidence >= min_confidence:
                            cn1_rule = self._create_cn1_rule(
                                condition_field, condition_value, 'result', result_name,
                                result_confidence, stats['total_count'], stats['experiences']
                            )
                            cn1_rules.append(cn1_rule)
        
        return cn1_rules
    
    def _generate_cn2_rules(self, experiences: List, min_support: int, min_confidence: float) -> List[Dict]:
        """
        ç”ŸæˆCN2è§„å¾‹ï¼ˆå¤šæ¡ä»¶é¢„æµ‹ï¼‰
        
        Args:
            experiences: ç»éªŒæ•°æ®åˆ—è¡¨
            min_support: æœ€å°æ”¯æŒåº¦
            min_confidence: æœ€å°ç½®ä¿¡åº¦
            
        Returns:
            CN2è§„å¾‹åˆ—è¡¨
        """
        cn2_rules = []
        
        # å®šä¹‰æ¡ä»¶å­—æ®µç»„åˆ
        condition_combinations = [
            ['environment', 'object'],
            ['environment', 'action'],
            ['object', 'action'],
            ['action', 'tools'],
            ['environment', 'object', 'action'],
            ['object', 'characteristics', 'action'],
            ['environment', 'action', 'tools']
        ]
        
        prediction_fields = ['result', 'success']
        
        # ä¸ºæ¯ä¸ªæ¡ä»¶ç»„åˆç”Ÿæˆè§„å¾‹
        for condition_fields in condition_combinations:
            # ç»Ÿè®¡æ¡ä»¶ç»„åˆçš„åˆ†å¸ƒ
            combination_stats = {}
            
            for exp in experiences:
                # åˆ›å»ºæ¡ä»¶ç»„åˆé”®
                condition_key = tuple(exp[field] for field in condition_fields)
                
                if condition_key not in combination_stats:
                    combination_stats[condition_key] = {
                        'total_count': 0,
                        'success_count': 0,
                        'results': {},
                        'experiences': []
                    }
                
                stats = combination_stats[condition_key]
                stats['total_count'] += exp['occurrence_count']
                stats['success_count'] += exp['success_count']
                stats['experiences'].append(exp)
                
                # ç»Ÿè®¡ç»“æœåˆ†å¸ƒ
                result = exp['result']
                if result not in stats['results']:
                    stats['results'][result] = {'count': 0, 'success_rate': 0.0}
                stats['results'][result]['count'] += exp['occurrence_count']
                stats['results'][result]['success_rate'] = exp['avg_success_rate']
            
            # ä¸ºæ¯ä¸ªæ¡ä»¶ç»„åˆç”Ÿæˆè§„å¾‹
            for condition_values, stats in combination_stats.items():
                if stats['total_count'] >= min_support:
                    # åˆ›å»ºæ¡ä»¶å­—å…¸
                    conditions = dict(zip(condition_fields, condition_values))
                    
                    # ç”ŸæˆæˆåŠŸç‡é¢„æµ‹è§„å¾‹
                    success_rate = stats['success_count'] / stats['total_count'] if stats['total_count'] > 0 else 0.0
                    
                    if success_rate >= min_confidence or success_rate <= (1 - min_confidence):
                        cn2_rule = self._create_cn2_rule(
                            conditions, 'success', success_rate >= 0.5,
                            success_rate, stats['total_count'], stats['experiences']
                        )
                        cn2_rules.append(cn2_rule)
                    
                    # ç”Ÿæˆæœ€å¯èƒ½ç»“æœé¢„æµ‹è§„å¾‹
                    if stats['results']:
                        most_common_result = max(stats['results'].items(), key=lambda x: x[1]['count'])
                        result_name, result_stats = most_common_result
                        result_confidence = result_stats['count'] / stats['total_count']
                        
                        if result_confidence >= min_confidence:
                            cn2_rule = self._create_cn2_rule(
                                conditions, 'result', result_name,
                                result_confidence, stats['total_count'], stats['experiences']
                            )
                            cn2_rules.append(cn2_rule)
        
        return cn2_rules
    
    def _create_cn1_rule(self, condition_field: str, condition_value: str, prediction_field: str, 
                        prediction_value, confidence: float, support_count: int, experiences: List) -> Dict:
        """
        åˆ›å»ºCN1è§„å¾‹
        
        Args:
            condition_field: æ¡ä»¶å­—æ®µå
            condition_value: æ¡ä»¶å€¼
            prediction_field: é¢„æµ‹å­—æ®µå
            prediction_value: é¢„æµ‹å€¼
            confidence: ç½®ä¿¡åº¦
            support_count: æ”¯æŒåº¦
            experiences: æ”¯æŒè¯¥è§„å¾‹çš„ç»éªŒåˆ—è¡¨
            
        Returns:
            CN1è§„å¾‹å­—å…¸
        """
        conditions = {condition_field: condition_value}
        predictions = {prediction_field: prediction_value}
        
        rule_id = f"CN1_{hashlib.md5(f'{conditions}_{predictions}'.encode()).hexdigest()[:12]}"
        
        # è®¡ç®—é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        discoverers = set()
        first_discovery_time = float('inf')
        last_seen_time = 0.0
        
        for exp in experiences:
            try:
                exp_discoverers = json.loads(exp['discoverers'])
                discoverers.update(exp_discoverers)
            except (json.JSONDecodeError, TypeError):
                discoverers.add(exp['first_discovered_by'])
            
            first_discovery_time = min(first_discovery_time, exp['first_discovered_time'])
            last_seen_time = max(last_seen_time, exp['last_seen_time'])
        
        return {
            'rule_id': rule_id,
            'rule_type': 'CN1',
            'conditions': conditions,
            'predictions': predictions,
            'confidence': confidence,
            'support_count': support_count,
            'contradiction_count': 0,  # åˆå§‹ä¸º0ï¼Œåç»­éªŒè¯æ—¶æ›´æ–°
            'created_time': time.time(),
            'creator_id': 'BPM_SYSTEM',
            'validation_status': 'pending',
            'discoverers': list(discoverers),
            'first_discovered_time': first_discovery_time if first_discovery_time != float('inf') else time.time(),
            'last_seen_time': last_seen_time,
            'supporting_experiences': len(experiences),
            'content_hash': hashlib.md5(f'{conditions}_{predictions}'.encode()).hexdigest()
        }
    
    def _create_cn2_rule(self, conditions: Dict, prediction_field: str, prediction_value, 
                        confidence: float, support_count: int, experiences: List) -> Dict:
        """
        åˆ›å»ºCN2è§„å¾‹
        
        Args:
            conditions: æ¡ä»¶å­—å…¸
            prediction_field: é¢„æµ‹å­—æ®µå
            prediction_value: é¢„æµ‹å€¼
            confidence: ç½®ä¿¡åº¦
            support_count: æ”¯æŒåº¦
            experiences: æ”¯æŒè¯¥è§„å¾‹çš„ç»éªŒåˆ—è¡¨
            
        Returns:
            CN2è§„å¾‹å­—å…¸
        """
        predictions = {prediction_field: prediction_value}
        
        rule_id = f"CN2_{hashlib.md5(f'{conditions}_{predictions}'.encode()).hexdigest()[:12]}"
        
        # è®¡ç®—é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        discoverers = set()
        first_discovery_time = float('inf')
        last_seen_time = 0.0
        
        for exp in experiences:
            try:
                exp_discoverers = json.loads(exp['discoverers'])
                discoverers.update(exp_discoverers)
            except (json.JSONDecodeError, TypeError):
                discoverers.add(exp['first_discovered_by'])
            
            first_discovery_time = min(first_discovery_time, exp['first_discovered_time'])
            last_seen_time = max(last_seen_time, exp['last_seen_time'])
        
        return {
            'rule_id': rule_id,
            'rule_type': 'CN2',
            'conditions': conditions,
            'predictions': predictions,
            'confidence': confidence,
            'support_count': support_count,
            'contradiction_count': 0,  # åˆå§‹ä¸º0ï¼Œåç»­éªŒè¯æ—¶æ›´æ–°
            'created_time': time.time(),
            'creator_id': 'BPM_SYSTEM',
            'validation_status': 'pending',
            'discoverers': list(discoverers),
            'first_discovered_time': first_discovery_time if first_discovery_time != float('inf') else time.time(),
            'last_seen_time': last_seen_time,
            'supporting_experiences': len(experiences),
            'content_hash': hashlib.md5(f'{conditions}_{predictions}'.encode()).hexdigest()
        }
    
    def _calculate_rule_generation_stats(self, rules: List[Dict], experiences: List) -> Dict:
        """
        è®¡ç®—è§„å¾‹ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        
        Args:
            rules: ç”Ÿæˆçš„è§„å¾‹åˆ—è¡¨
            experiences: åŸå§‹ç»éªŒæ•°æ®
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'total_experiences_processed': len(experiences),
            'total_rules_generated': len(rules),
            'cn1_rules': len([r for r in rules if r['rule_type'] == 'CN1']),
            'cn2_rules': len([r for r in rules if r['rule_type'] == 'CN2']),
            'avg_confidence': 0.0,
            'avg_support': 0.0,
            'confidence_distribution': {'high': 0, 'medium': 0, 'low': 0},
            'support_distribution': {'high': 0, 'medium': 0, 'low': 0},
            'prediction_types': {'success': 0, 'result': 0},
            'unique_discoverers': set(),
            'coverage_rate': 0.0
        }
        
        if not rules:
            return stats
        
        # è®¡ç®—å¹³å‡å€¼
        total_confidence = sum(rule['confidence'] for rule in rules)
        total_support = sum(rule['support_count'] for rule in rules)
        
        stats['avg_confidence'] = total_confidence / len(rules)
        stats['avg_support'] = total_support / len(rules)
        
        # è®¡ç®—åˆ†å¸ƒ
        for rule in rules:
            # ç½®ä¿¡åº¦åˆ†å¸ƒ
            if rule['confidence'] >= 0.8:
                stats['confidence_distribution']['high'] += 1
            elif rule['confidence'] >= 0.6:
                stats['confidence_distribution']['medium'] += 1
            else:
                stats['confidence_distribution']['low'] += 1
            
            # æ”¯æŒåº¦åˆ†å¸ƒ
            if rule['support_count'] >= 10:
                stats['support_distribution']['high'] += 1
            elif rule['support_count'] >= 5:
                stats['support_distribution']['medium'] += 1
            else:
                stats['support_distribution']['low'] += 1
            
            # é¢„æµ‹ç±»å‹ç»Ÿè®¡
            for pred_field in rule['predictions'].keys():
                if pred_field in stats['prediction_types']:
                    stats['prediction_types'][pred_field] += 1
            
            # æ”¶é›†å‘ç°è€…
            stats['unique_discoverers'].update(rule['discoverers'])
        
        # è½¬æ¢setä¸ºæ•°é‡
        stats['unique_discoverers'] = len(stats['unique_discoverers'])
        
        # è®¡ç®—è¦†ç›–ç‡ï¼ˆæœ‰å¤šå°‘ç»éªŒè¢«è§„å¾‹è¦†ç›–ï¼‰
        covered_experiences = set()
        for rule in rules:
            covered_experiences.add(rule['content_hash'])
        
        stats['coverage_rate'] = len(covered_experiences) / max(len(experiences), 1)
        
        return stats
    
    def add_rules_to_direct_library(self, rules: List[Dict]) -> Dict[str, Any]:
        """æ·»åŠ è§„å¾‹åˆ—è¡¨åˆ°ç›´æ¥è§„å¾‹åº“"""
        if not rules:
            return {
                'success': False,
                'added_count': 0,
                'reason': 'empty_rules_list'
            }
        
        db_manager = self.db_managers['direct_rules']
        added_rules = []
        duplicate_rules = []
        error_rules = []
        
        for rule in rules:
            try:
                # éªŒè¯è§„å¾‹æ•°æ®å®Œæ•´æ€§
                required_fields = ['rule_id', 'rule_type', 'conditions', 'predictions', 'confidence']
                missing_fields = [field for field in required_fields if field not in rule]
                
                if missing_fields:
                    error_rules.append({
                        'rule': rule,
                        'error': f'missing_fields: {missing_fields}'
                    })
                    continue
                
                # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
                content_hash = Rule(
                    rule_id=rule['rule_id'],
                    rule_type=rule['rule_type'], 
                    conditions=rule['conditions'],
                    predictions=rule['predictions'],
                    confidence=rule['confidence'],
                    support_count=rule.get('support_count', 0),
                    contradiction_count=rule.get('contradiction_count', 0),
                    created_time=time.time(),
                    creator_id=rule.get('creator_id', 'system')
                ).generate_hash()
                
                # æ£€æŸ¥é‡å¤
                existing = db_manager.execute_query(
                    "SELECT rule_id FROM direct_rules WHERE content_hash = ?",
                    (content_hash,)
                )
                
                if existing:
                    duplicate_rules.append(rule['rule_id'])
                    continue
                
                # æ’å…¥è§„å¾‹
                db_manager.execute_update("""
                    INSERT INTO direct_rules (
                        rule_id, content_hash, rule_type, conditions, predictions, 
                        confidence, support_count, contradiction_count, validation_count,
                        created_time, creator_id, validation_status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    rule['rule_id'],
                    content_hash,
                    rule['rule_type'],
                    json.dumps(rule['conditions']),
                    json.dumps(rule['predictions']),
                    rule['confidence'],
                    rule.get('support_count', 0),
                    rule.get('contradiction_count', 0),
                    rule.get('validation_count', 0),
                    time.time(),
                    rule.get('creator_id', 'system'),
                    rule.get('validation_status', 'pending')
                ))
                
                added_rules.append(rule['rule_id'])
                
            except Exception as e:
                error_rules.append({
                    'rule': rule.get('rule_id', 'unknown'),
                    'error': str(e)
                })
        
        # æ›´æ–°ç¼“å­˜
        if added_rules:
            self._update_cache()
        
        result = {
            'success': len(added_rules) > 0,
            'added_count': len(added_rules),
            'duplicate_count': len(duplicate_rules),
            'error_count': len(error_rules),
            'added_rules': added_rules,
            'duplicate_rules': duplicate_rules,
            'error_rules': error_rules,
            'timestamp': time.time()
        }
        
        if len(added_rules) > 0:
            logger.info(f"âœ… Successfully added {len(added_rules)} rules to direct rule library")
        if len(duplicate_rules) > 0:
            logger.info(f"âš ï¸ Skipped {len(duplicate_rules)} duplicate rules")
        if len(error_rules) > 0:
            logger.warning(f"âŒ {len(error_rules)} rules failed to add")
        
        return result
    
    def add_rule(self, rule_type: str = None, conditions: Dict = None, predictions: Dict = None, 
                 confidence: float = 0.7, creator_id: str = "system", rule_dict: Dict = None, 
                 **kwargs) -> Dict[str, Any]:
        """
        æ·»åŠ å•ä¸ªè§„å¾‹åˆ°ç›´æ¥è§„å¾‹åº“
        
        æ”¯æŒä¸¤ç§è°ƒç”¨æ–¹å¼ï¼š
        1. ä¼ é€’å­—å…¸: add_rule(rule_dict=rule_data)
        2. ä¼ é€’å‚æ•°: add_rule(rule_type="E-A-R", conditions={...}, predictions={...})
        """
        try:
            # æ–¹å¼1ï¼šå¦‚æœä¼ é€’äº†rule_dictï¼Œä½¿ç”¨å­—å…¸æ–¹å¼
            if rule_dict:
                return self.add_rules_to_direct_library([rule_dict])
            
            # æ–¹å¼2ï¼šä»å…³é”®å­—å‚æ•°æ„å»ºè§„å¾‹å­—å…¸
            if rule_type and conditions and predictions:
                import time
                rule_id = f"{rule_type}_{int(time.time() * 1000)}_{hash(str(conditions)) % 10000}"
                
                rule_data = {
                    'rule_id': rule_id,
                    'rule_type': rule_type,
                    'conditions': conditions,
                    'predictions': predictions,
                    'confidence': confidence,
                    'support_count': kwargs.get('support_count', 1),
                    'contradiction_count': kwargs.get('contradiction_count', 0),
                    'created_time': time.time(),
                    'creator_id': creator_id,
                    'validation_status': kwargs.get('validation_status', 'pending')
                }
                
                return self.add_rules_to_direct_library([rule_data])
            
            # å‚æ•°ä¸è¶³
            return {
                'success': False,
                'error': 'Missing required parameters: rule_type, conditions, predictions or rule_dict',
                'rules_added': 0
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'Failed to add rule: {str(e)}',
                'rules_added': 0
            }
    
    def get_rule_generation_summary(self) -> Dict[str, Any]:
        """
        è·å–è§„å¾‹ç”Ÿæˆæ‘˜è¦ä¿¡æ¯
        
        Returns:
            è§„å¾‹ç”Ÿæˆæ‘˜è¦
        """
        summary = {
            'direct_rules_count': 0,
            'total_rules_count': 0,
            'rule_types': {'CN1': 0, 'CN2': 0},
            'validation_status': {'pending': 0, 'validated': 0, 'rejected': 0},
            'confidence_levels': {'high': 0, 'medium': 0, 'low': 0},
            'recent_activity': [],
            'top_rules': []
        }
        
        try:
            # ç›´æ¥è§„å¾‹åº“ç»Ÿè®¡
            direct_rules = self.db_managers['direct_rules'].execute_query(
                "SELECT * FROM direct_rules ORDER BY created_time DESC"
            )
            summary['direct_rules_count'] = len(direct_rules)
            
            # æ€»è§„å¾‹åº“ç»Ÿè®¡
            total_rules = self.db_managers['total_rules'].execute_query(
                "SELECT * FROM total_rules ORDER BY created_time DESC"
            )
            summary['total_rules_count'] = len(total_rules)
            
            # åˆ†æç›´æ¥è§„å¾‹åº“
            for rule in direct_rules:
                # è§„å¾‹ç±»å‹ç»Ÿè®¡
                rule_type = rule['rule_type']
                if rule_type in summary['rule_types']:
                    summary['rule_types'][rule_type] += 1
                
                # éªŒè¯çŠ¶æ€ç»Ÿè®¡
                status = rule['validation_status']
                if status in summary['validation_status']:
                    summary['validation_status'][status] += 1
                
                # ç½®ä¿¡åº¦ç­‰çº§ç»Ÿè®¡
                confidence = rule['confidence']
                if confidence >= 0.8:
                    summary['confidence_levels']['high'] += 1
                elif confidence >= 0.6:
                    summary['confidence_levels']['medium'] += 1
                else:
                    summary['confidence_levels']['low'] += 1
            
            # æœ€è¿‘æ´»åŠ¨ï¼ˆæœ€è¿‘10æ¡ï¼‰
            recent_rules = direct_rules[:10]
            for rule in recent_rules:
                summary['recent_activity'].append({
                    'rule_id': rule['rule_id'],
                    'rule_type': rule['rule_type'],
                    'confidence': rule['confidence'],
                    'support_count': rule['support_count'],
                    'created_time': rule['created_time'],
                    'status': rule['validation_status']
                })
            
            # é¡¶çº§è§„å¾‹ï¼ˆæŒ‰ç½®ä¿¡åº¦å’Œæ”¯æŒåº¦æ’åºï¼‰
            top_rules = sorted(direct_rules, key=lambda x: (x['confidence'], x['support_count']), reverse=True)[:5]
            for rule in top_rules:
                summary['top_rules'].append({
                    'rule_id': rule['rule_id'],
                    'rule_type': rule['rule_type'],
                    'confidence': rule['confidence'],
                    'support_count': rule['support_count'],
                    'conditions': rule['conditions'],
                    'predictions': rule['predictions']
                })
        
        except Exception as e:
            summary['error'] = str(e)
            logger.error(f"âŒ è·å–è§„å¾‹æ‘˜è¦å¤±è´¥: {str(e)}")
        
        return summary

    # ==================== è§„å¾‹éªŒè¯æ¨¡å— ====================
    
    def validate_rules_against_experience(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        ä½¿ç”¨æ–°ç»éªŒéªŒè¯ç°æœ‰è§„å¾‹
        
        Args:
            experience: æ–°çš„EOCATRç»éªŒ
            
        Returns:
            éªŒè¯ç»“æœ
        """
        validation_result = {
            'success': False,
            'experience_hash': None,
            'matched_rules': [],
            'validated_rules': 0,
            'contradicted_rules': 0,
            'updated_rules': 0,
            'validation_details': [],
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # éªŒè¯ç»éªŒ
            exp_validation = self.validate_eocatr_experience(experience)
            if not exp_validation['is_valid']:
                validation_result['error'] = f"ç»éªŒéªŒè¯å¤±è´¥: {exp_validation['errors']}"
                return validation_result
            
            normalized_exp = exp_validation['normalized_experience']
            validation_result['experience_hash'] = normalized_exp.generate_hash()
            
            # è·å–æ‰€æœ‰å¾…éªŒè¯çš„è§„å¾‹
            pending_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT * FROM direct_rules 
                WHERE validation_status = 'pending' OR validation_status = 'validated'
                ORDER BY confidence DESC, support_count DESC
            """)
            
            logger.info(f"ğŸ” å¼€å§‹éªŒè¯ {len(pending_rules)} æ¡è§„å¾‹")
            
            # é€ä¸€éªŒè¯è§„å¾‹
            for rule in pending_rules:
                match_result = self._match_rule_with_experience(rule, normalized_exp)
                
                if match_result['is_match']:
                    validation_result['matched_rules'].append(rule['rule_id'])
                    
                    # æ‰§è¡ŒéªŒè¯
                    verify_result = self._verify_rule_prediction(rule, normalized_exp, match_result)
                    
                    if verify_result['is_correct']:
                        validation_result['validated_rules'] += 1
                        self._update_rule_validation_success(rule, verify_result)
                    else:
                        validation_result['contradicted_rules'] += 1
                        self._update_rule_validation_failure(rule, verify_result)
                    
                    validation_result['updated_rules'] += 1
                    validation_result['validation_details'].append({
                        'rule_id': rule['rule_id'],
                        'rule_type': rule['rule_type'],
                        'is_match': True,
                        'is_correct': verify_result['is_correct'],
                        'prediction_field': verify_result['prediction_field'],
                        'expected_value': verify_result['expected_value'],
                        'actual_value': verify_result['actual_value'],
                        'confidence_before': rule['confidence'],
                        'confidence_after': verify_result.get('new_confidence', rule['confidence'])
                    })
            
            validation_result['success'] = True
            validation_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… è§„å¾‹éªŒè¯å®Œæˆ: åŒ¹é…={len(validation_result['matched_rules'])}, éªŒè¯={validation_result['validated_rules']}, çŸ›ç›¾={validation_result['contradicted_rules']}")
            
        except Exception as e:
            validation_result['error'] = str(e)
            logger.error(f"âŒ è§„å¾‹éªŒè¯å¤±è´¥: {str(e)}")
        
        return validation_result
    
    def _match_rule_with_experience(self, rule: dict, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        æ£€æŸ¥è§„å¾‹æ˜¯å¦ä¸ç»éªŒåŒ¹é…
        
        Args:
            rule: è§„å¾‹è®°å½•
            experience: ç»éªŒå¯¹è±¡
            
        Returns:
            åŒ¹é…ç»“æœ
        """
        match_result = {
            'is_match': False,
            'matched_conditions': [],
            'match_score': 0.0,
            'total_conditions': 0
        }
        
        try:
            # è§£æè§„å¾‹æ¡ä»¶
            conditions = json.loads(rule['conditions'])
            match_result['total_conditions'] = len(conditions)
            
            matched_count = 0
            
            # æ£€æŸ¥æ¯ä¸ªæ¡ä»¶
            for field, expected_value in conditions.items():
                actual_value = getattr(experience, field, None)
                
                if actual_value is not None and str(actual_value).lower() == str(expected_value).lower():
                    matched_count += 1
                    match_result['matched_conditions'].append({
                        'field': field,
                        'expected': expected_value,
                        'actual': actual_value,
                        'match': True
                    })
                else:
                    match_result['matched_conditions'].append({
                        'field': field,
                        'expected': expected_value,
                        'actual': actual_value,
                        'match': False
                    })
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            match_result['match_score'] = matched_count / len(conditions) if conditions else 0.0
            match_result['is_match'] = match_result['match_score'] == 1.0  # è¦æ±‚å®Œå…¨åŒ¹é…
            
        except Exception as e:
            logger.error(f"âŒ è§„å¾‹åŒ¹é…å¤±è´¥: {str(e)}")
        
        return match_result
    
    def _verify_rule_prediction(self, rule: dict, experience: EOCATRExperience, match_result: dict) -> Dict[str, Any]:
        """
        éªŒè¯è§„å¾‹çš„é¢„æµ‹æ˜¯å¦æ­£ç¡®
        
        Args:
            rule: è§„å¾‹è®°å½•
            experience: ç»éªŒå¯¹è±¡
            match_result: åŒ¹é…ç»“æœ
            
        Returns:
            éªŒè¯ç»“æœ
        """
        verify_result = {
            'is_correct': False,
            'prediction_field': None,
            'expected_value': None,
            'actual_value': None,
            'confidence_impact': 0.0,
            'new_confidence': rule['confidence']
        }
        
        try:
            # è§£æè§„å¾‹é¢„æµ‹
            predictions = json.loads(rule['predictions'])
            
            # æ£€æŸ¥æ¯ä¸ªé¢„æµ‹
            correct_predictions = 0
            total_predictions = len(predictions)
            
            for field, expected_value in predictions.items():
                verify_result['prediction_field'] = field
                verify_result['expected_value'] = expected_value
                
                if field == 'success':
                    actual_value = experience.success
                    verify_result['actual_value'] = actual_value
                    
                    # å¸ƒå°”å€¼æ¯”è¾ƒ
                    if isinstance(expected_value, bool):
                        is_correct = actual_value == expected_value
                    else:
                        is_correct = actual_value == (str(expected_value).lower() == 'true')
                    
                elif field == 'result':
                    actual_value = experience.result
                    verify_result['actual_value'] = actual_value
                    
                    # å­—ç¬¦ä¸²æ¯”è¾ƒï¼ˆå¯ä»¥æ˜¯éƒ¨åˆ†åŒ¹é…ï¼‰
                    is_correct = (str(expected_value).lower() in str(actual_value).lower() or 
                                str(actual_value).lower() in str(expected_value).lower())
                
                else:
                    # å…¶ä»–å­—æ®µçš„ç›´æ¥æ¯”è¾ƒ
                    actual_value = getattr(experience, field, None)
                    verify_result['actual_value'] = actual_value
                    is_correct = str(actual_value).lower() == str(expected_value).lower()
                
                if is_correct:
                    correct_predictions += 1
            
            # è®¡ç®—éªŒè¯ç»“æœ
            verify_result['is_correct'] = correct_predictions == total_predictions
            
            # è®¡ç®—ç½®ä¿¡åº¦å½±å“
            current_confidence = rule['confidence']
            support_count = rule['support_count']
            
            if verify_result['is_correct']:
                # éªŒè¯æˆåŠŸï¼Œè½»å¾®æå‡ç½®ä¿¡åº¦
                confidence_boost = 0.05 * (1 - current_confidence)  # è¶Šæ¥è¿‘1æå‡è¶Šå°
                verify_result['new_confidence'] = min(0.99, current_confidence + confidence_boost)
                verify_result['confidence_impact'] = confidence_boost
            else:
                # éªŒè¯å¤±è´¥ï¼Œé™ä½ç½®ä¿¡åº¦
                confidence_penalty = 0.1 * current_confidence  # æŒ‰æ¯”ä¾‹é™ä½
                verify_result['new_confidence'] = max(0.01, current_confidence - confidence_penalty)
                verify_result['confidence_impact'] = -confidence_penalty
            
        except Exception as e:
            logger.error(f"âŒ è§„å¾‹é¢„æµ‹éªŒè¯å¤±è´¥: {str(e)}")
        
        return verify_result
    
    def _update_rule_validation_success(self, rule: dict, verify_result: dict):
        """
        æ›´æ–°è§„å¾‹éªŒè¯æˆåŠŸçš„ç»Ÿè®¡
        
        Args:
            rule: è§„å¾‹è®°å½•
            verify_result: éªŒè¯ç»“æœ
        """
        try:
            self.db_managers['direct_rules'].execute_update("""
                UPDATE direct_rules 
                SET support_count = support_count + 1,
                    confidence = ?,
                    last_validated = ?,
                    validation_count = validation_count + 1,
                    validation_status = CASE 
                        WHEN validation_count + 1 >= 3 AND confidence >= 0.7 THEN 'validated'
                        ELSE validation_status
                    END
                WHERE rule_id = ?
            """, (
                verify_result['new_confidence'],
                time.time(),
                rule['rule_id']
            ))
            
            logger.debug(f"âœ… è§„å¾‹ {rule['rule_id']} éªŒè¯æˆåŠŸæ›´æ–°")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è§„å¾‹éªŒè¯æˆåŠŸå¤±è´¥: {str(e)}")
    
    def _update_rule_validation_failure(self, rule: dict, verify_result: dict):
        """
        æ›´æ–°è§„å¾‹éªŒè¯å¤±è´¥çš„ç»Ÿè®¡
        
        Args:
            rule: è§„å¾‹è®°å½•
            verify_result: éªŒè¯ç»“æœ
        """
        try:
            self.db_managers['direct_rules'].execute_update("""
                UPDATE direct_rules 
                SET contradiction_count = contradiction_count + 1,
                    confidence = ?,
                    last_validated = ?,
                    validation_count = validation_count + 1,
                    validation_status = CASE 
                        WHEN contradiction_count + 1 >= 3 OR confidence < 0.3 THEN 'rejected'
                        ELSE validation_status
                    END
                WHERE rule_id = ?
            """, (
                verify_result['new_confidence'],
                time.time(),
                rule['rule_id']
            ))
            
            logger.debug(f"âš ï¸ è§„å¾‹ {rule['rule_id']} éªŒè¯å¤±è´¥æ›´æ–°")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è§„å¾‹éªŒè¯å¤±è´¥å¤±è´¥: {str(e)}")
    
    def batch_validate_rules(self, experiences: List[EOCATRExperience]) -> Dict[str, Any]:
        """
        æ‰¹é‡éªŒè¯è§„å¾‹
        
        Args:
            experiences: ç»éªŒåˆ—è¡¨
            
        Returns:
            æ‰¹é‡éªŒè¯ç»“æœ
        """
        batch_result = {
            'success': False,
            'total_experiences': len(experiences),
            'processed_experiences': 0,
            'total_validations': 0,
            'total_contradictions': 0,
            'updated_rules': set(),
            'validation_summary': {},
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            for i, experience in enumerate(experiences):
                validation_result = self.validate_rules_against_experience(experience)
                
                if validation_result['success']:
                    batch_result['processed_experiences'] += 1
                    batch_result['total_validations'] += validation_result['validated_rules']
                    batch_result['total_contradictions'] += validation_result['contradicted_rules']
                    batch_result['updated_rules'].update(validation_result['matched_rules'])
                
                # æ¯å¤„ç†10ä¸ªç»éªŒè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if (i + 1) % 10 == 0:
                    logger.info(f"ğŸ“Š æ‰¹é‡éªŒè¯è¿›åº¦: {i + 1}/{len(experiences)}")
            
            # ç”ŸæˆéªŒè¯æ‘˜è¦
            batch_result['validation_summary'] = self._generate_validation_summary()
            batch_result['updated_rules'] = list(batch_result['updated_rules'])
            batch_result['success'] = True
            batch_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… æ‰¹é‡éªŒè¯å®Œæˆ: å¤„ç†={batch_result['processed_experiences']}, éªŒè¯={batch_result['total_validations']}, çŸ›ç›¾={batch_result['total_contradictions']}")
            
        except Exception as e:
            batch_result['error'] = str(e)
            logger.error(f"âŒ æ‰¹é‡éªŒè¯å¤±è´¥: {str(e)}")
        
        return batch_result
    
    def _generate_validation_summary(self) -> Dict[str, Any]:
        """
        ç”ŸæˆéªŒè¯æ‘˜è¦
        
        Returns:
            éªŒè¯æ‘˜è¦
        """
        summary = {
            'rule_status_distribution': {},
            'confidence_distribution': {},
            'validation_metrics': {},
            'top_validated_rules': [],
            'problematic_rules': []
        }
        
        try:
            # è§„å¾‹çŠ¶æ€åˆ†å¸ƒ
            status_stats = self.db_managers['direct_rules'].execute_query("""
                SELECT validation_status, COUNT(*) as count
                FROM direct_rules
                GROUP BY validation_status
            """)
            
            for stat in status_stats:
                summary['rule_status_distribution'][stat['validation_status']] = stat['count']
            
            # ç½®ä¿¡åº¦åˆ†å¸ƒ
            confidence_stats = self.db_managers['direct_rules'].execute_query("""
                SELECT 
                    CASE 
                        WHEN confidence >= 0.8 THEN 'high'
                        WHEN confidence >= 0.6 THEN 'medium'
                        ELSE 'low'
                    END as confidence_level,
                    COUNT(*) as count
                FROM direct_rules
                GROUP BY confidence_level
            """)
            
            for stat in confidence_stats:
                summary['confidence_distribution'][stat['confidence_level']] = stat['count']
            
            # éªŒè¯æŒ‡æ ‡
            metrics = self.db_managers['direct_rules'].execute_query("""
                SELECT 
                    AVG(confidence) as avg_confidence,
                    AVG(support_count) as avg_support,
                    AVG(contradiction_count) as avg_contradictions,
                    AVG(validation_count) as avg_validations,
                    COUNT(*) as total_rules
                FROM direct_rules
            """)[0]
            
            summary['validation_metrics'] = dict(metrics)
            
            # é¡¶çº§éªŒè¯è§„å¾‹
            top_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT rule_id, rule_type, confidence, support_count, contradiction_count, validation_status
                FROM direct_rules
                WHERE validation_status = 'validated'
                ORDER BY confidence DESC, support_count DESC
                LIMIT 5
            """)
            
            summary['top_validated_rules'] = [dict(rule) for rule in top_rules]
            
            # é—®é¢˜è§„å¾‹
            problem_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT rule_id, rule_type, confidence, support_count, contradiction_count, validation_status
                FROM direct_rules
                WHERE validation_status = 'rejected' OR (contradiction_count > support_count AND contradiction_count > 0)
                ORDER BY contradiction_count DESC, confidence ASC
                LIMIT 5
            """)
            
            summary['problematic_rules'] = [dict(rule) for rule in problem_rules]
            
        except Exception as e:
            summary['error'] = str(e)
            logger.error(f"âŒ ç”ŸæˆéªŒè¯æ‘˜è¦å¤±è´¥: {str(e)}")
        
        return summary
    
    def get_rule_validation_report(self, rule_id: str = None) -> Dict[str, Any]:
        """
        è·å–è§„å¾‹éªŒè¯æŠ¥å‘Š
        
        Args:
            rule_id: ç‰¹å®šè§„å¾‹IDï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›å…¨å±€æŠ¥å‘Š
            
        Returns:
            éªŒè¯æŠ¥å‘Š
        """
        report = {
            'success': False,
            'report_type': 'specific' if rule_id else 'global',
            'rule_details': None,
            'validation_history': [],
            'performance_metrics': {},
            'recommendations': []
        }
        
        try:
            if rule_id:
                # ç‰¹å®šè§„å¾‹æŠ¥å‘Š
                rule_details = self.db_managers['direct_rules'].execute_query(
                    "SELECT * FROM direct_rules WHERE rule_id = ?", (rule_id,)
                )
                
                if not rule_details:
                    report['error'] = f"è§„å¾‹ {rule_id} ä¸å­˜åœ¨"
                    return report
                
                rule = rule_details[0]
                report['rule_details'] = dict(rule)
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                total_tests = rule['support_count'] + rule['contradiction_count']
                success_rate = rule['support_count'] / total_tests if total_tests > 0 else 0.0
                
                report['performance_metrics'] = {
                    'success_rate': success_rate,
                    'total_tests': total_tests,
                    'support_count': rule['support_count'],
                    'contradiction_count': rule['contradiction_count'],
                    'current_confidence': rule['confidence'],
                    'validation_count': rule['validation_count'],
                    'status': rule['validation_status']
                }
                
                # ç”Ÿæˆå»ºè®®
                report['recommendations'] = self._generate_rule_recommendations(rule)
                
            else:
                # å…¨å±€æŠ¥å‘Š
                report['validation_summary'] = self._generate_validation_summary()
                
                # å…¨å±€æ€§èƒ½æŒ‡æ ‡
                global_metrics = self.db_managers['direct_rules'].execute_query("""
                    SELECT 
                        COUNT(*) as total_rules,
                        AVG(confidence) as avg_confidence,
                        SUM(support_count) as total_supports,
                        SUM(contradiction_count) as total_contradictions,
                        COUNT(CASE WHEN validation_status = 'validated' THEN 1 END) as validated_rules,
                        COUNT(CASE WHEN validation_status = 'rejected' THEN 1 END) as rejected_rules,
                        COUNT(CASE WHEN validation_status = 'pending' THEN 1 END) as pending_rules
                    FROM direct_rules
                """)[0]
                
                report['performance_metrics'] = dict(global_metrics)
                
                # è®¡ç®—å…¨å±€æˆåŠŸç‡
                total_tests = global_metrics['total_supports'] + global_metrics['total_contradictions']
                global_success_rate = global_metrics['total_supports'] / total_tests if total_tests > 0 else 0.0
                report['performance_metrics']['global_success_rate'] = global_success_rate
                
                # ç”Ÿæˆå…¨å±€å»ºè®®
                report['recommendations'] = self._generate_global_recommendations(global_metrics)
            
            report['success'] = True
            
        except Exception as e:
            report['error'] = str(e)
            logger.error(f"âŒ è·å–éªŒè¯æŠ¥å‘Šå¤±è´¥: {str(e)}")
        
        return report
    
    def _generate_rule_recommendations(self, rule: dict) -> List[str]:
        """
        ä¸ºç‰¹å®šè§„å¾‹ç”Ÿæˆå»ºè®®
        
        Args:
            rule: è§„å¾‹è®°å½•
            
        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        confidence = rule['confidence']
        support_count = rule['support_count']
        contradiction_count = rule['contradiction_count']
        validation_count = rule['validation_count']
        status = rule['validation_status']
        
        # åŸºäºç½®ä¿¡åº¦çš„å»ºè®®
        if confidence < 0.3:
            recommendations.append("âš ï¸ ç½®ä¿¡åº¦è¿‡ä½ï¼Œå»ºè®®è€ƒè™‘åˆ é™¤æ­¤è§„å¾‹")
        elif confidence < 0.6:
            recommendations.append("ğŸ“Š ç½®ä¿¡åº¦è¾ƒä½ï¼Œéœ€è¦æ›´å¤šéªŒè¯æ•°æ®")
        elif confidence > 0.9:
            recommendations.append("âœ… ç½®ä¿¡åº¦å¾ˆé«˜ï¼Œå¯ä»¥ä¼˜å…ˆä½¿ç”¨")
        
        # åŸºäºæ”¯æŒåº¦çš„å»ºè®®
        if support_count < 3:
            recommendations.append("ğŸ“ˆ æ”¯æŒåº¦ä¸è¶³ï¼Œéœ€è¦æ›´å¤šæ­£é¢éªŒè¯")
        elif support_count > 10:
            recommendations.append("ğŸ¯ æ”¯æŒåº¦å……è¶³ï¼Œè§„å¾‹è¾ƒä¸ºå¯é ")
        
        # åŸºäºçŸ›ç›¾çš„å»ºè®®
        if contradiction_count > support_count:
            recommendations.append("âŒ çŸ›ç›¾è¿‡å¤šï¼Œå»ºè®®é‡æ–°è¯„ä¼°è§„å¾‹æ¡ä»¶")
        elif contradiction_count == 0 and validation_count > 5:
            recommendations.append("ğŸŒŸ æ— çŸ›ç›¾ä¸”éªŒè¯å……åˆ†ï¼Œè§„å¾‹è´¨é‡ä¼˜ç§€")
        
        # åŸºäºçŠ¶æ€çš„å»ºè®®
        if status == 'pending' and validation_count < 3:
            recommendations.append("â³ éœ€è¦æ›´å¤šéªŒè¯æ‰èƒ½ç¡®å®šè§„å¾‹æœ‰æ•ˆæ€§")
        elif status == 'rejected':
            recommendations.append("ğŸ—‘ï¸ è§„å¾‹å·²è¢«æ‹’ç»ï¼Œå»ºè®®ä»ç³»ç»Ÿä¸­ç§»é™¤")
        elif status == 'validated':
            recommendations.append("âœ… è§„å¾‹å·²éªŒè¯ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨")
        
        return recommendations
    
    def _generate_global_recommendations(self, metrics: dict) -> List[str]:
        """
        ç”Ÿæˆå…¨å±€å»ºè®®
        
        Args:
            metrics: å…¨å±€æŒ‡æ ‡
            
        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        total_rules = metrics.get('total_rules', 0)
        avg_confidence = metrics.get('avg_confidence', 0.0)
        global_success_rate = metrics.get('global_success_rate', 0.0)
        validated_rules = metrics.get('validated_rules', 0)
        rejected_rules = metrics.get('rejected_rules', 0)
        pending_rules = metrics.get('pending_rules', 0)
        
        # åŸºäºè§„å¾‹æ•°é‡çš„å»ºè®®
        if total_rules < 10:
            recommendations.append("ğŸ“Š è§„å¾‹æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æ›´å¤šç»éªŒæ•°æ®ä»¥ç”Ÿæˆè§„å¾‹")
        elif total_rules > 1000:
            recommendations.append("ğŸ—‚ï¸ è§„å¾‹æ•°é‡è¾ƒå¤šï¼Œå»ºè®®å®šæœŸæ¸…ç†ä½è´¨é‡è§„å¾‹")
        
        # åŸºäºå¹³å‡ç½®ä¿¡åº¦çš„å»ºè®®
        if avg_confidence < 0.5:
            recommendations.append("âš ï¸ å¹³å‡ç½®ä¿¡åº¦åä½ï¼Œå»ºè®®æé«˜è§„å¾‹ç”Ÿæˆé˜ˆå€¼")
        elif avg_confidence > 0.8:
            recommendations.append("âœ… å¹³å‡ç½®ä¿¡åº¦è‰¯å¥½ï¼Œè§„å¾‹è´¨é‡è¾ƒé«˜")
        
        # åŸºäºæˆåŠŸç‡çš„å»ºè®®
        if global_success_rate < 0.6:
            recommendations.append("ğŸ“‰ å…¨å±€æˆåŠŸç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–è§„å¾‹ç”Ÿæˆç®—æ³•")
        elif global_success_rate > 0.8:
            recommendations.append("ğŸ¯ å…¨å±€æˆåŠŸç‡è‰¯å¥½ï¼ŒéªŒè¯æœºåˆ¶æœ‰æ•ˆ")
        
        # åŸºäºéªŒè¯çŠ¶æ€çš„å»ºè®®
        pending_ratio = pending_rules / total_rules if total_rules > 0 else 0
        if pending_ratio > 0.7:
            recommendations.append("â³ å¾…éªŒè¯è§„å¾‹è¿‡å¤šï¼Œå»ºè®®å¢åŠ éªŒè¯é¢‘ç‡")
        
        rejected_ratio = rejected_rules / total_rules if total_rules > 0 else 0
        if rejected_ratio > 0.3:
            recommendations.append("ğŸ—‘ï¸ æ‹’ç»è§„å¾‹è¿‡å¤šï¼Œå»ºè®®ä¼˜åŒ–è§„å¾‹ç”Ÿæˆæ¡ä»¶")
        
        validated_ratio = validated_rules / total_rules if total_rules > 0 else 0
        if validated_ratio > 0.5:
            recommendations.append("âœ… éªŒè¯è§„å¾‹æ¯”ä¾‹è‰¯å¥½ï¼Œç³»ç»Ÿè¿è¡Œç¨³å®š")
        
        return recommendations

    # ==================== è§„å¾‹åŒæ­¥æ¨¡å— ====================
    
    def sync_rule_to_total_library(self, rule_hash: str) -> Dict[str, Any]:
        """
        å°†å•ä¸ªè§„å¾‹ä»ç›´æ¥åº“åŒæ­¥åˆ°æ€»åº“
        
        Args:
            rule_hash: è§„å¾‹å†…å®¹å“ˆå¸Œ
            
        Returns:
            åŒæ­¥ç»“æœ
        """
        sync_result = {
            'success': False,
            'rule_hash': rule_hash,
            'action': None,  # 'created', 'updated', 'merged'
            'rule_id': None,
            'sync_details': {},
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # ä»ç›´æ¥åº“è·å–è§„å¾‹
            direct_rule = self.db_managers['direct_rules'].execute_query(
                "SELECT * FROM direct_rules WHERE content_hash = ?", (rule_hash,)
            )
            
            if not direct_rule:
                sync_result['error'] = f"ç›´æ¥åº“ä¸­æœªæ‰¾åˆ°è§„å¾‹ {rule_hash}"
                return sync_result
            
            rule = direct_rule[0]
            sync_result['rule_id'] = rule['rule_id']
            
            # æ£€æŸ¥æ€»åº“ä¸­æ˜¯å¦å­˜åœ¨ç›¸åŒè§„å¾‹
            existing_rule = self.db_managers['total_rules'].execute_query(
                "SELECT * FROM total_rules WHERE content_hash = ?", (rule_hash,)
            )
            
            if existing_rule:
                # è§„å¾‹å·²å­˜åœ¨ï¼Œæ‰§è¡Œåˆå¹¶æ›´æ–°
                merge_result = self._merge_rule_to_total(rule, existing_rule[0])
                sync_result['action'] = 'merged'
                sync_result['sync_details'] = merge_result
            else:
                # è§„å¾‹ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è®°å½•
                create_result = self._create_rule_in_total(rule)
                sync_result['action'] = 'created'
                sync_result['sync_details'] = create_result
            
            # æ›´æ–°ç›´æ¥åº“çš„åŒæ­¥çŠ¶æ€
            self.db_managers['direct_rules'].execute_update(
                "UPDATE direct_rules SET synced_to_total = 1, last_sync_time = ? WHERE rule_id = ?",
                (time.time(), rule['rule_id'])
            )
            
            sync_result['success'] = True
            sync_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… è§„å¾‹åŒæ­¥æˆåŠŸ: {rule['rule_id'][:8]}... â†’ {sync_result['action']}")
            
        except Exception as e:
            sync_result['error'] = str(e)
            logger.error(f"âŒ è§„å¾‹åŒæ­¥å¤±è´¥: {str(e)}")
        
        return sync_result
    
    def _merge_rule_to_total(self, direct_rule: dict, total_rule: dict) -> Dict[str, Any]:
        """
        åˆå¹¶è§„å¾‹åˆ°æ€»åº“
        
        Args:
            direct_rule: ç›´æ¥åº“è§„å¾‹
            total_rule: æ€»åº“è§„å¾‹
            
        Returns:
            åˆå¹¶ç»“æœ
        """
        merge_result = {
            'merged_fields': [],
            'statistics_updated': False,
            'discoverers_merged': False
        }
        
        try:
            # ç¡®ä¿è§„å¾‹å¯¹è±¡æ˜¯å­—å…¸æ ¼å¼
            if hasattr(direct_rule, 'keys'):
                direct_dict = dict(direct_rule)
            else:
                direct_dict = direct_rule
                
            if hasattr(total_rule, 'keys'):
                total_dict = dict(total_rule)
            else:
                total_dict = total_rule
            
            # åˆå¹¶ç»Ÿè®¡æ•°æ®
            new_support_count = total_dict['support_count'] + direct_dict['support_count']
            new_contradiction_count = total_dict['contradiction_count'] + direct_dict['contradiction_count']
            new_validation_count = total_dict['validation_count'] + direct_dict['validation_count']
            
            # è®¡ç®—æ–°çš„ç½®ä¿¡åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
            total_tests_old = total_dict['support_count'] + total_dict['contradiction_count']
            total_tests_new = direct_dict['support_count'] + direct_dict['contradiction_count']
            total_tests_combined = total_tests_old + total_tests_new
            
            if total_tests_combined > 0:
                # åŸºäºæµ‹è¯•æ¬¡æ•°çš„åŠ æƒå¹³å‡
                weight_old = total_tests_old / total_tests_combined
                weight_new = total_tests_new / total_tests_combined
                new_confidence = (total_dict['confidence'] * weight_old + 
                                direct_dict['confidence'] * weight_new)
            else:
                # å¦‚æœæ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨ç®€å•å¹³å‡
                new_confidence = (total_dict['confidence'] + direct_dict['confidence']) / 2
            
            # åˆå¹¶å‘ç°è€…åˆ—è¡¨
            total_discoverers = set(json.loads(total_dict.get('discoverers', '[]')))
            direct_discoverers = {direct_dict['creator_id']}
            merged_discoverers = list(total_discoverers.union(direct_discoverers))
            
            # ç¡®å®šéªŒè¯çŠ¶æ€ï¼ˆå–æ›´ä¸¥æ ¼çš„çŠ¶æ€ï¼‰
            status_priority = {'rejected': 0, 'pending': 1, 'validated': 2}
            current_status = total_dict['validation_status']
            new_status = direct_dict['validation_status']
            
            if status_priority.get(new_status, 1) < status_priority.get(current_status, 1):
                final_status = new_status
            else:
                final_status = current_status
            
            # æ›´æ–°æ€»åº“è®°å½•
            self.db_managers['total_rules'].execute_update("""
                UPDATE total_rules 
                SET support_count = ?,
                    contradiction_count = ?,
                    validation_count = ?,
                    confidence = ?,
                    discoverers = ?,
                    validation_status = ?,
                    occurrence_count = occurrence_count + 1,
                    last_updated = ?,
                    last_validated = CASE 
                        WHEN ? > last_validated THEN ? 
                        ELSE last_validated 
                    END
                WHERE rule_id = ?
            """, (
                new_support_count,
                new_contradiction_count,
                new_validation_count,
                new_confidence,
                json.dumps(merged_discoverers),
                final_status,
                time.time(),
                direct_dict.get('last_validated', 0),
                direct_dict.get('last_validated', 0),
                total_dict['rule_id']
            ))
            
            merge_result['merged_fields'] = [
                'support_count', 'contradiction_count', 'validation_count',
                'confidence', 'discoverers', 'validation_status'
            ]
            merge_result['statistics_updated'] = True
            merge_result['discoverers_merged'] = len(merged_discoverers) > len(total_discoverers)
            
            logger.debug(f"ğŸ”„ è§„å¾‹åˆå¹¶å®Œæˆ: {total_dict['rule_id'][:8]}...")
            
        except Exception as e:
            merge_result['error'] = str(e)
            logger.error(f"âŒ è§„å¾‹åˆå¹¶å¤±è´¥: {str(e)}")
        
        return merge_result
    
    def _create_rule_in_total(self, direct_rule: dict) -> Dict[str, Any]:
        """
        åœ¨æ€»åº“ä¸­åˆ›å»ºæ–°è§„å¾‹
        
        Args:
            direct_rule: ç›´æ¥åº“è§„å¾‹
            
        Returns:
            åˆ›å»ºç»“æœ
        """
        create_result = {
            'new_rule_id': None,
            'fields_copied': [],
            'created_successfully': False
        }
        
        try:
            # ç¡®ä¿direct_ruleæ˜¯å­—å…¸æ ¼å¼
            if hasattr(direct_rule, 'keys'):
                rule_dict = dict(direct_rule)
            else:
                rule_dict = direct_rule
            
            # ç”Ÿæˆæ–°çš„è§„å¾‹ID
            new_rule_id = f"TOTAL_{rule_dict['rule_type']}_{uuid.uuid4().hex[:12]}"
            
            # å‡†å¤‡æ’å…¥æ•°æ®
            insert_data = (
                new_rule_id,
                rule_dict['rule_type'],
                rule_dict['conditions'],
                rule_dict['predictions'],
                rule_dict['confidence'],
                rule_dict['support_count'],
                rule_dict['contradiction_count'],
                rule_dict['validation_count'],
                rule_dict['content_hash'],
                json.dumps([rule_dict['creator_id']]),  # å‘ç°è€…åˆ—è¡¨
                1,  # occurrence_count
                rule_dict['created_time'],
                time.time(),  # last_updated
                rule_dict.get('last_validated', 0),
                rule_dict['validation_status']
            )
            
            # æ’å…¥æ€»åº“
            self.db_managers['total_rules'].execute_update("""
                INSERT INTO total_rules (
                    rule_id, rule_type, conditions, predictions, confidence,
                    support_count, contradiction_count, validation_count, content_hash,
                    discoverers, occurrence_count, created_time, last_updated,
                    last_validated, validation_status
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, insert_data)
            
            create_result['new_rule_id'] = new_rule_id
            create_result['fields_copied'] = [
                'rule_type', 'conditions', 'predictions', 'confidence',
                'support_count', 'contradiction_count', 'validation_count',
                'content_hash', 'validation_status'
            ]
            create_result['created_successfully'] = True
            
            logger.debug(f"â• æ–°è§„å¾‹åˆ›å»º: {new_rule_id[:8]}...")
            
        except Exception as e:
            create_result['error'] = str(e)
            logger.error(f"âŒ è§„å¾‹åˆ›å»ºå¤±è´¥: {str(e)}")
        
        return create_result
    
    def batch_sync_rules_to_total(self, limit: int = 50) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥è§„å¾‹åˆ°æ€»åº“
        
        Args:
            limit: æ¯æ¬¡åŒæ­¥çš„æœ€å¤§è§„å¾‹æ•°é‡
            
        Returns:
            æ‰¹é‡åŒæ­¥ç»“æœ
        """
        batch_result = {
            'success': False,
            'total_processed': 0,
            'created_count': 0,
            'merged_count': 0,
            'failed_count': 0,
            'sync_details': [],
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # è·å–æœªåŒæ­¥çš„è§„å¾‹
            unsynced_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT content_hash, rule_id 
                FROM direct_rules 
                WHERE synced_to_total = 0 
                ORDER BY confidence DESC, support_count DESC
                LIMIT ?
            """, (limit,))
            
            logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡åŒæ­¥ {len(unsynced_rules)} æ¡è§„å¾‹")
            
            # é€ä¸ªåŒæ­¥
            for rule_info in unsynced_rules:
                sync_result = self.sync_rule_to_total_library(rule_info['content_hash'])
                
                batch_result['total_processed'] += 1
                
                if sync_result['success']:
                    if sync_result['action'] == 'created':
                        batch_result['created_count'] += 1
                    elif sync_result['action'] == 'merged':
                        batch_result['merged_count'] += 1
                else:
                    batch_result['failed_count'] += 1
                
                batch_result['sync_details'].append({
                    'rule_id': rule_info['rule_id'],
                    'action': sync_result.get('action', 'failed'),
                    'success': sync_result['success'],
                    'error': sync_result.get('error')
                })
                
                # æ¯å¤„ç†10ä¸ªè§„å¾‹è¾“å‡ºä¸€æ¬¡è¿›åº¦
                if batch_result['total_processed'] % 10 == 0:
                    logger.info(f"ğŸ“Š åŒæ­¥è¿›åº¦: {batch_result['total_processed']}/{len(unsynced_rules)}")
            
            batch_result['success'] = True
            batch_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… æ‰¹é‡åŒæ­¥å®Œæˆ: å¤„ç†={batch_result['total_processed']}, åˆ›å»º={batch_result['created_count']}, åˆå¹¶={batch_result['merged_count']}, å¤±è´¥={batch_result['failed_count']}")
            
        except Exception as e:
            batch_result['error'] = str(e)
            logger.error(f"âŒ æ‰¹é‡åŒæ­¥å¤±è´¥: {str(e)}")
        
        return batch_result
    
    def sync_all_direct_rules_to_total(self) -> Dict[str, int]:
        """
        æ‰¹é‡åŒæ­¥æ‰€æœ‰ç›´æ¥è§„å¾‹åˆ°æ€»è§„å¾‹åº“
        
        Returns:
            åŒæ­¥ç»Ÿè®¡ç»“æœ
        """
        sync_result = {
            'rules_synced': 0,
            'rules_updated': 0,
            'rules_failed': 0,
            'total_processed': 0
        }
        
        try:
            # è·å–æ‰€æœ‰æœªåŒæ­¥çš„ç›´æ¥è§„å¾‹
            unsynced_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT content_hash, rule_id 
                FROM direct_rules 
                WHERE synced_to_total = 0 
                ORDER BY confidence DESC, support_count DESC
            """)
            
            logger.info(f"ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰ç›´æ¥è§„å¾‹: {len(unsynced_rules)} æ¡")
            
            for rule_info in unsynced_rules:
                try:
                    # ä½¿ç”¨ç°æœ‰çš„å•ä¸ªè§„å¾‹åŒæ­¥æ–¹æ³•
                    single_sync_result = self.sync_rule_to_total_library(rule_info['content_hash'])
                    
                    sync_result['total_processed'] += 1
                    
                    if single_sync_result['success']:
                        if single_sync_result['action'] == 'created':
                            sync_result['rules_synced'] += 1
                        elif single_sync_result['action'] == 'merged':
                            sync_result['rules_updated'] += 1
                    else:
                        sync_result['rules_failed'] += 1
                        
                except Exception as e:
                    sync_result['rules_failed'] += 1
                    logger.error(f"âŒ åŒæ­¥è§„å¾‹å¤±è´¥ {rule_info['rule_id']}: {str(e)}")
            
            logger.info(f"âœ… è§„å¾‹åŒæ­¥å®Œæˆ: æ–°å¢={sync_result['rules_synced']}, æ›´æ–°={sync_result['rules_updated']}, å¤±è´¥={sync_result['rules_failed']}")
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åŒæ­¥è§„å¾‹å¤±è´¥: {str(e)}")
            sync_result['error'] = str(e)
        
        return sync_result
    
    def get_recent_experiences(self, limit: int = 5) -> List[Dict]:
        """
        è·å–æœ€è¿‘çš„ç›´æ¥ç»éªŒ
        
        Args:
            limit: è¿”å›çš„ç»éªŒæ•°é‡é™åˆ¶
            
        Returns:
            æœ€è¿‘çš„ç»éªŒåˆ—è¡¨
        """
        try:
            recent_experiences = self.db_managers['direct_experiences'].execute_query("""
                SELECT * FROM direct_experiences 
                ORDER BY timestamp DESC 
                LIMIT ?
            """, (limit,))
            
            return [dict(exp) for exp in recent_experiences]
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€è¿‘ç»éªŒå¤±è´¥: {str(e)}")
            return []
    
    def get_recent_rules(self, limit: int = 5) -> List[Dict]:
        """
        è·å–æœ€è¿‘çš„ç›´æ¥è§„å¾‹
        
        Args:
            limit: è¿”å›çš„è§„å¾‹æ•°é‡é™åˆ¶
            
        Returns:
            æœ€è¿‘çš„è§„å¾‹åˆ—è¡¨
        """
        try:
            recent_rules = self.db_managers['direct_rules'].execute_query("""
                SELECT * FROM direct_rules 
                ORDER BY created_time DESC 
                LIMIT ?
            """, (limit,))
            
            return [dict(rule) for rule in recent_rules]
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€è¿‘è§„å¾‹å¤±è´¥: {str(e)}")
            return []
    
    def get_rule_sync_statistics(self) -> Dict[str, Any]:
        """
        è·å–è§„å¾‹åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            'success': False,
            'direct_library': {},
            'total_library': {},
            'sync_status': {},
            'quality_metrics': {},
            'sync_recommendations': []
        }
        
        try:
            # ç›´æ¥åº“ç»Ÿè®¡
            direct_stats = self.db_managers['direct_rules'].execute_query("""
                SELECT 
                    COUNT(*) as total_rules,
                    COUNT(CASE WHEN synced_to_total = 1 THEN 1 END) as synced_rules,
                    COUNT(CASE WHEN synced_to_total = 0 THEN 1 END) as unsynced_rules,
                    AVG(confidence) as avg_confidence,
                    AVG(support_count) as avg_support,
                    COUNT(CASE WHEN validation_status = 'validated' THEN 1 END) as validated_rules
                FROM direct_rules
            """)[0]
            
            stats['direct_library'] = dict(direct_stats)
            
            # æ€»åº“ç»Ÿè®¡
            total_stats = self.db_managers['total_rules'].execute_query("""
                SELECT 
                    COUNT(*) as total_rules,
                    AVG(confidence) as avg_confidence,
                    AVG(support_count) as avg_support,
                    AVG(occurrence_count) as avg_occurrence,
                    COUNT(CASE WHEN validation_status = 'validated' THEN 1 END) as validated_rules,
                    SUM(occurrence_count) as total_occurrences
                FROM total_rules
            """)[0]
            
            stats['total_library'] = dict(total_stats)
            
            # åŒæ­¥çŠ¶æ€åˆ†æ
            sync_rate = (direct_stats['synced_rules'] / direct_stats['total_rules'] 
                        if direct_stats['total_rules'] > 0 else 0)
            
            stats['sync_status'] = {
                'sync_rate': sync_rate,
                'pending_sync': direct_stats['unsynced_rules'],
                'sync_efficiency': sync_rate * 100,
                'total_vs_direct_ratio': (total_stats['total_rules'] / direct_stats['total_rules'] 
                                        if direct_stats['total_rules'] > 0 else 0)
            }
            
            # è´¨é‡æŒ‡æ ‡å¯¹æ¯”
            stats['quality_metrics'] = {
                'confidence_improvement': (total_stats['avg_confidence'] - direct_stats['avg_confidence']
                                         if direct_stats['avg_confidence'] > 0 else 0),
                'support_consolidation': (total_stats['avg_support'] / direct_stats['avg_support']
                                        if direct_stats['avg_support'] > 0 else 1),
                'validation_rate_direct': (direct_stats['validated_rules'] / direct_stats['total_rules']
                                         if direct_stats['total_rules'] > 0 else 0),
                'validation_rate_total': (total_stats['validated_rules'] / total_stats['total_rules']
                                        if total_stats['total_rules'] > 0 else 0)
            }
            
            # ç”ŸæˆåŒæ­¥å»ºè®®
            stats['sync_recommendations'] = self._generate_sync_recommendations(stats)
            
            stats['success'] = True
            
        except Exception as e:
            stats['error'] = str(e)
            logger.error(f"âŒ è·å–åŒæ­¥ç»Ÿè®¡å¤±è´¥: {str(e)}")
        
        return stats
    
    def _generate_sync_recommendations(self, stats: dict) -> List[str]:
        """
        ç”ŸæˆåŒæ­¥å»ºè®®
        
        Args:
            stats: ç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        try:
            sync_status = stats.get('sync_status', {})
            direct_lib = stats.get('direct_library', {})
            total_lib = stats.get('total_library', {})
            quality = stats.get('quality_metrics', {})
            
            # åŸºäºåŒæ­¥ç‡çš„å»ºè®®
            sync_rate = sync_status.get('sync_rate', 0)
            if sync_rate < 0.5:
                recommendations.append("âš ï¸ åŒæ­¥ç‡è¿‡ä½ï¼Œå»ºè®®ç«‹å³æ‰§è¡Œæ‰¹é‡åŒæ­¥")
            elif sync_rate < 0.8:
                recommendations.append("ğŸ“Š åŒæ­¥ç‡ä¸­ç­‰ï¼Œå»ºè®®å®šæœŸæ‰§è¡ŒåŒæ­¥")
            else:
                recommendations.append("âœ… åŒæ­¥ç‡è‰¯å¥½ï¼Œä¿æŒå½“å‰åŒæ­¥é¢‘ç‡")
            
            # åŸºäºå¾…åŒæ­¥æ•°é‡çš„å»ºè®®
            pending_sync = sync_status.get('pending_sync', 0)
            if pending_sync > 50:
                recommendations.append(f"ğŸ”„ å¾…åŒæ­¥è§„å¾‹è¿‡å¤š({pending_sync}æ¡)ï¼Œå»ºè®®å¢åŠ åŒæ­¥é¢‘ç‡")
            elif pending_sync > 20:
                recommendations.append(f"ğŸ“ˆ æœ‰{pending_sync}æ¡è§„å¾‹å¾…åŒæ­¥ï¼Œå»ºè®®è¿‘æœŸæ‰§è¡ŒåŒæ­¥")
            
            # åŸºäºè´¨é‡æ”¹è¿›çš„å»ºè®®
            confidence_improvement = quality.get('confidence_improvement', 0)
            if confidence_improvement > 0.1:
                recommendations.append("ğŸ¯ æ€»åº“ç½®ä¿¡åº¦æ˜¾è‘—æå‡ï¼ŒåŒæ­¥æœºåˆ¶æœ‰æ•ˆ")
            elif confidence_improvement < -0.05:
                recommendations.append("âš ï¸ æ€»åº“ç½®ä¿¡åº¦ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥åˆå¹¶ç®—æ³•")
            
            # åŸºäºåº“å¤§å°æ¯”ä¾‹çš„å»ºè®®
            ratio = sync_status.get('total_vs_direct_ratio', 0)
            if ratio < 0.3:
                recommendations.append("ğŸ“Š æ€»åº“è§„å¾‹è¿‡å°‘ï¼Œå»ºè®®åŠ å¼ºåŒæ­¥å’Œå»é‡")
            elif ratio > 0.9:
                recommendations.append("ğŸ—‚ï¸ æ€»åº“è§„å¾‹æ¥è¿‘ç›´æ¥åº“ï¼Œå»é‡æ•ˆæœè‰¯å¥½")
            
            # åŸºäºéªŒè¯ç‡çš„å»ºè®®
            validation_rate_total = quality.get('validation_rate_total', 0)
            if validation_rate_total < 0.2:
                recommendations.append("ğŸ“‹ æ€»åº“éªŒè¯ç‡åä½ï¼Œå»ºè®®åŠ å¼ºè§„å¾‹éªŒè¯")
            elif validation_rate_total > 0.5:
                recommendations.append("âœ… æ€»åº“éªŒè¯ç‡è‰¯å¥½ï¼Œè§„å¾‹è´¨é‡è¾ƒé«˜")
            
        except Exception as e:
            recommendations.append(f"âŒ ç”Ÿæˆå»ºè®®æ—¶å‡ºé”™: {str(e)}")
        
        return recommendations
    
    def resolve_rule_sync_conflicts(self, content_hash: str) -> Dict[str, Any]:
        """
        è§£å†³è§„å¾‹åŒæ­¥å†²çª
        
        Args:
            content_hash: è§„å¾‹å†…å®¹å“ˆå¸Œ
            
        Returns:
            å†²çªè§£å†³ç»“æœ
        """
        conflict_result = {
            'success': False,
            'conflict_type': None,
            'resolution_action': None,
            'details': {}
        }
        
        try:
            # è·å–ç›´æ¥åº“å’Œæ€»åº“ä¸­çš„è§„å¾‹
            direct_rule = self.db_managers['direct_rules'].execute_query(
                "SELECT * FROM direct_rules WHERE content_hash = ?", (content_hash,)
            )
            
            total_rule = self.db_managers['total_rules'].execute_query(
                "SELECT * FROM total_rules WHERE content_hash = ?", (content_hash,)
            )
            
            if not direct_rule:
                conflict_result['error'] = "ç›´æ¥åº“ä¸­æœªæ‰¾åˆ°è§„å¾‹"
                return conflict_result
            
            if not total_rule:
                conflict_result['error'] = "æ€»åº“ä¸­æœªæ‰¾åˆ°è§„å¾‹ï¼Œæ— å†²çª"
                return conflict_result
            
            direct_rule = direct_rule[0]
            total_rule = total_rule[0]
            
            # æ£€æµ‹å†²çªç±»å‹
            conflicts = []
            
            # ç½®ä¿¡åº¦å†²çª
            conf_diff = abs(direct_rule['confidence'] - total_rule['confidence'])
            if conf_diff > 0.2:
                conflicts.append('confidence_mismatch')
            
            # éªŒè¯çŠ¶æ€å†²çª
            if direct_rule['validation_status'] != total_rule['validation_status']:
                conflicts.append('status_mismatch')
            
            # ç»Ÿè®¡æ•°æ®å¼‚å¸¸
            if (direct_rule['support_count'] > total_rule['support_count'] or
                direct_rule['contradiction_count'] > total_rule['contradiction_count']):
                conflicts.append('statistics_inconsistency')
            
            if not conflicts:
                conflict_result['success'] = True
                conflict_result['conflict_type'] = 'no_conflict'
                conflict_result['resolution_action'] = 'none_needed'
                return conflict_result
            
            # è§£å†³å†²çª
            conflict_result['conflict_type'] = conflicts
            
            if 'statistics_inconsistency' in conflicts:
                # é‡æ–°åˆå¹¶ç»Ÿè®¡æ•°æ®
                merge_result = self._merge_rule_to_total(direct_rule, total_rule)
                conflict_result['resolution_action'] = 'statistics_remerged'
                conflict_result['details'] = merge_result
            
            elif 'status_mismatch' in conflicts:
                # é‡‡ç”¨æ›´ä¿å®ˆçš„çŠ¶æ€
                status_priority = {'rejected': 0, 'pending': 1, 'validated': 2}
                if (status_priority.get(direct_rule['validation_status'], 1) < 
                    status_priority.get(total_rule['validation_status'], 1)):
                    
                    self.db_managers['total_rules'].execute_update(
                        "UPDATE total_rules SET validation_status = ? WHERE rule_id = ?",
                        (direct_rule['validation_status'], total_rule['rule_id'])
                    )
                    conflict_result['resolution_action'] = 'status_updated'
            
            elif 'confidence_mismatch' in conflicts:
                # é‡æ–°è®¡ç®—ç½®ä¿¡åº¦
                merge_result = self._merge_rule_to_total(direct_rule, total_rule)
                conflict_result['resolution_action'] = 'confidence_recalculated'
                conflict_result['details'] = merge_result
            
            conflict_result['success'] = True
            
            logger.info(f"ğŸ”§ å†²çªè§£å†³å®Œæˆ: {content_hash[:8]}... - {conflict_result['resolution_action']}")
            
        except Exception as e:
            conflict_result['error'] = str(e)
            logger.error(f"âŒ å†²çªè§£å†³å¤±è´¥: {str(e)}")
        
        return conflict_result

    def close(self):
        """å…³é—­äº”åº“ç³»ç»Ÿ"""
        logger.info("ğŸ”’ äº”åº“ç³»ç»Ÿå·²å…³é—­")

    # ==================== å†³ç­–åº“ç®¡ç†æ¨¡å— ====================
    
    def generate_decision_from_context(self, context: Dict[str, Any], source: str = 'rule_based') -> Dict[str, Any]:
        """
        åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå†³ç­–
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            source: å†³ç­–æ¥æº ('rule_based', 'experience_based', 'hybrid')
            
        Returns:
            å†³ç­–ç”Ÿæˆç»“æœ
        """
        decision_result = {
            'success': False,
            'decision': None,
            'confidence': 0.0,
            'reasoning': [],
            'alternatives': [],
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # éªŒè¯ä¸Šä¸‹æ–‡
            if not context or not isinstance(context, dict):
                decision_result['error'] = "æ— æ•ˆçš„å†³ç­–ä¸Šä¸‹æ–‡"
                return decision_result
            
            # æ ¹æ®æ¥æºé€‰æ‹©å†³ç­–ç”Ÿæˆç­–ç•¥
            if source == 'rule_based':
                decision_result = self._generate_rule_based_decision(context)
            elif source == 'experience_based':
                decision_result = self._generate_experience_based_decision(context)
            elif source == 'hybrid':
                decision_result = self._generate_hybrid_decision(context)
            else:
                decision_result['error'] = f"ä¸æ”¯æŒçš„å†³ç­–æ¥æº: {source}"
                return decision_result
            
            decision_result['processing_time'] = time.time() - start_time
            
            # å¦‚æœç”ŸæˆæˆåŠŸï¼Œæ·»åŠ åˆ°å†³ç­–åº“
            if decision_result['success'] and decision_result['decision']:
                add_result = self.add_decision_to_library(decision_result['decision'])
                decision_result['added_to_library'] = add_result['success']
                decision_result['decision_id'] = add_result.get('decision_id')
            
            logger.info(f"âœ… å†³ç­–ç”Ÿæˆå®Œæˆ: {source} - ç½®ä¿¡åº¦{decision_result['confidence']:.3f}")
            
        except Exception as e:
            decision_result['error'] = str(e)
            logger.error(f"âŒ å†³ç­–ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return decision_result
    
    def _generate_rule_based_decision(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸºäºè§„å¾‹ç”Ÿæˆå†³ç­–
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        result = {
            'success': False,
            'decision': None,
            'confidence': 0.0,
            'reasoning': [],
            'alternatives': []
        }
        
        try:
            # æŸ¥æ‰¾åŒ¹é…çš„è§„å¾‹
            matching_rules = self._find_matching_rules(context)
            
            if not matching_rules:
                result['reasoning'].append("æœªæ‰¾åˆ°åŒ¹é…çš„è§„å¾‹")
                return result
            
            # æŒ‰ç½®ä¿¡åº¦æ’åºè§„å¾‹
            matching_rules.sort(key=lambda x: x['confidence'], reverse=True)
            
            # é€‰æ‹©æœ€ä½³è§„å¾‹
            best_rule = matching_rules[0]
            predictions = json.loads(best_rule['predictions'])
            
            # ç”Ÿæˆå†³ç­–
            if 'result' in predictions:
                action = f"æ‰§è¡Œä»¥è·å¾—: {predictions['result']}"
            elif 'success' in predictions:
                success_prob = predictions['success']
                if success_prob:
                    action = "æ‰§è¡Œè¯¥è¡ŒåŠ¨ï¼ˆé«˜æˆåŠŸæ¦‚ç‡ï¼‰"
                else:
                    action = "é¿å…è¯¥è¡ŒåŠ¨ï¼ˆä½æˆåŠŸæ¦‚ç‡ï¼‰"
            else:
                action = "åŸºäºè§„å¾‹æ‰§è¡Œæ¨èè¡ŒåŠ¨"
            
            # åˆ›å»ºå†³ç­–å¯¹è±¡
            decision = Decision(
                decision_id=f"RULE_{uuid.uuid4().hex[:12]}",
                context=context,
                action=action,
                confidence=best_rule['confidence'],
                source='rule_based'
            )
            
            result['success'] = True
            result['decision'] = decision
            result['confidence'] = best_rule['confidence']
            result['reasoning'].append(f"åŸºäºè§„å¾‹ {best_rule['rule_id'][:8]}...")
            result['reasoning'].append(f"è§„å¾‹ç½®ä¿¡åº¦: {best_rule['confidence']:.3f}")
            result['reasoning'].append(f"è§„å¾‹æ”¯æŒåº¦: {best_rule['support_count']}")
            
            # æ·»åŠ å¤‡é€‰æ–¹æ¡ˆ
            for rule in matching_rules[1:3]:  # æœ€å¤š3ä¸ªå¤‡é€‰
                alt_predictions = json.loads(rule['predictions'])
                if 'result' in alt_predictions:
                    alt_action = f"å¤‡é€‰: æ‰§è¡Œä»¥è·å¾— {alt_predictions['result']}"
                else:
                    alt_action = "å¤‡é€‰: åŸºäºæ¬¡ä¼˜è§„å¾‹çš„è¡ŒåŠ¨"
                
                result['alternatives'].append({
                    'action': alt_action,
                    'confidence': rule['confidence'],
                    'rule_id': rule['rule_id']
                })
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ åŸºäºè§„å¾‹çš„å†³ç­–ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return result
    
    def _generate_experience_based_decision(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸºäºç»éªŒç”Ÿæˆå†³ç­–
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        result = {
            'success': False,
            'decision': None,
            'confidence': 0.0,
            'reasoning': [],
            'alternatives': []
        }
        
        try:
            # æŸ¥æ‰¾ç›¸ä¼¼ç»éªŒ
            similar_experiences = self._find_similar_experiences(context)
            
            if not similar_experiences:
                result['reasoning'].append("æœªæ‰¾åˆ°ç›¸ä¼¼çš„å†å²ç»éªŒ")
                return result
            
            # åˆ†æç»éªŒæ¨¡å¼
            action_stats = {}
            for exp in similar_experiences:
                action = exp['action']
                if action not in action_stats:
                    action_stats[action] = {
                        'total_count': 0,
                        'success_count': 0,
                        'avg_success_rate': 0.0,
                        'results': []
                    }
                
                stats = action_stats[action]
                stats['total_count'] += exp['occurrence_count']
                stats['success_count'] += exp['success_count']
                stats['results'].append(exp['result'])
                stats['avg_success_rate'] = stats['success_count'] / stats['total_count']
            
            # é€‰æ‹©æœ€ä½³è¡ŒåŠ¨
            if action_stats:
                best_action = max(action_stats.items(), key=lambda x: x[1]['avg_success_rate'])
                action_name, action_data = best_action
                
                # åˆ›å»ºå†³ç­–å¯¹è±¡
                decision = Decision(
                    decision_id=f"EXP_{uuid.uuid4().hex[:12]}",
                    context=context,
                    action=f"æ‰§è¡Œè¡ŒåŠ¨: {action_name}",
                    confidence=action_data['avg_success_rate'],
                    source='experience_based'
                )
                
                result['success'] = True
                result['decision'] = decision
                result['confidence'] = action_data['avg_success_rate']
                result['reasoning'].append(f"åŸºäº {len(similar_experiences)} æ¡ç›¸ä¼¼ç»éªŒ")
                result['reasoning'].append(f"è¡ŒåŠ¨ '{action_name}' æˆåŠŸç‡: {action_data['avg_success_rate']:.3f}")
                result['reasoning'].append(f"å†å²æ‰§è¡Œæ¬¡æ•°: {action_data['total_count']}")
                
                # æ·»åŠ å¤‡é€‰æ–¹æ¡ˆ
                sorted_actions = sorted(action_stats.items(), key=lambda x: x[1]['avg_success_rate'], reverse=True)
                for action_name, action_data in sorted_actions[1:3]:
                    result['alternatives'].append({
                        'action': f"å¤‡é€‰: {action_name}",
                        'confidence': action_data['avg_success_rate'],
                        'experience_count': action_data['total_count']
                    })
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ åŸºäºç»éªŒçš„å†³ç­–ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return result
    
    def _generate_hybrid_decision(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ··åˆç­–ç•¥ç”Ÿæˆå†³ç­–
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        result = {
            'success': False,
            'decision': None,
            'confidence': 0.0,
            'reasoning': [],
            'alternatives': []
        }
        
        try:
            # è·å–åŸºäºè§„å¾‹çš„å†³ç­–
            rule_result = self._generate_rule_based_decision(context)
            
            # è·å–åŸºäºç»éªŒçš„å†³ç­–
            exp_result = self._generate_experience_based_decision(context)
            
            # æ··åˆå†³ç­–é€»è¾‘
            if rule_result['success'] and exp_result['success']:
                # ä¸¤ç§æ–¹æ³•éƒ½æˆåŠŸï¼Œé€‰æ‹©ç½®ä¿¡åº¦æ›´é«˜çš„
                if rule_result['confidence'] >= exp_result['confidence']:
                    primary_result = rule_result
                    secondary_result = exp_result
                    primary_source = "è§„å¾‹"
                    secondary_source = "ç»éªŒ"
                else:
                    primary_result = exp_result
                    secondary_result = rule_result
                    primary_source = "ç»éªŒ"
                    secondary_source = "è§„å¾‹"
                
                # è®¡ç®—æ··åˆç½®ä¿¡åº¦
                weight_primary = 0.7
                weight_secondary = 0.3
                hybrid_confidence = (primary_result['confidence'] * weight_primary + 
                                   secondary_result['confidence'] * weight_secondary)
                
                # åˆ›å»ºæ··åˆå†³ç­–
                decision = Decision(
                    decision_id=f"HYBRID_{uuid.uuid4().hex[:12]}",
                    context=context,
                    action=primary_result['decision'].action,
                    confidence=hybrid_confidence,
                    source='hybrid'
                )
                
                result['success'] = True
                result['decision'] = decision
                result['confidence'] = hybrid_confidence
                result['reasoning'].append(f"æ··åˆå†³ç­–: ä¸»è¦åŸºäº{primary_source}")
                result['reasoning'].extend(primary_result['reasoning'])
                result['reasoning'].append(f"è¾…åŠ©éªŒè¯: {secondary_source}ç½®ä¿¡åº¦{secondary_result['confidence']:.3f}")
                
                # åˆå¹¶å¤‡é€‰æ–¹æ¡ˆ
                result['alternatives'].extend(primary_result['alternatives'])
                if secondary_result['decision']:
                    result['alternatives'].append({
                        'action': f"å¤‡é€‰({secondary_source}): {secondary_result['decision'].action}",
                        'confidence': secondary_result['confidence'],
                        'source': secondary_source
                    })
                
            elif rule_result['success']:
                # åªæœ‰è§„å¾‹æ–¹æ³•æˆåŠŸ
                result = rule_result
                result['reasoning'].append("ä»…åŸºäºè§„å¾‹ç”Ÿæˆï¼ˆæ— åŒ¹é…ç»éªŒï¼‰")
                
            elif exp_result['success']:
                # åªæœ‰ç»éªŒæ–¹æ³•æˆåŠŸ
                result = exp_result
                result['reasoning'].append("ä»…åŸºäºç»éªŒç”Ÿæˆï¼ˆæ— åŒ¹é…è§„å¾‹ï¼‰")
                
            else:
                # ä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥
                result['reasoning'].append("è§„å¾‹å’Œç»éªŒæ–¹æ³•å‡æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
                result['reasoning'].extend(rule_result.get('reasoning', []))
                result['reasoning'].extend(exp_result.get('reasoning', []))
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"âŒ æ··åˆå†³ç­–ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return result
    
    def _find_matching_rules(self, context: Dict[str, Any]) -> List[dict]:
        """
        æŸ¥æ‰¾åŒ¹é…ä¸Šä¸‹æ–‡çš„è§„å¾‹
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ¹é…çš„è§„å¾‹åˆ—è¡¨
        """
        matching_rules = []
        
        try:
            # ä»æ€»è§„å¾‹åº“æŸ¥æ‰¾
            all_rules = self.db_managers['total_rules'].execute_query("""
                SELECT * FROM total_rules 
                WHERE validation_status != 'rejected'
                ORDER BY confidence DESC, support_count DESC
            """)
            
            for rule in all_rules:
                conditions = json.loads(rule['conditions'])
                
                # æ£€æŸ¥æ¡ä»¶åŒ¹é…
                match_score = 0
                total_conditions = len(conditions)
                
                for key, value in conditions.items():
                    if key in context and context[key] == value:
                        match_score += 1
                
                # å¦‚æœåŒ¹é…åº¦è¶…è¿‡é˜ˆå€¼ï¼Œæ·»åŠ åˆ°ç»“æœ
                if total_conditions > 0 and match_score / total_conditions >= 0.8:
                    rule_dict = dict(rule)
                    rule_dict['match_score'] = match_score / total_conditions
                    matching_rules.append(rule_dict)
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾åŒ¹é…è§„å¾‹å¤±è´¥: {str(e)}")
        
        return matching_rules
    
    def _find_similar_experiences(self, context: Dict[str, Any]) -> List[dict]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼çš„å†å²ç»éªŒ
        
        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            ç›¸ä¼¼ç»éªŒåˆ—è¡¨
        """
        similar_experiences = []
        
        try:
            # ä»æ€»ç»éªŒåº“æŸ¥æ‰¾
            all_experiences = self.db_managers['total_experiences'].execute_query("""
                SELECT * FROM total_experiences 
                WHERE occurrence_count >= 2
                ORDER BY avg_success_rate DESC, occurrence_count DESC
            """)
            
            for exp in all_experiences:
                similarity_score = 0
                total_fields = 0
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                for field in ['environment', 'object', 'characteristics', 'action', 'tools']:
                    if field in context:
                        total_fields += 1
                        if exp[field] == context[field]:
                            similarity_score += 1
                
                # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼Œæ·»åŠ åˆ°ç»“æœ
                if total_fields > 0 and similarity_score / total_fields >= 0.6:
                    exp_dict = dict(exp)
                    exp_dict['similarity_score'] = similarity_score / total_fields
                    similar_experiences.append(exp_dict)
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾ç›¸ä¼¼ç»éªŒå¤±è´¥: {str(e)}")
        
        return similar_experiences
    
    def add_decision_to_library(self, decision: Decision) -> Dict[str, Any]:
        """
        æ·»åŠ å†³ç­–åˆ°å†³ç­–åº“
        
        Args:
            decision: å†³ç­–å¯¹è±¡
            
        Returns:
            æ·»åŠ ç»“æœ
        """
        add_result = {
            'success': False,
            'decision_id': None,
            'action': None,  # 'added', 'updated'
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
            content_hash = decision.generate_hash()
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_decision = self.db_managers['decisions'].execute_query(
                "SELECT * FROM decisions WHERE content_hash = ?", (content_hash,)
            )
            
            if existing_decision:
                # æ›´æ–°ç°æœ‰å†³ç­–
                existing = existing_decision[0]
                self.db_managers['decisions'].execute_update("""
                    UPDATE decisions 
                    SET total_uses = total_uses + 1,
                        last_used = ?,
                        updated_time = ?
                    WHERE decision_id = ?
                """, (time.time(), time.time(), existing['decision_id']))
                
                add_result['action'] = 'updated'
                add_result['decision_id'] = existing['decision_id']
                
            else:
                # æ·»åŠ æ–°å†³ç­–
                decision_data = decision.to_dict()
                decision_data['content_hash'] = content_hash
                
                self.db_managers['decisions'].execute_update("""
                    INSERT INTO decisions (
                        decision_id, content_hash, context, action, confidence,
                        source, success_count, failure_count, total_uses,
                        created_time, last_used, avg_success_rate, emrs_score
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    decision.decision_id,
                    content_hash,
                    decision_data['context'],
                    decision.action,
                    decision.confidence,
                    decision.source,
                    decision.success_count,
                    decision.failure_count,
                    decision.total_uses,
                    decision.created_time,
                    decision.last_used,
                    0.0,  # avg_success_rate
                    0.0   # emrs_score
                ))
                
                add_result['action'] = 'added'
                add_result['decision_id'] = decision.decision_id
            
            add_result['success'] = True
            add_result['processing_time'] = time.time() - start_time
            
            logger.debug(f"âœ… å†³ç­–{add_result['action']}: {add_result['decision_id'][:8]}...")
            
        except Exception as e:
            add_result['error'] = str(e)
            logger.error(f"âŒ æ·»åŠ å†³ç­–å¤±è´¥: {str(e)}")
        
        return add_result
    
    def query_decisions(self, context: Dict[str, Any] = None, limit: int = 10) -> Dict[str, Any]:
        """
        æŸ¥è¯¢å†³ç­–åº“
        
        Args:
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        query_result = {
            'success': False,
            'decisions': [],
            'total_count': 0,
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            if context:
                # åŸºäºä¸Šä¸‹æ–‡çš„ç›¸ä¼¼åº¦æŸ¥è¯¢
                all_decisions = self.db_managers['decisions'].execute_query("""
                    SELECT * FROM decisions 
                    ORDER BY confidence DESC, avg_success_rate DESC, total_uses DESC
                """)
                
                scored_decisions = []
                for decision in all_decisions:
                    decision_context = json.loads(decision['context'])
                    similarity = self._calculate_context_similarity(context, decision_context)
                    
                    if similarity >= 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                        decision_dict = dict(decision)
                        decision_dict['similarity_score'] = similarity
                        scored_decisions.append(decision_dict)
                
                # æŒ‰ç›¸ä¼¼åº¦å’Œç½®ä¿¡åº¦æ’åº
                scored_decisions.sort(key=lambda x: (x['similarity_score'], x['confidence']), reverse=True)
                query_result['decisions'] = scored_decisions[:limit]
                
            else:
                # é€šç”¨æŸ¥è¯¢
                decisions = self.db_managers['decisions'].execute_query("""
                    SELECT * FROM decisions 
                    ORDER BY confidence DESC, avg_success_rate DESC, total_uses DESC
                    LIMIT ?
                """, (limit,))
                
                query_result['decisions'] = [dict(d) for d in decisions]
            
            query_result['total_count'] = len(query_result['decisions'])
            query_result['success'] = True
            query_result['processing_time'] = time.time() - start_time
            
            logger.debug(f"âœ… å†³ç­–æŸ¥è¯¢å®Œæˆ: è¿”å›{query_result['total_count']}æ¡ç»“æœ")
            
        except Exception as e:
            query_result['error'] = str(e)
            logger.error(f"âŒ å†³ç­–æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        return query_result
    
    def _calculate_context_similarity(self, context1: Dict, context2: Dict) -> float:
        """
        è®¡ç®—ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦
        
        Args:
            context1: ä¸Šä¸‹æ–‡1
            context2: ä¸Šä¸‹æ–‡2
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        if not context1 or not context2:
            return 0.0
        
        all_keys = set(context1.keys()) | set(context2.keys())
        if not all_keys:
            return 0.0
        
        matching_keys = 0
        for key in all_keys:
            if key in context1 and key in context2:
                if context1[key] == context2[key]:
                    matching_keys += 1
        
        return matching_keys / len(all_keys)
    
    def update_decision_feedback(self, decision_id: str, success: bool, result: str = None) -> Dict[str, Any]:
        """
        æ›´æ–°å†³ç­–åé¦ˆ
        
        Args:
            decision_id: å†³ç­–ID
            success: æ˜¯å¦æˆåŠŸ
            result: æ‰§è¡Œç»“æœï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ›´æ–°ç»“æœ
        """
        update_result = {
            'success': False,
            'decision_id': decision_id,
            'updated_metrics': {},
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # è·å–ç°æœ‰å†³ç­–
            decision = self.db_managers['decisions'].execute_query(
                "SELECT * FROM decisions WHERE decision_id = ?", (decision_id,)
            )
            
            if not decision:
                update_result['error'] = f"å†³ç­– {decision_id} ä¸å­˜åœ¨"
                return update_result
            
            decision = decision[0]
            
            # æ›´æ–°ç»Ÿè®¡æ•°æ®
            new_total_uses = decision['total_uses'] + 1
            if success:
                new_success_count = decision['success_count'] + 1
                new_failure_count = decision['failure_count']
            else:
                new_success_count = decision['success_count']
                new_failure_count = decision['failure_count'] + 1
            
            # è®¡ç®—æ–°çš„å¹³å‡æˆåŠŸç‡
            new_avg_success_rate = new_success_count / new_total_uses if new_total_uses > 0 else 0.0
            
            # è®¡ç®—EMRSåˆ†æ•°ï¼ˆç»éªŒ-è®°å¿†-æ¨ç†-æˆåŠŸç‡ï¼‰
            confidence_weight = 0.3
            usage_weight = 0.2
            success_weight = 0.5
            
            normalized_usage = min(new_total_uses / 10.0, 1.0)  # å½’ä¸€åŒ–ä½¿ç”¨æ¬¡æ•°
            new_emrs_score = (decision['confidence'] * confidence_weight + 
                            normalized_usage * usage_weight + 
                            new_avg_success_rate * success_weight)
            
            # æ›´æ–°æ•°æ®åº“
            self.db_managers['decisions'].execute_update("""
                UPDATE decisions 
                SET success_count = ?,
                    failure_count = ?,
                    total_uses = ?,
                    avg_success_rate = ?,
                    emrs_score = ?,
                    last_used = ?,
                    updated_time = ?
                WHERE decision_id = ?
            """, (
                new_success_count,
                new_failure_count,
                new_total_uses,
                new_avg_success_rate,
                new_emrs_score,
                time.time(),
                time.time(),
                decision_id
            ))
            
            update_result['success'] = True
            update_result['updated_metrics'] = {
                'total_uses': new_total_uses,
                'success_count': new_success_count,
                'failure_count': new_failure_count,
                'avg_success_rate': new_avg_success_rate,
                'emrs_score': new_emrs_score
            }
            update_result['processing_time'] = time.time() - start_time
            
            logger.info(f"âœ… å†³ç­–åé¦ˆæ›´æ–°: {decision_id[:8]}... - æˆåŠŸç‡{new_avg_success_rate:.3f}")
            
        except Exception as e:
            update_result['error'] = str(e)
            logger.error(f"âŒ å†³ç­–åé¦ˆæ›´æ–°å¤±è´¥: {str(e)}")
        
        return update_result
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """
        è·å–å†³ç­–åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            'success': False,
            'total_decisions': 0,
            'by_source': {},
            'performance_metrics': {},
            'top_decisions': [],
            'recommendations': []
        }
        
        try:
            # åŸºæœ¬ç»Ÿè®¡
            total_result = self.db_managers['decisions'].execute_query(
                "SELECT COUNT(*) as count FROM decisions"
            )
            stats['total_decisions'] = total_result[0]['count'] if total_result else 0
            
            # æŒ‰æ¥æºåˆ†ç±»ç»Ÿè®¡
            source_stats = self.db_managers['decisions'].execute_query("""
                SELECT source, 
                       COUNT(*) as count,
                       AVG(confidence) as avg_confidence,
                       AVG(avg_success_rate) as avg_success_rate,
                       AVG(emrs_score) as avg_emrs_score
                FROM decisions 
                GROUP BY source
            """)
            
            for stat in source_stats:
                stats['by_source'][stat['source']] = dict(stat)
            
            # æ€§èƒ½æŒ‡æ ‡
            performance = self.db_managers['decisions'].execute_query("""
                SELECT AVG(confidence) as avg_confidence,
                       AVG(avg_success_rate) as avg_success_rate,
                       AVG(emrs_score) as avg_emrs_score,
                       AVG(total_uses) as avg_usage,
                       COUNT(CASE WHEN avg_success_rate >= 0.7 THEN 1 END) as high_performance_count,
                       COUNT(CASE WHEN total_uses >= 5 THEN 1 END) as well_tested_count
                FROM decisions
            """)[0]
            
            # å¤„ç†Noneå€¼
            performance_dict = dict(performance)
            for key, value in performance_dict.items():
                if value is None:
                    performance_dict[key] = 0.0
            
            stats['performance_metrics'] = performance_dict
            
            # é¡¶çº§å†³ç­–
            top_decisions = self.db_managers['decisions'].execute_query("""
                SELECT decision_id, action, confidence, avg_success_rate, emrs_score, total_uses
                FROM decisions 
                ORDER BY emrs_score DESC, avg_success_rate DESC
                LIMIT 5
            """)
            
            stats['top_decisions'] = [dict(d) for d in top_decisions]
            
            # ç”Ÿæˆå»ºè®®
            stats['recommendations'] = self._generate_decision_recommendations(stats)
            
            stats['success'] = True
            
        except Exception as e:
            stats['error'] = str(e)
            logger.error(f"âŒ è·å–å†³ç­–ç»Ÿè®¡å¤±è´¥: {str(e)}")
        
        return stats
    
    def _generate_decision_recommendations(self, stats: dict) -> List[str]:
        """
        ç”Ÿæˆå†³ç­–åº“å»ºè®®
        
        Args:
            stats: ç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        try:
            total_decisions = stats.get('total_decisions', 0)
            performance = stats.get('performance_metrics', {})
            
            # åŸºäºå†³ç­–æ•°é‡çš„å»ºè®®
            if total_decisions < 10:
                recommendations.append("ğŸ“Š å†³ç­–åº“è§„æ¨¡è¾ƒå°ï¼Œå»ºè®®å¢åŠ æ›´å¤šå†³ç­–ç”Ÿæˆ")
            elif total_decisions > 1000:
                recommendations.append("ğŸ—‚ï¸ å†³ç­–åº“è§„æ¨¡è¾ƒå¤§ï¼Œå»ºè®®å®šæœŸæ¸…ç†ä½æ•ˆå†³ç­–")
            
            # åŸºäºæ€§èƒ½æŒ‡æ ‡çš„å»ºè®®
            avg_success_rate = performance.get('avg_success_rate', 0)
            if avg_success_rate < 0.5:
                recommendations.append("âš ï¸ å¹³å‡æˆåŠŸç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–å†³ç­–ç”Ÿæˆç®—æ³•")
            elif avg_success_rate > 0.8:
                recommendations.append("âœ… å¹³å‡æˆåŠŸç‡è‰¯å¥½ï¼Œå†³ç­–è´¨é‡è¾ƒé«˜")
            
            # åŸºäºä½¿ç”¨æƒ…å†µçš„å»ºè®®
            avg_usage = performance.get('avg_usage', 0)
            if avg_usage < 2:
                recommendations.append("ğŸ“ˆ å†³ç­–ä½¿ç”¨é¢‘ç‡è¾ƒä½ï¼Œå»ºè®®åŠ å¼ºå†³ç­–æ¨è")
            
            # åŸºäºæ¥æºåˆ†å¸ƒçš„å»ºè®®
            by_source = stats.get('by_source', {})
            if len(by_source) == 1:
                recommendations.append("ğŸ”„ å†³ç­–æ¥æºå•ä¸€ï¼Œå»ºè®®å¯ç”¨æ··åˆå†³ç­–ç­–ç•¥")
            
            # åŸºäºé«˜æ€§èƒ½å†³ç­–æ¯”ä¾‹çš„å»ºè®®
            high_perf_count = performance.get('high_performance_count', 0)
            if total_decisions > 0:
                high_perf_ratio = high_perf_count / total_decisions
                if high_perf_ratio < 0.3:
                    recommendations.append("ğŸ¯ é«˜æ€§èƒ½å†³ç­–æ¯”ä¾‹åä½ï¼Œå»ºè®®åŠ å¼ºå†³ç­–éªŒè¯")
                elif high_perf_ratio > 0.7:
                    recommendations.append("ğŸ† é«˜æ€§èƒ½å†³ç­–æ¯”ä¾‹è‰¯å¥½ï¼Œç³»ç»Ÿè¿è¡Œç¨³å®š")
            
        except Exception as e:
            recommendations.append(f"âŒ ç”Ÿæˆå»ºè®®æ—¶å‡ºé”™: {str(e)}")
        
        return recommendations

    def close(self):
        """å…³é—­ç³»ç»Ÿèµ„æº"""
        # æ¸…ç†ç¼“å­˜
        self.cache.clear()
        logger.info("ğŸ”’ äº”åº“ç³»ç»Ÿå·²å…³é—­")

    # ========== å¯¹è±¡å±æ€§éªŒè¯å’Œå·¥å…·æœ‰æ•ˆæ€§åˆ†æ ==========
    
    def validate_object_attributes(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        éªŒè¯ç»éªŒä¸­çš„å¯¹è±¡å±æ€§æ˜¯å¦ç¬¦åˆé…ç½®
        
        Args:
            experience: EOCATRç»éªŒå¯¹è±¡
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        result = {
            'valid': True,
            'warnings': [],
            'errors': [],
            'suggestions': [],
            'object_info': {},
            'tool_effectiveness': None
        }
        
        if not self.object_config_enabled:
            result['warnings'].append("å¯¹è±¡å±æ€§é…ç½®ç³»ç»Ÿæœªå¯ç”¨ï¼Œè·³è¿‡éªŒè¯")
            return result
        
        try:
            # éªŒè¯å¯¹è±¡æ˜¯å¦å­˜åœ¨
            object_attrs = get_object_attributes(experience.object)
            if not object_attrs:
                result['errors'].append(f"æœªçŸ¥å¯¹è±¡: {experience.object}")
                result['valid'] = False
            else:
                result['object_info'] = object_attrs
                
                # éªŒè¯ç‰¹å¾æ˜¯å¦åŒ¹é…
                if experience.characteristics:
                    self._validate_object_characteristics(experience, object_attrs, result)
                
                # éªŒè¯ç¯å¢ƒå…¼å®¹æ€§
                if experience.environment:
                    self._validate_environment_compatibility(experience, result)
            
            # åˆ†æå·¥å…·æœ‰æ•ˆæ€§
            if experience.tools and experience.object:
                self._analyze_tool_effectiveness(experience, result)
            
            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            self._generate_attribute_suggestions(experience, result)
            
        except Exception as e:
            result['errors'].append(f"å¯¹è±¡å±æ€§éªŒè¯å¤±è´¥: {str(e)}")
            result['valid'] = False
            logger.error(f"å¯¹è±¡å±æ€§éªŒè¯å¼‚å¸¸: {e}")
        
        return result
    
    def _validate_object_characteristics(self, experience: EOCATRExperience, object_attrs: Dict, result: Dict):
        """éªŒè¯å¯¹è±¡ç‰¹å¾"""
        characteristics = experience.characteristics.split(',') if ',' in experience.characteristics else [experience.characteristics]
        
        for char in characteristics:
            char = char.strip()
            if char:
                # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åœ¨å¯¹è±¡å±æ€§ä¸­
                found = False
                for attr_name, attr_value in object_attrs.items():
                    if isinstance(attr_value, str) and char in attr_value:
                        found = True
                        break
                    elif str(attr_value) == char:
                        found = True
                        break
                
                if not found:
                    result['warnings'].append(f"ç‰¹å¾ '{char}' å¯èƒ½ä¸åŒ¹é…å¯¹è±¡ '{experience.object}'")
    
    def _validate_environment_compatibility(self, experience: EOCATRExperience, result: Dict):
        """éªŒè¯ç¯å¢ƒå…¼å®¹æ€§"""
        if experience.environment in ENVIRONMENT_TYPES:
            env_info = ENVIRONMENT_TYPES[experience.environment]
            result['object_info']['environment_info'] = env_info
            
            # æ£€æŸ¥ç¯å¢ƒå®‰å…¨æ€§
            if env_info['safety'] < 0.3:
                result['warnings'].append(f"ç¯å¢ƒ '{experience.environment}' å®‰å…¨æ€§è¾ƒä½ ({env_info['safety']:.1f})")
        else:
            result['warnings'].append(f"æœªçŸ¥ç¯å¢ƒç±»å‹: {experience.environment}")
    
    def _analyze_tool_effectiveness(self, experience: EOCATRExperience, result: Dict):
        """åˆ†æå·¥å…·æœ‰æ•ˆæ€§"""
        tools = experience.tools.split(',') if ',' in experience.tools else [experience.tools]
        tool_analysis = {}
        
        for tool in tools:
            tool = tool.strip()
            if tool and tool != 'None':
                effectiveness = calculate_tool_effectiveness(tool, experience.object)
                tool_analysis[tool] = {
                    'effectiveness': effectiveness,
                    'rating': self._get_effectiveness_rating(effectiveness)
                }
                
                # å»ºè®®æ›´å¥½çš„å·¥å…·
                best_tool, best_effectiveness = get_best_tool_for_target(experience.object)
                if best_tool != tool and best_effectiveness > effectiveness + 0.1:
                    result['suggestions'].append(
                        f"å¯¹äº '{experience.object}'ï¼Œ'{best_tool}' (æœ‰æ•ˆæ€§: {best_effectiveness:.2f}) "
                        f"å¯èƒ½æ¯” '{tool}' (æœ‰æ•ˆæ€§: {effectiveness:.2f}) æ›´æœ‰æ•ˆ"
                    )
        
        result['tool_effectiveness'] = tool_analysis
    
    def _get_effectiveness_rating(self, effectiveness: float) -> str:
        """è·å–æœ‰æ•ˆæ€§è¯„çº§"""
        if effectiveness >= 0.8:
            return "ä¼˜ç§€"
        elif effectiveness >= 0.6:
            return "è‰¯å¥½"
        elif effectiveness >= 0.4:
            return "ä¸€èˆ¬"
        else:
            return "è¾ƒå·®"
    
    def _generate_attribute_suggestions(self, experience: EOCATRExperience, result: Dict):
        """ç”Ÿæˆå±æ€§æ”¹è¿›å»ºè®®"""
        if not result['errors']:
            # åŸºäºå¯¹è±¡ç±»å‹ç”Ÿæˆå»ºè®®
            object_attrs = result.get('object_info', {})
            category = object_attrs.get('category', '')
            
            if category == 'predator':
                result['suggestions'].append("é¢å¯¹çŒ›å…½æ—¶å»ºè®®ä½¿ç”¨é•¿çŸ›ç­‰é«˜ç©¿é€åŠ›æ­¦å™¨")
            elif category == 'bird':
                result['suggestions'].append("æ•æ‰é¸Ÿç±»å»ºè®®ä½¿ç”¨å¼“ç®­ç­‰é«˜ç²¾ç¡®åº¦æ­¦å™¨")
            elif category == 'underground_plant':
                result['suggestions'].append("æŒ–æ˜åœ°ä¸‹æ¤ç‰©å»ºè®®ä½¿ç”¨é“é”¹ç­‰æŒ–æ˜å·¥å…·")
    
    def get_tool_effectiveness_report(self, tool_name: str = None, target_name: str = None) -> Dict[str, Any]:
        """
        è·å–å·¥å…·æœ‰æ•ˆæ€§æŠ¥å‘Š
        
        Args:
            tool_name: å·¥å…·åç§°ï¼ˆå¯é€‰ï¼‰
            target_name: ç›®æ ‡åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å·¥å…·æœ‰æ•ˆæ€§æŠ¥å‘Š
        """
        if not self.object_config_enabled:
            return {'error': 'å¯¹è±¡å±æ€§é…ç½®ç³»ç»Ÿæœªå¯ç”¨'}
        
        report = {
            'timestamp': time.time(),
            'tool_analysis': {},
            'target_analysis': {},
            'recommendations': []
        }
        
        try:
            if tool_name:
                # åˆ†æç‰¹å®šå·¥å…·å¯¹æ‰€æœ‰ç›®æ ‡çš„æœ‰æ•ˆæ€§
                report['tool_analysis'][tool_name] = {}
                for target in TARGET_TYPE_MAPPING.keys():
                    effectiveness = calculate_tool_effectiveness(tool_name, target)
                    report['tool_analysis'][tool_name][target] = {
                        'effectiveness': effectiveness,
                        'rating': self._get_effectiveness_rating(effectiveness)
                    }
            
            if target_name:
                # åˆ†ææ‰€æœ‰å·¥å…·å¯¹ç‰¹å®šç›®æ ‡çš„æœ‰æ•ˆæ€§
                report['target_analysis'][target_name] = {}
                for tool in TOOL_CHARACTERISTICS.keys():
                    effectiveness = calculate_tool_effectiveness(tool, target_name)
                    report['target_analysis'][target_name][tool] = {
                        'effectiveness': effectiveness,
                        'rating': self._get_effectiveness_rating(effectiveness)
                    }
                
                # æ¨èæœ€ä½³å·¥å…·
                best_tool, best_effectiveness = get_best_tool_for_target(target_name)
                report['recommendations'].append(
                    f"å¯¹äº '{target_name}'ï¼Œæ¨èä½¿ç”¨ '{best_tool}' (æœ‰æ•ˆæ€§: {best_effectiveness:.2f})"
                )
            
            if not tool_name and not target_name:
                # ç”Ÿæˆå®Œæ•´çš„å·¥å…·-ç›®æ ‡å…¼å®¹æ€§çŸ©é˜µ
                from object_attributes_config import get_tool_target_compatibility_matrix
                report['compatibility_matrix'] = get_tool_target_compatibility_matrix()
        
        except Exception as e:
            report['error'] = f"ç”Ÿæˆå·¥å…·æœ‰æ•ˆæ€§æŠ¥å‘Šå¤±è´¥: {str(e)}"
            logger.error(f"å·¥å…·æœ‰æ•ˆæ€§æŠ¥å‘Šå¼‚å¸¸: {e}")
        
        return report
    
    def analyze_experience_with_attributes(self, experience: EOCATRExperience) -> Dict[str, Any]:
        """
        ä½¿ç”¨å¯¹è±¡å±æ€§ç³»ç»Ÿåˆ†æç»éªŒ
        
        Args:
            experience: EOCATRç»éªŒå¯¹è±¡
            
        Returns:
            åˆ†æç»“æœ
        """
        analysis = {
            'experience_hash': experience.generate_hash(),
            'attribute_validation': self.validate_object_attributes(experience),
            'learning_insights': [],
            'optimization_suggestions': []
        }
        
        if not self.object_config_enabled:
            analysis['warning'] = "å¯¹è±¡å±æ€§é…ç½®ç³»ç»Ÿæœªå¯ç”¨"
            return analysis
        
        try:
            # åˆ†æå­¦ä¹ æ´å¯Ÿ
            self._extract_learning_insights(experience, analysis)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            self._generate_optimization_suggestions(experience, analysis)
            
        except Exception as e:
            analysis['error'] = f"ç»éªŒå±æ€§åˆ†æå¤±è´¥: {str(e)}"
            logger.error(f"ç»éªŒå±æ€§åˆ†æå¼‚å¸¸: {e}")
        
        return analysis
    
    def _extract_learning_insights(self, experience: EOCATRExperience, analysis: Dict):
        """æå–å­¦ä¹ æ´å¯Ÿ"""
        insights = []
        
        # æˆåŠŸ/å¤±è´¥æ¨¡å¼åˆ†æ
        if experience.success:
            insights.append(f"æˆåŠŸç»éªŒ: åœ¨{experience.environment}ç¯å¢ƒä¸­ä½¿ç”¨{experience.tools}å¯¹{experience.object}æ‰§è¡Œ{experience.action}")
        else:
            insights.append(f"å¤±è´¥ç»éªŒ: åœ¨{experience.environment}ç¯å¢ƒä¸­ä½¿ç”¨{experience.tools}å¯¹{experience.object}æ‰§è¡Œ{experience.action}å¤±è´¥")
        
        # å·¥å…·é€‰æ‹©æ´å¯Ÿ
        tool_effectiveness = analysis['attribute_validation'].get('tool_effectiveness', {})
        for tool, info in tool_effectiveness.items():
            if info['effectiveness'] > 0.8:
                insights.append(f"å·¥å…·é€‰æ‹©ä¼˜ç§€: {tool}å¯¹{experience.object}çš„æœ‰æ•ˆæ€§ä¸º{info['effectiveness']:.2f}")
            elif info['effectiveness'] < 0.4:
                insights.append(f"å·¥å…·é€‰æ‹©éœ€æ”¹è¿›: {tool}å¯¹{experience.object}çš„æœ‰æ•ˆæ€§ä»…ä¸º{info['effectiveness']:.2f}")
        
        analysis['learning_insights'] = insights
    
    def _generate_optimization_suggestions(self, experience: EOCATRExperience, analysis: Dict):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # åŸºäºå±æ€§éªŒè¯ç»“æœç”Ÿæˆå»ºè®®
        validation = analysis['attribute_validation']
        suggestions.extend(validation.get('suggestions', []))
        
        # åŸºäºæˆåŠŸç‡ç”Ÿæˆå»ºè®®
        if not experience.success:
            suggestions.append("è€ƒè™‘å°è¯•ä¸åŒçš„å·¥å…·æˆ–åœ¨ä¸åŒç¯å¢ƒä¸­æ‰§è¡Œç›¸åŒè¡ŒåŠ¨")
        
        # åŸºäºå¯¹è±¡ç±»å‹ç”Ÿæˆå»ºè®®
        object_attrs = validation.get('object_info', {})
        if object_attrs:
            category = object_attrs.get('category', '')
            if category == 'predator' and experience.action == 'collect':
                suggestions.append("è­¦å‘Š: å°è¯•æ”¶é›†çŒ›å…½å¯èƒ½å¾ˆå±é™©ï¼Œå»ºè®®å…ˆä½¿ç”¨æ­¦å™¨")
            elif category in ['ground_plant', 'underground_plant', 'tree_plant'] and experience.action == 'attack':
                suggestions.append("æç¤º: å¯¹æ¤ç‰©ä½¿ç”¨æ”»å‡»è¡ŒåŠ¨å¯èƒ½ä¸å¦‚ä½¿ç”¨æ”¶é›†è¡ŒåŠ¨æœ‰æ•ˆ")
        
        analysis['optimization_suggestions'] = suggestions

    # ============================================================================
    # EOCATRçŸ©é˜µé…ç½®ç®¡ç†å™¨ (æ–°å¢)
    # ============================================================================
    
    def initialize_eocatr_matrix_config(self) -> Dict[str, List[str]]:
        """
        åˆå§‹åŒ–å®Œæ•´EOCATRçŸ©é˜µé…ç½®
        åŸºäºæœ€ç»ˆç¡®è®¤çš„çŸ©é˜µè§„æ ¼
        
        Returns:
            å®Œæ•´çš„EOCATRçŸ©é˜µé…ç½®å­—å…¸
        """
        return {
            'environments': [
                'bush', 'cave', 'forest', 'open_field', 'plain', 'river', 'big_tree'
            ],
            'objects': [
                'berry', 'bear', 'dove', 'fish', 'mushroom', 'potato', 
                'strawberry', 'tiger', 'toxic_mushroom', 'toxic_strawberry', 'water_source'
            ],
            'attributes': [
                'red_color', 'green_color', 'blue_color', 'yellow_color', 'brown_color',
                'black_color', 'white_color', 'round_shape', 'long_shape', 'umbrella_shape',
                'irregular_shape', 'soft_texture', 'hard_texture', 'medium_texture',
                'sweet_smell', 'bad_smell', 'no_smell', 'earth_smell', 'x_coordinate',
                'y_coordinate', 'environment_type', 'vision_range', 'alive_status',
                'collected_status', 'visible_status', 'food_value', 'toxic_property',
                'hp_value', 'damage_value', 'stationary_move', 'slow_move', 'fast_move',
                'no_attack', 'passive_attack', 'active_attack', 'collectable',
                'not_collectable', 'no_escape', 'easy_escape'
            ],
            'actions': [
                'up', 'down', 'left', 'right', 'move_up', 'move_down', 'move_left',
                'move_right', 'climb', 'collect', 'gather', 'harvest', 'forage',
                'attack', 'hunt', 'defend', 'explore', 'explore_new_area', 'search',
                'investigate', 'examine', 'discover', 'observe', 'interact',
                'communicate', 'trade', 'help', 'craft', 'make_tool', 'repair', 'rest', 'mine'
            ],
            'tools': [
                'spear', 'stone', 'bow', 'basket', 'shovel', 'stick', 'net', 'pickaxe', 'hands', 'none'
            ],
            'results': [
                'success', 'failure', 'hp_increase_5', 'hp_increase_10', 'hp_decrease_5',
                'hp_decrease_8', 'hp_decrease_15', 'hp_decrease_30', 'food_increase_5',
                'food_increase_15', 'food_increase_20', 'food_increase_25', 'food_increase_30',
                'food_increase_50', 'food_increase_60', 'water_increase_10', 'water_increase_15',
                'position_change_x_plus_1', 'position_change_x_minus_1', 'position_change_y_plus_1',
                'position_change_y_minus_1', 'position_change_climb_tree', 'vision_enhancement',
                'discover_new_area', 'discover_resource', 'gain_experience', 'map_expansion',
                'gain_item', 'lose_item', 'stay_alive', 'death', 'poisoned'
            ]
        }

    def trigger_systematic_eocatr_rule_generation(self) -> Dict[str, Any]:
        """
        è§¦å‘ç³»ç»Ÿæ€§EOCATRè§„å¾‹ç”Ÿæˆ
        åè°ƒBPMè¿›è¡Œå®Œæ•´çŸ©é˜µè§„å¾‹ç”Ÿæˆ
        
        Returns:
            ç”Ÿæˆè§¦å‘ç»“æœå’Œé…ç½®ä¿¡æ¯
        """
        try:
            # è·å–EOCATRçŸ©é˜µé…ç½®
            matrix_config = self.initialize_eocatr_matrix_config()
            
            # è®¡ç®—é¢„æœŸè§„å¾‹æ•°é‡
            expected_counts = {
                'EAR': len(matrix_config['environments']) * len(matrix_config['actions']) * len(matrix_config['results']),
                'ETR': len(matrix_config['environments']) * len(matrix_config['tools']) * len(matrix_config['results']),
                'OAR': len(matrix_config['objects']) * len(matrix_config['actions']) * len(matrix_config['results']),
                'OTR': len(matrix_config['objects']) * len(matrix_config['tools']) * len(matrix_config['results']),
                'CAR': len(matrix_config['attributes']) * len(matrix_config['actions']) * len(matrix_config['results']),
                'CTR': len(matrix_config['attributes']) * len(matrix_config['tools']) * len(matrix_config['results'])
            }
            
            total_expected = sum(expected_counts.values())
            
            # è®°å½•é…ç½®ä¿¡æ¯åˆ°å†³ç­–åº“
            config_decision = Decision(
                decision_id=f"EOCATR_CONFIG_{int(time.time())}",
                context={
                    'action_type': 'eocatr_matrix_config',
                    'matrix_dimensions': {key: len(values) for key, values in matrix_config.items()},
                    'expected_rule_counts': expected_counts,
                    'total_expected_rules': total_expected
                },
                action='initialize_eocatr_matrix',
                confidence=1.0,
                source='five_library_system'
            )
            
            # æ·»åŠ åˆ°å†³ç­–åº“
            self.add_decision_to_library(config_decision)
            
            logger.info(f"EOCATR matrix configuration ready, expected to generate {total_expected} basic rules")
            
            return {
                'status': 'success',
                'message': f'EOCATR matrix configuration ready, expected to generate {total_expected} basic rules',
                'matrix_config': matrix_config,
                'expected_counts': expected_counts,
                'total_expected': total_expected,
                'config_decision_id': config_decision.decision_id
            }
            
        except Exception as e:
            error_msg = f'EOCATRè§„å¾‹ç”Ÿæˆè§¦å‘å¤±è´¥: {str(e)}'
            logger.error(error_msg)
            
            return {
                'status': 'error',
                'message': error_msg,
                'error_detail': str(e)
            }

    def get_eocatr_matrix_statistics(self) -> Dict[str, Any]:
        """
        è·å–EOCATRçŸ©é˜µç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            çŸ©é˜µé…ç½®å’Œä½¿ç”¨ç»Ÿè®¡
        """
        try:
            matrix_config = self.initialize_eocatr_matrix_config()
            
            # è®¡ç®—çŸ©é˜µç»´åº¦
            matrix_dimensions = {key: len(values) for key, values in matrix_config.items()}
            
            # è®¡ç®—ç†è®ºè§„å¾‹æ•°é‡
            theoretical_counts = {
                'EAR': matrix_dimensions['environments'] * matrix_dimensions['actions'] * matrix_dimensions['results'],
                'ETR': matrix_dimensions['environments'] * matrix_dimensions['tools'] * matrix_dimensions['results'],
                'OAR': matrix_dimensions['objects'] * matrix_dimensions['actions'] * matrix_dimensions['results'],
                'OTR': matrix_dimensions['objects'] * matrix_dimensions['tools'] * matrix_dimensions['results'],
                'CAR': matrix_dimensions['attributes'] * matrix_dimensions['actions'] * matrix_dimensions['results'],
                'CTR': matrix_dimensions['attributes'] * matrix_dimensions['tools'] * matrix_dimensions['results']
            }
            
            total_theoretical = sum(theoretical_counts.values())
            
            # æŸ¥è¯¢å·²å­˜å‚¨çš„EOCATRç›¸å…³å†³ç­–
            eocatr_decisions = self.query_decisions(
                context={'action_type': 'eocatr_matrix_config'}, 
                limit=10
            )
            
            # ç»Ÿè®¡ç›´æ¥ç»éªŒåº“ä¸­çš„EOCATRç»éªŒ
            try:
                direct_experiences_count = self.db_managers['direct_experiences'].execute_query(
                    "SELECT COUNT(*) as count FROM experiences"
                )[0]['count']
            except:
                # å¦‚æœè¡¨ä¸å­˜åœ¨ï¼Œä½¿ç”¨0
                direct_experiences_count = 0
            
            return {
                'matrix_dimensions': matrix_dimensions,
                'theoretical_rule_counts': theoretical_counts,
                'total_theoretical_rules': total_theoretical,
                'eocatr_config_decisions': len(eocatr_decisions.get('decisions', [])),
                'direct_experiences_count': direct_experiences_count,
                'configuration_timestamp': time.time()
            }
            
        except Exception as e:
            return {
                'error': f'è·å–EOCATRçŸ©é˜µç»Ÿè®¡å¤±è´¥: {str(e)}',
                'configuration_timestamp': time.time()
            }

    def validate_eocatr_matrix_completeness(self, bmp_statistics: Dict = None) -> Dict[str, Any]:
        """
        éªŒè¯EOCATRçŸ©é˜µå®Œæ•´æ€§
        
        Args:
            bmp_statistics: BPMç³»ç»Ÿçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å®Œæ•´æ€§éªŒè¯ç»“æœ
        """
        try:
            # è·å–ç†è®ºæœŸæœ›
            matrix_stats = self.get_eocatr_matrix_statistics()
            total_theoretical = matrix_stats['total_theoretical_rules']
            theoretical_counts = matrix_stats['theoretical_rule_counts']
            
            validation_result = {
                'total_theoretical_rules': total_theoretical,
                'theoretical_breakdown': theoretical_counts,
                'completeness_check': {
                    'status': 'pending',
                    'coverage_percentage': 0.0,
                    'missing_rule_types': [],
                    'implemented_rule_types': []
                }
            }
            
            if bmp_statistics:
                # å¦‚æœæä¾›äº†BPMç»Ÿè®¡ä¿¡æ¯ï¼Œè¿›è¡Œè¯¦ç»†å¯¹æ¯”
                bmp_systematic = bmp_statistics.get('systematic_eocatr_rules', {})
                bmp_total_systematic = bmp_systematic.get('candidate', 0) + bmp_systematic.get('validated', 0)
                
                coverage_percentage = (bmp_total_systematic / total_theoretical) * 100 if total_theoretical > 0 else 0
                
                validation_result['completeness_check'] = {
                    'status': 'completed',
                    'coverage_percentage': coverage_percentage,
                    'bmp_systematic_rules': bmp_total_systematic,
                    'coverage_assessment': 'excellent' if coverage_percentage > 90 else 
                                         'good' if coverage_percentage > 70 else
                                         'moderate' if coverage_percentage > 50 else 'low'
                }
                
                # åˆ†æå„ç±»å‹è¦†ç›–æƒ…å†µ
                bmp_by_type = bmp_systematic.get('by_type', {})
                for rule_type in ['conditional', 'tool_effectiveness', 'causal']:
                    type_count = bmp_by_type.get(rule_type, {})
                    total_type_count = type_count.get('candidate', 0) + type_count.get('validated', 0)
                    
                    if total_type_count > 0:
                        validation_result['completeness_check']['implemented_rule_types'].append(rule_type)
                    else:
                        validation_result['completeness_check']['missing_rule_types'].append(rule_type)
            
            return validation_result
            
        except Exception as e:
            return {
                'error': f'EOCATRçŸ©é˜µå®Œæ•´æ€§éªŒè¯å¤±è´¥: {str(e)}',
                'validation_timestamp': time.time()
            }

    def _initialize_sync_tracker(self):
        """åˆå§‹åŒ–åŒæ­¥çŠ¶æ€è·Ÿè¸ªå™¨"""
        try:
            # è·å–æ€»ç»éªŒåº“ä¸­æ‰€æœ‰å·²åŒæ­¥çš„ç»éªŒå“ˆå¸Œ
            total_hashes = self.db_managers['total_experiences'].execute_query(
                "SELECT content_hash FROM total_experiences"
            )
            
            for record in total_hashes:
                self.sync_tracker['synced_experience_hashes'].add(record['content_hash'])
            
            logger.info(f"ğŸ“Š Sync tracker initialized: {len(self.sync_tracker['synced_experience_hashes'])} experiences synced")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Sync tracker initialization failed: {e}")

    def _smart_sync_experience(self, content_hash: str, action: str):
        """
        æ™ºèƒ½åŒæ­¥ç»éªŒï¼šåªåŒæ­¥çœŸæ­£éœ€è¦åŒæ­¥çš„ç»éªŒ
        
        Args:
            content_hash: ç»éªŒå†…å®¹å“ˆå¸Œ
            action: æ“ä½œç±»å‹ ('added', 'updated')
        """
        try:
            # 1. æ£€æŸ¥æ˜¯å¦å·²ç»åŒæ­¥è¿‡
            if content_hash in self.sync_tracker['synced_experience_hashes']:
                # å¦‚æœæ˜¯æ›´æ–°æ“ä½œï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŒæ­¥
                if action == 'updated':
                    # æ£€æŸ¥æ›´æ–°æ˜¯å¦æ˜¾è‘—ï¼ˆä¾‹å¦‚occurrence_countå˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼‰
                    if self._should_resync_updated_experience(content_hash):
                        logger.debug(f"ğŸ”„ ç»éªŒéœ€è¦é‡æ–°åŒæ­¥: {content_hash[:16]}...")
                        self._add_to_pending_sync(content_hash)
                    else:
                        logger.debug(f"â­ï¸ è·³è¿‡é‡å¤åŒæ­¥: {content_hash[:16]}...")
                        return
                else:
                    logger.debug(f"â­ï¸ ç»éªŒå·²åŒæ­¥ï¼Œè·³è¿‡: {content_hash[:16]}...")
                    return
            
            # 2. æ–°ç»éªŒæˆ–éœ€è¦é‡æ–°åŒæ­¥çš„ç»éªŒ
            if action == 'added':
                # ç«‹å³åŒæ­¥æ–°ç»éªŒ
                sync_result = self.sync_experience_to_total_library(content_hash)
                if sync_result['success']:
                    self.sync_tracker['synced_experience_hashes'].add(content_hash)
                    logger.debug(f"âœ… æ–°ç»éªŒç«‹å³åŒæ­¥: {sync_result['action']} - {content_hash[:16]}...")
                else:
                    logger.warning(f"âŒ New experience sync failed: {content_hash[:16]}...")
            else:
                # æ›´æ–°çš„ç»éªŒåŠ å…¥å¾…åŒæ­¥é˜Ÿåˆ—
                self._add_to_pending_sync(content_hash)
            
            # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡åŒæ­¥
            self._check_and_perform_batch_sync()
            
        except Exception as e:
            logger.warning(f"âš ï¸ Smart sync failed: {e}")
    
    def _should_resync_updated_experience(self, content_hash: str) -> bool:
        """
        åˆ¤æ–­æ›´æ–°çš„ç»éªŒæ˜¯å¦éœ€è¦é‡æ–°åŒæ­¥
        
        Args:
            content_hash: ç»éªŒå†…å®¹å“ˆå¸Œ
            
        Returns:
            æ˜¯å¦éœ€è¦é‡æ–°åŒæ­¥
        """
        try:
            # è·å–ç›´æ¥ç»éªŒåº“ä¸­çš„è®°å½•
            direct_record = self.db_managers['direct_experiences'].execute_query(
                "SELECT occurrence_count, last_seen_time FROM direct_experiences WHERE content_hash = ?", 
                (content_hash,)
            )
            
            # è·å–æ€»ç»éªŒåº“ä¸­çš„è®°å½•
            total_record = self.db_managers['total_experiences'].execute_query(
                "SELECT occurrence_count, last_seen_time FROM total_experiences WHERE content_hash = ?", 
                (content_hash,)
            )
            
            if not direct_record or not total_record:
                return True  # å¦‚æœè®°å½•ä¸å­˜åœ¨ï¼Œéœ€è¦åŒæ­¥
            
            direct_count = direct_record[0]['occurrence_count']
            total_count = total_record[0]['occurrence_count']
            
            # å¦‚æœoccurrence_countå·®å¼‚è¶…è¿‡5ï¼Œæˆ–è€…æ—¶é—´å·®å¼‚è¶…è¿‡1å°æ—¶ï¼Œåˆ™éœ€è¦é‡æ–°åŒæ­¥
            count_diff = abs(direct_count - total_count)
            time_diff = abs(direct_record[0]['last_seen_time'] - total_record[0]['last_seen_time'])
            
            return count_diff >= 5 or time_diff >= 3600
            
        except Exception as e:
            logger.debug(f"æ£€æŸ¥é‡æ–°åŒæ­¥éœ€æ±‚å¤±è´¥: {e}")
            return False  # å‡ºé”™æ—¶ä¸é‡æ–°åŒæ­¥ï¼Œé¿å…è¿‡åº¦åŒæ­¥
    
    def _add_to_pending_sync(self, content_hash: str):
        """å°†ç»éªŒå“ˆå¸Œæ·»åŠ åˆ°å¾…åŒæ­¥é˜Ÿåˆ—"""
        self.sync_tracker['pending_sync_hashes'].add(content_hash)
        logger.debug(f"ğŸ“‹ æ·»åŠ åˆ°å¾…åŒæ­¥é˜Ÿåˆ—: {content_hash[:16]}... (é˜Ÿåˆ—é•¿åº¦: {len(self.sync_tracker['pending_sync_hashes'])})")
    
    def _check_and_perform_batch_sync(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œæ‰¹é‡åŒæ­¥"""
        current_time = time.time()
        pending_count = len(self.sync_tracker['pending_sync_hashes'])
        time_since_last_sync = current_time - self.sync_tracker['last_sync_check']
        
        # æ¡ä»¶1ï¼šå¾…åŒæ­¥é˜Ÿåˆ—è¾¾åˆ°æ‰¹é‡å¤§å°
        # æ¡ä»¶2ï¼šè·ç¦»ä¸Šæ¬¡åŒæ­¥è¶…è¿‡é—´éš”æ—¶é—´ä¸”æœ‰å¾…åŒæ­¥é¡¹ç›®
        should_sync = (
            pending_count >= self.sync_tracker['sync_batch_size'] or
            (time_since_last_sync >= self.sync_tracker['sync_interval'] and pending_count > 0)
        )
        
        if should_sync:
            logger.info(f"ğŸš€ Batch sync: {pending_count} experiences")  # Simplified log
            self._perform_batch_sync()
            self.sync_tracker['last_sync_check'] = current_time
    
    def _perform_batch_sync(self):
        """æ‰§è¡Œæ‰¹é‡åŒæ­¥"""
        if not self.sync_tracker['pending_sync_hashes']:
            return
        
        sync_count = 0
        failed_count = 0
        
        # å¤åˆ¶å¾…åŒæ­¥é›†åˆï¼Œé¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹
        pending_hashes = self.sync_tracker['pending_sync_hashes'].copy()
        self.sync_tracker['pending_sync_hashes'].clear()
        
        for content_hash in pending_hashes:
            try:
                sync_result = self.sync_experience_to_total_library(content_hash)
                if sync_result['success']:
                    self.sync_tracker['synced_experience_hashes'].add(content_hash)
                    sync_count += 1
                else:
                    failed_count += 1
                    # å¤±è´¥çš„é‡æ–°åŠ å…¥å¾…åŒæ­¥é˜Ÿåˆ—
                    self.sync_tracker['pending_sync_hashes'].add(content_hash)
                    
            except Exception as e:
                failed_count += 1
                logger.warning(f"æ‰¹é‡åŒæ­¥å¤±è´¥: {content_hash[:16]}... - {e}")
                # å¤±è´¥çš„é‡æ–°åŠ å…¥å¾…åŒæ­¥é˜Ÿåˆ—
                self.sync_tracker['pending_sync_hashes'].add(content_hash)
        
        logger.info(f"ğŸ“Š Sync completed: {sync_count} successful/{failed_count} failed")  # Simplified log

# æµ‹è¯•å‡½æ•°
def test_five_library_system():
    """æµ‹è¯•äº”åº“ç³»ç»ŸåŸºç¡€åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•äº”åº“ç³»ç»ŸåŸºç¡€åŠŸèƒ½")
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = FiveLibrarySystem()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = system.get_system_statistics()
    print(f"ğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats}")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    for name, db_manager in system.db_managers.items():
        try:
            result = db_manager.execute_query("SELECT name FROM sqlite_master WHERE type='table'")
            table_count = len(result)
            print(f"âœ… {name}: {table_count} ä¸ªè¡¨")
        except Exception as e:
            print(f"âŒ {name}: è¿æ¥å¤±è´¥ - {str(e)}")
    
    print("âœ… äº”åº“ç³»ç»ŸåŸºç¡€æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_five_library_system() 