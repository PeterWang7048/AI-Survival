"""
æ€’æ”¾ä¸å‰ªææ¨¡å‹ï¼ˆBlooming and Pruning Model, BPMï¼‰

æ¨¡æ‹Ÿç¥ç»å¯å¡‘æ€§çš„çŸ¥è¯†åŠ¨æ€æ¼”åŒ–æœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
1. å€™é€‰è§„å¾‹ç”Ÿæˆï¼ˆ"æ€’æ”¾"é˜¶æ®µï¼‰
2. ç»éªŒé©±åŠ¨éªŒè¯ä¸å‰ªææœºåˆ¶  
3. è§„å¾‹å·©å›ºå’Œç½®ä¿¡åº¦ç®¡ç†
4. è§„å¾‹è´¨é‡è¯„ä¼°ç³»ç»Ÿ

åŸºäºæ–¯å¦ç¦4.0æ–‡æ¡£ä¸­çš„è®¤çŸ¥æ¶æ„è®¾è®¡ã€‚

ä½œè€…ï¼šAIç”Ÿå­˜æ¸¸æˆé¡¹ç›®ç»„
ç‰ˆæœ¬ï¼š1.0.0
"""

import math
import random
import time
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple, Set
from enum import Enum
from collections import defaultdict, Counter
from scene_symbolization_mechanism import EOCATR_Tuple, SymbolicAction, SymbolicObjectCategory


class RuleType(Enum):
    """è§„å¾‹ç±»å‹æšä¸¾"""
    CAUSAL = "causal"              # å› æœè§„å¾‹ (Aå¯¼è‡´B)
    CONDITIONAL = "conditional"     # æ¡ä»¶è§„å¾‹ (å¦‚æœAåˆ™B)
    SEQUENTIAL = "sequential"       # æ—¶åºè§„å¾‹ (Aä¹‹åB)
    SPATIAL = "spatial"            # ç©ºé—´è§„å¾‹ (åœ¨ä½ç½®XåšY)
    ASSOCIATIVE = "associative"    # å…³è”è§„å¾‹ (Aä¸BåŒæ—¶å‡ºç°)
    EXCLUSION = "exclusion"        # æ’é™¤è§„å¾‹ (Aæ’é™¤B)
    OPTIMIZATION = "optimization"   # ä¼˜åŒ–è§„å¾‹ (åœ¨æƒ…å†µAä¸‹ï¼ŒBæ¯”Cæ›´å¥½)
    TOOL_EFFECTIVENESS = "tool_effectiveness"  # å·¥å…·æ•ˆç”¨è§„å¾‹ (å·¥å…·Xå¯¹ç›®æ ‡Yçš„æ•ˆæœZ)


class RuleConfidence(Enum):
    """è§„å¾‹ç½®ä¿¡åº¦ç­‰çº§"""
    HYPOTHESIS = "hypothesis"      # å‡è®¾ (0.0-0.3)
    TENTATIVE = "tentative"       # è¯•æ¢æ€§ (0.3-0.6)  
    PROBABLE = "probable"         # å¯èƒ½æ€§ (0.6-0.8)
    CONFIDENT = "confident"       # ç¡®ä¿¡ (0.8-0.95)
    CERTAIN = "certain"           # ç¡®å®š (0.95-1.0)


@dataclass
class RuleEvidence:
    """è§„å¾‹è¯æ®æ•°æ®ç±»"""
    supporting_experiences: List[str] = field(default_factory=list)  # æ”¯æŒç»éªŒ
    contradicting_experiences: List[str] = field(default_factory=list)  # åé©³ç»éªŒ
    total_tests: int = 0           # æ€»æµ‹è¯•æ¬¡æ•°
    successful_tests: int = 0      # æˆåŠŸæµ‹è¯•æ¬¡æ•°
    last_tested: float = 0.0       # æœ€åæµ‹è¯•æ—¶é—´
    test_contexts: List[str] = field(default_factory=list)  # æµ‹è¯•ä¸Šä¸‹æ–‡
    
    @property
    def success_rate(self) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        if self.total_tests == 0:
            return 0.0
        return self.successful_tests / self.total_tests
    
    @property
    def support_ratio(self) -> float:
        """è®¡ç®—æ”¯æŒæ¯”ä¾‹"""
        total_evidence = len(self.supporting_experiences) + len(self.contradicting_experiences)
        if total_evidence == 0:
            return 0.0
        return len(self.supporting_experiences) / total_evidence
    
    @property
    def contradicting_evidence_ratio(self) -> float:
        """è®¡ç®—çŸ›ç›¾è¯æ®æ¯”ä¾‹"""
        total_evidence = len(self.supporting_experiences) + len(self.contradicting_experiences)
        if total_evidence == 0:
            return 0.0
        return len(self.contradicting_experiences) / total_evidence


@dataclass 
class CandidateRule:
    """å€™é€‰è§„å¾‹æ•°æ®ç±»"""
    # === æ ¸å¿ƒå±æ€§ (æ— é»˜è®¤å€¼) ===
    rule_id: str
    rule_type: RuleType
    pattern: str
    conditions: Dict[str, Any]
    predictions: Dict[str, Any]

    # === ç»“æ„åŒ–ä¸å…¼å®¹æ€§å±æ€§ (æœ‰é»˜è®¤å€¼) ===
    pattern_elements: List[Any] = field(default_factory=list)
    condition_elements: List[str] = field(default_factory=list)
    expected_result: Dict[str, Any] = field(default_factory=dict)
    abstraction_level: int = 1
    generation_time: float = field(default_factory=time.time)
    validation_attempts: int = 0
    
    # === æ¼”åŒ–å±æ€§ (æœ‰é»˜è®¤å€¼) ===
    confidence: float = 0.1
    strength: float = 0.1
    generalization: float = 0.1
    specificity: float = 0.9
    
    # === è¯æ®å’ŒéªŒè¯ (æœ‰é»˜è®¤å€¼) ===
    evidence: RuleEvidence = field(default_factory=RuleEvidence)
    birth_time: float = field(default_factory=time.time)
    last_activation: float = 0.0
    activation_count: int = 0
    
    # === è´¨é‡æŒ‡æ ‡ (æœ‰é»˜è®¤å€¼) ===
    precision: float = 0.0
    recall: float = 0.0
    utility: float = 0.0
    
    # === å…ƒä¿¡æ¯ (æœ‰é»˜è®¤å€¼) ===
    parent_rules: List[str] = field(default_factory=list)
    derived_rules: List[str] = field(default_factory=list)
    complexity: int = 1
    # === éªŒè¯çŠ¶æ€ ===
    status: str = "pending"  # pending | provisional | validated | deprecated | pruned
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œç¡®ä¿å…¼å®¹æ€§å±æ€§æ­£ç¡®è®¾ç½®"""
        # å¦‚æœcondition_elementsä¸ºç©ºï¼Œä»conditionsç”Ÿæˆ
        if not self.condition_elements and self.conditions:
            self._generate_condition_elements()
        
        # å¦‚æœpattern_elementsä¸ºç©ºï¼Œå°è¯•ä»patternå­—ç¬¦ä¸²ç”Ÿæˆ
        if not self.pattern_elements and self.pattern:
            self._generate_pattern_elements_from_pattern()
        
        # å¦‚æœexpected_resultä¸ºç©ºï¼Œä»predictionsç”Ÿæˆ
        if not self.expected_result and self.predictions:
            self.expected_result = self.predictions.copy()
    
    def _generate_pattern_elements_from_pattern(self):
        """(ä¿®å¤ç‰ˆ)ä»patternå­—ç¬¦ä¸²ç”Ÿæˆpattern_elements"""
        try:
            # ğŸ”§ ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ„é€ å‡½æ•°
            from symbolic_learning_system import SymbolicElement, SymbolicCategory
            
            parts = []
            if '->' in self.pattern:
                parts = self.pattern.split('->')
            elif '+' in self.pattern:
                parts = self.pattern.split('+')
            else:
                parts = [self.pattern]

            self.pattern_elements = []
            for part in parts:
                if part.strip():
                    # ğŸ”§ ä¿®å¤æ„é€ å‡½æ•°å‚æ•° - ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åå’Œæšä¸¾å€¼
                    element = SymbolicElement(
                        name=part.strip(), 
                        category=SymbolicCategory.ACTION  # ä½¿ç”¨é»˜è®¤ç±»åˆ«
                    )
                    self.pattern_elements.append(element)
                    
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åˆ—è¡¨ä½œä¸ºå›é€€
            parts = []
            if '->' in self.pattern:
                parts = self.pattern.split('->')
            elif '+' in self.pattern:
                parts = self.pattern.split('+')
            else:
                parts = [self.pattern]
            self.pattern_elements = [part.strip() for part in parts if part.strip()]
        except Exception as e:
            # ğŸ”§ æ·»åŠ é”™è¯¯å¤„ç†ï¼Œé˜²æ­¢contentå±æ€§é”™è¯¯
            if hasattr(self, 'logger') and self.logger:
                self.logger.log(f"ç”Ÿæˆpattern_elementså¤±è´¥: {str(e)}")
            # ä½¿ç”¨å­—ç¬¦ä¸²ä½œä¸ºå›é€€
            self.pattern_elements = [self.pattern] if self.pattern else []
    
    def _generate_condition_elements(self):
        """ä»conditionså­—å…¸ç”Ÿæˆcondition_elementsåˆ—è¡¨"""
        elements = []
        for key, value in self.conditions.items():
            if isinstance(value, str):
                elements.append(f"{key}={value}")
            elif isinstance(value, (int, float)):
                elements.append(f"{key}={value}")
            elif isinstance(value, bool):
                elements.append(f"{key}={str(value).lower()}")
            else:
                elements.append(f"{key}={str(value)}")
        self.condition_elements = elements
    
    def get_confidence_level(self) -> RuleConfidence:
        """è·å–ç½®ä¿¡åº¦ç­‰çº§"""
        if self.confidence < 0.3:
            return RuleConfidence.HYPOTHESIS
        elif self.confidence < 0.6:
            return RuleConfidence.TENTATIVE
        elif self.confidence < 0.8:
            return RuleConfidence.PROBABLE
        elif self.confidence < 0.95:
            return RuleConfidence.CONFIDENT
        else:
            return RuleConfidence.CERTAIN
    
    def calculate_quality_score(self) -> float:
        """è®¡ç®—è§„å¾‹è´¨é‡ç»¼åˆå¾—åˆ†"""
        # åŸºç¡€å¾—åˆ†åŸºäºç½®ä¿¡åº¦å’Œè¯æ®æ”¯æŒç‡
        base_score = (self.confidence * 0.4 + self.evidence.support_ratio * 0.3)
        
        # è€ƒè™‘æ¿€æ´»é¢‘ç‡å’Œæ•ˆç”¨
        activation_bonus = min(self.activation_count / 10.0, 0.2)
        utility_bonus = self.utility * 0.1
        
        # æƒ©ç½šè¿‡åº¦å¤æ‚çš„è§„å¾‹
        complexity_penalty = max(0, (self.complexity - 3) * 0.05)
        
        return base_score + activation_bonus + utility_bonus - complexity_penalty

    def to_wbm_format(self) -> dict:
        """è½¬æ¢ä¸ºWBMé€ æ¡¥ç®—æ³•éœ€è¦çš„æ ¼å¼"""
        try:
            # ä»patternæˆ–conditionsä¸­æå–åŠ¨ä½œ
            action = self._extract_action_from_rule()
            
            # ç®€åŒ–æ¡ä»¶ä¸ºWBMå¯ç†è§£çš„æ ¼å¼
            wbm_condition = self._simplify_conditions_for_wbm()
            
            # è½¬æ¢é¢„æµ‹ç»“æœä¸ºçŠ¶æ€å˜åŒ–
            wbm_result = self._convert_predictions_to_state_changes()
            
            return {
                'id': self.rule_id,
                'condition': wbm_condition,
                'action': action,
                'result': wbm_result,
                'confidence': self.confidence,
                'source': 'bmp_generated',
                'original_pattern': self.pattern,
                'rule_type': self.rule_type.value if hasattr(self.rule_type, 'value') else str(self.rule_type)
            }
        except Exception as e:
            # è¿”å›å®‰å…¨çš„é»˜è®¤æ ¼å¼
            return {
                'id': self.rule_id,
                'condition': {'position': 'any'},
                'action': 'explore',
                'result': {'exploration_progress': 0.1},
                'confidence': max(0.1, self.confidence),
                'source': 'bmp_fallback'
            }
    
    def _extract_action_from_rule(self) -> str:
        """ä»è§„å¾‹ä¸­æå–å¯æ‰§è¡ŒåŠ¨ä½œ"""
        # æ£€æŸ¥conditionsä¸­æ˜¯å¦æœ‰action
        if isinstance(self.conditions, dict) and 'action' in self.conditions:
            return self.conditions['action']
        
        # ä»patternå­—ç¬¦ä¸²ä¸­æå–åŠ¨ä½œ
        if hasattr(self, 'pattern') and self.pattern:
            import re
            # åŒ¹é…å¸¸è§åŠ¨ä½œæ¨¡å¼
            action_patterns = [
                r'(\w+)è¡ŒåŠ¨', r'æ‰§è¡Œ(\w+)', r'è¿›è¡Œ(\w+)', 
                r'ä½¿ç”¨(\w+)', r'æ”¶é›†(\w+)', r'æ”»å‡»(\w+)',
                r'ç§»åŠ¨', r'æ¢ç´¢', r'å¯»æ‰¾', r'æ”¶é›†', r'æ”»å‡»', r'é€ƒè·‘'
            ]
            
            for pattern in action_patterns:
                match = re.search(pattern, self.pattern)
                if match:
                    if match.groups():
                        return match.group(1)
                    else:
                        return match.group(0)
        
        # æ ¹æ®è§„å¾‹ç±»å‹æ¨æ–­åŠ¨ä½œ
        if hasattr(self, 'rule_type'):
            type_to_action = {
                'CAUSAL': 'explore',
                'CONDITIONAL': 'conditional_action',
                'SEQUENTIAL': 'sequential_action',
                'SPATIAL': 'move',
                'TOOL_EFFECTIVENESS': 'use_tool'
            }
            rule_type_str = self.rule_type.value if hasattr(self.rule_type, 'value') else str(self.rule_type)
            return type_to_action.get(rule_type_str, 'explore')
        
        return 'explore'  # é»˜è®¤åŠ¨ä½œ
    
    def _simplify_conditions_for_wbm(self) -> dict:
        """ç®€åŒ–æ¡ä»¶ä¸ºWBMå¯ç†è§£çš„æ ¼å¼"""
        simplified = {}
        
        if isinstance(self.conditions, dict):
            for key, value in self.conditions.items():
                if key in ['environment', 'current_cell', 'position']:
                    simplified[key] = value
                elif key in ['health', 'food', 'water']:
                    # è½¬æ¢ä¸ºé˜ˆå€¼æ¡ä»¶
                    if isinstance(value, (int, float)):
                        if value < 50:
                            simplified[f'{key}_low'] = True
                        elif value > 80:
                            simplified[f'{key}_high'] = True
                elif key in ['nearby_plant', 'nearby_animal', 'nearby_water']:
                    simplified[key] = bool(value)
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ¡ä»¶ï¼Œè®¾ç½®é»˜è®¤æ¡ä»¶
        if not simplified:
            simplified = {'position': 'any'}
        
        return simplified
    
    def _convert_predictions_to_state_changes(self) -> dict:
        """è½¬æ¢é¢„æµ‹ç»“æœä¸ºçŠ¶æ€å˜åŒ–"""
        result = {}
        
        if isinstance(self.predictions, dict):
            for key, value in self.predictions.items():
                if key == 'result':
                    # è§£æç»“æœå­—ç¬¦ä¸²
                    if isinstance(value, str):
                        if 'water' in value.lower():
                            result['water_gain'] = 30
                        elif 'food' in value.lower():
                            result['food_gain'] = 20
                        elif 'discovery' in value.lower():
                            result['new_area_discovered'] = True
                        elif 'damage' in value.lower():
                            result['damage_dealt'] = 25
                elif key in ['water_gain', 'food_gain', 'health_change']:
                    result[key] = value
                elif key in ['success_probability', 'effectiveness']:
                    # è½¬æ¢ä¸ºå…·ä½“æ”¶ç›Š
                    if isinstance(value, (int, float)) and value > 0.5:
                        result['success_bonus'] = True
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç»“æœï¼Œè®¾ç½®é»˜è®¤ç»“æœ
        if not result:
            result = {'exploration_progress': 0.1}
        
        return result


class BloomingAndPruningModel:
    """æ€’æ”¾ä¸å‰ªææ¨¡å‹ä¸»ç±»"""
    
    def __init__(self, logger=None, config=None, *args, **kwargs):
        super().__init__(*args, **kwargs) if hasattr(super(), '__init__') else None
        
        # æ€§èƒ½ä¼˜åŒ–: æ·»åŠ ç”Ÿæˆé¢‘ç‡æ§åˆ¶
        self.last_generation_time = 0
        self.generation_interval = 15  # 15ç§’é—´éš”
        self.min_experience_count = 5  # æœ€å°‘ç»éªŒæ•°é‡
        self.logger = logger
        self.config = config or self._default_config()
        
        # è§„å¾‹å­˜å‚¨
        self.candidate_rules: Dict[str, CandidateRule] = {}  # å€™é€‰è§„å¾‹
        self.validated_rules: Dict[str, CandidateRule] = {}  # å·²éªŒè¯è§„å¾‹
        self.pruned_rules: Dict[str, CandidateRule] = {}     # å·²å‰ªæè§„å¾‹
        
        # === æ–°å¢ï¼šè§„å¾‹å»é‡å’Œè´¨é‡æ§åˆ¶ ===
        self.rule_fingerprints: Set[str] = set()  # è§„å¾‹æŒ‡çº¹é›†åˆï¼Œç”¨äºå¿«é€Ÿå»é‡
        self.rule_similarity_threshold = 0.95  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé™ä½è¯¯åˆ¤ï¼‰
        self.min_quality_threshold = 0.01  # æœ€ä½è´¨é‡é˜ˆå€¼ï¼ˆæåº¦é™ä½ï¼‰
        self.rule_merge_history: List[Tuple[str, str, float]] = []  # åˆå¹¶å†å²
        
        # === æ–°å¢ï¼šæ™ºèƒ½å†…å­˜ç®¡ç† ===
        self.max_total_rules = config.get('max_total_rules', 1000) if config else 1000  # æœ€å¤§è§„å¾‹æ€»æ•°
        self.max_candidate_rules = config.get('max_candidate_rules', 500) if config else 500  # æœ€å¤§å€™é€‰è§„å¾‹æ•°
        self.max_validated_rules = config.get('max_validated_rules', 300) if config else 300  # æœ€å¤§å·²éªŒè¯è§„å¾‹æ•°
        self.memory_cleanup_threshold = 0.9  # å†…å­˜æ¸…ç†é˜ˆå€¼ï¼ˆ90%æ»¡æ—¶æ¸…ç†ï¼‰
        self.lru_access_times: Dict[str, float] = {}  # LRUè®¿é—®æ—¶é—´è®°å½•
        self.memory_pressure_level = 0.0  # å†…å­˜å‹åŠ›çº§åˆ« (0.0-1.0)
        
        # ç”Ÿæˆç»Ÿè®¡
        self.rule_generation_history: List[Tuple[float, int]] = []  # (æ—¶é—´, ç”Ÿæˆæ•°é‡)
        self.pruning_history: List[Tuple[float, str, str]] = []     # (æ—¶é—´, è§„å¾‹ID, åŸå› )
        
        # ç”Ÿæˆå‚æ•°
        self.min_support = config.get('min_support', 1) if config else 1  # æœ€å°æ”¯æŒåº¦ï¼ˆé™ä½åˆ°1ï¼‰
        
        # æ¨¡å¼åº“
        self.pattern_templates: Dict[RuleType, List[str]] = self._initialize_pattern_templates()
        
        # æ€§èƒ½æŒ‡æ ‡
        self.total_rules_generated = 0
        self.total_rules_pruned = 0
        self.total_rules_validated = 0
        self.total_rules_merged = 0  # æ–°å¢ï¼šåˆå¹¶ç»Ÿè®¡
        self.total_rules_rejected = 0  # æ–°å¢ï¼šæ‹’ç»ç»Ÿè®¡
        
        if self.logger:
            self.logger.log("æ€’æ”¾ä¸å‰ªææ¨¡å‹å·²åˆå§‹åŒ–")
    
    def _format_rule_to_standard_pattern(self, rule: CandidateRule) -> str:
        """åŸºäºè§„å¾‹çš„å®é™…EOCATRå†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼"""
        try:
            # è·å–è§„å¾‹çš„å®é™…ç»éªŒå†…å®¹
            condition_elements = getattr(rule, 'condition_elements', [])
            condition_text = getattr(rule, 'condition_text', '')
            pattern = getattr(rule, 'pattern', '')
            
            # æå–è§„å¾‹ä¸­çš„å®é™…EOCATRå†…å®¹
            actual_content = self._extract_rule_content(rule, condition_elements, condition_text, pattern)
            
            # æ ¹æ®å®é™…å†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼
            return self._generate_content_based_pattern(actual_content)
                
        except Exception as e:
            return f"å†…å®¹æ ¼å¼åŒ–å¤±è´¥: {str(e)}"
    
    def _extract_rule_content(self, rule, condition_elements, condition_text, pattern):
        """æå–è§„å¾‹ä¸­çš„å®é™…EOCATRå†…å®¹"""
        content = {
            'environment': None,
            'object': None, 
            'characteristics': [],
            'action': None,
            'tool': None,
            'result': None
        }
        
        # ğŸ”¥ ä¼˜å…ˆä»è§„å¾‹çš„conditionså­—å…¸ä¸­æå–å†…å®¹
        if hasattr(rule, 'conditions') and rule.conditions:
            for key, value in rule.conditions.items():
                if 'environment' in key.lower():
                    content['environment'] = value
                elif 'object' in key.lower():
                    content['object'] = value
                elif 'action' in key.lower():
                    content['action'] = value
                elif 'tool' in key.lower():
                    content['tool'] = value
                elif 'characteristic' in key.lower():
                    if isinstance(value, list):
                        content['characteristics'].extend(value)
                    else:
                        content['characteristics'].append(value)
        
        # ğŸ”¥ ä»predictionså­—å…¸ä¸­æå–ç»“æœä¿¡æ¯
        if hasattr(rule, 'predictions') and rule.predictions:
            for key, value in rule.predictions.items():
                if 'result' in key.lower() or 'success' in key.lower():
                    if isinstance(value, bool):
                        content['result'] = 'success' if value else 'failure'
                    else:
                        content['result'] = str(value)
                    break
        
        # ä»è§„å¾‹çš„æ¡ä»¶æ–‡æœ¬å’Œæ¨¡å¼ä¸­æå–å®é™…å†…å®¹
        all_text = f"{condition_text} {pattern}"
        
        # å°è¯•ä»æ¡ä»¶å…ƒç´ ä¸­æå–å†…å®¹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
        if not any([content['environment'], content['object'], content['action']]):
            for element in condition_elements:
                if hasattr(element, 'content') or hasattr(element, 'name'):
                    # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨è·å–elementå†…å®¹
                    element_content = getattr(element, "content", getattr(element, "name", str(element))).lower()
                    element_type = getattr(element, 'symbol_type', None)
                    
                    if element_type:
                        type_name = element_type.value.lower() if hasattr(element_type, 'value') else str(element_type).lower()
                        safe_content = getattr(element, "content", getattr(element, "name", str(element)))
                        if 'environment' in type_name:
                            content['environment'] = safe_content
                        elif 'object' in type_name:
                            content['object'] = safe_content
                        elif 'character' in type_name:
                            content['characteristics'].append(safe_content)
                        elif 'action' in type_name:
                            content['action'] = safe_content
                        elif 'tool' in type_name:
                            content['tool'] = safe_content
                        elif 'result' in type_name:
                            content['result'] = safe_content
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æå–åˆ°ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­è§£æ
        if not any([content['environment'], content['object'], content['action']]):
            parsed_content = self._parse_content_from_text(all_text)
            for key, value in parsed_content.items():
                if content[key] is None or (key == 'characteristics' and not content[key]):
                    content[key] = value
        
        return content
    
    def _parse_content_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­è§£æEOCATRå†…å®¹"""
        content = {
            'environment': None,
            'object': None, 
            'characteristics': [],
            'action': None,
            'tool': None,
            'result': None
        }
        
        text_lower = text.lower()
        
        # è§£æç¯å¢ƒ - æ”¯æŒä¸­è‹±æ–‡
        env_keywords = [
            'open_field', 'forest', 'water_source', 'danger_zone', 'safe_area',
            'å¼€é˜”åœ°', 'æ£®æ—', 'æ°´åŸŸ', 'å±é™©åŒºåŸŸ', 'å®‰å…¨åŒºåŸŸ', 'æ°´æºåŒºåŸŸ'
        ]
        for env in env_keywords:
            if env in text_lower:
                content['environment'] = env
                break
        
        # è§£æå¯¹è±¡ - æ”¯æŒä¸­è‹±æ–‡
        obj_keywords = [
            'berry', 'mushroom', 'tiger', 'rabbit', 'unknown', 'strawberry', 'potato',
            'è‰è“', 'è˜‘è‡', 'è€è™', 'å…”å­', 'é‡çŒª', 'é»‘ç†Š', 'æœªçŸ¥'
        ]
        for obj in obj_keywords:
            if obj in text_lower:
                content['object'] = obj
                break
        
        # è§£æç‰¹å¾ - æ”¯æŒä¸­è‹±æ–‡
        char_keywords = [
            'ripe', 'dangerous', 'safe', 'normal', 'toxic', 'near', 'far', 'healthy',
            'æˆç†Ÿ', 'å±é™©', 'å®‰å…¨', 'æ­£å¸¸', 'æœ‰æ¯’', 'è·ç¦»è¿‘', 'è·ç¦»è¿œ', 'å¥åº·',
            'å¯é£Ÿç”¨', 'è¥å…»ä¸°å¯Œ', 'è¡€é‡é«˜', 'è¡€é‡ä½'
        ]
        for char in char_keywords:
            if char in text_lower:
                content['characteristics'].append(char)
        
        # è§£æè¡ŒåŠ¨ - æ”¯æŒä¸­è‹±æ–‡
        action_keywords = [
            'explore', 'collect', 'move', 'attack', 'flee', 'right', 'left', 'up', 'down',
            'æ¢ç´¢', 'é‡‡é›†', 'ç§»åŠ¨', 'æ”»å‡»', 'é€ƒè·‘', 'è§‚å¯Ÿ', 'è·Ÿè¸ª', 'é€ƒé¿'
        ]
        for action in action_keywords:
            if action in text_lower:
                content['action'] = action
                break
        
        # è§£æå·¥å…· - æ”¯æŒä¸­è‹±æ–‡
        tool_keywords = [
            'basket', 'spear', 'axe', 'knife', 'rope',
            'ç¯®å­', 'é•¿çŸ›', 'æ–§å¤´', 'åˆ€', 'ç»³å­', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±'
        ]
        for tool in tool_keywords:
            if tool in text_lower:
                content['tool'] = tool
                break
        if 'none' in text_lower or 'æ— å·¥å…·' in text_lower:
            content['tool'] = 'none'
        
        # è§£æç»“æœ - æ”¯æŒä¸­è‹±æ–‡ï¼Œæ›´å…·ä½“çš„ç»“æœæè¿°
        result_keywords = [
            'success', 'failure', 'discovery', 'escape', 'damage', 'food_gained', 'water_gained',
            'position_changed', 'damage_dealt', 'health+', 'food+', 'water+', 'health-', 'food-', 'water-',
            'æˆåŠŸ', 'å¤±è´¥', 'å‘ç°', 'é€ƒè„±', 'ä¼¤å®³', 'è·å¾—é£Ÿç‰©', 'è·å¾—æ°´åˆ†', 'æ”¶é›†æˆåŠŸ', 
            'æ”»å‡»ç”Ÿæ•ˆ', 'æ•ˆç‡æå‡', 'å—åˆ°ä¼¤å®³', 'è·å¾—å¥–åŠ±', 'é£Ÿç‰©å¢åŠ ', 'æ°´åˆ†å¢åŠ ', 'è¡€é‡å¢åŠ ',
            'é£Ÿç‰©å‡å°‘', 'æ°´åˆ†å‡å°‘', 'è¡€é‡å‡å°‘', 'ç§»åŠ¨æˆåŠŸ', 'é‡‡é›†æˆåŠŸ', 'æ”»å‡»æˆåŠŸ', 'æ¢ç´¢æˆåŠŸ',
            'ç§»åŠ¨å¤±è´¥', 'é‡‡é›†å¤±è´¥', 'æ”»å‡»å¤±è´¥', 'æ¢ç´¢å¤±è´¥', 'ä½ç½®æ”¹å˜', 'é€ æˆä¼¤å®³'
        ]
        for result in result_keywords:
            if result in text_lower:
                content['result'] = result
                break
        
        return content
    
    def _generate_content_based_pattern(self, content):
        """æ ¹æ®å®é™…å†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼"""
        pattern_parts = []
        type_parts = []
        
        # æŒ‰ç…§EOCATRé¡ºåºæ£€æŸ¥å®é™…å†…å®¹
        if content['environment']:
            pattern_parts.append(content['environment'])
            type_parts.append('E')
        
        if content['object']:
            pattern_parts.append(content['object'])
            type_parts.append('O')
        
        if content['characteristics']:
            char_count = len(content['characteristics'])
            if char_count == 1:
                pattern_parts.append(content['characteristics'][0])
                type_parts.append('C1')
            elif char_count == 2:
                pattern_parts.append(','.join(content['characteristics']))
                type_parts.append('C2')
            else:
                pattern_parts.append(','.join(content['characteristics'][:3]))
                type_parts.append('C3')
        
        # Aå’ŒTè‡³å°‘è¦æœ‰ä¸€ä¸ª
        if content['action'] and content['tool'] and content['tool'] != 'none':
            # å¦‚æœåŒæ—¶æœ‰è¡ŒåŠ¨å’Œå·¥å…·ï¼Œä¼˜å…ˆæ˜¾ç¤ºå·¥å…·
            pattern_parts.append(content['tool'])
            type_parts.append('T')
        elif content['tool'] and content['tool'] != 'none':
            pattern_parts.append(content['tool'])
            type_parts.append('T')
        elif content['action']:
            pattern_parts.append(content['action'])
            type_parts.append('A')
        
        # ç»“æœ
        if content['result']:
            pattern_parts.append(content['result'])
            type_parts.append('R')
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®ç»“æœï¼Œä½¿ç”¨é»˜è®¤
            pattern_parts.append('result')
            type_parts.append('R')
        
        # ç”Ÿæˆæœ€ç»ˆæ ¼å¼ï¼šå®é™…å†…å®¹-ç±»å‹æ ‡è¯†
        if len(pattern_parts) >= 2:
            content_pattern = '-'.join(pattern_parts)
            type_pattern = '-'.join(type_parts)
            return f"{content_pattern} ({type_pattern})"
        else:
            return 'UNKNOWN'

    def _default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½® - å¹³è¡¡ç‰ˆæœ¬"""
        return {
            # æ€’æ”¾å‚æ•°ï¼ˆå¹³è¡¡è®¾ç½®ï¼‰
            'max_candidate_rules': 5000,        # é€‚ä¸­çš„æœ€å¤§å€™é€‰è§„å¾‹æ•°é‡
            'generation_threshold': 2,          # é™ä½ç”Ÿæˆé˜ˆå€¼ï¼š2ä¸ªç»éªŒå³å¯è§¦å‘
            'pattern_diversity_weight': 0.3,    # é€‚ä¸­çš„å¤šæ ·æ€§æƒé‡
            'immediate_rule_generation': True,   # ä¿æŒç«‹å³ç”Ÿæˆ
            
            # å‰ªæå‚æ•°ï¼ˆé€‚ä¸­ä¸¥æ ¼ï¼‰
            'pruning_confidence_threshold': 0.05,  # é€‚ä¸­çš„å‰ªæé˜ˆå€¼
            'pruning_age_threshold': 200,          # é€‚ä¸­çš„ä¿ç•™æ—¶é—´
            'contradicting_evidence_threshold': 0.8,  # é€‚ä¸­çš„çŸ›ç›¾å®¹å¿åº¦
            
            # éªŒè¯å‚æ•°ï¼ˆé™ä½é—¨æ§›ï¼‰
            'validation_confidence_threshold': 0.2,   # è¿›ä¸€æ­¥é™ä½éªŒè¯ç½®ä¿¡åº¦é˜ˆå€¼
            'validation_success_rate_threshold': 0.4, # æ–°å¢ï¼šæˆåŠŸç‡é˜ˆå€¼
            'validation_evidence_threshold': 1,       # ä¿æŒä½è¯æ®è¦æ±‚
            
            # è‡ªåŠ¨æ™‹å‡ï¼ˆæ–°å¢ï¼‰
            'auto_promotion_enabled': True,
            'auto_promote_repeat_threshold': 4,
            'auto_promote_confidence_threshold': 0.5,
            'auto_promote_max_contradiction_ratio': 0.5,
            
            # è´¨é‡æ§åˆ¶ï¼ˆå®½æ¾ä½†æœ‰æ ‡å‡†ï¼‰
            'min_activation_for_validation': 0,       # æ— æ¿€æ´»æ¬¡æ•°è¦æ±‚
            'max_complexity': 8,                      # å…è®¸è¾ƒé«˜å¤æ‚åº¦
            'min_quality_threshold': 0.01,            # éå¸¸ä½çš„è´¨é‡é˜ˆå€¼
            'enable_single_experience_rules': True,   # å…è®¸å•ç»éªŒè§„å¾‹
            'force_rule_generation': False,           # ä¸å¼ºåˆ¶ç”Ÿæˆ
        }
    def _initialize_pattern_templates(self) -> Dict[RuleType, List[str]]:
        """åˆå§‹åŒ–æ¨¡å¼æ¨¡æ¿"""
        return {
            RuleType.CAUSAL: [
                "å½“{condition}æ—¶ï¼Œæ‰§è¡Œ{action}å¯¼è‡´{result}",
                "åœ¨{environment}ä¸­ï¼Œ{object}+{action}â†’{outcome}",
                "{trigger}å¼•èµ·{consequence}"
            ],
            RuleType.CONDITIONAL: [
                "å¦‚æœ{condition}ï¼Œåˆ™{action}",
                "å½“{state}æ»¡è¶³{threshold}æ—¶ï¼Œé€‰æ‹©{action}",
                "åœ¨{context}ä¸‹ï¼Œé¿å…{negative_action}"
            ],
            RuleType.SEQUENTIAL: [
                "{action1}ä¹‹ååº”è¯¥{action2}",
                "å…ˆ{prerequisite}ï¼Œå†{main_action}",
                "{sequence}çš„æœ€ä¼˜é¡ºåº"
            ],
            RuleType.SPATIAL: [
                "åœ¨{location}é™„è¿‘ï¼Œé€‚åˆ{action}",
                "è·ç¦»{object} {distance}æ—¶ï¼Œ{recommendation}",
                "{spatial_pattern}çš„è¡Œä¸ºæ¨¡å¼"
            ],
            RuleType.ASSOCIATIVE: [
                "{object1}é€šå¸¸ä¸{object2}ä¸€èµ·å‡ºç°",
                "{pattern}çš„ç»„åˆæ•ˆåº”",
                "{correlation}çš„å…³è”æ€§"
            ],
            RuleType.EXCLUSION: [
                "{condition}æ—¶ï¼Œé¿å…{action}",
                "{object}ä¸{incompatible}ä¸èƒ½åŒæ—¶å¤„ç†",
                "{exclusion_pattern}"
            ],
            RuleType.OPTIMIZATION: [
                "åœ¨{situation}ä¸­ï¼Œ{option1}ä¼˜äº{option2}",
                "{context}ä¸‹çš„æœ€ä¼˜ç­–ç•¥æ˜¯{strategy}",
                "{optimization_rule}"
            ],
            RuleType.TOOL_EFFECTIVENESS: [
                "å·¥å…·{tool}å¯¹{target}çš„æ•ˆæœæ˜¯{effect}",
                "åœ¨{context}ä¸‹ï¼Œå·¥å…·{tool}å¯¹{target}çš„æ•ˆæœæ˜¯{effect}",
                "{tool}å¯¹{target}çš„æ•ˆæœæ˜¯{effect}"
            ]
        }
    
    def bloom(self, eocar_experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """æ€’æ”¾é˜¶æ®µçš„åˆ«åæ–¹æ³•"""
        return self.blooming_phase(eocar_experiences)
    
    def blooming_phase(self, eocar_experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """
        æ€’æ”¾é˜¶æ®µï¼šåŸºäºç»éªŒç”Ÿæˆå€™é€‰è§„å¾‹
        
        ğŸ”¥ æ ¸å¿ƒç­–ç•¥å˜æ›´ï¼šç§»é™¤æ‰€æœ‰é˜ˆå€¼é™åˆ¶ï¼Œç«‹å³è§„å¾‹åŒ–
        """
        try:
            # ğŸš€ æ•ˆç‡ä¼˜åŒ–ï¼šè¿‡æ»¤ç›¸å…³ç»éªŒ
            eocar_experiences = self._filter_relevant_experiences_for_blooming(eocar_experiences)
            
            # ğŸ¯ æ£€æŸ¥æ–°ç»éªŒå……è¶³æ€§
            if not self._has_sufficient_new_experiences(eocar_experiences):
                return []
            
            if not eocar_experiences:
                return []
            
            new_rules = []
            
            # ğŸ”§ é¢„å¤„ç†ï¼šåˆ†ç¦»å·¥å…·ä½¿ç”¨å’Œå¸¸è§„ç»éªŒ
            tool_usage_experiences = [exp for exp in eocar_experiences if exp.is_tool_usage()]
            regular_experiences = [exp for exp in eocar_experiences if not exp.is_tool_usage()]
            
            if self.logger:
                self.logger.log(f"ğŸŒ¸ æ€’æ”¾é˜¶æ®µå¼€å§‹ï¼šæ€»ç»éªŒ{len(eocar_experiences)}ä¸ªï¼ˆå·¥å…·ä½¿ç”¨:{len(tool_usage_experiences)}, å¸¸è§„:{len(regular_experiences)}ï¼‰")
            
            # === ğŸ”§ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå·¥å…·ä½¿ç”¨è§„å¾‹ç”Ÿæˆ ===
            if tool_usage_experiences:
                if self.logger:
                    self.logger.log(f"ğŸ”§ ä¼˜å…ˆå¤„ç†å·¥å…·ä½¿ç”¨ç»éªŒ...")
                
                # ç›´æ¥è°ƒç”¨å·¥å…·æ•ˆæœè§„å¾‹ç”Ÿæˆ
                tool_rules = self._generate_tool_effectiveness_rules(tool_usage_experiences)
                new_rules.extend(tool_rules)
                
                if self.logger and tool_rules:
                    self.logger.log(f"ğŸ”§ å·¥å…·è§„å¾‹ç”Ÿæˆ: {len(tool_rules)}æ¡è§„å¾‹")
                    for rule in tool_rules[:3]:  # æ˜¾ç¤ºå‰3æ¡
                        self.logger.log(f"   -> {rule.pattern}")
            
            # === ğŸ”¥ æ ¸å¿ƒç­–ç•¥ï¼šæ— é˜ˆå€¼æ¨¡å¼åˆ†ç»„ ===
            # æŒ‰æ¨¡å¼åˆ†ç»„æ‰€æœ‰ç»éªŒï¼Œä½†ä¸è®¾ç½®ä»»ä½•é™åˆ¶
            experience_groups = self._group_experiences_by_pattern(eocar_experiences)
            
            if self.logger:
                self.logger.log(f"ğŸ”¥ ç»éªŒåˆ†ç»„å®Œæˆï¼šå…±{len(experience_groups)}ä¸ªæ¨¡å¼ç»„")
                for pattern_key, group_experiences in experience_groups.items():
                    self.logger.log(f"ğŸ”¥   æ¨¡å¼'{pattern_key}': {len(group_experiences)}ä¸ªç»éªŒ")
            
            # === ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šç§»é™¤é˜ˆå€¼é™åˆ¶ï¼Œæ¯ä¸ªæ¨¡å¼ç»„éƒ½ç”Ÿæˆè§„å¾‹ ===
            group_rule_counts = {}
            for pattern_key, group_experiences in experience_groups.items():
                # ğŸ”¥ ç§»é™¤ min_group_size æ£€æŸ¥ï¼šä»»ä½•æ¨¡å¼ç»„éƒ½å¤„ç†
                try:
                    if self.logger:
                        self.logger.log(f"ğŸ”¥ å¤„ç†æ¨¡å¼ç»„ '{pattern_key}': {len(group_experiences)}ä¸ªç»éªŒ")
                    
                    # ç”Ÿæˆè§„å¾‹ï¼ˆæ— æ•°é‡é™åˆ¶ï¼‰
                    group_rules = self._generate_rules_for_pattern(pattern_key, group_experiences)
                    
                    if self.logger:
                        self.logger.log(f"ğŸ”¥ æ¨¡å¼ç»„'{pattern_key}'ç”Ÿæˆ{len(group_rules)}æ¡åˆå§‹è§„å¾‹")
                    
                    # ğŸ”¥ ç§»é™¤è´¨é‡æ£€æŸ¥å’Œæ•°é‡é™åˆ¶ï¼Œåªè¿›è¡ŒåŸºæœ¬å»é‡
                    accepted_rules = []
                    for rule in group_rules:
                        # åªåšæœ€åŸºæœ¬çš„é‡å¤æ£€æŸ¥ï¼Œä¸åšè´¨é‡ç­›é€‰
                        if not self._is_obvious_duplicate_simple(rule):
                            accepted_rules.append(rule)
                            if self.logger:
                                self.logger.log(f"ğŸ”¥ æ¥å—è§„å¾‹: {rule.pattern[:50]}...")
                        else:
                            if self.logger:
                                self.logger.log(f"ğŸ”¥ è·³è¿‡é‡å¤è§„å¾‹: {rule.pattern[:50]}...")
                    
                    new_rules.extend(accepted_rules)
                    group_rule_counts[pattern_key] = len(accepted_rules)
                    
                    if self.logger:
                        self.logger.log(f"ğŸ”¥ æ¨¡å¼ç»„'{pattern_key}'æœ€ç»ˆæ¥å—{len(accepted_rules)}æ¡è§„å¾‹")
                        
                except Exception as e:
                    if self.logger:
                        self.logger.log(f"âŒ æ¨¡å¼ç»„'{pattern_key}'è§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
                        import traceback
                        self.logger.log(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            # === ğŸ”¥ ç§»é™¤è´¨é‡æ§åˆ¶ï¼Œç›´æ¥æ¥å—æ‰€æœ‰è§„å¾‹ ===
            if new_rules:
                # ğŸ”¥ åªåšæœ€åŸºæœ¬çš„å»é‡ï¼Œä¸åšè´¨é‡ç­›é€‰
                final_rules = []
                for rule in new_rules:
                    # ğŸ”¥ ç§»é™¤è´¨é‡æ£€æŸ¥ï¼Œç›´æ¥æ¥å—è§„å¾‹
                    if not self._is_obvious_duplicate_simple(rule):
                        final_rules.append(rule)
                        if self.logger:
                            self.logger.log(f"ğŸ”¥ æœ€ç»ˆæ¥å—è§„å¾‹: {rule.rule_id[:8]}... - {rule.pattern[:30]}...")
                    else:
                        if self.logger:
                            self.logger.log(f"ğŸ”¥ æœ€ç»ˆè·³è¿‡é‡å¤: {rule.rule_id[:8]}...")
                
                # å°†æ–°è§„å¾‹æ·»åŠ åˆ°å€™é€‰é›†åˆ
                for rule in final_rules:
                    self.candidate_rules[rule.rule_id] = rule
                    # ğŸ”¥ ä½¿ç”¨å†…å®¹æŒ‡çº¹è¿›è¡Œå»é‡è·Ÿè¸ª
                    content_fingerprint = self._generate_content_fingerprint(rule)
                    self.rule_fingerprints.add(content_fingerprint)
                    self.total_rules_generated += 1
                
                # è®°å½•ç”Ÿæˆå†å²
                self.rule_generation_history.append((time.time(), len(final_rules)))
                
                if self.logger:
                    self.logger.log(f"ğŸ”¥ æ–°ç»éªŒç«‹å³è§„å¾‹åŒ–æˆåŠŸï¼šç”Ÿæˆ {len(final_rules)} ä¸ªå€™é€‰è§„å¾‹")
                    
                    # ç»Ÿè®¡è§„å¾‹ç±»å‹åˆ†å¸ƒ
                    type_counts = {}
                    for rule in final_rules:
                        rule_type = rule.rule_type.value
                        type_counts[rule_type] = type_counts.get(rule_type, 0) + 1
                    
                    # è¯¦ç»†æŠ¥å‘Šå„ç±»å‹è§„å¾‹æ•°é‡  
                    for rule_type, count in sorted(type_counts.items()):
                        self.logger.log(f"ğŸ”¥   {rule_type}: {count}æ¡è§„å¾‹")
                    
                    # ç‰¹åˆ«æŠ¥å‘Šå·¥å…·è§„å¾‹
                    tool_rule_count = type_counts.get('tool_effectiveness', 0)
                    if tool_rule_count > 0:
                        self.logger.log(f"ğŸ”§ å·¥å…·æ•ˆç”¨è§„å¾‹: {tool_rule_count}æ¡ â­")
                    
                    # æ˜¾ç¤ºå‰å‡ æ¡è§„å¾‹çš„å†…å®¹
                    self.logger.log(f"ğŸ”¥ å‰3æ¡ç”Ÿæˆçš„è§„å¾‹ç¤ºä¾‹:")
                    for i, rule in enumerate(final_rules[:3]):
                        rule_format = self._format_rule_to_standard_pattern(rule)
                        self.logger.log(f"ğŸ”¥   {i+1}. {rule_format}")
                
                return final_rules
            else:
                if self.logger:
                    self.logger.log("ğŸ”¥ è­¦å‘Šï¼šå³ä½¿ç§»é™¤æ‰€æœ‰é˜ˆå€¼é™åˆ¶ï¼Œä»æœªç”Ÿæˆä»»ä½•è§„å¾‹")
                    self.logger.log(f"ğŸ”¥ è¾“å…¥ç»éªŒæ•°é‡: {len(eocar_experiences)}")
                    self.logger.log(f"ğŸ”¥ ç»éªŒåˆ†ç»„æ•°é‡: {len(experience_groups)}")
                    for pattern_key, group_experiences in experience_groups.items():
                        self.logger.log(f"ğŸ”¥   æ¨¡å¼'{pattern_key}': {len(group_experiences)}ä¸ªç»éªŒ")
                return []
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ æ–°ç»éªŒç«‹å³è§„å¾‹åŒ–å‘ç”Ÿé”™è¯¯: {str(e)}")
                import traceback
                self.logger.log(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []
    
    def _group_experiences_by_pattern(self, experiences: List[EOCATR_Tuple]) -> Dict[str, List[EOCATR_Tuple]]:
        """æŒ‰æ¨¡å¼åˆ†ç»„ç»éªŒï¼Œè¿›è¡Œé¢„å¤„ç†å’Œåˆ†ç±»"""
        pattern_groups = defaultdict(list)
        
        # ğŸ”§ ä¼˜å…ˆå¤„ç†å·¥å…·ä½¿ç”¨ç»éªŒï¼ˆæ–°å¢ç‰¹æ®Šå¤„ç†ï¼‰
        tool_usage_experiences = []
        non_tool_experiences = []
        
        for exp in experiences:
            if exp.is_tool_usage():  # ä½¿ç”¨å·¥å…·çš„ç»éªŒ
                tool_usage_experiences.append(exp)
                
                # ä¸ºå·¥å…·ä½¿ç”¨ç»éªŒåˆ›å»ºä¸“é—¨çš„æ¨¡å¼ç»„
                tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                obj_val = exp.object_category.value if exp.object_category and hasattr(exp.object_category, 'value') else 'unknown'
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                tool_pattern_key = f"TOOL_USAGE_{tool_val}_{obj_val}_{act_val}"
                pattern_groups[tool_pattern_key].append(exp)
                
                # åŒæ—¶ä¿ç•™åŸæœ‰åˆ†ç»„é€»è¾‘
                basic_pattern = f"{obj_val}+{act_val}+{tool_val}"
                pattern_groups[basic_pattern].append(exp)
            else:
                non_tool_experiences.append(exp)
                # åŸæœ‰åˆ†ç»„é€»è¾‘
                obj_val = exp.object_category.value if exp.object_category and hasattr(exp.object_category, 'value') else 'unknown'
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                basic_pattern = f"{obj_val}+{act_val}"
                pattern_groups[basic_pattern].append(exp)
        
        # ğŸ’¡ ç¯å¢ƒ-åŠ¨ä½œ-å·¥å…·ç»„åˆæ¨¡å¼ï¼ˆå¢å¼ºçš„ä¸‰ç»´æ¨¡å¼ï¼‰
        for exp in experiences:
            env_val = exp.environment.value if exp.environment and hasattr(exp.environment, 'value') else 'unknown'
            act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
            tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
            env_action_tool_pattern = f"ENV_{env_val}+ACT_{act_val}+TOOL_{tool_val}"
            pattern_groups[env_action_tool_pattern].append(exp)
        
        # ğŸ’ ç»“æœæˆåŠŸæ€§æ¨¡å¼ï¼ˆæŒ‰æˆåŠŸ/å¤±è´¥åˆ†ç»„ï¼‰
        success_pattern_key = "SUCCESS_PATTERNS"
        failure_pattern_key = "FAILURE_PATTERNS"
        
        for exp in experiences:
            if exp.result.success:
                pattern_groups[success_pattern_key].append(exp)
            else:
                pattern_groups[failure_pattern_key].append(exp)
        
        # ğŸ¯ å·¥å…·æ•ˆæœä¼˜åŒ–æ¨¡å¼ï¼ˆä¸“é—¨ç”¨äºå·¥å…·æ¯”è¾ƒï¼‰
        if tool_usage_experiences:
            # æŒ‰ç›®æ ‡ç±»å‹åˆ†ç»„å·¥å…·ä½¿ç”¨ç»éªŒ
            tool_targets = defaultdict(list)
            for exp in tool_usage_experiences:
                obj_val = exp.object_category.value if exp.object_category and hasattr(exp.object_category, 'value') else 'unknown'
                target_key = f"TARGET_{obj_val}"
                tool_targets[target_key].append(exp)
            
            # ä¸ºæ¯ä¸ªç›®æ ‡ç±»å‹åˆ›å»ºå·¥å…·æ¯”è¾ƒæ¨¡å¼
            for target_key, target_experiences in tool_targets.items():
                if len(target_experiences) >= 2:  # è‡³å°‘éœ€è¦2æ¬¡ç»éªŒè¿›è¡Œæ¯”è¾ƒ
                    comparison_pattern_key = f"TOOL_COMPARISON_{target_key}"
                    pattern_groups[comparison_pattern_key] = target_experiences
        
        # ğŸ“ è·ç¦»æ•ˆæœæ¨¡å¼
        for exp in experiences:
            distance_range = self._get_distance_range(exp.characteristics.distance)
            act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
            tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
            distance_pattern = f"DISTANCE_{distance_range}+{act_val}+{tool_val}"
            pattern_groups[distance_pattern].append(exp)
        
        # ğŸ“Š è®°å½•åˆ†ç»„ç»Ÿè®¡
        if self.logger:
            tool_groups = len([k for k in pattern_groups.keys() if 'TOOL_USAGE' in k])
            total_groups = len(pattern_groups)
            tool_exp_count = len(tool_usage_experiences)
            total_exp_count = len(experiences)
            
            if tool_groups > 0:
                self.logger.log(f"ğŸ”§ BPMç»éªŒåˆ†ç»„å®Œæˆ: {total_groups}ä¸ªæ¨¡å¼ç»„ï¼ˆå«{tool_groups}ä¸ªå·¥å…·ä¸“ç”¨ç»„ï¼‰")
                self.logger.log(f"ğŸ”§ å·¥å…·ä½¿ç”¨ç»éªŒï¼š{tool_exp_count}/{total_exp_count} ({tool_exp_count/total_exp_count*100:.1f}%)")
            else:
                self.logger.log(f"ğŸ”§ BPMç»éªŒåˆ†ç»„å®Œæˆ: {total_groups}ä¸ªæ¨¡å¼ç»„ï¼ˆæ— å·¥å…·ä½¿ç”¨è®°å½•ï¼‰")
        
        return dict(pattern_groups)
    
    def _generate_rules_for_pattern(self, pattern_key: str, experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """ğŸ”¥ é‡æ„ç‰ˆæœ¬ï¼šä¸ºç‰¹å®šæ¨¡å¼ç”Ÿæˆè§„å¾‹ï¼Œç§»é™¤é˜ˆå€¼é™åˆ¶"""
        # ğŸ”¥ ç§»é™¤é˜ˆå€¼æ£€æŸ¥ï¼šä»»ä½•æ•°é‡çš„ç»éªŒéƒ½åº”è¯¥å°è¯•ç”Ÿæˆè§„å¾‹
        if self.logger:
            self.logger.log(f"ğŸ”¥ å¼€å§‹ä¸ºæ¨¡å¼'{pattern_key}'ç”Ÿæˆè§„å¾‹ï¼Œç»éªŒæ•°: {len(experiences)}")
        
        # åˆ†æç»éªŒç‰¹å¾
        common_chars = self._extract_common_characteristics(experiences)
        common_results = self._extract_common_results(experiences)
        
        new_rules = []

        # === æ–°å¢ï¼šå•ç‰¹å¾Cå…­æ—ç”Ÿæˆï¼ˆE-C-A-R / E-C-T-R / O-C-A-R / O-C-T-R / C-A-R / C-T-Rï¼‰===
        try:
            # ä»æ¯æ¡ç»éªŒæå–å¯è§ç‰¹å¾é›†åˆï¼ˆcharacteristic_*ï¼‰ï¼Œé€ä¸ªç”Ÿæˆå•ç‰¹å¾Cå€™é€‰è§„å¾‹
            for exp in experiences:
                try:
                    # å°† E/O/A/T å–å€¼
                    env_val = exp.get_environment_compat().value if hasattr(exp, 'get_environment_compat') and exp.get_environment_compat() else None
                    obj_val = exp.object_category.value if hasattr(exp, 'object_category') and exp.object_category else None
                    act_val = exp.get_action_compat().value if hasattr(exp, 'get_action_compat') and exp.get_action_compat() else None
                    tool_val = exp.get_tool_compat().value if hasattr(exp, 'get_tool_compat') and exp.get_tool_compat() else None
                    res_val = exp.get_result_compat().content if hasattr(exp, 'get_result_compat') and exp.get_result_compat() else None

                    # è§£æ Cï¼šæ”¯æŒå­—ç¬¦ä¸²å½¢å¼çš„ "characteristic_x=y;..." æˆ–å…¼å®¹åŒ…è£…å™¨ä¸­çš„ content
                    c_candidates = []
                    try:
                        raw_c = getattr(exp, 'character', None)
                        raw_content = getattr(raw_c, 'content', None)
                        if isinstance(raw_content, str) and 'characteristic_' in raw_content:
                            for part in raw_content.split(';'):
                                part = part.strip()
                                if not part:
                                    continue
                                if '=' in part:
                                    k, v = part.split('=', 1)
                                    k = k.strip()
                                    v = v.strip()
                                    if k and v:
                                        c_candidates.append((k, v))
                    except Exception:
                        pass

                    # å¯¹æ¯ä¸ªå•ç‰¹å¾Cç”Ÿæˆå…­æ—å€™é€‰
                    for c_key, c_val in c_candidates[:8]:  # è½»åº¦é™æµï¼šæ¯æ¡ç»éªŒæœ€å¤šå–å‰8ä¸ªç‰¹å¾
                        # E-C-A-R
                        if env_val and act_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"ECAR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"åœ¨{env_val}ä¸­ï¼Œè‹¥{c_key}={c_val}ï¼Œæ‰§è¡Œ{act_val}â†’{res_val}",
                                conditions={'environment': env_val, c_key: c_val, 'action': act_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=3
                            ))
                        # E-C-T-R
                        if env_val and tool_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"ECTR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"åœ¨{env_val}ä¸­ï¼Œè‹¥{c_key}={c_val}ï¼Œä½¿ç”¨{tool_val}â†’{res_val}",
                                conditions={'environment': env_val, c_key: c_val, 'tool': tool_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=3
                            ))
                        # O-C-A-R
                        if obj_val and act_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"OCAR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"å¯¹{obj_val}ï¼Œè‹¥{c_key}={c_val}ï¼Œæ‰§è¡Œ{act_val}â†’{res_val}",
                                conditions={'object_category': obj_val, c_key: c_val, 'action': act_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=3
                            ))
                        # O-C-T-R
                        if obj_val and tool_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"OCTR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"å¯¹{obj_val}ï¼Œè‹¥{c_key}={c_val}ï¼Œä½¿ç”¨{tool_val}â†’{res_val}",
                                conditions={'object_category': obj_val, c_key: c_val, 'tool': tool_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=3
                            ))
                        # C-A-R
                        if act_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"CAR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"è‹¥{c_key}={c_val}ï¼Œæ‰§è¡Œ{act_val}â†’{res_val}",
                                conditions={c_key: c_val, 'action': act_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=2
                            ))
                        # C-T-R
                        if tool_val and res_val:
                            new_rules.append(CandidateRule(
                                rule_id=f"CTR_{int(time.time()*1000000)%1000000}",
                                rule_type=RuleType.CAUSAL,
                                pattern=f"è‹¥{c_key}={c_val}ï¼Œä½¿ç”¨{tool_val}â†’{res_val}",
                                conditions={c_key: c_val, 'tool': tool_val},
                                predictions={'result': res_val, 'expected_success': exp.success},
                                confidence=0.5,
                                complexity=2
                            ))
                except Exception:
                    continue
        except Exception:
            pass
        
        # æ ¹æ®æ¨¡å¼ç±»å‹ç”Ÿæˆä¸åŒç±»å‹çš„è§„å¾‹ï¼ˆä¿®å¤ç‰ˆï¼‰
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åŠ¨ä½œæ¨¡å¼ï¼ˆä¿®å¤ï¼šæ£€æŸ¥å®é™…çš„åŠ¨ä½œåç§°ï¼‰
        action_patterns = ['GATHER', 'MOVE', 'AVOID', 'ATTACK', 'DRINK', 'EXPLORE', 'collect', 'drink', 'move', 'explore', 'rest']
        has_action_pattern = any(action in pattern_key for action in action_patterns)
        
        if has_action_pattern or "+" in pattern_key:  # å¯¹è±¡+åŠ¨ä½œç»„åˆ
            new_rules.extend(self._generate_causal_rules(pattern_key, experiences, common_chars, common_results))
            new_rules.extend(self._generate_conditional_rules(pattern_key, experiences, common_chars))
        
        # æ£€æŸ¥ç»“æœæ¨¡å¼
        if "success" in pattern_key or "failure" in pattern_key:
            new_rules.extend(self._generate_optimization_rules(pattern_key, experiences))
        
        # æ£€æŸ¥ç¯å¢ƒæ¨¡å¼
        if "env_" in pattern_key:
            new_rules.extend(self._generate_spatial_rules(experiences))
        
        # æ£€æŸ¥æ—¶åºæ¨¡å¼
        if "sequence" in pattern_key or len(experiences) > 5:
            new_rules.extend(self._generate_sequential_rules(experiences))
        
        # === æ–°å¢ï¼šå·¥å…·æ•ˆç”¨è§„å¾‹ç”Ÿæˆ ===
        if ("tool_usage_" in pattern_key or "tool_effect_" in pattern_key or "tool_type_" in pattern_key or 
            "tool_use" in pattern_key or "tool" in pattern_key.lower()):
            new_rules.extend(self._generate_tool_effectiveness_rules(experiences))
        
        # === ğŸ”¥ æåº¦å®½æ¾çš„è§„å¾‹æ¥å—ç­–ç•¥ ===
        filtered_rules = []
        for rule in new_rules:
            # ğŸ”¥ åªåšæœ€åŸºæœ¬çš„ç»“æ„æ£€æŸ¥ï¼Œç§»é™¤æ‰€æœ‰è´¨é‡å’Œé‡å¤é™åˆ¶
            if rule.rule_id and rule.pattern:  # åªè¦æœ‰åŸºæœ¬ç»“æ„å°±æ¥å—
                filtered_rules.append(rule)
                # æ·»åŠ è§„å¾‹æŒ‡çº¹ï¼ˆä½†ä¸ç”¨äºæ‹’ç»ï¼‰
                try:
                    self.rule_fingerprints.add(self._generate_rule_fingerprint(rule))
                except:
                    pass  # æŒ‡çº¹ç”Ÿæˆå¤±è´¥ä¹Ÿä¸å½±å“è§„å¾‹æ¥å—
                
                if self.logger:
                    self.logger.log(f"ğŸ”¥ æ¥å—è§„å¾‹: {rule.rule_id[:8]}... - {rule.pattern[:50]}...")
            else:
                if self.logger:
                    self.logger.log(f"ğŸ”¥ è·³è¿‡æ— æ•ˆè§„å¾‹: rule_id={getattr(rule, 'rule_id', 'None')}, pattern={getattr(rule, 'pattern', 'None')}")
        
        if self.logger:
            self.logger.log(f"ğŸ”¥ æ¨¡å¼'{pattern_key}'æœ€ç»ˆç”Ÿæˆ{len(filtered_rules)}æ¡è§„å¾‹")
        
        return filtered_rules
    
    def _passes_quality_check(self, rule: CandidateRule) -> bool:
        """å¢å¼ºçš„è´¨é‡æ£€æŸ¥ - å¹³è¡¡ä¸¥æ ¼æ€§å’ŒåŒ…å®¹æ€§"""
        try:
            # åŸºç¡€ç»“æ„æ£€æŸ¥
            if not rule.rule_id or not rule.pattern:
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: ç¼ºå°‘åŸºæœ¬ç»“æ„")
                return False
            
            # è®¡ç®—è´¨é‡å¾—åˆ†
            quality_score = rule.calculate_quality_score()
            
            # é™ä½è´¨é‡é˜ˆå€¼ï¼Œæé«˜åŒ…å®¹æ€§
            min_threshold = self.config.get('min_quality_threshold', 0.01)
            if quality_score < min_threshold:
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: è´¨é‡å¾—åˆ†{quality_score:.3f} < é˜ˆå€¼{min_threshold}")
                return False
            
            # ç½®ä¿¡åº¦æ£€æŸ¥ - éå¸¸å®½æ¾
            if rule.confidence < 0.001:  # æä½é˜ˆå€¼
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: ç½®ä¿¡åº¦è¿‡ä½{rule.confidence:.3f}")
                return False
            
            # å¤æ‚åº¦æ£€æŸ¥ - å…è®¸æ›´é«˜å¤æ‚åº¦
            max_complexity = self.config.get('max_complexity', 10)
            if rule.complexity > max_complexity:
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: å¤æ‚åº¦è¿‡é«˜{rule.complexity} > {max_complexity}")
                return False
            
            # æ¡ä»¶å’Œé¢„æµ‹å®Œæ•´æ€§æ£€æŸ¥ - å®½æ¾æ£€æŸ¥
            if not rule.conditions and not rule.predictions:
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: æ¡ä»¶å’Œé¢„æµ‹éƒ½ä¸ºç©º")
                return False
            
            # æ¨¡å¼æœ‰æ•ˆæ€§æ£€æŸ¥ - æ›´å®½æ¾
            if len(rule.pattern.strip()) < 5:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
                if self.logger:
                    self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¤±è´¥: æ¨¡å¼è¿‡çŸ­")
                return False
            
            if self.logger:
                self.logger.log(f"âœ… è´¨é‡æ£€æŸ¥é€šè¿‡: {rule.rule_id[:8]} (å¾—åˆ†:{quality_score:.3f})")
            return True
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ è´¨é‡æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return False

    def _is_obvious_duplicate_simple(self, rule: CandidateRule) -> bool:
        """
        ğŸ”¥ æ”¹è¿›çš„é‡å¤æ£€æŸ¥ï¼šåŸºäºå†…å®¹æŒ‡çº¹è€Œä¸æ˜¯ID
        æ£€æŸ¥è§„å¾‹å†…å®¹æ˜¯å¦çœŸæ­£é‡å¤
        """
        try:
            # ç”ŸæˆåŸºäºå†…å®¹çš„æŒ‡çº¹ï¼ˆä¸åŒ…å«æ—¶é—´æˆ³ï¼‰
            content_fingerprint = self._generate_content_fingerprint(rule)
            
            # æ£€æŸ¥æŒ‡çº¹æ˜¯å¦å·²å­˜åœ¨
            if content_fingerprint in self.rule_fingerprints:
                if self.logger:
                    self.logger.log(f"ğŸ”¥ å‘ç°é‡å¤è§„å¾‹å†…å®¹: {rule.pattern[:30]}...")
                return True
            
            # æ£€æŸ¥ä¸ç°æœ‰è§„å¾‹çš„ç›¸ä¼¼åº¦
            all_existing_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
            for existing_rule in all_existing_rules:
                if self._is_content_identical(rule, existing_rule):
                    if self.logger:
                        self.logger.log(f"ğŸ”¥ å‘ç°å†…å®¹ç›¸åŒçš„è§„å¾‹: {rule.pattern[:30]}...")
                    return True
            
            return False
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ ç®€å•é‡å¤æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False  # å¼‚å¸¸æ—¶ä¸è®¤ä¸ºé‡å¤
    def _is_duplicate_rule(self, rule: CandidateRule) -> bool:
        """æ£€æŸ¥è§„å¾‹æ˜¯å¦ä¸ºé‡å¤è§„å¾‹ï¼ˆå¢å¼ºè°ƒè¯•ç‰ˆæœ¬ï¼‰"""
        try:
            # ğŸš¨ FORCE DEBUG
            if self.logger:
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: æ£€æŸ¥è§„å¾‹ rule_id={rule.rule_id[:8]}...")
            
            # ç”Ÿæˆå½“å‰è§„å¾‹çš„æŒ‡çº¹
            current_fingerprint = self._generate_rule_fingerprint(rule)
            if self.logger:
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: å½“å‰æŒ‡çº¹={current_fingerprint[:8]}...")
            
            # å¿«é€ŸæŒ‡çº¹æ£€æŸ¥
            if current_fingerprint in self.rule_fingerprints:
                if self.logger:
                    self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: æŒ‡çº¹é‡å¤! å·²å­˜åœ¨ç›¸åŒæŒ‡çº¹")
                return True
            
            if self.logger:
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: æŒ‡çº¹æ£€æŸ¥é€šè¿‡ï¼Œå¼€å§‹è¯¦ç»†ç›¸ä¼¼åº¦æ£€æŸ¥...")
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: ç°æœ‰å€™é€‰è§„å¾‹æ•°={len(self.candidate_rules)}, å·²éªŒè¯è§„å¾‹æ•°={len(self.validated_rules)}")
            
            # è¯¦ç»†ç›¸ä¼¼åº¦æ£€æŸ¥
            all_existing_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
            for i, existing_rule in enumerate(all_existing_rules):
                similarity = self._calculate_rule_similarity(rule, existing_rule)
                if self.logger:
                    self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: ä¸ç°æœ‰è§„å¾‹{i+1} ç›¸ä¼¼åº¦={similarity:.3f}, é˜ˆå€¼={self.rule_similarity_threshold}")
                
                if similarity > self.rule_similarity_threshold:
                    if self.logger:
                        self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: ç›¸ä¼¼åº¦è¿‡é«˜! è®¤å®šä¸ºé‡å¤")
                    return True
            
            if self.logger:
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œéé‡å¤è§„å¾‹")
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ğŸ”¥ DUPLICATE CHECK: å¼‚å¸¸={str(e)}")
                self.logger.log(f"é‡å¤æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    def _generate_rule_fingerprint(self, rule: CandidateRule) -> str:
        """ç”Ÿæˆè§„å¾‹çš„å”¯ä¸€æŒ‡çº¹ï¼ˆåŒ…å«IDç¡®ä¿å”¯ä¸€æ€§ï¼‰"""
        try:
            # åŒ…å«IDçš„å®Œæ•´æŒ‡çº¹ï¼Œç”¨äºLRUç­‰ç®¡ç†
            fingerprint_components = [
                rule.rule_type.value,
                rule.rule_id,  # ä¿ç•™IDç¡®ä¿ç»å¯¹å”¯ä¸€
                str(sorted(enumerate(rule.condition_elements))),
                str(sorted(rule.predictions.items())),
                rule.pattern,
                str(rule.confidence),
                str(rule.complexity)
            ]
            
            # ä½¿ç”¨å“ˆå¸Œç”ŸæˆæŒ‡çº¹
            import hashlib
            fingerprint_str = "|".join(fingerprint_components)
            fingerprint = hashlib.md5(fingerprint_str.encode()).hexdigest()
            
            return fingerprint
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ç”ŸæˆæŒ‡çº¹å¤±è´¥: {str(e)}")
            # ç¡®ä¿å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè¿”å›å”¯ä¸€æŒ‡çº¹
            return f"error_{rule.rule_id}_{int(time.time() * 1000000)}"
    
    def _generate_content_fingerprint(self, rule: CandidateRule) -> str:
        """ç”ŸæˆåŸºäºå†…å®¹çš„æŒ‡çº¹ï¼ˆç”¨äºå»é‡ï¼‰"""
        try:
            # ğŸ”¥ åªåŸºäºè§„å¾‹å†…å®¹ï¼Œä¸åŒ…å«IDå’Œæ—¶é—´æˆ³
            content_components = [
                rule.rule_type.value,
                str(sorted(rule.condition_elements)),
                str(sorted(rule.predictions.items())),
                rule.pattern.strip().lower(),  # æ ‡å‡†åŒ–æ¨¡å¼æ–‡æœ¬
                str(sorted(rule.conditions.items())),
            ]
            
            # ä½¿ç”¨å“ˆå¸Œç”Ÿæˆå†…å®¹æŒ‡çº¹
            import hashlib
            content_str = "|".join(content_components)
            content_fingerprint = hashlib.md5(content_str.encode()).hexdigest()
            
            return content_fingerprint
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ç”Ÿæˆå†…å®¹æŒ‡çº¹å¤±è´¥: {str(e)}")
            return f"content_error_{int(time.time() * 1000000)}"
    
    def _is_content_identical(self, rule1: CandidateRule, rule2: CandidateRule) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªè§„å¾‹çš„å†…å®¹æ˜¯å¦å®Œå…¨ç›¸åŒ"""
        try:
            # æ£€æŸ¥æ ¸å¿ƒå†…å®¹æ˜¯å¦ç›¸åŒ
            return (
                rule1.rule_type == rule2.rule_type and
                rule1.pattern.strip().lower() == rule2.pattern.strip().lower() and
                sorted(rule1.condition_elements) == sorted(rule2.condition_elements) and
                rule1.predictions == rule2.predictions and
                rule1.conditions == rule2.conditions
            )
        except Exception as e:
            if self.logger:
                self.logger.log(f"å†…å®¹æ¯”è¾ƒå¤±è´¥: {str(e)}")
            return False

    def _calculate_rule_similarity(self, rule1: CandidateRule, rule2: CandidateRule) -> float:
        """è®¡ç®—ä¸¤ä¸ªè§„å¾‹ä¹‹é—´çš„ç›¸ä¼¼åº¦"""
        try:
            if rule1.rule_type != rule2.rule_type:
                return 0.0
            
            # æ¡ä»¶ç›¸ä¼¼åº¦
            conditions_similarity = self._calculate_dict_similarity(rule1.conditions, rule2.conditions)
            
            # é¢„æµ‹ç›¸ä¼¼åº¦
            predictions_similarity = self._calculate_dict_similarity(rule1.predictions, rule2.predictions)
            
            # æ¨¡å¼ç›¸ä¼¼åº¦
            pattern_similarity = self._calculate_text_similarity(rule1.pattern, rule2.pattern)
            
            # åŠ æƒå¹³å‡
            overall_similarity = (
                conditions_similarity * 0.4 +
                predictions_similarity * 0.4 +
                pattern_similarity * 0.2
            )
            
            return overall_similarity
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return 0.0
    
    def _calculate_dict_similarity(self, dict1: Dict, dict2: Dict) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—å…¸çš„ç›¸ä¼¼åº¦"""
        if not dict1 and not dict2:
            return 1.0
        if not dict1 or not dict2:
            return 0.0
        
        # æ‰¾åˆ°å…±åŒçš„é”®
        common_keys = set(dict1.keys()) & set(dict2.keys())
        all_keys = set(dict1.keys()) | set(dict2.keys())
        
        if not all_keys:
            return 1.0
        
        # è®¡ç®—å…±åŒé”®çš„æ¯”ä¾‹
        key_similarity = len(common_keys) / len(all_keys)
        
        # è®¡ç®—å…±åŒé”®çš„å€¼ç›¸ä¼¼åº¦
        value_similarity = 0.0
        if common_keys:
            for key in common_keys:
                if dict1[key] == dict2[key]:
                    value_similarity += 1.0
                elif isinstance(dict1[key], (int, float)) and isinstance(dict2[key], (int, float)):
                    # æ•°å€¼ç±»å‹è®¡ç®—ç›¸å¯¹å·®å¼‚
                    diff = abs(dict1[key] - dict2[key])
                    max_val = max(abs(dict1[key]), abs(dict2[key]), 1)
                    value_similarity += max(0, 1 - diff / max_val)
            value_similarity /= len(common_keys)
        
        return (key_similarity + value_similarity) / 2
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        if not text1 and not text2:
            return 1.0
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„åŸºäºè¯æ±‡é‡å çš„ç›¸ä¼¼åº¦è®¡ç®—
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _attempt_rule_merge(self, new_rule: CandidateRule) -> Optional[CandidateRule]:
        """å°è¯•å°†æ–°è§„å¾‹ä¸ç°æœ‰è§„å¾‹åˆå¹¶"""
        try:
            best_merge_candidate = None
            best_similarity = 0.0
            merge_threshold = 0.7  # åˆå¹¶é˜ˆå€¼
            
            # å¯»æ‰¾æœ€ä½³åˆå¹¶å€™é€‰
            all_existing_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
            
            for existing_rule in all_existing_rules:
                similarity = self._calculate_rule_similarity(new_rule, existing_rule)
                if similarity > merge_threshold and similarity > best_similarity:
                    best_similarity = similarity
                    best_merge_candidate = existing_rule
            
            # å¦‚æœæ‰¾åˆ°åˆé€‚çš„åˆå¹¶å€™é€‰ï¼Œæ‰§è¡Œåˆå¹¶
            if best_merge_candidate:
                merged_rule = self._merge_rules(new_rule, best_merge_candidate, best_similarity)
                if merged_rule:
                    self.total_rules_merged += 1
                    self.rule_merge_history.append((new_rule.rule_id, best_merge_candidate.rule_id, best_similarity))
                    
                    # ä»åŸå­˜å‚¨ä¸­ç§»é™¤è¢«åˆå¹¶çš„è§„å¾‹
                    if best_merge_candidate.rule_id in self.candidate_rules:
                        del self.candidate_rules[best_merge_candidate.rule_id]
                    elif best_merge_candidate.rule_id in self.validated_rules:
                        del self.validated_rules[best_merge_candidate.rule_id]
                    
                    if self.logger:
                        self.logger.log(f"è§„å¾‹åˆå¹¶: {new_rule.rule_id} + {best_merge_candidate.rule_id} -> {merged_rule.rule_id}")
                    
                    return merged_rule
            
            return None
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"è§„å¾‹åˆå¹¶å¤±è´¥: {str(e)}")
            return None
    
    def _merge_rules(self, rule1: CandidateRule, rule2: CandidateRule, similarity: float) -> Optional[CandidateRule]:
        """åˆå¹¶ä¸¤ä¸ªç›¸ä¼¼çš„è§„å¾‹"""
        try:
            # é€‰æ‹©è´¨é‡æ›´é«˜çš„è§„å¾‹ä½œä¸ºåŸºç¡€
            base_rule = rule1 if rule1.calculate_quality_score() > rule2.calculate_quality_score() else rule2
            other_rule = rule2 if base_rule == rule1 else rule1
            
            # åˆ›å»ºåˆå¹¶åçš„è§„å¾‹ï¼ˆä¿®å¤åˆå¹¶æ ‡ç­¾é‡å¤é—®é¢˜ï¼‰
            # æ¸…ç†åŸºç¡€è§„å¾‹çš„patternï¼Œç§»é™¤å·²æœ‰çš„[åˆå¹¶]æ ‡ç­¾
            clean_pattern = base_rule.pattern
            if clean_pattern.startswith("[åˆå¹¶]"):
                clean_pattern = clean_pattern.replace("[åˆå¹¶]", "").strip()
            
            # åªåœ¨ç¬¬ä¸€æ¬¡åˆå¹¶æ—¶æ·»åŠ [åˆå¹¶]æ ‡ç­¾
            if not base_rule.pattern.startswith("[åˆå¹¶]"):
                merged_pattern = f"[åˆå¹¶] {clean_pattern}"
            else:
                merged_pattern = base_rule.pattern  # ä¿æŒåŸæœ‰çš„åˆå¹¶æ ‡ç­¾ï¼Œä¸é‡å¤æ·»åŠ 
            
            merged_rule = CandidateRule(
                rule_id=f"merged_{base_rule.rule_id}_{other_rule.rule_id}_{int(time.time())}",
                rule_type=base_rule.rule_type,
                pattern=merged_pattern,
                conditions=self._merge_dicts(base_rule.condition_elements, other_rule.condition_elements),
                predictions=self._merge_dicts(base_rule.predictions, other_rule.predictions),
                confidence=max(base_rule.confidence, other_rule.confidence),  # å–æ›´é«˜çš„ç½®ä¿¡åº¦
                strength=(base_rule.strength + other_rule.strength) / 2,
                generalization=max(base_rule.generalization, other_rule.generalization),
                specificity=min(base_rule.specificity, other_rule.specificity),
                complexity=max(base_rule.complexity, other_rule.complexity),
                parent_rules=[base_rule.rule_id, other_rule.rule_id]
            )
            
            # åˆå¹¶è¯æ®
            merged_rule.evidence.supporting_experiences.extend(base_rule.evidence.supporting_experiences)
            merged_rule.evidence.supporting_experiences.extend(other_rule.evidence.supporting_experiences)
            merged_rule.evidence.contradicting_experiences.extend(base_rule.evidence.contradicting_experiences)
            merged_rule.evidence.contradicting_experiences.extend(other_rule.evidence.contradicting_experiences)
            
            merged_rule.evidence.total_tests = base_rule.evidence.total_tests + other_rule.evidence.total_tests
            merged_rule.evidence.successful_tests = base_rule.evidence.successful_tests + other_rule.evidence.successful_tests
            
            # åˆå¹¶æ¿€æ´»ä¿¡æ¯
            merged_rule.activation_count = base_rule.activation_count + other_rule.activation_count
            merged_rule.last_activation = max(base_rule.last_activation, other_rule.last_activation)
            
            return merged_rule
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"è§„å¾‹åˆå¹¶æ“ä½œå¤±è´¥: {str(e)}")
            return None
    
    def _merge_dicts(self, dict1: Dict, dict2: Dict) -> Dict:
        """æ™ºèƒ½åˆå¹¶ä¸¤ä¸ªå­—å…¸"""
        merged = dict1.copy()
        
        for key, value in dict2.items():
            if key in merged:
                # å¦‚æœé”®å·²å­˜åœ¨ï¼Œæ ¹æ®å€¼ç±»å‹è¿›è¡Œåˆå¹¶
                if isinstance(value, (int, float)) and isinstance(merged[key], (int, float)):
                    merged[key] = (merged[key] + value) / 2  # æ•°å€¼å–å¹³å‡
                elif isinstance(value, str) and isinstance(merged[key], str):
                    if value != merged[key]:
                        merged[key] = f"{merged[key]}|{value}"  # å­—ç¬¦ä¸²è¿æ¥
                # å…¶ä»–ç±»å‹ä¿æŒåŸå€¼
            else:
                merged[key] = value
        
        return merged
    
    def _generate_causal_rules(self, pattern_key: str, experiences: List[EOCATR_Tuple], 
                              common_chars: Dict, common_results: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆå› æœè§„å¾‹ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå•ä¸ªç»éªŒï¼‰"""
        rules = []
        
        if self.logger:
            self.logger.log(f"ğŸ”¥ CAUSAL RULES: å¼€å§‹ç”Ÿæˆå› æœè§„å¾‹ï¼Œç»éªŒæ•°={len(experiences)}, pattern_key={pattern_key}")
        
        # åˆ†ææˆåŠŸå’Œå¤±è´¥çš„ç»éªŒ
        successful_experiences = [exp for exp in experiences if exp.result.success]
        failed_experiences = [exp for exp in experiences if not exp.result.success]
        
        if self.logger:
            self.logger.log(f"ğŸ”¥ CAUSAL RULES: æˆåŠŸç»éªŒ={len(successful_experiences)}, å¤±è´¥ç»éªŒ={len(failed_experiences)}")
        
        # ğŸš¨ ä¿®æ”¹ï¼šä»æˆåŠŸç»éªŒç”Ÿæˆæ­£å‘è§„å¾‹
        if len(successful_experiences) >= 1:
            if self.logger:
                self.logger.log(f"ğŸ”¥ CAUSAL RULES: ç”Ÿæˆæ­£å‘å› æœè§„å¾‹...")
            
            # ç”Ÿæˆæ­£å‘å› æœè§„å¾‹
            rule_id = f"causal_positive_{pattern_key}_{int(time.time() * 1000000) % 1000000}"  # ç¡®ä¿å”¯ä¸€ID
            
            # ä½¿ç”¨é¦–ä¸ªç»éªŒçš„ä¿¡æ¯
            first_exp = successful_experiences[0]
            
            conditions = {
                'object_category': first_exp.object_category.value if first_exp.object_category and hasattr(first_exp.object_category, 'value') else 'unknown',
                'action': first_exp.action.value if first_exp.action and hasattr(first_exp.action, 'value') else 'unknown',
                'environment': first_exp.environment.value if first_exp.environment and hasattr(first_exp.environment, 'value') else 'unknown',
                'tool': first_exp.tool.value if first_exp.tool and hasattr(first_exp.tool, 'value') else 'none',  # ğŸš¨ æ·»åŠ å·¥å…·ä¿¡æ¯
            }
            
            # æ·»åŠ å…¬å…±ç‰¹å¾ä½œä¸ºæ¡ä»¶
            for char_name, char_value in common_chars.items():
                if char_value is not None:
                    conditions[f'characteristic_{char_name}'] = char_value
            
            predictions = {
                'expected_success': True,
                'expected_results': common_results,
                'pattern_key': pattern_key  # ğŸš¨ æ·»åŠ æ¨¡å¼é”®
            }
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼šæˆåŠŸç‡
            confidence = len(successful_experiences) / len(experiences) if experiences else 1.0
            
            pattern_text = f"åœ¨{conditions.get('environment', 'ä»»ä½•ç¯å¢ƒ')}ä¸­ï¼Œä½¿ç”¨{conditions.get('tool', 'æ— å·¥å…·')}å¯¹{conditions.get('object_category', 'å¯¹è±¡')}æ‰§è¡Œ{conditions.get('action', 'åŠ¨ä½œ')}ï¼Œé¢„æœŸç»“æœï¼š{predictions.get('expected_success', 'æˆåŠŸ')}"
            
            rule = CandidateRule(
                rule_id=rule_id,
                rule_type=RuleType.CAUSAL,
                pattern=pattern_text,
                conditions=conditions,
                predictions=predictions,
                confidence=confidence,
                complexity=len(conditions) + len(predictions)
            )
            
            # æ·»åŠ æ”¯æŒè¯æ®
            for exp in successful_experiences:
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                rule.evidence.supporting_experiences.append(f"exp_{act_val}_{tool_val}_{int(time.time())}")
            
            for exp in failed_experiences:
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                rule.evidence.contradicting_experiences.append(f"exp_{act_val}_{tool_val}_{int(time.time())}")
            
            if self.logger:
                self.logger.log(f"ğŸ”¥ CAUSAL RULES: åˆ›å»ºæ­£å‘è§„å¾‹ {rule_id}, ç½®ä¿¡åº¦={confidence:.3f}")
            rules.append(rule)
        
        # ğŸš¨ æ–°å¢ï¼šä»å¤±è´¥ç»éªŒä¹Ÿç”Ÿæˆè§„å¾‹ï¼ˆè´Ÿå‘å› æœè§„å¾‹ï¼‰
        if len(failed_experiences) >= 1:
            if self.logger:
                self.logger.log(f"ğŸ”¥ CAUSAL RULES: ç”Ÿæˆè´Ÿå‘å› æœè§„å¾‹...")
            
            # ç”Ÿæˆè´Ÿå‘å› æœè§„å¾‹
            rule_id = f"causal_negative_{pattern_key}_{int(time.time() * 1000000) % 1000000}"
            
            # ä½¿ç”¨é¦–ä¸ªå¤±è´¥ç»éªŒçš„ä¿¡æ¯
            first_exp = failed_experiences[0]
            
            conditions = {
                'object_category': first_exp.object_category.value if first_exp.object_category and hasattr(first_exp.object_category, 'value') else 'unknown',
                'action': first_exp.action.value if first_exp.action and hasattr(first_exp.action, 'value') else 'unknown',
                'environment': first_exp.environment.value if first_exp.environment and hasattr(first_exp.environment, 'value') else 'unknown',
                'tool': first_exp.tool.value if first_exp.tool and hasattr(first_exp.tool, 'value') else 'none',
            }
            
            # æ·»åŠ å…¬å…±ç‰¹å¾ä½œä¸ºæ¡ä»¶
            for char_name, char_value in common_chars.items():
                if char_value is not None:
                    conditions[f'characteristic_{char_name}'] = char_value
            
            predictions = {
                'expected_success': False,
                'expected_results': {'failure_type': 'action_ineffective'},
                'pattern_key': pattern_key,
                'avoid_action': True  # æ ‡è®°ä¸ºåº”é¿å…çš„åŠ¨ä½œ
            }
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼šå¤±è´¥ç‡
            confidence = len(failed_experiences) / len(experiences) if experiences else 1.0
            
            pattern_text = f"åœ¨{conditions.get('environment', 'ä»»ä½•ç¯å¢ƒ')}ä¸­ï¼Œä½¿ç”¨{conditions.get('tool', 'æ— å·¥å…·')}å¯¹{conditions.get('object_category', 'å¯¹è±¡')}æ‰§è¡Œ{conditions.get('action', 'åŠ¨ä½œ')}ï¼Œé€šå¸¸ä¼šå¤±è´¥"
            
            rule = CandidateRule(
                rule_id=rule_id,
                rule_type=RuleType.CAUSAL,
                pattern=pattern_text,
                conditions=conditions,
                predictions=predictions,
                confidence=confidence,
                complexity=len(conditions) + len(predictions)
            )
            
            # æ·»åŠ å¤±è´¥è¯æ®
            for exp in failed_experiences:
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                rule.evidence.supporting_experiences.append(f"fail_exp_{act_val}_{tool_val}_{int(time.time())}")
            
            # æˆåŠŸç»éªŒä½œä¸ºåé©³è¯æ®
            for exp in successful_experiences:
                act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                tool_val = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                rule.evidence.contradicting_experiences.append(f"success_exp_{act_val}_{tool_val}_{int(time.time())}")
            
            if self.logger:
                self.logger.log(f"ğŸ”¥ CAUSAL RULES: åˆ›å»ºè´Ÿå‘è§„å¾‹ {rule_id}, ç½®ä¿¡åº¦={confidence:.3f}")
            rules.append(rule)
        
        if self.logger:
            self.logger.log(f"ğŸ”¥ CAUSAL RULES: ç”Ÿæˆ {len(rules)} ä¸ªå› æœè§„å¾‹")
        return rules

    def _generate_conditional_rules(self, pattern_key: str, experiences: List[EOCATR_Tuple], 
                                   common_chars: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆæ¡ä»¶è§„å¾‹"""
        rules = []
        
        # åŸºäºç‰¹å¾é˜ˆå€¼ç”Ÿæˆæ¡ä»¶è§„å¾‹
        numeric_characteristics = {}
        for exp in experiences:
            chars = exp.characteristics
            for attr_name in ['distance', 'nutrition_value', 'water_value']:
                attr_value = getattr(chars, attr_name, None)
                if attr_value is not None and isinstance(attr_value, (int, float)):
                    if attr_name not in numeric_characteristics:
                        numeric_characteristics[attr_name] = []
                    numeric_characteristics[attr_name].append((attr_value, exp.result.success))
        
        # ä¸ºæ¯ä¸ªæ•°å€¼ç‰¹å¾ç”Ÿæˆé˜ˆå€¼è§„å¾‹
        for char_name, values in numeric_characteristics.items():
            if len(values) >= 3:
                successful_values = [v for v, success in values if success]
                failed_values = [v for v, success in values if not success]
                
                if successful_values and failed_values:
                    # è®¡ç®—åˆ†ç¦»é˜ˆå€¼
                    threshold = self._calculate_optimal_threshold(successful_values, failed_values)
                    
                    if threshold is not None:
                        rule_id = f"conditional_{pattern_key}_{char_name}_{int(time.time() * 1000) % 10000}"
                        
                        conditions = {
                            'object_category': experiences[0].object_category.value,
                            f'{char_name}_threshold': threshold,
                            'comparison': 'less_than' if successful_values[0] < threshold else 'greater_than'
                        }
                        
                        predictions = {
                            'recommended_action': experiences[0].action.value,
                            'expected_success_rate': len(successful_values) / len(values)
                        }
                        
                        rule = CandidateRule(
                            rule_id=rule_id,
                            rule_type=RuleType.CONDITIONAL,
                            pattern=f"å½“{char_name}{'å°äº' if conditions['comparison'] == 'less_than' else 'å¤§äº'}{threshold}æ—¶ï¼Œå¯¹{conditions['object_category']}æ‰§è¡Œ{predictions['recommended_action']}",
                            conditions=conditions,
                            predictions=predictions,
                            confidence=predictions['expected_success_rate'],
                            complexity=2
                        )
                        
                        rules.append(rule)
        
        return rules
    
    def _generate_optimization_rules(self, pattern_key: str, experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """ç”Ÿæˆä¼˜åŒ–è§„å¾‹"""
        rules = []
        
        # æŒ‰åŠ¨ä½œåˆ†ç»„ï¼Œæ¯”è¾ƒæ•ˆæœ
        actions_results = defaultdict(list)
        for exp in experiences:
            act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
            actions_results[act_val].append(exp.result.reward)
        
        if len(actions_results) >= 2:
            # æ‰¾åˆ°æœ€ä½³åŠ¨ä½œ
            action_avg_rewards = {}
            for action, rewards in actions_results.items():
                if rewards:
                    action_avg_rewards[action] = sum(rewards) / len(rewards)
            
            if len(action_avg_rewards) >= 2:
                best_action = max(action_avg_rewards.keys(), key=lambda a: action_avg_rewards[a])
                worst_action = min(action_avg_rewards.keys(), key=lambda a: action_avg_rewards[a])
                
                if action_avg_rewards[best_action] > action_avg_rewards[worst_action]:
                    rule_id = f"optimization_{pattern_key}_{int(time.time() * 1000) % 10000}"
                    
                    conditions = {
                        'context': pattern_key,
                        'object_category': experiences[0].object_category.value,
                        'environment': experiences[0].environment.value
                    }
                    
                    predictions = {
                        'optimal_action': best_action,
                        'suboptimal_action': worst_action,
                        'reward_difference': action_avg_rewards[best_action] - action_avg_rewards[worst_action]
                    }
                    
                    rule = CandidateRule(
                        rule_id=rule_id,
                        rule_type=RuleType.OPTIMIZATION,
                        pattern=f"åœ¨{conditions['environment']}ä¸­å¤„ç†{conditions['object_category']}æ—¶ï¼Œ{best_action}æ¯”{worst_action}æ›´ä¼˜",
                        conditions=conditions,
                        predictions=predictions,
                        confidence=0.7,  # åˆå§‹ç½®ä¿¡åº¦
                        complexity=3
                    )
                    
                    rules.append(rule)
        
        return rules
    
    def _generate_sequential_rules(self, experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """ç”Ÿæˆæ—¶åºè§„å¾‹"""
        rules = []
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        sorted_experiences = sorted(experiences, key=lambda x: x.timestamp)
        
        # å¯»æ‰¾è¿ç»­çš„åŠ¨ä½œåºåˆ—
        for i in range(len(sorted_experiences) - 1):
            exp1 = sorted_experiences[i]
            exp2 = sorted_experiences[i + 1]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„åºåˆ—
            if (exp2.timestamp - exp1.timestamp < 10.0 and  # æ—¶é—´é—´éš”ä¸è¶…è¿‡10å•ä½
                exp1.result.success and exp2.result.success):  # ä¸¤ä¸ªåŠ¨ä½œéƒ½æˆåŠŸ
                
                rule_id = f"sequential_{exp1.action.value}_{exp2.action.value}_{int(time.time() * 1000) % 10000}"
                
                conditions = {
                    'first_action': exp1.action.value,
                    'first_object': exp1.object_category.value,
                    'sequence_gap': exp2.timestamp - exp1.timestamp
                }
                
                predictions = {
                    'next_action': exp2.action.value,
                    'next_object': exp2.object_category.value,
                    'combined_reward': exp1.result.reward + exp2.result.reward
                }
                
                rule = CandidateRule(
                    rule_id=rule_id,
                    rule_type=RuleType.SEQUENTIAL,
                    pattern=f"åœ¨æ‰§è¡Œ{exp1.action.value}ä¹‹åï¼Œåº”è¯¥æ‰§è¡Œ{exp2.action.value}",
                    conditions=conditions,
                    predictions=predictions,
                    confidence=0.5,  # æ—¶åºè§„å¾‹åˆå§‹ç½®ä¿¡åº¦è¾ƒä½
                    complexity=4
                )
                
                rules.append(rule)
        
        return rules
    
    def _generate_spatial_rules(self, experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """ç”Ÿæˆç©ºé—´è§„å¾‹"""
        rules = []
        
        # æŒ‰è·ç¦»åˆ†ç»„åˆ†æ
        distance_groups = defaultdict(list)
        for exp in experiences:
            distance_range = self._get_distance_range(exp.characteristics.distance)
            distance_groups[distance_range].append(exp)
        
        for distance_range, group_experiences in distance_groups.items():
            if len(group_experiences) >= 3:
                # åˆ†æè¯¥è·ç¦»èŒƒå›´å†…çš„æœ€ä½³åŠ¨ä½œ
                action_success_rates = defaultdict(list)
                for exp in group_experiences:
                    act_val = exp.action.value if exp.action and hasattr(exp.action, 'value') else 'unknown'
                    action_success_rates[act_val].append(exp.result.success)
                
                best_action = None
                best_success_rate = 0
                
                for action, successes in action_success_rates.items():
                    success_rate = sum(successes) / len(successes)
                    if success_rate > best_success_rate:
                        best_success_rate = success_rate
                        best_action = action
                
                if best_action and best_success_rate > 0.6:
                    rule_id = f"spatial_{distance_range}_{best_action}_{int(time.time() * 1000) % 10000}"
                    
                    conditions = {
                        'distance_range': distance_range,
                        'spatial_context': 'distance_based'
                    }
                    
                    predictions = {
                        'recommended_action': best_action,
                        'expected_success_rate': best_success_rate
                    }
                    
                    rule = CandidateRule(
                        rule_id=rule_id,
                        rule_type=RuleType.SPATIAL,
                        pattern=f"åœ¨{distance_range}è·ç¦»èŒƒå›´å†…ï¼Œ{best_action}æ˜¯æœ€ä½³é€‰æ‹©",
                        conditions=conditions,
                        predictions=predictions,
                        confidence=best_success_rate,
                        complexity=2
                    )
                    
                    rules.append(rule)
        
        return rules
    
    def _generate_tool_effectiveness_rules(self, experiences: List[EOCATR_Tuple]) -> List[CandidateRule]:
        """ç”Ÿæˆå·¥å…·æ•ˆç”¨è§„å¾‹"""
        rules = []
        
        # ğŸ”§ æŒ‰å·¥å…·-ç›®æ ‡ç»„åˆåˆ†ç»„åˆ†æ
        tool_target_combinations = defaultdict(list)
        tool_environment_combinations = defaultdict(list)
        
        for exp in experiences:
            if exp.is_tool_usage():  # ä»…å¤„ç†å·¥å…·ä½¿ç”¨è®°å½•
                # å·¥å…·-ç›®æ ‡ç»„åˆ - ä¿®å¤ï¼šä½¿ç”¨å…¼å®¹çš„æ–¹å¼è·å–å·¥å…·-ç›®æ ‡é”®
                tool_target_key = self._get_tool_target_key_v3(exp)
                if tool_target_key:
                    tool_target_combinations[tool_target_key].append(exp)
                
                # å·¥å…·-ç¯å¢ƒç»„åˆ - ä¿®å¤ï¼šä½¿ç”¨å…¼å®¹çš„æ–¹å¼è·å–å€¼
                tool_value = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
                env_value = exp.environment.value if exp.environment and hasattr(exp.environment, 'value') else 'unknown'
                tool_env_key = f"{tool_value}_{env_value}"
                tool_environment_combinations[tool_env_key].append(exp)
        
        # === ç”Ÿæˆå·¥å…·-ç›®æ ‡åŒ¹é…è§„å¾‹ ===
        for combination_key, combo_experiences in tool_target_combinations.items():
            if len(combo_experiences) >= 1:  # ğŸ”¥ é™ä½é˜ˆå€¼ï¼šæœ€å°‘1æ¬¡ç»éªŒ
                try:
                    tool_type, target_type = combination_key.split('_', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿
                except ValueError:
                    # å¦‚æœåˆ†å‰²å¤±è´¥ï¼Œè·³è¿‡æ­¤ç»„åˆ
                    continue
                
                # è®¡ç®—æ•ˆæœç»Ÿè®¡
                total_attempts = len(combo_experiences)
                successful_attempts = sum(1 for exp in combo_experiences if self._get_result_success_v3(exp))
                success_rate = successful_attempts / total_attempts if total_attempts > 0 else 0.0
                
                # è®¡ç®—å¹³å‡æ•ˆæœå€¼
                avg_effectiveness = 0.0
                effectiveness_count = 0
                for exp in combo_experiences:
                    # ä¿®å¤ï¼šå…¼å®¹V3ç»“æœæ ¼å¼
                    tool_eff = self._get_tool_effectiveness_v3(exp)
                    if tool_eff is not None:
                        avg_effectiveness += tool_eff
                        effectiveness_count += 1
                
                if effectiveness_count > 0:
                    avg_effectiveness /= effectiveness_count
                else:
                    avg_effectiveness = success_rate  # å›é€€åˆ°æˆåŠŸç‡
                
                # æ•ˆæœåˆ†ç±»
                if avg_effectiveness >= 0.8:
                    effectiveness_category = "é«˜æ•ˆ"
                    effect_level = "high"
                elif avg_effectiveness >= 0.6:
                    effectiveness_category = "ä¸­æ•ˆ"
                    effect_level = "medium"
                elif avg_effectiveness >= 0.4:
                    effectiveness_category = "ä½æ•ˆ"
                    effect_level = "low"
                else:
                    effectiveness_category = "æ— æ•ˆ"
                    effect_level = "ineffective"
                
                # ğŸ¯ åˆ›å»ºå·¥å…·æ•ˆç”¨è§„å¾‹
                rule_text = f"å·¥å…·{tool_type.capitalize()}å¯¹{target_type}çš„æ•ˆæœæ˜¯{effectiveness_category}"
                rule_id = f"tool_effectiveness_{tool_type}_{target_type}_{effect_level}_{int(time.time())}"
                
                conditions = {
                    'tool_type': tool_type,
                    'target_type': target_type,
                    'context': 'tool_usage'
                }
                
                predictions = {
                    'effectiveness': avg_effectiveness,
                    'success_rate': success_rate,
                    'recommended': avg_effectiveness >= 0.6,
                    'effect_category': effectiveness_category
                }
                
                rule = CandidateRule(
                    rule_id=rule_id,
                    rule_type=RuleType.TOOL_EFFECTIVENESS,
                    pattern=rule_text,
                    conditions=conditions,
                    predictions=predictions,
                    confidence=min(0.9, success_rate + 0.1),
                    complexity=1
                )
                
                # è®¾ç½®è¯æ®ä¿¡æ¯
                rule.evidence.total_tests = total_attempts
                rule.evidence.successful_tests = successful_attempts
                
                rules.append(rule)
                
                if self.logger:
                    self.logger.log(f"ğŸ”§ ç”Ÿæˆå·¥å…·æ•ˆç”¨è§„å¾‹: {rule_text} (æ•ˆæœ:{avg_effectiveness:.3f}, è¯æ®:{total_attempts}æ¬¡)")
        
        # === ç”Ÿæˆå·¥å…·ç¯å¢ƒé€‚åº”æ€§è§„å¾‹ ===
        for combination_key, combo_experiences in tool_environment_combinations.items():
            if len(combo_experiences) >= 1:  # ğŸ”¥ é™ä½é˜ˆå€¼ï¼šæœ€å°‘1æ¬¡ç»éªŒ
                try:
                    tool_type, env_type = combination_key.split('_', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿
                except ValueError:
                    continue
                
                success_rate = sum(1 for exp in combo_experiences if self._get_result_success_v3(exp)) / len(combo_experiences)
                
                if success_rate >= 0.5:  # ğŸ”¥ é™ä½é˜ˆå€¼ï¼šä¸­ç­‰é€‚åº”æ€§
                    rule_text = f"å·¥å…·{tool_type.capitalize()}åœ¨{env_type}ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½"
                    
                    rule_id = f"tool_environment_{tool_type}_{env_type}_good_{int(time.time())}"
                    
                    conditions = {
                        'tool_type': tool_type,
                        'environment': env_type,
                        'context': 'environmental_adaptation'
                    }
                    
                    predictions = {
                        'success_rate': success_rate,
                        'environmental_fit': 'good',
                        'recommended_environment': env_type
                    }
                    
                    rule = CandidateRule(
                        rule_id=rule_id,
                        rule_type=RuleType.TOOL_EFFECTIVENESS,
                        pattern=rule_text,
                        conditions=conditions,
                        predictions=predictions,
                        confidence=success_rate,
                        complexity=2
                    )
                    
                    # è®¾ç½®è¯æ®ä¿¡æ¯
                    rule.evidence.total_tests = len(combo_experiences)
                    rule.evidence.successful_tests = int(success_rate * len(combo_experiences))
                    
                    rules.append(rule)
        
        if self.logger and rules:
            self.logger.log(f"ğŸ”§ å·¥å…·æ•ˆç”¨è§„å¾‹ç”Ÿæˆå®Œæˆ: å…±{len(rules)}æ¡è§„å¾‹")
        
        return rules
    
    def _get_tool_target_key_v3(self, exp) -> Optional[str]:
        """V3å…¼å®¹ï¼šè·å–å·¥å…·-ç›®æ ‡é”®"""
        try:
            # è·å–å·¥å…·å€¼
            tool_value = exp.tool.value if exp.tool and hasattr(exp.tool, 'value') else 'none'
            
            # è·å–å¯¹è±¡å€¼
            object_value = exp.object.value if hasattr(exp.object, 'value') else getattr(exp.object, "content", getattr(exp.object, "name", str(exp.object)))
            
            # æ¸…ç†å€¼ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            tool_clean = tool_value.replace(" ", "_").replace("-", "_").lower()
            object_clean = object_value.replace(" ", "_").replace("-", "_").lower()
            
            return f"{tool_clean}_{object_clean}"
        except Exception as e:
            if self.logger:
                self.logger.log(f"ğŸ”§ è·å–å·¥å…·-ç›®æ ‡é”®å¤±è´¥: {str(e)}")
            return None
    
    def _get_result_success_v3(self, exp) -> bool:
        """V3å…¼å®¹ï¼šè·å–ç»“æœæˆåŠŸçŠ¶æ€"""
        try:
            # å°è¯•å¤šç§æ–¹å¼è·å–æˆåŠŸçŠ¶æ€
            if hasattr(exp.result, 'success'):
                return exp.result.success
            elif hasattr(exp.result, 'content'):
                content = str(getattr(exp.result, "content", getattr(exp.result, "name", str(exp.result)))).lower()
                return "æˆåŠŸ" in content or "success" in content
            else:
                return False
        except Exception:
            return False
    
    def _get_tool_effectiveness_v3(self, exp) -> Optional[float]:
        """V3å…¼å®¹ï¼šè·å–å·¥å…·æ•ˆæœå€¼"""
        try:
            # å°è¯•ä»ç»“æœä¸­è·å–å·¥å…·æ•ˆæœ
            if hasattr(exp.result, 'tool_effectiveness') and exp.result.tool_effectiveness is not None:
                return exp.result.tool_effectiveness
            elif hasattr(exp.result, 'reward'):
                # åŸºäºå¥–åŠ±å€¼ä¼°ç®—æ•ˆæœ
                reward = exp.result.reward
                if reward > 0:
                    return min(1.0, reward / 10.0)  # æ ‡å‡†åŒ–åˆ°0-1
                else:
                    return max(0.0, 0.5 + reward / 20.0)  # è´Ÿå¥–åŠ±è½¬æ¢
            else:
                # åŸºäºæˆåŠŸçŠ¶æ€ç»™é»˜è®¤å€¼
                return 0.8 if self._get_result_success_v3(exp) else 0.2
        except Exception:
            return None
    
    def pruning_phase(self) -> List[str]:
        """å‰ªæé˜¶æ®µï¼šç§»é™¤ä½è´¨é‡æˆ–è¿‡æ—¶çš„è§„å¾‹"""
        try:
            # === å¼ºåŒ–å†…å­˜ç®¡ç†çš„å‰ªæç­–ç•¥ ===
            pruned_rule_ids = []
            current_time = time.time()
            
            # è®¡ç®—å†…å­˜å‹åŠ›
            self._check_memory_pressure()
            
            # æ ¹æ®å†…å­˜å‹åŠ›è°ƒæ•´å‰ªæç­–ç•¥
            if self.memory_pressure_level > 0.8:
                # é«˜å†…å­˜å‹åŠ›ï¼šæ›´æ¿€è¿›çš„å‰ªæ
                confidence_threshold = self.config['pruning_confidence_threshold'] * 1.5
                age_threshold = self.config['pruning_age_threshold'] * 0.5
            elif self.memory_pressure_level > 0.6:
                # ä¸­ç­‰å†…å­˜å‹åŠ›ï¼šæ ‡å‡†å‰ªæ
                confidence_threshold = self.config['pruning_confidence_threshold']
                age_threshold = self.config['pruning_age_threshold']
            else:
                # ä½å†…å­˜å‹åŠ›ï¼šä¿å®ˆå‰ªæ
                confidence_threshold = self.config['pruning_confidence_threshold'] * 0.5
                age_threshold = self.config['pruning_age_threshold'] * 2
            
            # å€™é€‰è§„å¾‹å‰ªæ
            rules_to_prune = []
            for rule_id, rule in self.candidate_rules.items():
                should_prune = False
                prune_reason = ""
                
                # ç½®ä¿¡åº¦è¿‡ä½
                if rule.confidence < confidence_threshold:
                    should_prune = True
                    prune_reason = f"ç½®ä¿¡åº¦è¿‡ä½ ({rule.confidence:.3f} < {confidence_threshold:.3f})"
                
                # è§„å¾‹è¿‡äºé™ˆæ—§ä¸”æœªè¢«æ¿€æ´»
                rule_age = current_time - rule.birth_time
                if rule_age > age_threshold and rule.activation_count == 0:
                    should_prune = True
                    prune_reason = f"è§„å¾‹é™ˆæ—§ä¸”æœªæ¿€æ´» (å¹´é¾„: {rule_age:.0f}s)"
                
                # çŸ›ç›¾è¯æ®è¿‡å¤š
                if rule.evidence.contradicting_evidence_ratio > self.config['contradicting_evidence_threshold']:
                    should_prune = True
                    prune_reason = f"çŸ›ç›¾è¯æ®è¿‡å¤š ({rule.evidence.contradicting_evidence_ratio:.2f})"
                
                # è´¨é‡åˆ†æ•°è¿‡ä½
                quality_score = rule.calculate_quality_score()
                if quality_score < 0.1:
                    should_prune = True
                    prune_reason = f"è´¨é‡åˆ†æ•°è¿‡ä½ ({quality_score:.3f})"
                
                # LRUï¼šé•¿æœŸæœªè®¿é—®ä¸”å†…å­˜å‹åŠ›å¤§
                if self.memory_pressure_level > 0.7:
                    last_access = self.lru_access_times.get(rule_id, rule.birth_time)
                    if current_time - last_access > age_threshold * 0.5:
                        should_prune = True
                        prune_reason = f"é•¿æœŸæœªè®¿é—® ({current_time - last_access:.0f}s)"
                
                if should_prune:
                    rules_to_prune.append((rule_id, prune_reason))
            
            # æ‰§è¡Œå‰ªæ
            for rule_id, reason in rules_to_prune:
                if rule_id in self.candidate_rules:
                    pruned_rule = self.candidate_rules.pop(rule_id)
                    self.pruned_rules[rule_id] = pruned_rule
                    self.pruning_history.append((current_time, rule_id, reason))
                    pruned_rule_ids.append(rule_id)
                    self.total_rules_pruned += 1
                    
                    # æ¸…ç†ç›¸å…³æ•°æ®
                    if rule_id in self.lru_access_times:
                        del self.lru_access_times[rule_id]
            
            # å·²éªŒè¯è§„å¾‹çš„å‰ªæï¼ˆæ›´ä¿å®ˆï¼‰
            validated_rules_to_prune = []
            for rule_id, rule in self.validated_rules.items():
                # åªæœ‰åœ¨æç«¯æƒ…å†µä¸‹æ‰å‰ªæå·²éªŒè¯è§„å¾‹
                if self.memory_pressure_level > 0.9:
                    quality_score = rule.calculate_quality_score()
                    if quality_score < 0.3 or rule.confidence < 0.2:
                        validated_rules_to_prune.append((rule_id, "å†…å­˜å‹åŠ›è¿‡å¤§ä¸”è´¨é‡ä½"))
            
            for rule_id, reason in validated_rules_to_prune:
                if rule_id in self.validated_rules:
                    pruned_rule = self.validated_rules.pop(rule_id)
                    self.pruned_rules[rule_id] = pruned_rule
                    self.pruning_history.append((current_time, rule_id, reason))
                    pruned_rule_ids.append(rule_id)
                    self.total_rules_pruned += 1
                    
                    if rule_id in self.lru_access_times:
                        del self.lru_access_times[rule_id]
            
            # é™åˆ¶å·²å‰ªæè§„å¾‹çš„æ•°é‡ï¼ˆé¿å…æ— é™å¢é•¿ï¼‰
            if len(self.pruned_rules) > 200:
                # ä¿ç•™æœ€è¿‘çš„100ä¸ªå‰ªæè§„å¾‹
                sorted_pruned = sorted(
                    self.pruned_rules.items(),
                    key=lambda x: x[1].birth_time,
                    reverse=True
                )
                self.pruned_rules = dict(sorted_pruned[:100])
            
            if self.logger and pruned_rule_ids:
                self.logger.log(f"å‰ªæé˜¶æ®µç§»é™¤ {len(pruned_rule_ids)} ä¸ªè§„å¾‹")
            
            return pruned_rule_ids
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"å‰ªæé˜¶æ®µå¤±è´¥: {str(e)}")
            return []
    
    def _check_memory_pressure(self):
        """æ£€æŸ¥å’Œè®¡ç®—å†…å­˜å‹åŠ›çº§åˆ«"""
        try:
            total_rules = len(self.candidate_rules) + len(self.validated_rules)
            
            # è®¡ç®—å†…å­˜ä½¿ç”¨ç‡
            memory_usage_ratio = total_rules / self.max_total_rules
            
            # è®¡ç®—å„ç±»è§„å¾‹çš„ä½¿ç”¨ç‡
            candidate_usage_ratio = len(self.candidate_rules) / self.max_candidate_rules
            validated_usage_ratio = len(self.validated_rules) / self.max_validated_rules
            
            # ç»¼åˆè®¡ç®—å†…å­˜å‹åŠ›çº§åˆ«
            self.memory_pressure_level = max(memory_usage_ratio, candidate_usage_ratio, validated_usage_ratio)
            
            # è®°å½•é«˜å‹åŠ›æƒ…å†µ
            if self.memory_pressure_level > 0.8 and self.logger:
                self.logger.log(f"é«˜å†…å­˜å‹åŠ›: {self.memory_pressure_level:.2f} "
                              f"(æ€»è§„å¾‹: {total_rules}/{self.max_total_rules}, "
                              f"å€™é€‰: {len(self.candidate_rules)}/{self.max_candidate_rules}, "
                              f"å·²éªŒè¯: {len(self.validated_rules)}/{self.max_validated_rules})")
        
        except Exception as e:
            if self.logger:
                self.logger.log(f"å†…å­˜å‹åŠ›æ£€æŸ¥å¤±è´¥: {str(e)}")
            self.memory_pressure_level = 0.0
    
    def _perform_memory_cleanup(self):
        """æ‰§è¡Œå†…å­˜æ¸…ç†"""
        try:
            if self.logger:
                self.logger.log("å¼€å§‹æ‰§è¡Œå†…å­˜æ¸…ç†...")
            
            initial_count = len(self.candidate_rules) + len(self.validated_rules)
            
            # 1. æ¸…ç†æœ€å°‘ä½¿ç”¨çš„å€™é€‰è§„å¾‹
            self._cleanup_least_used_candidates(cleanup_ratio=0.3)
            
            # 2. æ¸…ç†ä½è´¨é‡çš„å·²éªŒè¯è§„å¾‹
            self._cleanup_low_quality_validated(cleanup_ratio=0.2)
            
            # 3. æ¸…ç†è¿‡æœŸçš„å‰ªæè§„å¾‹
            self._cleanup_old_pruned_rules()
            
            # 4. æ¸…ç†è¿‡æœŸçš„LRUè®°å½•
            self._cleanup_lru_records()
            
            final_count = len(self.candidate_rules) + len(self.validated_rules)
            cleaned_count = initial_count - final_count
            
            if self.logger:
                self.logger.log(f"å†…å­˜æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾ {cleaned_count} ä¸ªè§„å¾‹")
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"å†…å­˜æ¸…ç†å¤±è´¥: {str(e)}")
    
    def _cleanup_least_used_candidates(self, cleanup_ratio=0.2):
        """æ¸…ç†æœ€å°‘ä½¿ç”¨çš„å€™é€‰è§„å¾‹"""
        if not self.candidate_rules:
            return
        
        cleanup_count = max(1, int(len(self.candidate_rules) * cleanup_ratio))
        
        # æŒ‰ç…§LRUå’Œè´¨é‡åˆ†æ•°æ’åº
        candidates_with_scores = []
        current_time = time.time()
        
        for rule_id, rule in self.candidate_rules.items():
            last_access = self.lru_access_times.get(rule_id, rule.birth_time)
            access_score = 1.0 / (current_time - last_access + 1)  # è¶Šè¿‘è®¿é—®åˆ†æ•°è¶Šé«˜
            quality_score = rule.calculate_quality_score()
            combined_score = access_score * 0.6 + quality_score * 0.4
            
            candidates_with_scores.append((rule_id, combined_score))
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œç§»é™¤åˆ†æ•°æœ€ä½çš„
        candidates_with_scores.sort(key=lambda x: x[1])
        
        for rule_id, _ in candidates_with_scores[:cleanup_count]:
            if rule_id in self.candidate_rules:
                removed_rule = self.candidate_rules.pop(rule_id)
                self.pruned_rules[rule_id] = removed_rule
                
                if rule_id in self.lru_access_times:
                    del self.lru_access_times[rule_id]
                
                self.total_rules_pruned += 1
    
    def _cleanup_low_quality_validated(self, cleanup_ratio=0.1):
        """æ¸…ç†ä½è´¨é‡çš„å·²éªŒè¯è§„å¾‹"""
        if not self.validated_rules:
            return
        
        cleanup_count = max(1, int(len(self.validated_rules) * cleanup_ratio))
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        validated_with_scores = []
        for rule_id, rule in self.validated_rules.items():
            quality_score = rule.calculate_quality_score()
            validated_with_scores.append((rule_id, quality_score))
        
        # ç§»é™¤è´¨é‡æœ€ä½çš„
        validated_with_scores.sort(key=lambda x: x[1])
        
        for rule_id, score in validated_with_scores[:cleanup_count]:
            if score < 0.5:  # åªç§»é™¤è´¨é‡ç¡®å®å¾ˆä½çš„
                if rule_id in self.validated_rules:
                    removed_rule = self.validated_rules.pop(rule_id)
                    self.pruned_rules[rule_id] = removed_rule
                    
                    if rule_id in self.lru_access_times:
                        del self.lru_access_times[rule_id]
                    
                    self.total_rules_pruned += 1
    
    def _cleanup_old_pruned_rules(self):
        """æ¸…ç†è¿‡æœŸçš„å‰ªæè§„å¾‹"""
        if len(self.pruned_rules) > 100:
            # åªä¿ç•™æœ€è¿‘100ä¸ªå‰ªæè§„å¾‹
            sorted_pruned = sorted(
                self.pruned_rules.items(),
                key=lambda x: x[1].birth_time,
                reverse=True
            )
            self.pruned_rules = dict(sorted_pruned[:100])
    
    def _cleanup_lru_records(self):
        """æ¸…ç†è¿‡æœŸçš„LRUè®°å½•"""
        current_time = time.time()
        expired_records = []
        
        for rule_id, last_access in self.lru_access_times.items():
            # å¦‚æœè§„å¾‹å·²ä¸å­˜åœ¨ï¼Œæˆ–è€…å¾ˆä¹…æœªè®¿é—®ï¼Œæ¸…ç†è®°å½•
            if (rule_id not in self.candidate_rules and 
                rule_id not in self.validated_rules) or \
               (current_time - last_access > 86400):  # 24å°æ—¶æœªè®¿é—®
                expired_records.append(rule_id)
        
        for rule_id in expired_records:
            del self.lru_access_times[rule_id]
    
    def _update_lru_access(self, rule_id: str):
        """æ›´æ–°LRUè®¿é—®æ—¶é—´"""
        self.lru_access_times[rule_id] = time.time()
    
    def get_applicable_rules(self, context: EOCATR_Tuple) -> List[CandidateRule]:
        """è·å–é€‚ç”¨äºç»™å®šä¸Šä¸‹æ–‡çš„è§„å¾‹"""
        applicable_rules = []
        
        # æ£€æŸ¥å·²éªŒè¯è§„å¾‹
        for rule_id, rule in self.validated_rules.items():
            if self._is_rule_applicable(rule, context):
                applicable_rules.append(rule)
                self._update_lru_access(rule_id)  # æ›´æ–°è®¿é—®æ—¶é—´
        
        # æ£€æŸ¥é«˜ç½®ä¿¡åº¦çš„å€™é€‰è§„å¾‹
        for rule_id, rule in self.candidate_rules.items():
            if (rule.confidence > 0.6 and 
                self._is_rule_applicable(rule, context)):
                applicable_rules.append(rule)
                self._update_lru_access(rule_id)  # æ›´æ–°è®¿é—®æ—¶é—´
        
        # æŒ‰è´¨é‡å¾—åˆ†æ’åº
        applicable_rules.sort(key=lambda r: r.calculate_quality_score(), reverse=True)
        
        return applicable_rules
    
    def validation_phase(self, new_experiences: List[EOCATR_Tuple]) -> List[str]:
        """éªŒè¯é˜¶æ®µ - å¢å¼ºç‰ˆæœ¬"""
        if not new_experiences:
            # å³ä½¿æ— æ–°ç»éªŒï¼Œä¹Ÿè¿›è¡Œè‡ªåŠ¨æ™‹å‡æ£€æŸ¥
            auto_ids = self._auto_promotion_check()
            if auto_ids and self.logger:
                self.logger.log(f"âš¡ è‡ªåŠ¨æ™‹å‡: {len(auto_ids)} ä¸ªè§„å¾‹åŸºäºé‡å¤å‡ºç°ä¸ç½®ä¿¡åº¦è¢«æå‡")
            return auto_ids
        
        validated_rule_ids = []
        
        try:
            if self.logger:
                self.logger.log(f"ğŸ“Š BMPéªŒè¯é˜¶æ®µå¼€å§‹: {len(new_experiences)}ä¸ªæ–°ç»éªŒ, {len(self.candidate_rules)}ä¸ªå€™é€‰è§„å¾‹")
            
            # å¯¹æ¯ä¸ªå€™é€‰è§„å¾‹è¿›è¡ŒéªŒè¯
            for rule_id, rule in list(self.candidate_rules.items()):
                try:
                    # ä½¿ç”¨æ–°ç»éªŒéªŒè¯è§„å¾‹
                    validation_result = self._validate_rule_with_experiences(rule, new_experiences)
                    
                    if validation_result['total_applicable'] > 0:
                        # æ›´æ–°è§„å¾‹åŸºäºéªŒè¯ç»“æœ
                        self._update_rule_based_on_validation(rule, validation_result)
                        
                        # å¦‚æœéªŒè¯æˆåŠŸä¸”ç½®ä¿¡åº¦æé«˜ï¼Œç§»åˆ°å·²éªŒè¯è§„å¾‹
                        success_rate_threshold = self.config.get('validation_success_rate_threshold', 0.5)
                        if (validation_result['success_rate'] >= success_rate_threshold and 
                            rule.confidence >= self.config.get('validation_confidence_threshold', 0.3)):
                            
                            self.validated_rules[rule_id] = rule
                            del self.candidate_rules[rule_id]
                            validated_rule_ids.append(rule_id)
                            
                            if self.logger:
                                self.logger.log(f"âœ… è§„å¾‹éªŒè¯æˆåŠŸ: {rule_id[:8]} (ç½®ä¿¡åº¦: {rule.confidence:.3f})")
                        
                except Exception as e:
                    if self.logger:
                        self.logger.log(f"âŒ è§„å¾‹éªŒè¯å¤±è´¥: {rule_id[:8]} - {str(e)}")
                    continue
            
            if self.logger:
                self.logger.log(f"ğŸ“Š BMPéªŒè¯é˜¶æ®µå®Œæˆ: éªŒè¯äº†{len(validated_rule_ids)}ä¸ªè§„å¾‹")
            
            # éªŒè¯åè¡¥å……è‡ªåŠ¨æ™‹å‡
            auto_ids = self._auto_promotion_check()
            if auto_ids:
                validated_rule_ids.extend(auto_ids)
                if self.logger:
                    self.logger.log(f"âš¡ è‡ªåŠ¨æ™‹å‡: é¢å¤–æå‡ {len(auto_ids)} ä¸ªè§„å¾‹")
            return validated_rule_ids
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ BMPéªŒè¯é˜¶æ®µå¼‚å¸¸: {str(e)}")
            return []

    def _auto_promotion_check(self) -> List[str]:
        """åŸºäºé‡å¤å‡ºç°ä¸ç½®ä¿¡åº¦çš„è‡ªåŠ¨æ™‹å‡ä¸ºæ­£å¼è§„å¾‹"""
        promoted: List[str] = []
        try:
            if not self.config.get('auto_promotion_enabled', True):
                return promoted
            repeat_threshold = self.config.get('auto_promote_repeat_threshold', 4)
            conf_threshold = self.config.get('auto_promote_confidence_threshold', 0.5)
            max_contra_ratio = self.config.get('auto_promote_max_contradiction_ratio', 0.5)

            for rule_id, rule in list(self.candidate_rules.items()):
                try:
                    if rule.activation_count < repeat_threshold:
                        continue
                    if rule.confidence < conf_threshold:
                        continue
                    supp = len(getattr(rule.evidence, 'supporting_experiences', []) or [])
                    contra = len(getattr(rule.evidence, 'contradicting_experiences', []) or [])
                    total_ev = supp + contra
                    contra_ratio = (contra / total_ev) if total_ev > 0 else 0.0
                    if contra_ratio > max_contra_ratio:
                        continue

                    # æ™‹å‡
                    self.validated_rules[rule_id] = rule
                    if rule_id in self.candidate_rules:
                        del self.candidate_rules[rule_id]
                    rule.status = 'validated'
                    promoted.append(rule_id)
                    if self.logger:
                        self.logger.log(f"âœ… è§„åˆ™è‡ªåŠ¨æ™‹å‡: {rule_id[:8]} (activation:{rule.activation_count}, confidence:{rule.confidence:.3f}, contra_ratio:{contra_ratio:.2f})")
                except Exception as inner_e:
                    if self.logger:
                        self.logger.log(f"âš ï¸ è‡ªåŠ¨æ™‹å‡æ£€æŸ¥å¼‚å¸¸: {rule_id[:8]} - {str(inner_e)}")
                    continue
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ è‡ªåŠ¨æ™‹å‡æµç¨‹å¼‚å¸¸: {str(e)}")
        return promoted
    def _validate_rule_with_experiences(self, rule: CandidateRule, 
                                       experiences: List[EOCATR_Tuple]) -> Dict[str, Any]:
        """ä½¿ç”¨ç»éªŒéªŒè¯è§„å¾‹"""
        validation_result = {
            'matches': 0,
            'predictions_correct': 0,
            'predictions_wrong': 0,
            'total_applicable': 0,
            'success_rate': 0.0
        }
        
        for exp in experiences:
            # æ£€æŸ¥è§„å¾‹æ˜¯å¦é€‚ç”¨äºæ­¤ç»éªŒ
            if self._is_rule_applicable(rule, exp):
                validation_result['total_applicable'] += 1
                validation_result['matches'] += 1
                
                # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
                if self._check_rule_prediction(rule, exp):
                    validation_result['predictions_correct'] += 1
                else:
                    validation_result['predictions_wrong'] += 1
            else:
                # è½»åº¦æ³›åŒ–ï¼šè‹¥actionã€environmentåŒ¹é…ä½†toolä¸åŒï¼Œç»™äºˆéƒ¨åˆ†åŒ¹é…ï¼ˆæ”¾å®½éªŒè¯å›°éš¾ï¼‰
                try:
                    cond = rule.conditions if isinstance(rule.conditions, dict) else {}
                    act_ok = ('action' not in cond) or (cond.get('action') == getattr(exp.action, 'value', None))
                    env_ok = ('environment' not in cond) or (cond.get('environment') == getattr(exp.environment, 'value', None))
                    if act_ok and env_ok:
                        # ä½œä¸ºå¼±è¯æ®ï¼Œè®¡å…¥æ€»æ ·æœ¬ä½†ä¸åŠ æ­£ç¡®è®¡æ•°
                        validation_result['total_applicable'] += 1
                except Exception:
                    pass
        
        # è®¡ç®—æˆåŠŸç‡ï¼ˆé¿å…é™¤é›¶ï¼‰
        if validation_result['total_applicable'] > 0:
            total = validation_result['predictions_correct'] + validation_result['predictions_wrong']
            if total > 0:
                validation_result['success_rate'] = validation_result['predictions_correct'] / total
            else:
                # æ²¡æœ‰å¯¹é”™è®°å½•ä½†å­˜åœ¨å¼±åŒ¹é…æ—¶ï¼Œç»™äºˆæœ€ä½é€šè¿‡å¯èƒ½çš„åŸºçº¿ï¼ˆå¯è°ƒï¼‰
                validation_result['success_rate'] = 0.4 if validation_result['total_applicable'] > 0 else 0.0
        return validation_result
    
    def _is_rule_applicable(self, rule: CandidateRule, experience: EOCATR_Tuple) -> bool:
        """æ£€æŸ¥è§„å¾‹æ˜¯å¦é€‚ç”¨äºç»™å®šç»éªŒï¼ˆä¿®å¤ï¼šåŸºäº rule.conditions å­—å…¸åˆ¤æ–­ï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–çš„ conditions å­—å…¸ï¼›è‹¥ä¸å¯ç”¨åˆ™å›é€€ä¸ºç©º
        conditions_dict = rule.conditions if isinstance(rule.conditions, dict) else {}

        # æä¾›å®‰å…¨å–å€¼å‡½æ•°ï¼Œå…¼å®¹æšä¸¾/ç¬¦å·å…ƒç´ 
        def _safe_value(x):
            return getattr(x, 'value', getattr(x, 'content', x))

        # æ£€æŸ¥åŸºæœ¬æ¡ä»¶ï¼šå¯¹è±¡ç±»åˆ«/åŠ¨ä½œ/ç¯å¢ƒ
        if 'object_category' in conditions_dict:
            if _safe_value(experience.object_category) != conditions_dict['object_category']:
                return False

        if 'action' in conditions_dict:
            if _safe_value(experience.action) != conditions_dict['action']:
                return False

        if 'environment' in conditions_dict:
            if _safe_value(experience.environment) != conditions_dict['environment']:
                return False

        # å…¼å®¹å¢å¼ºBMPçš„ç®€å†™é”®ä½ï¼ˆE/O/C/A/Tï¼‰
        shorthand_map = {
            'E': _safe_value(experience.environment),
            'O': _safe_value(experience.object_category),
            'A': _safe_value(experience.action),
            # 'C' ç‰¹å¾é›†åˆä¸‹æ–¹ç»Ÿä¸€å¤„ç†
            'T': _safe_value(getattr(experience, 'tool', None))
        }
        for key, expected in list(conditions_dict.items()):
            if key in shorthand_map and expected is not None:
                if shorthand_map[key] != expected:
                    return False

        # æ£€æŸ¥ç‰¹å¾æ¡ä»¶ä¸é˜ˆå€¼æ¡ä»¶
        # æ”¯æŒ C ä¸º dict æˆ– list çš„æƒ…å†µï¼šéšæœºæŠ½å–ä¸€ä¸ªç‰¹å¾ä½œä¸ºä»£è¡¨åŒ¹é…
        if 'C' in conditions_dict and isinstance(conditions_dict['C'], (dict, list)):
            c_pool = []
            if isinstance(conditions_dict['C'], dict):
                c_pool = list(conditions_dict['C'].items())
            else:
                # list ä¸­æ¯ä¸ªå…ƒç´ å¯ä»¥æ˜¯ (name, value) æˆ– {'name': v}
                for item in conditions_dict['C']:
                    if isinstance(item, tuple) and len(item) == 2:
                        c_pool.append(item)
                    elif isinstance(item, dict) and len(item) == 1:
                        k, v = list(item.items())[0]
                        c_pool.append((k, v))
            if c_pool:
                k, v = random.choice(c_pool)
                exp_val = getattr(experience.characteristics, k, None)
                if exp_val != v:
                    return False

        for cond_name, cond_value in conditions_dict.items():
            if cond_name.startswith('characteristic_'):
                char_name = cond_name.replace('characteristic_', '')
                exp_char_value = getattr(experience.characteristics, char_name, None)
                if exp_char_value != cond_value:
                    return False

            elif cond_name.endswith('_threshold'):
                char_name = cond_name.replace('_threshold', '')
                exp_char_value = getattr(experience.characteristics, char_name, None)
                comparison = conditions_dict.get('comparison', 'greater_than')
                if exp_char_value is not None:
                    if comparison == 'greater_than' and exp_char_value <= cond_value:
                        return False
                    if comparison == 'less_than' and exp_char_value >= cond_value:
                        return False

        # æœªè®¾ç½®ä»»ä½•é™åˆ¶æ¡ä»¶æ—¶ï¼Œè®¤ä¸ºé€‚ç”¨
        return True
    
    def _check_rule_prediction(self, rule: CandidateRule, experience: EOCATR_Tuple) -> bool:
        """æ£€æŸ¥è§„å¾‹é¢„æµ‹æ˜¯å¦æ­£ç¡®"""
        predictions = rule.predictions
        
        # æ£€æŸ¥æˆåŠŸé¢„æµ‹
        if 'expected_success' in predictions:
            if predictions['expected_success'] != experience.result.success:
                return False
        
        # æ£€æŸ¥å¥–åŠ±é¢„æµ‹ï¼ˆå…è®¸ä¸€å®šè¯¯å·®ï¼‰
        if 'expected_reward' in predictions:
            expected_reward = predictions['expected_reward']
            actual_reward = experience.result.reward
            if abs(expected_reward - actual_reward) > abs(expected_reward) * 0.3:  # 30%è¯¯å·®å®¹å¿
                return False
        
        # æ£€æŸ¥æ¨èåŠ¨ä½œ
        if 'recommended_action' in predictions:
            if predictions['recommended_action'] != experience.action.value:
                return False
        
        return True
    
    def _update_rule_based_on_validation(self, rule: CandidateRule, validation_result: Dict[str, Any]):
        """åŸºäºéªŒè¯ç»“æœæ›´æ–°è§„å¾‹"""
        if validation_result['total_applicable'] > 0:
            # æ›´æ–°è¯æ®è®¡æ•°
            rule.evidence.total_tests += validation_result['total_applicable']
            rule.evidence.successful_tests += validation_result['predictions_correct']
            rule.evidence.last_tested = time.time()
            
            # æ›´æ–°supporting_experiencesåˆ—è¡¨ï¼ˆä¿®å¤ï¼šç¡®ä¿æ”¯æŒç»éªŒè¢«æ­£ç¡®è®°å½•ï¼‰
            if validation_result['predictions_correct'] > 0:
                # ä¸ºæ¯ä¸ªæˆåŠŸé¢„æµ‹æ·»åŠ æ”¯æŒç»éªŒè®°å½•
                for i in range(validation_result['predictions_correct']):
                    experience_id = f"validation_{int(time.time() * 1000)}_{i}"
                    if experience_id not in rule.evidence.supporting_experiences:
                        rule.evidence.supporting_experiences.append(experience_id)
            
            # æ›´æ–°ç½®ä¿¡åº¦ï¼ˆä¿®å¤ï¼šä½¿ç”¨æ›´åˆç†çš„æ›´æ–°ç®—æ³•ï¼‰
            if validation_result['total_applicable'] > 0:
                success_rate = validation_result['predictions_correct'] / validation_result['total_applicable']
                # è´å¶æ–¯æ›´æ–°ï¼šå½“æœ‰è¶³å¤Ÿè¯æ®æ—¶é€æ¸ç¨³å®šç½®ä¿¡åº¦
                evidence_weight = min(validation_result['total_applicable'] / 10.0, 0.5)
                rule.confidence = rule.confidence * (1 - evidence_weight) + success_rate * evidence_weight
                
                # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
                rule.confidence = max(0.0, min(1.0, rule.confidence))
            
            # æ›´æ–°ç²¾ç¡®åº¦å’Œå¬å›ç‡
            total_predictions = validation_result['predictions_correct'] + validation_result['predictions_wrong']
            if total_predictions > 0:
                rule.precision = validation_result['predictions_correct'] / total_predictions
            
            # æ¿€æ´»è®¡æ•°
            rule.activation_count += validation_result['matches']
            rule.last_activation = time.time()
            
            # æ›´æ–°æ•ˆç”¨å€¼ï¼ˆæ–°å¢ï¼šåŸºäºéªŒè¯ç»“æœï¼‰
            if validation_result['predictions_correct'] > 0:
                rule.utility = min(1.0, rule.utility + 0.1 * validation_result['predictions_correct'])
    
    # å·¥å…·æ–¹æ³•
    def _extract_common_characteristics(self, experiences: List[EOCATR_Tuple]) -> Dict[str, Any]:
        """æå–å…¬å…±ç‰¹å¾"""
        if not experiences:
            return {}
        
        common_chars = {}
        char_attrs = ['edible', 'poisonous', 'dangerous', 'health_state', 'size', 'accessibility']
        
        for attr in char_attrs:
            values = []
            for exp in experiences:
                value = getattr(exp.characteristics, attr, None)
                if value is not None:
                    values.append(value)
            
            if values:
                # å¦‚æœæ‰€æœ‰å€¼ç›¸åŒï¼Œåˆ™ä¸ºå…¬å…±ç‰¹å¾
                if len(set(values)) == 1:
                    common_chars[attr] = values[0]
                # å¯¹äºæ•°å€¼ç±»å‹ï¼Œè®¡ç®—å¹³å‡å€¼
                elif all(isinstance(v, (int, float)) for v in values):
                    common_chars[attr] = sum(values) / len(values)
        
        return common_chars
    
    def _extract_common_results(self, experiences: List[EOCATR_Tuple]) -> Dict[str, Any]:
        """æå–å…¬å…±ç»“æœ"""
        if not experiences:
            return {}
        
        common_results = {}
        
        # æˆåŠŸç‡
        successes = [exp.result.success for exp in experiences]
        common_results['success_rate'] = sum(successes) / len(successes)
        
        # å¹³å‡å¥–åŠ±
        rewards = [exp.result.reward for exp in experiences if exp.result.reward is not None]
        if rewards:
            common_results['average_reward'] = sum(rewards) / len(rewards)
        
        # çŠ¶æ€å˜åŒ–
        for change_type in ['hp_change', 'food_change', 'water_change']:
            changes = [getattr(exp.result, change_type, 0) for exp in experiences]
            if any(c != 0 for c in changes):
                common_results[change_type] = sum(changes) / len(changes)
        
        return common_results
    
    def _calculate_optimal_threshold(self, positive_values: List[float], 
                                   negative_values: List[float]) -> Optional[float]:
        """è®¡ç®—æœ€ä¼˜åˆ†ç¦»é˜ˆå€¼"""
        if not positive_values or not negative_values:
            return None
        
        all_values = sorted(positive_values + negative_values)
        best_threshold = None
        best_separation = 0
        
        # å°è¯•æ¯ä¸ªå¯èƒ½çš„åˆ†å‰²ç‚¹
        for i in range(1, len(all_values)):
            threshold = (all_values[i-1] + all_values[i]) / 2
            
            # è®¡ç®—åˆ†ç¦»æ•ˆæœ
            correct_positive = sum(1 for v in positive_values if v > threshold)
            correct_negative = sum(1 for v in negative_values if v <= threshold)
            total_correct = correct_positive + correct_negative
            total_samples = len(positive_values) + len(negative_values)
            
            separation = total_correct / total_samples
            
            if separation > best_separation:
                best_separation = separation
                best_threshold = threshold
        
        return best_threshold if best_separation > 0.7 else None
    
    def _get_distance_range(self, distance: float) -> str:
        """è·å–è·ç¦»èŒƒå›´åˆ†ç±»"""
        if distance <= 1:
            return "adjacent"
        elif distance <= 3:
            return "near"
        elif distance <= 7:
            return "medium"
        else:
            return "far"
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_rules_generated': self.total_rules_generated,
            'total_rules_pruned': self.total_rules_pruned,
            'total_rules_validated': self.total_rules_validated,
            'current_candidate_rules': len(self.candidate_rules),
            'current_validated_rules': len(self.validated_rules),
            'current_pruned_rules': len(self.pruned_rules),
            'rule_types_distribution': self._get_rule_type_distribution(),
            'average_rule_confidence': self._get_average_confidence(),
            'quality_score_distribution': self._get_quality_score_distribution()
        }
    
    def _get_rule_type_distribution(self) -> Dict[str, int]:
        """è·å–è§„å¾‹ç±»å‹åˆ†å¸ƒ"""
        distribution = defaultdict(int)
        
        for rule in self.candidate_rules.values():
            distribution[rule.rule_type.value] += 1
        
        for rule in self.validated_rules.values():
            distribution[rule.rule_type.value] += 1
        
        return dict(distribution)
    
    def _get_average_confidence(self) -> float:
        """è·å–å¹³å‡ç½®ä¿¡åº¦"""
        all_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
        if not all_rules:
            return 0.0
        
        return sum(rule.confidence for rule in all_rules) / len(all_rules)
    
    def _get_quality_score_distribution(self) -> Dict[str, int]:
        """è·å–è´¨é‡å¾—åˆ†åˆ†å¸ƒ"""
        distribution = {'high': 0, 'medium': 0, 'low': 0}
        
        all_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
        
        for rule in all_rules:
            score = rule.calculate_quality_score()
            if score >= 0.7:
                distribution['high'] += 1
            elif score >= 0.4:
                distribution['medium'] += 1
            else:
                distribution['low'] += 1
        
        return distribution

    def get_all_validated_rules(self) -> List[CandidateRule]:
        """è·å–æ‰€æœ‰å·²éªŒè¯çš„è§„å¾‹"""
        return list(self.validated_rules.values())
    
    def get_candidate_rules(self) -> List[CandidateRule]:
        """è·å–æ‰€æœ‰å€™é€‰è§„å¾‹"""
        return list(self.candidate_rules.values())
    
    def get_all_rules(self) -> List[CandidateRule]:
        """è·å–æ‰€æœ‰è§„å¾‹ï¼ˆå€™é€‰+å·²éªŒè¯ï¼‰"""
        return list(self.candidate_rules.values()) + list(self.validated_rules.values())
    
    def get_rule_count(self) -> Dict[str, int]:
        """è·å–è§„å¾‹æ•°é‡ç»Ÿè®¡"""
        return {
            'candidate_rules': len(self.candidate_rules),
            'validated_rules': len(self.validated_rules),
            'pruned_rules': len(self.pruned_rules),
            'total_rules': len(self.candidate_rules) + len(self.validated_rules)
        }

    # === æ–°å¢ï¼šè§„å¾‹æŒä¹…åŒ–å­˜å‚¨åŠŸèƒ½ ===
    
    def save_rules_to_file(self, filepath: str = None, include_pruned: bool = False) -> bool:
        """ä¿å­˜è§„å¾‹åˆ°æ–‡ä»¶"""
        try:
            import json
            import os
            from datetime import datetime
            
            if filepath is None:
                # é»˜è®¤æ–‡ä»¶è·¯å¾„
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filepath = f"bpm_rules_{timestamp}.json"
            
            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
            save_data = {
                'metadata': {
                    'version': '1.0',
                    'timestamp': datetime.now().isoformat(),
                    'total_rules_generated': self.total_rules_generated,
                    'total_rules_pruned': self.total_rules_pruned,
                    'total_rules_validated': self.total_rules_validated,
                    'total_rules_merged': self.total_rules_merged,
                    'total_rules_rejected': self.total_rules_rejected
                },
                'config': self.config,
                'candidate_rules': self._serialize_rules(self.candidate_rules),
                'validated_rules': self._serialize_rules(self.validated_rules),
                'rule_fingerprints': list(self.rule_fingerprints),
                'rule_merge_history': self.rule_merge_history,
                'lru_access_times': self.lru_access_times
            }
            
            if include_pruned:
                save_data['pruned_rules'] = self._serialize_rules(self.pruned_rules)
                save_data['pruning_history'] = self.pruning_history
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False)
            
            if self.logger:
                self.logger.log(f"è§„å¾‹å·²ä¿å­˜åˆ°æ–‡ä»¶: {filepath}")
                self.logger.log(f"ä¿å­˜äº† {len(self.candidate_rules)} ä¸ªå€™é€‰è§„å¾‹å’Œ {len(self.validated_rules)} ä¸ªå·²éªŒè¯è§„å¾‹")
            
            return True
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ä¿å­˜è§„å¾‹åˆ°æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def load_rules_from_file(self, filepath: str, merge_mode: str = 'replace') -> bool:
        """ä»æ–‡ä»¶åŠ è½½è§„å¾‹
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            merge_mode: åˆå¹¶æ¨¡å¼ ('replace', 'merge', 'append')
        """
        try:
            import json
            import os
            
            if not os.path.exists(filepath):
                if self.logger:
                    self.logger.log(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                return False
            
            with open(filepath, 'r', encoding='utf-8') as f:
                load_data = json.load(f)
            
            # æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
            metadata = load_data.get('metadata', {})
            version = metadata.get('version', '1.0')
            
            if version != '1.0':
                if self.logger:
                    self.logger.log(f"ç‰ˆæœ¬ä¸å…¼å®¹: {version} (æœŸæœ›: 1.0)")
                return False
            
            # æ ¹æ®åˆå¹¶æ¨¡å¼å¤„ç†
            if merge_mode == 'replace':
                # å®Œå…¨æ›¿æ¢
                self.candidate_rules = self._deserialize_rules(load_data.get('candidate_rules', {}))
                self.validated_rules = self._deserialize_rules(load_data.get('validated_rules', {}))
                if 'pruned_rules' in load_data:
                    self.pruned_rules = self._deserialize_rules(load_data['pruned_rules'])
                
                # æ¢å¤å…¶ä»–æ•°æ®
                self.rule_fingerprints = set(load_data.get('rule_fingerprints', []))
                self.rule_merge_history = load_data.get('rule_merge_history', [])
                self.lru_access_times = load_data.get('lru_access_times', {})
                
                # æ¢å¤ç»Ÿè®¡æ•°æ®
                self.total_rules_generated = metadata.get('total_rules_generated', 0)
                self.total_rules_pruned = metadata.get('total_rules_pruned', 0)
                self.total_rules_validated = metadata.get('total_rules_validated', 0)
                self.total_rules_merged = metadata.get('total_rules_merged', 0)
                self.total_rules_rejected = metadata.get('total_rules_rejected', 0)
                
            elif merge_mode == 'merge':
                # æ™ºèƒ½åˆå¹¶ï¼ˆé¿å…é‡å¤ï¼‰
                loaded_candidate = self._deserialize_rules(load_data.get('candidate_rules', {}))
                loaded_validated = self._deserialize_rules(load_data.get('validated_rules', {}))
                
                merged_count = 0
                # åˆå¹¶å€™é€‰è§„å¾‹
                for rule_id, rule in loaded_candidate.items():
                    if not self._is_duplicate_rule(rule):
                        self.candidate_rules[rule_id] = rule
                        self.rule_fingerprints.add(self._generate_rule_fingerprint(rule))
                        merged_count += 1
                
                # åˆå¹¶å·²éªŒè¯è§„å¾‹
                for rule_id, rule in loaded_validated.items():
                    if not self._is_duplicate_rule(rule):
                        self.validated_rules[rule_id] = rule
                        self.rule_fingerprints.add(self._generate_rule_fingerprint(rule))
                        merged_count += 1
                
                if self.logger:
                    self.logger.log(f"æ™ºèƒ½åˆå¹¶å®Œæˆï¼Œæ–°å¢ {merged_count} ä¸ªè§„å¾‹")
                    
            elif merge_mode == 'append':
                # ç®€å•è¿½åŠ ï¼ˆå¯èƒ½äº§ç”Ÿé‡å¤ï¼‰
                loaded_candidate = self._deserialize_rules(load_data.get('candidate_rules', {}))
                loaded_validated = self._deserialize_rules(load_data.get('validated_rules', {}))
                
                self.candidate_rules.update(loaded_candidate)
                self.validated_rules.update(loaded_validated)
                
                # é‡æ–°ç”ŸæˆæŒ‡çº¹
                self.rule_fingerprints.clear()
                all_rules = list(self.candidate_rules.values()) + list(self.validated_rules.values())
                for rule in all_rules:
                    self.rule_fingerprints.add(self._generate_rule_fingerprint(rule))
            
            if self.logger:
                self.logger.log(f"è§„å¾‹å·²ä»æ–‡ä»¶åŠ è½½: {filepath}")
                self.logger.log(f"å½“å‰æœ‰ {len(self.candidate_rules)} ä¸ªå€™é€‰è§„å¾‹å’Œ {len(self.validated_rules)} ä¸ªå·²éªŒè¯è§„å¾‹")
            
            return True
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ä»æ–‡ä»¶åŠ è½½è§„å¾‹å¤±è´¥: {str(e)}")
            return False
    
    def _serialize_rules(self, rules_dict: Dict[str, CandidateRule]) -> Dict[str, Dict]:
        """åºåˆ—åŒ–è§„å¾‹å­—å…¸"""
        serialized = {}
        
        for rule_id, rule in rules_dict.items():
            serialized[rule_id] = {
                'rule_id': rule.rule_id,
                'rule_type': rule.rule_type.value,
                'pattern': rule.pattern,
                'conditions': rule.condition_elements,
                'predictions': rule.predictions,
                'confidence': rule.confidence,
                'strength': rule.strength,
                'generalization': rule.generalization,
                'specificity': rule.specificity,
                'complexity': rule.complexity,
                'birth_time': rule.birth_time,
                'last_activation': rule.last_activation,
                'activation_count': rule.activation_count,
                'precision': rule.precision,
                'recall': rule.recall,
                'utility': rule.utility,
                'parent_rules': rule.parent_rules,
                'derived_rules': rule.derived_rules,
                'evidence': {
                    'supporting_experiences': rule.evidence.supporting_experiences,
                    'contradicting_experiences': rule.evidence.contradicting_experiences,
                    'total_tests': rule.evidence.total_tests,
                    'successful_tests': rule.evidence.successful_tests,
                    'last_tested': rule.evidence.last_tested,
                    'test_contexts': rule.evidence.test_contexts
                }
            }
        
        return serialized
    
    def _deserialize_rules(self, serialized_dict: Dict[str, Dict]) -> Dict[str, CandidateRule]:
        """ååºåˆ—åŒ–è§„å¾‹å­—å…¸"""
        rules_dict = {}
        
        for rule_id, rule_data in serialized_dict.items():
            try:
                # é‡æ„è§„å¾‹è¯æ®
                evidence = RuleEvidence(
                    supporting_experiences=rule_data['evidence']['supporting_experiences'],
                    contradicting_experiences=rule_data['evidence']['contradicting_experiences'],
                    total_tests=rule_data['evidence']['total_tests'],
                    successful_tests=rule_data['evidence']['successful_tests'],
                    last_tested=rule_data['evidence']['last_tested'],
                    test_contexts=rule_data['evidence']['test_contexts']
                )
                
                # é‡æ„è§„å¾‹å¯¹è±¡
                rule = CandidateRule(
                    rule_id=rule_data['rule_id'],
                    rule_type=RuleType(rule_data['rule_type']),
                    pattern=rule_data['pattern'],
                    conditions=rule_data['conditions'],
                    predictions=rule_data['predictions'],
                    confidence=rule_data['confidence'],
                    strength=rule_data['strength'],
                    generalization=rule_data['generalization'],
                    specificity=rule_data['specificity'],
                    complexity=rule_data['complexity'],
                    evidence=evidence,
                    birth_time=rule_data['birth_time'],
                    last_activation=rule_data['last_activation'],
                    activation_count=rule_data['activation_count'],
                    precision=rule_data['precision'],
                    recall=rule_data['recall'],
                    utility=rule_data['utility'],
                    parent_rules=rule_data['parent_rules'],
                    derived_rules=rule_data['derived_rules']
                )
                
                rules_dict[rule_id] = rule
                
            except Exception as e:
                if self.logger:
                    self.logger.log(f"ååºåˆ—åŒ–è§„å¾‹å¤±è´¥ {rule_id}: {str(e)}")
                continue
        
        return rules_dict 

    # ============================================================================
    # ç³»ç»Ÿæ€§EOCATRè§„å¾‹ç”Ÿæˆå™¨ (æ–°å¢)
    # ============================================================================
    
    def generate_systematic_eocatr_rules(self, eocatr_matrix_config: Dict) -> List[CandidateRule]:
        """
        ç³»ç»Ÿæ€§ç”ŸæˆEOCATRçŸ©é˜µè§„å¾‹
        åŸºäºç”¨æˆ·ç¡®è®¤çš„ç»„åˆç­–ç•¥ï¼šE-A-R, E-T-R, O-A-R, O-T-R, C-A-R, C-T-R
        
        Args:
            eocatr_matrix_config: EOCATRçŸ©é˜µé…ç½®å­—å…¸
            
        Returns:
            ç”Ÿæˆçš„ç³»ç»Ÿæ€§è§„å¾‹åˆ—è¡¨
        """
        if self.logger:
            self.logger.log("å¼€å§‹ç”Ÿæˆç³»ç»Ÿæ€§EOCATRè§„å¾‹...")
        
        systematic_rules = []
        generation_start_time = time.time()
        
        try:
            # 1. ç¯å¢ƒ-è¡ŒåŠ¨-ç»“æœè§„å¾‹ (E-A-R)
            ear_rules = self._generate_ear_rules(eocatr_matrix_config)
            systematic_rules.extend(ear_rules)
            
            # 2. ç¯å¢ƒ-å·¥å…·-ç»“æœè§„å¾‹ (E-T-R)  
            etr_rules = self._generate_etr_rules(eocatr_matrix_config)
            systematic_rules.extend(etr_rules)
            
            # 3. å¯¹è±¡-è¡ŒåŠ¨-ç»“æœè§„å¾‹ (O-A-R)
            oar_rules = self._generate_oar_rules(eocatr_matrix_config)
            systematic_rules.extend(oar_rules)
            
            # 4. å¯¹è±¡-å·¥å…·-ç»“æœè§„å¾‹ (O-T-R)
            otr_rules = self._generate_otr_rules(eocatr_matrix_config)
            systematic_rules.extend(otr_rules)
            
            # 5. å±æ€§-è¡ŒåŠ¨-ç»“æœè§„å¾‹ (C-A-R)
            car_rules = self._generate_car_rules(eocatr_matrix_config)
            systematic_rules.extend(car_rules)
            
            # 6. å±æ€§-å·¥å…·-ç»“æœè§„å¾‹ (C-T-R)
            ctr_rules = self._generate_ctr_rules(eocatr_matrix_config)
            systematic_rules.extend(ctr_rules)
            
            generation_time = time.time() - generation_start_time
            
            if self.logger:
                self.logger.log(f"BPMç³»ç»Ÿæ€§ç”Ÿæˆäº† {len(systematic_rules)} æ¡EOCATRåŸºç¡€è§„å¾‹")
                self.logger.log(f"  E-A-Rè§„å¾‹: {len(ear_rules)}æ¡")
                self.logger.log(f"  E-T-Rè§„å¾‹: {len(etr_rules)}æ¡")
                self.logger.log(f"  O-A-Rè§„å¾‹: {len(oar_rules)}æ¡")
                self.logger.log(f"  O-T-Rè§„å¾‹: {len(otr_rules)}æ¡")
                self.logger.log(f"  C-A-Rè§„å¾‹: {len(car_rules)}æ¡")
                self.logger.log(f"  C-T-Rè§„å¾‹: {len(ctr_rules)}æ¡")
                self.logger.log(f"ç”Ÿæˆè€—æ—¶: {generation_time:.2f}ç§’")
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_rules_generated += len(systematic_rules)
            
            return systematic_rules
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"ç³»ç»Ÿæ€§EOCATRè§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    def _generate_ear_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆç¯å¢ƒ-è¡ŒåŠ¨-ç»“æœè§„å¾‹"""
        rules = []
        environments = config.get('environments', ['å¼€é˜”åœ°', 'æ£®æ—', 'æ°´åŸŸ', 'å±é™©åŒºåŸŸ'])
        actions = config.get('actions', ['ç§»åŠ¨', 'æ”»å‡»', 'é‡‡é›†', 'è§‚å¯Ÿ', 'é€ƒè·‘'])
        results = config.get('results', ['æˆåŠŸ', 'å¤±è´¥', 'è·å¾—å¥–åŠ±', 'å—åˆ°ä¼¤å®³'])
        
        for env in environments:
            for action in actions:
                for result in results:
                    # æ™ºèƒ½ç½®ä¿¡åº¦è®¡ç®—
                    confidence = self._calculate_intelligent_confidence(env, action, result, 'E-A-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.CONDITIONAL,
                        pattern=f"åœ¨{env}ç¯å¢ƒä¸‹æ‰§è¡Œ{action}è¡ŒåŠ¨",
                        conditions={'environment': env, 'action': action},
                        predictions={'result': result},
                        confidence=confidence,  # ä½¿ç”¨æ™ºèƒ½ç½®ä¿¡åº¦
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _generate_etr_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆç¯å¢ƒ-å·¥å…·-ç»“æœè§„å¾‹"""
        rules = []
        environments = config.get('environments', ['å¼€é˜”åœ°', 'æ£®æ—', 'æ°´åŸŸ'])
        tools = config.get('tools', ['æ— å·¥å…·', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±'])
        results = config.get('results', ['æˆåŠŸ', 'å¤±è´¥', 'æ•ˆç‡æå‡', 'èµ„æºæ¶ˆè€—'])
        
        for env in environments:
            for tool in tools:
                for result in results:
                    confidence = self._calculate_intelligent_confidence(env, tool, result, 'E-T-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.TOOL_EFFECTIVENESS,
                        pattern=f"åœ¨{env}ç¯å¢ƒä¸‹ä½¿ç”¨{tool}å·¥å…·",
                        conditions={'environment': env, 'tool': tool},
                        predictions={'result': result},
                        confidence=confidence,
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _generate_oar_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆå¯¹è±¡-è¡ŒåŠ¨-ç»“æœè§„å¾‹"""
        rules = []
        objects = config.get('objects', ['è‰è“', 'è˜‘è‡', 'è€è™', 'å…”å­', 'é‡çŒª', 'é»‘ç†Š'])
        actions = config.get('actions', ['é‡‡é›†', 'æ”»å‡»', 'é€ƒé¿', 'è§‚å¯Ÿ', 'è·Ÿè¸ª'])
        results = config.get('results', ['è·å¾—é£Ÿç‰©', 'å—åˆ°ä¼¤å®³', 'æˆåŠŸé€ƒè„±', 'å‘ç°ä¿¡æ¯'])
        
        for obj in objects:
            for action in actions:
                for result in results:
                    confidence = self._calculate_intelligent_confidence(obj, action, result, 'O-A-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.CAUSAL,
                        pattern=f"å¯¹{obj}å¯¹è±¡æ‰§è¡Œ{action}è¡ŒåŠ¨",
                        conditions={'object': obj, 'action': action},
                        predictions={'result': result},
                        confidence=confidence,
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _generate_otr_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆå¯¹è±¡-å·¥å…·-ç»“æœè§„å¾‹"""
        rules = []
        objects = config.get('objects', ['è‰è“', 'è˜‘è‡', 'è€è™', 'å…”å­'])
        tools = config.get('tools', ['æ— å·¥å…·', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±'])
        results = config.get('results', ['æ”¶é›†æˆåŠŸ', 'æ”»å‡»ç”Ÿæ•ˆ', 'å·¥å…·æŸå', 'æå‡æ•ˆç‡'])
        
        for obj in objects:
            for tool in tools:
                for result in results:
                    confidence = self._calculate_intelligent_confidence(obj, tool, result, 'O-T-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.TOOL_EFFECTIVENESS,
                        pattern=f"ä½¿ç”¨{tool}å·¥å…·å¤„ç†{obj}å¯¹è±¡",
                        conditions={'object': obj, 'tool': tool},
                        predictions={'result': result},
                        confidence=confidence,
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _generate_car_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆå±æ€§-è¡ŒåŠ¨-ç»“æœè§„å¾‹"""
        rules = []
        
        # æ”¯æŒå¤šç»´ç‰¹å¾åˆ†è§£
        attributes = config.get('attributes', [])
        if not attributes:
            # é»˜è®¤ç‰¹å¾é›†åˆ
            attributes = [
                'è·ç¦»è¿‘', 'è·ç¦»ä¸­', 'è·ç¦»è¿œ',
                'å¯é£Ÿç”¨', 'æœ‰æ¯’', 'å±é™©',
                'è¥å…»ä¸°å¯Œ', 'è¥å…»ä¸€èˆ¬', 'è¥å…»ç¼ºä¹',
                'è¡€é‡é«˜', 'è¡€é‡ä¸­', 'è¡€é‡ä½'
            ]
        
        actions = config.get('actions', ['ç§»åŠ¨', 'æ”»å‡»', 'é‡‡é›†', 'è§‚å¯Ÿ'])
        results = config.get('results', ['æˆåŠŸ', 'å¤±è´¥', 'é£é™©', 'æ”¶ç›Š'])
        
        for attr in attributes:
            for action in actions:
                for result in results:
                    confidence = self._calculate_intelligent_confidence(attr, action, result, 'C-A-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.CONDITIONAL,
                        pattern=f"åœ¨{attr}å±æ€§ä¸‹æ‰§è¡Œ{action}è¡ŒåŠ¨",
                        conditions={'attribute': attr, 'action': action},
                        predictions={'result': result},
                        confidence=confidence,
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _generate_ctr_rules(self, config: Dict) -> List[CandidateRule]:
        """ç”Ÿæˆå±æ€§-å·¥å…·-ç»“æœè§„å¾‹"""
        rules = []
        attributes = config.get('attributes', [
            'è·ç¦»è¿‘', 'è·ç¦»è¿œ', 'å±é™©', 'å®‰å…¨', 'è¥å…»ä¸°å¯Œ', 'è¡€é‡ä½'
        ])
        tools = config.get('tools', ['æ— å·¥å…·', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±'])
        results = config.get('results', ['æ•ˆæœå¢å¼º', 'é£é™©é™ä½', 'æ•ˆç‡æå‡', 'èµ„æºèŠ‚çœ'])
        
        for attr in attributes:
            for tool in tools:
                for result in results:
                    confidence = self._calculate_intelligent_confidence(attr, tool, result, 'C-T-R')
                    
                    rule = self._create_systematic_rule(
                        rule_type=RuleType.TOOL_EFFECTIVENESS,
                        pattern=f"åœ¨{attr}å±æ€§ä¸‹ä½¿ç”¨{tool}å·¥å…·",
                        conditions={'attribute': attr, 'tool': tool},
                        predictions={'result': result},
                        confidence=confidence,
                        complexity=1
                    )
                    rules.append(rule)
        
        return rules

    def _create_systematic_rule(self, rule_type: RuleType, pattern: str, 
                              conditions: Dict, predictions: Dict, 
                              confidence: float, complexity: int) -> CandidateRule:
        """åˆ›å»ºç³»ç»Ÿæ€§è§„å¾‹"""
        rule_id = f"SYS_{rule_type.value}_{hash(pattern) % 10000:04d}"
        
        rule = CandidateRule(
            rule_id=rule_id,
            rule_type=rule_type,
            pattern=pattern,
            conditions=conditions,
            predictions=predictions,
            confidence=confidence,
            complexity=complexity,
            birth_time=time.time()
        )
        
        return rule

    def _calculate_intelligent_confidence(self, element1: str, element2: str, result: str, combination_type: str) -> float:
        """
        æ™ºèƒ½è®¡ç®—è§„å¾‹çš„åˆå§‹ç½®ä¿¡åº¦
        åŸºäºå…ƒç´ ç»„åˆçš„åˆç†æ€§è¯„ä¼°
        """
        base_confidence = 0.3  # åŸºç¡€ç½®ä¿¡åº¦æå‡åˆ°0.3
        
        # åŸºäºç»„åˆç±»å‹çš„è°ƒæ•´
        type_multipliers = {
            'E-A-R': 0.4,     # ç¯å¢ƒ-è¡ŒåŠ¨ç»„åˆè¾ƒä¸ºç›´è§‚
            'E-T-R': 0.35,    # ç¯å¢ƒ-å·¥å…·ç»„åˆä¸­ç­‰åˆç†
            'O-A-R': 0.45,    # å¯¹è±¡-è¡ŒåŠ¨ç»„åˆæœ€ä¸ºç›´è§‚
            'O-T-R': 0.4,     # å¯¹è±¡-å·¥å…·ç»„åˆè¾ƒä¸ºåˆç†
            'C-A-R': 0.35,    # ç‰¹å¾-è¡ŒåŠ¨ç»„åˆéœ€è¦æ›´å¤šéªŒè¯
            'C-T-R': 0.35,    # ç‰¹å¾-å·¥å…·ç»„åˆéœ€è¦æ›´å¤šéªŒè¯
        }
        
        # åŸºäºå¸¸è¯†çš„åˆç†æ€§åˆ¤æ–­
        reasonableness_bonus = 0.0
        
        # é«˜åˆç†æ€§ç»„åˆ
        if any(combo in f"{element1}-{element2}-{result}" for combo in [
            "è‰è“-é‡‡é›†-è·å¾—é£Ÿç‰©", "è€è™-æ”»å‡»-å—åˆ°ä¼¤å®³", "å…”å­-é‡‡é›†-è·å¾—é£Ÿç‰©",
            "æ£®æ—-ç§»åŠ¨-æˆåŠŸ", "å±é™©åŒºåŸŸ-é€ƒè·‘-æˆåŠŸé€ƒè„±", "è·ç¦»è¿‘-æ”»å‡»-æˆåŠŸ"
        ]):
            reasonableness_bonus = 0.2
        
        # ä¸­ç­‰åˆç†æ€§
        elif any(combo in f"{element1}-{element2}-{result}" for combo in [
            "è˜‘è‡-é‡‡é›†-è·å¾—é£Ÿç‰©", "çŸ³å¤´-æ”»å‡»-æ”»å‡»ç”Ÿæ•ˆ", "å¼€é˜”åœ°-ç§»åŠ¨-æˆåŠŸ"
        ]):
            reasonableness_bonus = 0.1
        
        # ä½åˆç†æ€§ï¼ˆæ½œåœ¨åå¸¸è¯†ç»„åˆï¼‰
        elif any(combo in f"{element1}-{element2}-{result}" for combo in [
            "è€è™-é‡‡é›†", "è‰è“-æ”»å‡»", "æœ‰æ¯’-è·å¾—é£Ÿç‰©"
        ]):
            reasonableness_bonus = -0.1
        
        final_confidence = base_confidence + type_multipliers.get(combination_type, 0.3) + reasonableness_bonus
        
        # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
        return max(0.2, min(0.8, final_confidence))

    def get_eocatr_generation_statistics(self) -> Dict[str, Any]:
        """è·å–EOCATRè§„å¾‹ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_statistics()
        
        # ç»Ÿè®¡ç³»ç»Ÿæ€§ç”Ÿæˆçš„è§„å¾‹
        systematic_rules = {
            'candidate': 0,
            'validated': 0,
            'by_type': {}
        }
        
        # å€™é€‰è§„å¾‹ä¸­çš„ç³»ç»Ÿæ€§è§„å¾‹
        for rule in self.candidate_rules.values():
            if rule.rule_id.startswith('SYS_'):
                systematic_rules['candidate'] += 1
                rule_type = rule.rule_type.value
                if rule_type not in systematic_rules['by_type']:
                    systematic_rules['by_type'][rule_type] = {'candidate': 0, 'validated': 0}
                systematic_rules['by_type'][rule_type]['candidate'] += 1
        
        # å·²éªŒè¯è§„å¾‹ä¸­çš„ç³»ç»Ÿæ€§è§„å¾‹
        for rule in self.validated_rules.values():
            if rule.rule_id.startswith('SYS_'):
                systematic_rules['validated'] += 1
                rule_type = rule.rule_type.value
                if rule_type not in systematic_rules['by_type']:
                    systematic_rules['by_type'][rule_type] = {'candidate': 0, 'validated': 0}
                systematic_rules['by_type'][rule_type]['validated'] += 1
        
        stats['systematic_eocatr_rules'] = systematic_rules
        
        return stats

    # === æ–°å¢ï¼šprocess_experienceæ–¹æ³•ï¼ˆå…¼å®¹main.pyè°ƒç”¨ï¼‰===
    def process_experience(self, experience, historical_experiences=None):
        """
        å¤„ç†å•ä¸ªç»éªŒï¼Œç”Ÿæˆå¹¶éªŒè¯è§„å¾‹
        è¿™ä¸ªæ–¹æ³•å…¼å®¹main.pyä¸­çš„è°ƒç”¨æ¨¡å¼
        
        Args:
            experience: EOCATR_Tupleæ ¼å¼çš„ç»éªŒ
            historical_experiences: å†å²ç»éªŒåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            List[CandidateRule]: ç”Ÿæˆçš„å€™é€‰è§„å¾‹åˆ—è¡¨
        """
        try:
            if self.logger:
                self.logger.log(f"ğŸŒ¸ BMPå¼€å§‹å¤„ç†ç»éªŒ: {getattr(experience, 'tuple_id', 'unknown')}")
            
            # ç¡®ä¿è¾“å…¥æ˜¯EOCATR_Tupleæ ¼å¼
            if not hasattr(experience, 'environment'):
                if self.logger:
                    self.logger.log(f"âš ï¸ ç»éªŒæ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡å¤„ç†")
                return []
            
            # å‡†å¤‡ç»éªŒåˆ—è¡¨
            experiences_to_process = [experience]
            if historical_experiences:
                # é™åˆ¶å†å²ç»éªŒæ•°é‡ï¼Œé¿å…å†…å­˜è¿‡å¤§
                max_historical = 20
                if len(historical_experiences) > max_historical:
                    historical_experiences = historical_experiences[-max_historical:]
                experiences_to_process.extend(historical_experiences)
            
            # è°ƒç”¨ç°æœ‰çš„æ€’æ”¾é˜¶æ®µæ–¹æ³•ç”Ÿæˆè§„å¾‹
            new_candidate_rules = self.blooming_phase(experiences_to_process)
            
            # å¦‚æœæœ‰å†å²ç»éªŒï¼Œæ‰§è¡ŒéªŒè¯é˜¶æ®µ
            if historical_experiences and len(historical_experiences) > 0:
                validated_rule_ids = self.validation_phase(historical_experiences)
                if self.logger and validated_rule_ids:
                    self.logger.log(f"âœ… éªŒè¯é˜¶æ®µé€šè¿‡{len(validated_rule_ids)}ä¸ªè§„å¾‹")
            
            # æ‰§è¡Œå‰ªæé˜¶æ®µï¼ˆå†…å­˜ç®¡ç†ï¼‰
            pruned_rule_ids = self.pruning_phase()
            if self.logger and pruned_rule_ids:
                self.logger.log(f"âœ‚ï¸ å‰ªæé˜¶æ®µç§»é™¤{len(pruned_rule_ids)}ä¸ªè§„å¾‹")
            
            if self.logger:
                self.logger.log(f"ğŸŒ¸ BMPå¤„ç†å®Œæˆ: ç”Ÿæˆ{len(new_candidate_rules)}ä¸ªå€™é€‰è§„å¾‹")
            
            return new_candidate_rules
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"âŒ BMPç»éªŒå¤„ç†å¤±è´¥: {str(e)}")
            return []
    def _filter_relevant_experiences_for_blooming(self, experiences: List[EOCATR_Tuple], max_experiences: int = 50) -> List[EOCATR_Tuple]:
        """è¿‡æ»¤ç›¸å…³ç»éªŒä»¥æé«˜æ€’æ”¾æ•ˆç‡"""
        if len(experiences) <= max_experiences:
            return experiences
        
        # ä¼˜å…ˆé€‰æ‹©æœ€è¿‘çš„ç»éªŒ
        recent_experiences = experiences[-max_experiences//2:]
        
        # é€‰æ‹©å¤šæ ·åŒ–çš„å†å²ç»éªŒ
        historical_experiences = experiences[:-max_experiences//2]
        if historical_experiences:
            # æŒ‰ç»éªŒæ¨¡å¼åˆ†ç»„
            pattern_groups = {}
            for exp in historical_experiences:
                pattern = self._get_experience_pattern(exp)
                if pattern not in pattern_groups:
                    pattern_groups[pattern] = []
                pattern_groups[pattern].append(exp)
            
            # ä»æ¯ç»„é€‰æ‹©æœ€ä½³ç»éªŒ
            diverse_experiences = []
            remaining_slots = max_experiences - len(recent_experiences)
            per_group_limit = max(1, remaining_slots // max(1, len(pattern_groups)))
            
            for group_experiences in pattern_groups.values():
                # é€‰æ‹©ç»„å†…æœ€æ–°ç»éªŒ
                best_in_group = group_experiences[-per_group_limit:]
                diverse_experiences.extend(best_in_group)
        
        return recent_experiences + diverse_experiences[:max_experiences-len(recent_experiences)]
    
    def _get_experience_pattern(self, exp) -> str:
        """è·å–ç»éªŒæ¨¡å¼ç”¨äºåˆ†ç»„"""
        try:
            env = getattr(exp.environment, "content", getattr(exp.environment, "name", "unknown"))
            obj = getattr(exp.object, "content", getattr(exp.object, "name", "unknown"))
            action = getattr(exp.action, "content", getattr(exp.action, "name", "unknown"))
            return f"{env}_{obj}_{action}"
        except:
            return "unknown_pattern"
    
    def _has_sufficient_new_experiences(self, experiences: List[EOCATR_Tuple], min_new_patterns: int = 2) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ–°ç»éªŒæ¨¡å¼æ¥ç”Ÿæˆè§„å¾‹"""
        # æ”¾å®½ç­–ç•¥ï¼šè‡³å°‘2æ¡ç»éªŒå³å¯
        if len(experiences) < 2:
            return False
        
        # æ£€æŸ¥ç»éªŒçš„å¤šæ ·æ€§
        unique_patterns = set()
        for exp in experiences:
            pattern = self._get_experience_pattern(exp)
            unique_patterns.add(pattern)
        
        # æ”¾å®½ç­–ç•¥ï¼šä¸åŒæ¨¡å¼è‡³å°‘1ä¸ªå³å¯ï¼ˆåŒæ¨¡å¼é‡å¤ä¹Ÿå…è®¸ï¼‰
        if len(unique_patterns) < 1:
            if self.logger:
                self.logger.log(f"BMPï¼šç»éªŒæ¨¡å¼ä¸è¶³ ({len(unique_patterns)}/{1})ï¼Œè·³è¿‡è§„å¾‹ç”Ÿæˆ")
            return False
        
        return True