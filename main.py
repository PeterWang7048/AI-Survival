



# Performance optimization: Knowledge sharing frequency control
KNOWLEDGE_SHARE_INTERVAL = 5  # Share knowledge every 5 rounds
MAX_SHARES_PER_ROUND = 2      # Maximum 2 shares per round

def should_share_knowledge(player, round_num):
    """Check if knowledge should be shared"""
    # Check sharing interval
    if round_num % KNOWLEDGE_SHARE_INTERVAL != 0:
        return False
    
    # Check sharing count
    if not hasattr(player, 'shares_this_round'):
        player.shares_this_round = 0
    
    if player.shares_this_round >= MAX_SHARES_PER_ROUND:
        return False
    
    return True

def record_knowledge_share(player):
    """Record knowledge sharing"""
    if not hasattr(player, 'shares_this_round'):
        player.shares_this_round = 0
    player.shares_this_round += 1

def reset_round_shares(players):
    """Reset round sharing count"""
    for player in players:
        player.shares_this_round = 0

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI Survival Competition System - Main Program
Supports survival competition simulation with multiple AI algorithms including DQN, PPO, and ILAI
"""

import os
import time
import tkinter as tk
# EMRS repair patch import
try:
    from emrs_format_fix import EMRSFormatFixer
except ImportError:
    print("Warning: EMRS repair module not found")
from tkinter import ttk
import random
import numpy as np
from collections import deque
import json
import heapq
import math
import datetime
import logging
from typing import Any, Dict, List, Optional, Union, Tuple

# TensorFlow import
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Import dynamic multi-head attention mechanism
from dynamic_multi_head_attention import DynamicMultiHeadAttention, AttentionContext, AttentionFocus

# Import multi-layer memory system
from multi_layer_memory_system import MultiLayerMemorySystem, MemoryType, MemoryImportance, MemoryItem

# Add new module import at the top of the file
from wooden_bridge_model import WoodenBridgeModel, GoalType, ReasoningStrategy, Rule, Goal

# Import blooming and pruning model
from blooming_and_pruning_model import BloomingAndPruningModel, CandidateRule, RuleType

# Import new BPM integration system
from bpm_integration import BPMIntegrationManager
from eocar_combination_generator import EOCARCombinationGenerator, CombinationType
from rule_validation_system import RuleValidationSystem, ValidationStrategy

# Import SSM scene symbolization mechanism
from scene_symbolization_mechanism import (
    SceneSymbolizationMechanism, 
    create_experience_from_eocatr,
    SymbolicEnvironment,
    SymbolicObjectCategory,
    SymbolicAction
)

# Import V3 symbol system
from symbolic_core_v3 import (
    EOCATR_Tuple as EOCAR_Tuple
)

# Import data format unification module
from data_format_unifier import (
    DataFormatUnifier,
    UnifiedAction,
    UnifiedState,
    UnifiedExperience,
    UnifiedResult,
    ActionType,
    StateType,
    ExperienceType,
    DataFormatValidator,
    create_data_format_unifier,
    quick_convert_action,
    quick_convert_state,
    quick_convert_experience
)

# Import EMRS parameter repair module
from emrs_parameter_fix import (
    EMRSParameterFixer,
    EMRSParameterValidator,
    EMRSParameterMapper,
    EMRSCompatibilityWrapper,
    create_emrs_parameter_fixer,
    quick_fix_emrs_call,
    wrap_emrs_for_compatibility
)

# Import new BPM second module: rule validation system
from rule_validation_system import (
    RuleValidationSystem,
    ValidationStrategy,
    RiskLevel,
    ValidationAttempt,
    ConfidenceUpdater
)

# å¯¼å…¥ç»Ÿä¸€çŸ¥è¯†å†³ç­–ç³»ç»Ÿ
try:
    from unified_knowledge_decision_system import (
        UnifiedKnowledgeDecisionSystem,
        Experience,
        Scenario,
        GoalType as UnifiedGoalType,  # é‡å‘½åä»¥é¿å…å†²çª
        RuleStatus
    )
    UNIFIED_KNOWLEDGE_AVAILABLE = True
except ImportError:
    print("Warning: Unified knowledge decision system module not found")
    UNIFIED_KNOWLEDGE_AVAILABLE = False

# å¯¼å…¥æ•´åˆå†³ç­–ç³»ç»Ÿ
try:
    from integrated_decision_system import IntegratedDecisionSystem, DecisionContext
    from simplified_bmp_generator import SimplifiedBMPGenerator
    from unified_decision_system import UnifiedDecisionSystem
    INTEGRATED_DECISION_AVAILABLE = True
except ImportError:
    print("Warning: Integrated decision system module not found")
    INTEGRATED_DECISION_AVAILABLE = False

# åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
MODELS_DIR = "saved_models"
if not os.path.exists(MODELS_DIR):
    os.makedirs(MODELS_DIR)

# è®¾ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
logger.addHandler(handler)

# è®¾ç½®TensorFlowæ—¥å¿—çº§åˆ«
tf.get_logger().setLevel('ERROR')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Global settings, all initial parameters controlled by the main panel
settings = {
    "map_width": 100,
    "map_height": 100,
    "map_type": "grassland",  # Options: grassland, desert, forest, mountain
    "seed": 42,
    "resource_abundance": 100,  # Percentage, 1%-1000%
    "resource_regen": 20,       # Days 1 to 100 days
    "game_duration": 30,        # Game duration (rounds, each round is a day) 1 to 10000 days [Changed: 300->30 days]
    "group_hunt_frequency": 30, # Group hunt frequency every X days
    "reasoning_attention": 20,  # Reasoning attention allocation percentage for baby learning AI
    "honesty_true": 33,         # True message sharing percentage
    "honesty_false": 33,        # False message sharing percentage
    "honesty_none": 34,         # No message sharing percentage
    "enable_hierarchical_cognition": True,
    "enable_developmental_cognition": True,
    "enable_dynamic_multihead_attention": True,
    "enable_social_decision": True,
    "enable_diverse_rewards": True,
    "enable_lstm": True,
    "enable_curiosity": True,
    "enable_deep_logical_alignment": True,
    "enable_reinforcement_learning": True,
    "animal_abundance_predator": 50,   # Predator abundance [Changed: 100->50]
    "animal_abundance_prey": 100,      # Prey abundance
    "plant_abundance_edible": 100,     # Edible plant abundance
    "plant_abundance_toxic": 100,      # Toxic plant abundance
}


#
# Logging tool (automatically generates log files after game exit)
#
class Logger:
    def __init__(self):
        self.logs = []
        self.seed_logged = False
        self.predator_count_logged = False

    def log(self, message):
        self.logs.append(message)

    def log_seed(self, seed):
        if not self.seed_logged:
            self.logs.insert(0, f"Map seed: {seed}")
            self.seed_logged = True

    def log_predator_count(self, count):
        if not self.predator_count_logged:
            # Insert predator count after seed
            insert_pos = 1 if self.seed_logged else 0
            self.logs.insert(insert_pos, f"Initial predator count: {count}")
            self.predator_count_logged = True

    def write_log_file(self):
        if self.logs:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"game_{timestamp}.log"
            with open(filename, "w", encoding="utf-8") as f:
                for log in self.logs:
                    f.write(f"{log}\n")
            self.logs = []


logger = Logger()


#
# Map generation class: generates "grid" map and randomly places animals and plants on the map
#
class GameMap:
    def __init__(self, width, height, map_type, seed):
        self.width = width
        self.height = height
        self.map_type = map_type
        random.seed(seed)
        # Generate map grid, each cell stores terrain string
        self.grid = [
            [self.generate_cell() for _ in range(width)] for _ in range(height)
        ]
        self.animals = []  # Animal list
        self.plants = []   # Plant list
        self.populate_animals()
        self.populate_plants()

    def generate_cell(self):
        r = random.random()
        if r < 0.5:
            return "plain"
        elif r < 0.55:
            return "big_tree"
        elif r < 0.75:
            return "bush"
        elif r < 0.9:
            return "rock"
        elif r < 0.95:
            return "cave"
        elif r < 0.98:
            return "river"
        else:
            return "puddle"

    def populate_animals(self):
        # Distribute animals in arbitrary proportions based on animal abundance settings (numbers are simply scaled)
        total_cells = self.width * self.height
        num_predators = total_cells * settings["animal_abundance_predator"] // 10000
        for _ in range(num_predators // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Tiger(x, y))
        for _ in range(num_predators - num_predators // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(BlackBear(x, y))
        num_prey = total_cells * settings["animal_abundance_prey"] // 10000
        for _ in range(num_prey // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Rabbit(x, y))
        for _ in range(num_prey - num_prey // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Boar(x, y))

    def populate_plants(self):
        # Place edible and toxic plants based on plant abundance settings
        total_cells = self.width * self.height
        num_edible = total_cells * settings["plant_abundance_edible"] // 10000
        for _ in range(num_edible // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(Strawberry(x, y))
        for _ in range(num_edible - num_edible // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(Mushroom(x, y))
        num_toxic = total_cells * settings["plant_abundance_toxic"] // 10000
        for _ in range(num_toxic // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(ToxicStrawberry(x, y))
        for _ in range(num_toxic - num_toxic // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(ToxicMushroom(x, y))

    def is_within_bounds(self, x, y):
        return 0 <= x < self.width and 0 <= y < self.height

    def get_predator_count(self):
        """Get the number of predators on the map"""
        return sum(1 for animal in self.animals if hasattr(animal, 'is_predator') and animal.is_predator)

    @property
    def predators(self):
        """Get all predator animals on the map"""
        return [animal for animal in self.animals if hasattr(animal, 'is_predator') and animal.is_predator]


#
# Animal class (partial animal implementation, more animals can be added later as needed)
#
class Animal:
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.alive = True
        self.chase_steps = 0  # Chase steps counter
        self.chase_target = None  # Chase target
        self.vision_range = 5  # Default vision range
    
    @property
    def position(self):
        """Return animal's position coordinates"""
        return (self.x, self.y)

    def move(self, game_map, players=None):
        if not self.alive:
            return
            
        if hasattr(self, 'is_predator') and self.is_predator and players:
            # Find nearest player within vision range
            nearest_player = None
            min_dist = float('inf')
            for player in players:
                if player.is_alive():
                    dist = abs(self.x - player.x) + abs(self.y - player.y)
                    if dist <= self.vision_range and dist < min_dist:
                        nearest_player = player
                        min_dist = dist
            
            # If a new target player is found (different from current chase target), reset chase counter
            if nearest_player and (not self.chase_target or nearest_player.name != self.chase_target.name):
                self.chase_target = nearest_player
                self.chase_steps = 0
                logger.log(f"{self.type} spots new target: {nearest_player.name}")
            
            # If there's a chase target and steps limit not exceeded, perform chase
            if self.chase_target and self.chase_steps < 10:
                if self.chase_target.is_alive():
                    # Calculate movement direction
                    dx = 1 if self.chase_target.x > self.x else -1 if self.chase_target.x < self.x else 0
                    dy = 1 if self.chase_target.y > self.y else -1 if self.chase_target.y < self.y else 0
                    
                    # Check if movement is valid
                    new_x = self.x + dx
                    new_y = self.y + dy
                    if game_map.is_within_bounds(new_x, new_y):
                        self.x = new_x
                        self.y = new_y
                        self.chase_steps += 1
                        
                        # If adjacent to player, attack
                        if abs(self.x - self.chase_target.x) <= 1 and abs(self.y - self.chase_target.y) <= 1:
                            self.attack_player(self.chase_target)
                    
                    # If chase steps reach limit, log it
                    if self.chase_steps >= 10:
                        logger.log(f"{self.type} gives up chasing {self.chase_target.name}")
                    return
                else:
                    # If target is dead, reset chase state
                    self.chase_target = None
                    self.chase_steps = 0
            
            # If there's a new chaseable target but current chase has ended, reset chase state
            elif nearest_player:
                self.chase_target = nearest_player
                self.chase_steps = 0
                logger.log(f"{self.type} starts chasing {nearest_player.name}")
                return
        
        # é»˜è®¤éšæœºç§»åŠ¨è¡Œä¸º
        directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
        dx, dy = random.choice(directions)
        new_x = self.x + dx
        new_y = self.y + dy
        if game_map.is_within_bounds(new_x, new_y):
            self.x = new_x
            self.y = new_y

    def attack_player(self, player):
        # ğŸ”§ ä¿®å¤ï¼šè¢«åŠ¨æ”»å‡»æ—¶è®°å½•é­é‡
        if hasattr(player, 'encountered_animals_count'):
            encounter_key = f"{self.type}_{self.x}_{self.y}_{player.x}_{player.y}"
            if not hasattr(player, '_recorded_encounters'):
                player._recorded_encounters = set()
            
            if encounter_key not in player._recorded_encounters:
                player.encountered_animals_count += 1
                player._recorded_encounters.add(encounter_key)
                logger.log(f"{player.name} encountered {self.type} (passive attack)")
        
        if hasattr(self, 'attack'):
            damage = self.attack
            player.hp = max(0, player.hp - damage)
            logger.log(f"{self.type} attacks {player.name} for {damage} damage")
            if player.hp <= 0:
                player.alive = False
                logger.log(f"{player.name} was killed by {self.type}")


class Tiger(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Tiger"
        self.hp = 500
        self.attack = 50
        self.food = 500
        self.is_predator = True  # æ ‡è®°ä¸ºæ•é£Ÿè€…
        self.vision_range = 8  # è€è™è§†é‡èŒƒå›´æ›´å¤§
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "short",
            "sound": "roar",
        }


class BlackBear(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "BlackBear"
        self.hp = 300
        self.attack = 30
        self.food = 300
        self.is_predator = True  # æ ‡è®°ä¸ºæ•é£Ÿè€…
        self.vision_range = 6  # é»‘ç†Šè§†é‡èŒƒå›´
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "long",
            "sound": "roar",
        }


class Rabbit(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Rabbit"
        self.hp = 10
        self.attack = 0
        self.food = 10
        self.visible_info = {
            "body_type": "large",
            "teeth": "flat",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "short",
            "sound": "roar",
        }


class Boar(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Boar"
        self.hp = 50
        self.attack = 0
        self.food = 50
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "blunt",
            "speed": 2,
            "color": "yellow",
            "fur": "long",
            "sound": "roar",
        }


#
# æ¤ç‰©ç±»
#
class Plant:
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.collected = False
        self.alive = True  # æ·»åŠ aliveå±æ€§
    
    @property
    def position(self):
        """è¿”å›æ¤ç‰©çš„ä½ç½®åæ ‡"""
        return (self.x, self.y)
        
    def update(self):
        pass  # æ¤ç‰©æš‚æ—¶ä¸éœ€è¦æ›´æ–°é€»è¾‘


class Strawberry(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.food = 5
        self.toxic = False


class Mushroom(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.food = 3
        self.toxic = False


class ToxicStrawberry(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.food = 5
        self.toxic = True


class ToxicMushroom(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.food = 3
        self.toxic = True


#
# æ—¥å¿—è®°å½•å·¥å…·(æ¸¸æˆé€€å‡ºåè‡ªåŠ¨ç”Ÿæˆæ—¥å¿—æ–‡ä»¶)
#
class Logger:
    def __init__(self):
        self.logs = []
        self.seed_logged = False
        self.predator_count_logged = False

    def log(self, message):
        self.logs.append(message)

    def log_seed(self, seed):
        if not self.seed_logged:
            self.logs.insert(0, f"Map seed: {seed}")
            self.seed_logged = True

    def log_predator_count(self, count):
        if not self.predator_count_logged:
            # åœ¨ç§å­ä¹‹åæ’å…¥çŒ›å…½æ•°é‡
            insert_pos = 1 if self.seed_logged else 0
            self.logs.insert(insert_pos, f"Initial predator count: {count}")
            self.predator_count_logged = True

    def write_log_file(self):
        if self.logs:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"game_{timestamp}.log"
            with open(filename, "w", encoding="utf-8") as f:
                for log in self.logs:
                    f.write(f"{log}\n")
            self.logs = []


logger = Logger()


#
# åœ°å›¾ç”Ÿæˆç±»:ç”Ÿæˆ"ç½‘æ ¼"åœ°å›¾,å¹¶åœ¨åœ°å›¾ä¸Šéšæœºæ”¾ç½®åŠ¨ç‰©å’Œæ¤"
#
class GameMap:
    def __init__(self, width, height, map_type, seed):
        self.width = width
        self.height = height
        self.map_type = map_type
        random.seed(seed)
        # ç”Ÿæˆåœ°å›¾ç½‘æ ¼,æ¯ä¸ªæ ¼å­ä¿å­˜åœ°å½¢å­—ç¬¦ä¸²
        self.grid = [
            [self.generate_cell() for _ in range(width)] for _ in range(height)
        ]
        self.animals = []  # åŠ¨ç‰©åˆ—è¡¨
        self.plants = []   # æ¤ç‰©åˆ—è¡¨
        self.populate_animals()
        self.populate_plants()

    def generate_cell(self):
        r = random.random()
        if r < 0.5:
            return "plain"
        elif r < 0.55:
            return "big_tree"
        elif r < 0.75:
            return "bush"
        elif r < 0.9:
            return "rock"
        elif r < 0.95:
            return "cave"
        elif r < 0.98:
            return "river"
        else:
            return "puddle"

    def populate_animals(self):
        # æ ¹æ®è®¾ç½®ä¸­åŠ¨ç‰©ä¸°åº¦æŒ‰ä»»æ„æ¯”ä¾‹åˆ†å¸ƒ(æ•°é‡ç»è¿‡ç®€å•ç¼©æ”¾)
        total_cells = self.width * self.height
        num_predators = total_cells * settings["animal_abundance_predator"] // 10000
        for _ in range(num_predators // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Tiger(x, y))
        for _ in range(num_predators - num_predators // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(BlackBear(x, y))
        num_prey = total_cells * settings["animal_abundance_prey"] // 10000
        for _ in range(num_prey // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Rabbit(x, y))
        for _ in range(num_prey - num_prey // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.animals.append(Boar(x, y))

    def populate_plants(self):
        # æ ¹æ®è®¾ç½®ä¸­æ¤ç‰©ä¸°åº¦æ”¾ç½®æ— æ¯’å’Œæœ‰æ¯’æ¤ç‰©
        total_cells = self.width * self.height
        num_edible = total_cells * settings["plant_abundance_edible"] // 10000
        for _ in range(num_edible // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(Strawberry(x, y))
        for _ in range(num_edible - num_edible // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(Mushroom(x, y))
        num_toxic = total_cells * settings["plant_abundance_toxic"] // 10000
        for _ in range(num_toxic // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(ToxicStrawberry(x, y))
        for _ in range(num_toxic - num_toxic // 2):
            x = random.randint(0, self.width - 1)
            y = random.randint(0, self.height - 1)
            self.plants.append(ToxicMushroom(x, y))

    def is_within_bounds(self, x, y):
        return 0 <= x < self.width and 0 <= y < self.height

    def get_predator_count(self):
        """è·å–åœ°å›¾ä¸Šçš„çŒ›å…½æ•°é‡"""
        return sum(1 for animal in self.animals if hasattr(animal, 'is_predator') and animal.is_predator)

    @property
    def predators(self):
        """è·å–åœ°å›¾ä¸Šçš„æ‰€æœ‰æ•é£Ÿè€…åŠ¨ç‰©"""
        return [animal for animal in self.animals if hasattr(animal, 'is_predator') and animal.is_predator]


#
# åŠ¨ç‰©ç±»(éƒ¨åˆ†åŠ¨ç‰©å®ç°,åæœŸåŠ¨ç‰©å¯æŒ‰éœ€åŠ å…¥"""
#
class Animal:
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.alive = True
        self.chase_steps = 0  # è¿½å‡»æ­¥æ•°è®¡æ•°
        self.chase_target = None  # è¿½å‡»ç›®æ ‡
        self.vision_range = 5  # é»˜è®¤è§†é‡èŒƒå›´
    
    @property
    def position(self):
        """è¿”å›åŠ¨ç‰©çš„ä½ç½®åæ ‡"""
        return (self.x, self.y)

    def move(self, game_map, players=None):
        if not self.alive:
            return
            
        if hasattr(self, 'is_predator') and self.is_predator and players:
            # å¯»æ‰¾è§†é‡èŒƒå›´å†…æœ€è¿‘çš„ç©å®¶
            nearest_player = None
            min_dist = float('inf')
            for player in players:
                if player.is_alive():
                    dist = abs(self.x - player.x) + abs(self.y - player.y)
                    if dist <= self.vision_range and dist < min_dist:
                        nearest_player = player
                        min_dist = dist
            
            # å¦‚æœå‘ç°æ–°çš„ç›®æ ‡ç©å®¶(ä¸å½“å‰è¿½å‡»ç›®æ ‡ä¸åŒ),é‡ç½®è¿½å‡»è®¡æ•°
            if nearest_player and (not self.chase_target or nearest_player.name != self.chase_target.name):
                self.chase_target = nearest_player
                self.chase_steps = 0
                logger.log(f"{self.type} spots new target: {nearest_player.name}")
            
            # å¦‚æœæœ‰è¿½å‡»ç›®æ ‡ä¸”æœªè¶…è¿‡æ­¥æ•°é™åˆ¶,è¿›è¡Œè¿½å‡»
            if self.chase_target and self.chase_steps < 10:
                if self.chase_target.is_alive():
                    # è®¡ç®—ç§»åŠ¨æ–¹å‘
                    dx = 1 if self.chase_target.x > self.x else -1 if self.chase_target.x < self.x else 0
                    dy = 1 if self.chase_target.y > self.y else -1 if self.chase_target.y < self.y else 0
                    
                    # æ£€æŸ¥ç§»åŠ¨æ˜¯å¦æœ‰æ•ˆ
                    new_x = self.x + dx
                    new_y = self.y + dy
                    if game_map.is_within_bounds(new_x, new_y):
                        self.x = new_x
                        self.y = new_y
                        self.chase_steps += 1
                        
                        # å¦‚æœä¸ç©å®¶ç›¸é‚»,è¿›è¡Œæ”»å‡»
                        if abs(self.x - self.chase_target.x) <= 1 and abs(self.y - self.chase_target.y) <= 1:
                            self.attack_player(self.chase_target)
                    
                    # å¦‚æœè¿½å‡»æ­¥æ•°è¾¾åˆ°ä¸Šé™,è®°å½•æ—¥å¿—
                    if self.chase_steps >= 10:
                        logger.log(f"{self.type} gives up chasing {self.chase_target.name}")
                    return
                else:
                    # å¦‚æœç›®æ ‡å·²æ­»äº¡,é‡ç½®è¿½å‡»çŠ¶æ€
                    self.chase_target = None
                    self.chase_steps = 0
            
            # å¦‚æœæœ‰æ–°çš„å¯è¿½å‡»ç›®æ ‡ä½†å½“å‰è¿½å‡»å·²ç»“æŸ,é‡ç½®è¿½å‡»çŠ¶æ€
            elif nearest_player:
                self.chase_target = nearest_player
                self.chase_steps = 0
                logger.log(f"{self.type} starts chasing {nearest_player.name}")
                return
        
        # é»˜è®¤éšæœºç§»åŠ¨è¡Œä¸º
        directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
        dx, dy = random.choice(directions)
        new_x = self.x + dx
        new_y = self.y + dy
        if game_map.is_within_bounds(new_x, new_y):
            self.x = new_x
            self.y = new_y

    def attack_player(self, player):
        # ğŸ”§ ä¿®å¤ï¼šè¢«åŠ¨æ”»å‡»æ—¶è®°å½•é­é‡
        if hasattr(player, 'encountered_animals_count'):
            encounter_key = f"{self.type}_{self.x}_{self.y}_{player.x}_{player.y}"
            if not hasattr(player, '_recorded_encounters'):
                player._recorded_encounters = set()
            
            if encounter_key not in player._recorded_encounters:
                player.encountered_animals_count += 1
                player._recorded_encounters.add(encounter_key)
                logger.log(f"{player.name} encountered {self.type} (passive attack)")
        
        if hasattr(self, 'attack'):
            damage = self.attack
            player.hp = max(0, player.hp - damage)
            logger.log(f"{self.type} attacks {player.name} for {damage} damage")
            if player.hp <= 0:
                player.alive = False
                logger.log(f"{player.name} was killed by {self.type}")


class Tiger(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Tiger"
        self.hp = 500
        self.attack = 50
        self.food = 500
        self.is_predator = True  # æ ‡è®°ä¸ºæ•é£Ÿè€…
        self.vision_range = 8  # è€è™è§†é‡èŒƒå›´æ›´å¤§
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "short",
            "sound": "roar",
        }


class BlackBear(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "BlackBear"
        self.hp = 300
        self.attack = 30
        self.food = 300
        self.is_predator = True  # æ ‡è®°ä¸ºæ•é£Ÿè€…
        self.vision_range = 6  # é»‘ç†Šè§†é‡èŒƒå›´
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "long",
            "sound": "roar",
        }


class Rabbit(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Rabbit"
        self.hp = 10
        self.attack = 0
        self.food = 10
        self.visible_info = {
            "body_type": "large",
            "teeth": "flat",
            "claws": "sharp",
            "speed": 2,
            "color": "yellow",
            "fur": "short",
            "sound": "roar",
        }


class Boar(Animal):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.type = "Boar"
        self.hp = 50
        self.attack = 0
        self.food = 50
        self.visible_info = {
            "body_type": "large",
            "teeth": "sharp",
            "claws": "blunt",
            "speed": 2,
            "color": "yellow",
            "fur": "long",
            "sound": "roar",
        }


#
# æ¤ç‰©ç±»
#
class Plant:
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.collected = False
        self.alive = True  # æ·»åŠ aliveå±æ€§
    
    @property
    def position(self):
        """è¿”å›æ¤ç‰©çš„ä½ç½®åæ ‡"""
        return (self.x, self.y)
        
    def update(self):
        pass  # æ¤ç‰©æš‚æ—¶ä¸éœ€è¦æ›´æ–°é€»è¾‘


class Strawberry(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.visible_info = {"color": "red", "shape": "round", "hardness": "soft", "smell": "sweet"}
        self.food = 5
        self.toxic = False


class Mushroom(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.visible_info = {"color": "brown", "shape": "umbrella", "hardness": "soft", "smell": "sweet"}
        self.food = 5
        self.toxic = False


class ToxicStrawberry(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.visible_info = {"color": "red", "shape": "round", "hardness": "soft", "smell": "sweet"}
        self.food = 5
        self.toxic = True


class ToxicMushroom(Plant):
    def __init__(self, x, y):
        super().__init__(x, y)
        self.visible_info = {"color": "red", "shape": "umbrella", "hardness": "soft", "smell": "sweet"}
        self.food = 5
        self.toxic = True


#
# ç©å®¶åŸºç±»,åŒ…å«è¡€é‡ã€é£Ÿç‰©ã€æ°´é‡ã€ç§»åŠ¨ã€äº’åŠ¨ã€é‡‡é›†ä¸æ”»å‡»è¡Œä¸º"
# ç©å®¶æ­»äº¡æ¡ä»¶:è¡€é‡â‰¤0æˆ–é£Ÿç‰©ã€æ°´"
#
class Player:
    def __init__(self, name, player_type, game_map):
        self.name = name
        self.player_type = player_type
        self.hp = 100
        self.food = 100  # åˆå§‹é£Ÿç‰©ä¸ª00
        self.water = 100  # åˆå§‹æ°´åˆ†ä¸ª00
        self.speed = 1
        self.attention = 50
        self.reputation = 100
        # éšæœºæ”¾ç½®è‡³åœ°å›¾å†…
        self.x = random.randint(0, game_map.width - 1)
        self.y = random.randint(0, game_map.height - 1)
        self.alive = True

        # æˆå°±ç»Ÿè®¡æ•°æ®
        self.survival_days = 0
        self.collected_plants = 0
        self.killed_animals = 0
        self.damage_dealt = 0
        
        # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ çœŸå®ç»Ÿè®¡è®°å½•å˜é‡
        self.explored_cells = set()  # å·²æ¢ç´¢çš„æ ¼å­åæ ‡é›†åˆ
        self.explored_cells.add((self.x, self.y))  # åˆå§‹ä½ç½®
        self.found_plants_count = 0  # å‘ç°æ¤ç‰©æ•°é‡
        self.encountered_animals_count = 0  # é­é‡åŠ¨ç‰©æ•°é‡  
        self.found_big_tree_count = 0  # å‘ç°å¤§æ ‘æ¬¡æ•°
        self.explored_cave_count = 0  # æ¢ç´¢æ´ç©´æ¬¡æ•°
        self.shared_info_count = 0  # åˆ†äº«ä¿¡æ¯æ¬¡æ•°
        self.novelty_discoveries_count = 0  # æ–°é¢–å‘ç°æ€»æ•°ï¼ˆæ–°ç»éªŒ+æ–°è§„å¾‹ï¼‰
        self.new_experiences_count = 0  # æ–°ç»éªŒæ•°é‡
        self.new_rules_count = 0  # æ–°è§„å¾‹æ•°é‡
        self.kills = 0  # å‡»æ€æ•°é‡
        self.plants_collected = 0  # é‡‡é›†æ¤ç‰©æ•°é‡
        self.toxic_plants_collected = 0  # é‡‡é›†æœ‰æ¯’æ¤ç‰©æ•°é‡
        
        # ä¿å­˜game_mapå¼•ç”¨ç”¨äºè®¡ç®—æ¢ç´¢ç‡
        self._game_map = game_map

    @property
    def health(self):
        """healthå±æ€§åŠ¨æ€æŒ‡å‘hp,è§£å†³å±æ€§è®¿é—®é—®é¢˜"""
        return self.hp
    
    @health.setter
    def health(self, value):
        """è®¾ç½®healthæ—¶åŒæ­¥æ›´æ–°hp"""
        self.hp = value

    def is_alive(self):
        return self.alive

    def move(self, dx, dy, game_map):
        old_x, old_y = self.x, self.y
        new_x = self.x + dx
        new_y = self.y + dy
        if game_map and game_map.is_within_bounds(new_x, new_y):
            self.x, self.y = new_x, new_y
            logger.log(f"{self.name} è¡ŒåŠ¨è¯¦æƒ…: ç§»åŠ¨ | ä½ç½®:{old_x},{old_y}->{self.x},{self.y} | çŠ¶æ€HP{self.health}/F{self.food}/W{self.water}")
            
            # ğŸ”§ ä¿®å¤ï¼šè®°å½•æ¢ç´¢çš„æ–°æ ¼å­
            if hasattr(self, 'explored_cells'):
                self.explored_cells.add((self.x, self.y))
            
            # ä¸ºILAIå’ŒRILAIç©å®¶æ›´æ–°ä½ç½®è·Ÿè¸ª
            if (hasattr(self, 'player_type') and 
                self.player_type in ["ILAI", "RILAI"] and 
                hasattr(self, 'current_pos')):
                self.last_pos = (old_x, old_y)
                self.current_pos = (self.x, self.y)
                if hasattr(self, 'visited_positions'):
                    self.visited_positions.add(self.current_pos)
            
            return True
        return False

    def take_turn(self, game):
        """æ¯å›åˆåŸºç¡€è¡Œä¸º"""
        if not self.alive:
            return
            
        # æ¯å›åˆæ¶ˆè€—
        self.food = max(0, self.food - 1)
        self.water = max(0, self.water - 1)
        
        # æ£€æŸ¥å½“å‰æ ¼å­æ˜¯å¦æœ‰æ°´æº,è‡ªåŠ¨å–æ°´
        current_cell = game.game_map.grid[self.y][self.x]
        
        # ğŸ”§ ä¿®å¤ï¼šè®°å½•ç‰¹æ®Šåœ°å½¢æ¢ç´¢
        self._record_exploration(current_cell)
        if current_cell in ["river", "puddle"]:
            old_water = self.water
            self.water = min(100, self.water + 30)
            if self.water > old_water:
                logger.log(f"{self.name} drinks water at {current_cell}")
        
        # è‡ªåŠ¨é‡‡é›†åŠŸèƒ½å·²ç§»é™¤ - ç°åœ¨éœ€è¦ä¸»åŠ¨å†³ç­–é‡‡é›†
        
        # å¦‚æœé£Ÿç‰©æˆ–æ°´åˆ†ä¸º0,å‡å°‘ç”Ÿå‘½å€¼
        if self.food == 0 or self.water == 0:
            self.hp = max(0, self.hp - 10)
            
        # æ£€æŸ¥æ˜¯å¦æ­»äº¡
        if self.hp <= 0:
            self.alive = False
            logger.log(f"{self.name} æ­»äº¡")

    def collect_plant(self, plant):
        """é‡‡é›†æ¤ç‰©ï¼Œè·å¾—é£Ÿç‰©ï¼ˆè€ƒè™‘å·¥å…·æ•ˆæœï¼‰"""
        # ğŸ”§ ä¿®å¤ï¼šé¦–å…ˆè®°å½•å‘ç°æ¤ç‰©
        self._record_plant_discovery(plant)
        
        if not plant.collected and not plant.toxic:
            # ç¡®å®šæ¤ç‰©ç±»å‹
            if hasattr(plant, 'location_type'):
                if plant.location_type == "ground":
                    plant_type = "ground_plant"
                elif plant.location_type == "underground":
                    plant_type = "underground_plant"
                elif plant.location_type == "tree":
                    plant_type = "tree_plant"
                else:
                    plant_type = "ground_plant"  # é»˜è®¤
            else:
                plant_type = "ground_plant"  # æ—§æ¤ç‰©é»˜è®¤ä¸ºåœ°é¢æ¤ç‰©
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆé€‚çš„å·¥å…·
            tool = None
            if hasattr(self, 'get_best_tool_for_target'):
                tool = self.get_best_tool_for_target(plant_type)
            
            # æ ¹æ®å·¥å…·æƒ…å†µè®¡ç®—æˆåŠŸç‡å’Œæ”¶ç›Š
            if tool:
                success_rate = 0.95  # æœ‰æ­£ç¡®å·¥å…·ï¼Œ95%æˆåŠŸç‡
                food_multiplier = 1.5  # æœ‰å·¥å…·è·å¾—æ›´å¤šé£Ÿç‰©
                logger.log(f"{self.name} uses {tool.name} to collect plant")
            else:
                # ç‰¹æ®Šæ¤ç‰©æ²¡æœ‰å·¥å…·éš¾ä»¥é‡‡é›†
                if hasattr(plant, 'location_type') and plant.location_type in ["underground", "tree"]:
                    success_rate = 0.1  # æ²¡æœ‰å·¥å…·å¾’æ‰‹å¾ˆéš¾æˆåŠŸ
                    food_multiplier = 0.5  # å³ä½¿æˆåŠŸä¹Ÿè·å¾—å¾ˆå°‘é£Ÿç‰©
                elif hasattr(plant, 'has_thorns') and plant.has_thorns:
                    success_rate = 0.2  # æœ‰åˆºæ¤ç‰©å¾’æ‰‹å›°éš¾
                    food_multiplier = 0.7
                else:
                    success_rate = 0.8  # åœ°é¢æ¤ç‰©å¾’æ‰‹è¾ƒå®¹æ˜“
                    food_multiplier = 1.0
                logger.log(f"{self.name} attempts to collect plant bare-handed")
            
            # å°è¯•é‡‡é›†
            collection_success = random.random() < success_rate
            if collection_success:
                plant.collected = True
                food_gain = int(plant.food * food_multiplier)
                self.food = min(100, self.food + food_gain)
                self.collected_plants += 1
                logger.log(f"{self.name} successfully collected plant and gained {food_gain} food")
            else:
                food_gain = 0
                logger.log(f"{self.name} failed to collect plant")
            
            # ğŸ§  è®°å½•å·¥å…·ä½¿ç”¨ç»“æœç”¨äºå­¦ä¹ ï¼ˆILAIå’ŒRILAIï¼‰
            if hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"] and tool:
                # ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡º - è®°å½•å·¥å…·ä½¿ç”¨è°ƒç”¨
                try:
                    with open("tool_usage_debug.txt", "a", encoding="utf-8") as f:
                        f.write(f"ğŸ”§ {self.name} è°ƒç”¨_record_tool_usageï¼šå·¥å…·={tool.name}ï¼Œç›®æ ‡={plant_type}ï¼ŒæˆåŠŸ={collection_success}ï¼Œæ”¶ç›Š={food_gain}\n")
                except:
                    pass
                
                # ğŸ”§ è®¾ç½®å®æ—¶å·¥å…·ä½¿ç”¨æ ‡è®°ï¼Œè®©SSMèƒ½å¤Ÿæ£€æµ‹åˆ°
                if hasattr(self, '_last_tool_used'):
                    self._last_tool_used = (
                        tool.type,
                        plant_type,
                        'gather',
                        collection_success,
                        food_gain
                    )
                
                # è®°å½•å·¥å…·ä½¿ç”¨ç»éªŒ
                if hasattr(self, '_record_tool_usage'):
                    self._record_tool_usage(tool, plant_type, collection_success, food_gain)
                
                # ğŸŒŸ ä¸ºILAIç³»ç»Ÿæ·»åŠ ä¸“é—¨çš„æ¤ç‰©é‡‡é›†ç»éªŒ - ä¿®å¤ä¸ºå†³ç­–ç³»ç»Ÿå¯ç†è§£çš„æ ¼å¼
                if hasattr(self, 'add_eocar_experience'):
                    self.add_eocar_experience('collect_plant', {'success': collection_success, 'food_gain': food_gain}, source="direct")
                    logger.log(f"{self.name} ğŸ“š è®°å½•æ¤ç‰©é‡‡é›†ç»éªŒ: {plant_type} {'æˆåŠŸ' if collection_success else 'å¤±è´¥'}")
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šæ·»åŠ å¯æ‰§è¡Œçš„å†³ç­–è§„å¾‹
                if hasattr(self, '_add_actionable_rule_from_experience'):
                    # è·å–å·¥å…·ç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„å±æ€§å
                    tool_type_attr = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.name
                    
                    rule_conditions = {
                        'plant_type': plant_type,
                        'tool_available': tool_type_attr,
                        'food_level': 'low' if self.food < 50 else 'normal'
                    }
                    rule_predictions = {
                        'action': 'collect_plant',
                        'success_probability': success_rate,
                        'food_gain_expected': food_gain if collection_success else int(food_gain * success_rate),
                        'tool_recommendation': tool_type_attr
                    }
                    self._add_actionable_rule_from_experience(
                        'plant_collection_rule',
                        rule_conditions,
                        rule_predictions,
                        confidence=success_rate
                    )
                
                # ğŸŒŸ ä¸ºILAIç³»ç»Ÿæ·»åŠ äº”åº“ç»éªŒ
                if hasattr(self, 'add_experience_to_direct_library'):
                    # è·å–å·¥å…·ç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„å±æ€§å
                    tool_type_attr = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.name
                    
                    context = {
                        'plant_type': plant_type,
                        'tool_used': tool_type_attr,
                        'location': (self.x, self.y),
                        'success_rate': success_rate,
                        'food_multiplier': food_multiplier
                    }
                    self.add_experience_to_direct_library('collect_plant', 
                                                        {'success': collection_success, 'food_gain': food_gain}, 
                                                        context)
                    logger.log(f"{self.name} ğŸ“– è®°å½•äº”åº“é‡‡é›†ç»éªŒ: {plant_type}")
            
            # ğŸŒŸ å³ä½¿æ²¡æœ‰å·¥å…·ï¼ŒILAIä¹Ÿè¦è®°å½•é‡‡é›†ç»éªŒ
            elif hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"]:
                # è®°å½•æ— å·¥å…·é‡‡é›†ç»éªŒ
                if hasattr(self, 'add_eocar_experience'):
                    self.add_eocar_experience('collect_plant_barehanded', {'success': collection_success, 'food_gain': food_gain}, source="direct")
                    logger.log(f"{self.name} ğŸ“š è®°å½•å¾’æ‰‹é‡‡é›†ç»éªŒ: {plant_type} {'æˆåŠŸ' if collection_success else 'å¤±è´¥'}")
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šä¸ºå¾’æ‰‹é‡‡é›†ä¹Ÿæ·»åŠ å¯æ‰§è¡Œè§„å¾‹
                if hasattr(self, '_add_actionable_rule_from_experience'):
                    rule_conditions = {
                        'plant_type': plant_type,
                        'tool_available': None,
                        'food_level': 'low' if self.food < 50 else 'normal'
                    }
                    rule_predictions = {
                        'action': 'collect_plant_barehanded',
                        'success_probability': success_rate,
                        'food_gain_expected': food_gain if collection_success else int(food_gain * success_rate),
                        'tool_recommendation': 'none',
                        'difficulty': 'high' if plant_type in ["underground", "tree"] else 'medium'
                    }
                    self._add_actionable_rule_from_experience(
                        'plant_collection_barehanded_rule',
                        rule_conditions,
                        rule_predictions,
                        confidence=success_rate
                    )
                
                # è®°å½•äº”åº“ç»éªŒ
                if hasattr(self, 'add_experience_to_direct_library'):
                    context = {
                        'plant_type': plant_type,
                        'tool_used': None,
                        'location': (self.x, self.y),
                        'success_rate': success_rate,
                        'collection_method': 'barehanded'
                    }
                    self.add_experience_to_direct_library('collect_plant_barehanded', 
                                                        {'success': collection_success, 'food_gain': food_gain}, 
                                                        context)
                    logger.log(f"{self.name} ğŸ“– è®°å½•äº”åº“å¾’æ‰‹é‡‡é›†ç»éªŒ: {plant_type}")
            
            return collection_success
        else:
            return False

    def encounter_animal(self, animal, game):
        """é‡åˆ°åŠ¨ç‰©æ—¶çš„è®°å½•åŠŸèƒ½ï¼ˆä¸å†è‡ªåŠ¨æ”»å‡»æˆ–é€ƒè·‘ï¼‰"""
        # ğŸ”§ ä¿®å¤ï¼šè®°å½•é­é‡åŠ¨ç‰©
        self._record_animal_encounter(animal)
        
        self.encountered_animals += 1
        logger.log(f"{self.name} encounters {animal.type} at ({self.x},{self.y}) - decision needed")

    def flee(self, animal, game):
        dx = self.x - animal.x
        dy = self.y - animal.y
        if dx != 0:
            dx = int(dx / abs(dx))
        if dy != 0:
            dy = int(dy / abs(dy))
        self.move(dx, dy, game.game_map)
        logger.log(f"{self.name} fled from {animal.type}")

    def action_collect_plant(self, game):
        """ä¸»åŠ¨é‡‡é›†æ¤ç‰©è¡Œä¸º - æ‰€æœ‰ç©å®¶ç±»å‹éƒ½å¯ä½¿ç”¨"""
        plants_collected = 0
        for plant in game.game_map.plants:
            if plant.x == self.x and plant.y == self.y and plant.alive and not plant.collected:
                # ğŸ”§ ä¿®å¤ï¼šä¸ºILAIç©å®¶æ·»åŠ å·¥å…·é€‰æ‹©æœºåˆ¶
                if hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"]:
                    # ç¡®å®šæ¤ç‰©ç±»å‹
                    plant_type = self._determine_plant_type(plant)
                    # é€‰æ‹©å·¥å…·
                    selected_tool, context = self._select_and_use_tool_for_action('collect_plant', plant_type)
                    
                    old_food = self.food
                    success = self.collect_plant(plant)
                    benefit = self.food - old_food
                    
                    # è®°å½•å·¥å…·ä½¿ç”¨ç»“æœ
                    if selected_tool:
                        self._record_tool_usage_result(selected_tool, plant_type, 'collect_plant', success, benefit)
                    
                    if success:
                        logger.log(f"{self.name} actively collects plant with {self._last_used_tool} at ({self.x},{self.y})")
                        plants_collected += 1
                else:
                    # å…¶ä»–ç©å®¶ç±»å‹çš„åŸå§‹é€»è¾‘
                    old_food = self.food
                    self.collect_plant(plant)
                    if self.food > old_food:
                        logger.log(f"{self.name} actively collects plant at ({self.x},{self.y})")
                        plants_collected += 1
                break
        return plants_collected > 0

    def action_attack_animal(self, game):
        """ä¸»åŠ¨æ”»å‡»åŠ¨ç‰©è¡Œä¸º - æ‰€æœ‰ç©å®¶ç±»å‹éƒ½å¯ä½¿ç”¨"""
        # å¯»æ‰¾å½“å‰ä½ç½®æˆ–ç›¸é‚»ä½ç½®çš„åŠ¨ç‰©
        target_animal = None
        min_distance = float('inf')
        
        for animal in game.game_map.animals:
            if animal.alive:
                distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                if distance <= 1 and distance < min_distance:  # å½“å‰ä½ç½®æˆ–ç›¸é‚»1æ ¼
                    target_animal = animal
                    min_distance = distance
        
        if target_animal:
            # ğŸ”§ ä¿®å¤ï¼šä¸ºILAIç©å®¶æ·»åŠ å·¥å…·é€‰æ‹©æœºåˆ¶
            if hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"]:
                # ç¡®å®šåŠ¨ç‰©ç±»å‹
                animal_type = self._determine_animal_type(target_animal)
                # é€‰æ‹©å·¥å…·
                selected_tool, context = self._select_and_use_tool_for_action('attack_animal', animal_type)
                
                old_food = self.food
                damage = self.attack(target_animal)
                benefit = self.food - old_food
                success = damage > 0 or benefit > 0
                
                # è®°å½•å·¥å…·ä½¿ç”¨ç»“æœ
                if selected_tool:
                    self._record_tool_usage_result(selected_tool, animal_type, 'attack_animal', success, benefit)
                
                logger.log(f"{self.name} actively attacks {target_animal.type} with {self._last_used_tool}")
            else:
                # å…¶ä»–ç©å®¶ç±»å‹çš„åŸå§‹é€»è¾‘
                logger.log(f"{self.name} actively attacks {target_animal.type}")
                self.attack(target_animal)
            return True
        else:
            logger.log(f"{self.name} attempts to attack but no animal nearby")
            return False

    def attack(self, animal):
        if animal.alive:
            # ç¡®å®šåŠ¨ç‰©ç±»å‹
            animal_class = animal.__class__.__name__
            if animal_class in ["Tiger", "BlackBear"]:
                animal_type = "predator"
            elif animal_class in ["Rabbit", "Boar"]:
                animal_type = "prey"
            elif animal_class in ["Pheasant", "Dove"]:
                animal_type = "bird"
            else:
                animal_type = "prey"  # é»˜è®¤
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆé€‚çš„å·¥å…·
            tool = None
            if hasattr(self, 'get_best_tool_for_target'):
                tool = self.get_best_tool_for_target(animal_type)
            
            # æ ¹æ®å·¥å…·æƒ…å†µè®¡ç®—ä¼¤å®³å’ŒæˆåŠŸç‡
            if tool:
                # ğŸ”§ çœŸå®çš„å·¥å…·æ•ˆæœç³»ç»Ÿï¼šä¸åŒå·¥å…·å¯¹ä¸åŒç›®æ ‡æœ‰ä¸åŒæ•ˆæœ
                if hasattr(self, '_calculate_tool_effectiveness'):
                    base_damage, success_rate = self._calculate_tool_effectiveness(tool, animal_type)
                else:
                    base_damage = 15  # æœ‰å·¥å…·çš„åŸºç¡€ä¼¤å®³
                    success_rate = 0.8  # 80%å‘½ä¸­ç‡
                logger.log(f"{self.name} uses {tool.name} to attack {animal_class}")
            else:
                base_damage = 5   # å¾’æ‰‹ä¼¤å®³å¾ˆä½
                success_rate = 0.3  # 30%å‘½ä¸­ç‡ï¼Œç‰¹åˆ«æ˜¯å¯¹é¸Ÿç±»å¾ˆéš¾å‘½ä¸­
                if animal_type == "bird":
                    success_rate = 0.05  # å¾’æ‰‹æ‰“é¸Ÿå‡ ä¹ä¸å¯èƒ½
                elif animal_type == "predator":
                    success_rate = 0.1   # å¾’æ‰‹æ‰“çŒ›å…½æåº¦å±é™©
                logger.log(f"{self.name} attempts to attack {animal_class} bare-handed")
            
            # å°è¯•æ”»å‡»
            attack_success = random.random() < success_rate
            if attack_success:
                actual_damage = base_damage
                animal.hp -= actual_damage
                self.damage_dealt += actual_damage
                logger.log(f"{self.name} successfully attacked {animal_class} for {actual_damage} damage")
                
                if animal.hp <= 0:
                    animal.alive = False
                    self.killed_animals += 1
                    self.food = min(100, self.food + animal.food)
                    logger.log(f"{self.name} killed {animal_class} and gained {animal.food} food")
            else:
                actual_damage = 0
                logger.log(f"{self.name} missed the attack on {animal_class}")
                # æ”»å‡»å¤±è´¥æ—¶ï¼ŒçŒ›å…½å¯èƒ½åå‡»
                if animal_type == "predator" and random.random() < 0.5:
                    self.hp -= 15
                    logger.log(f"{animal_class} counter-attacks {self.name} for 15 damage")
            
            # ğŸ§  è®°å½•å·¥å…·ä½¿ç”¨ç»“æœç”¨äºå­¦ä¹ ï¼ˆILAIå’ŒRILAIï¼‰
            if hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"] and tool:
                # ğŸ”§ å¼ºåˆ¶è°ƒè¯•è¾“å‡º - è®°å½•å·¥å…·ä½¿ç”¨è°ƒç”¨
                try:
                    with open("tool_usage_debug.txt", "a", encoding="utf-8") as f:
                        f.write(f"ğŸ”§ {self.name} è°ƒç”¨_record_tool_usageï¼šå·¥å…·={tool.name}ï¼Œç›®æ ‡={animal_type}ï¼ŒæˆåŠŸ={attack_success}ï¼Œä¼¤å®³={actual_damage}\n")
                except:
                    pass
                
                # ğŸ”§ è®¾ç½®å®æ—¶å·¥å…·ä½¿ç”¨æ ‡è®°ï¼Œè®©SSMèƒ½å¤Ÿæ£€æµ‹åˆ°
                if hasattr(self, '_last_tool_used'):
                    self._last_tool_used = (
                        tool.type,
                        animal_type,
                        'attack',
                        attack_success,
                        actual_damage
                    )
                
                # è®°å½•å·¥å…·ä½¿ç”¨ç»éªŒ
                if hasattr(self, '_record_tool_usage'):
                    self._record_tool_usage(tool, animal_type, attack_success, actual_damage)
                
                # ğŸŒŸ ä¸ºILAIç³»ç»Ÿæ·»åŠ ä¸“é—¨çš„åŠ¨ç‰©æ”»å‡»ç»éªŒ - ä¿®å¤ä¸ºå†³ç­–ç³»ç»Ÿå¯ç†è§£çš„æ ¼å¼
                if hasattr(self, 'add_eocar_experience'):
                    self.add_eocar_experience('attack_animal', {'success': attack_success, 'damage': actual_damage}, source="direct")
                    logger.log(f"{self.name} ğŸ“š Record animal attack experience: {animal_class} {'Success' if attack_success else 'Failed'}")
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šæ·»åŠ å¯æ‰§è¡Œçš„æˆ˜æ–—å†³ç­–è§„å¾‹
                if hasattr(self, '_add_actionable_rule_from_experience'):
                    # è·å–å·¥å…·ç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„å±æ€§å
                    tool_type_attr = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.name
                    
                    rule_conditions = {
                        'animal_type': animal_type,
                        'tool_available': tool_type_attr,
                        'health_level': 'low' if self.health < 50 else 'normal',
                        'target_species': animal_class
                    }
                    rule_predictions = {
                        'action': 'attack_animal',
                        'success_probability': success_rate,
                        'damage_expected': actual_damage if attack_success else int(base_damage * success_rate),
                        'tool_recommendation': tool_type_attr,
                        'risk_level': 'high' if animal_type == 'predator' else 'medium'
                    }
                    self._add_actionable_rule_from_experience(
                        'animal_combat_rule',
                        rule_conditions,
                        rule_predictions,
                        confidence=success_rate
                    )
                
                # ğŸŒŸ ä¸ºILAIç³»ç»Ÿæ·»åŠ äº”åº“ç»éªŒ
                if hasattr(self, 'add_experience_to_direct_library'):
                    # è·å–å·¥å…·ç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„å±æ€§å
                    tool_type_attr = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.name
                    
                    context = {
                        'animal_type': animal_type,
                        'tool_used': tool_type_attr,
                        'location': (self.x, self.y),
                        'success_rate': success_rate,
                        'base_damage': base_damage,
                        'target_name': animal_class
                    }
                    self.add_experience_to_direct_library('attack_animal', 
                                                        {'success': attack_success, 'damage': actual_damage}, 
                                                        context)
                    logger.log(f"{self.name} ğŸ“– è®°å½•äº”åº“æ”»å‡»ç»éªŒ: {animal_class}")
            
            # ğŸŒŸ å³ä½¿æ²¡æœ‰å·¥å…·ï¼ŒILAIä¹Ÿè¦è®°å½•æ”»å‡»ç»éªŒ
            elif hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"]:
                # è®°å½•æ— å·¥å…·æ”»å‡»ç»éªŒ
                if hasattr(self, 'add_eocar_experience'):
                    self.add_eocar_experience('attack_animal_barehanded', {'success': attack_success, 'damage': actual_damage}, source="direct")
                    logger.log(f"{self.name} ğŸ“š Record bare-hand attack experience: {animal_class} {'Success' if attack_success else 'Failed'}")
                
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šä¸ºå¾’æ‰‹æ”»å‡»ä¹Ÿæ·»åŠ å¯æ‰§è¡Œè§„å¾‹
                if hasattr(self, '_add_actionable_rule_from_experience'):
                    rule_conditions = {
                        'animal_type': animal_type,
                        'tool_available': None,
                        'health_level': 'low' if self.health < 50 else 'normal',
                        'target_species': animal_class
                    }
                    rule_predictions = {
                        'action': 'attack_animal_barehanded',
                        'success_probability': success_rate,
                        'damage_expected': actual_damage if attack_success else int(base_damage * success_rate),
                        'tool_recommendation': 'none',
                        'risk_level': 'very_high' if animal_type == 'predator' else 'high'
                    }
                    self._add_actionable_rule_from_experience(
                        'animal_combat_barehanded_rule',
                        rule_conditions,
                        rule_predictions,
                        confidence=success_rate
                    )
                
                # è®°å½•äº”åº“ç»éªŒ
                if hasattr(self, 'add_experience_to_direct_library'):
                    context = {
                        'animal_type': animal_type,
                        'tool_used': None,
                        'location': (self.x, self.y),
                        'success_rate': success_rate,
                        'attack_method': 'barehanded',
                        'target_name': animal_class
                    }
                    self.add_experience_to_direct_library('attack_animal_barehanded', 
                                                        {'success': attack_success, 'damage': actual_damage}, 
                                                        context)
                    logger.log(f"{self.name} ğŸ“– è®°å½•äº”åº“å¾’æ‰‹æ”»å‡»ç»éªŒ: {animal_class}")
            
            return actual_damage
        else:
            return 0
    
    def get_best_tool_for_target(self, target_type):
        """è·å–å¯¹æŒ‡å®šç›®æ ‡æœ€æœ‰æ•ˆçš„å·¥å…·"""
        # å¯¹äºILAIå’ŒRILAIï¼Œä½¿ç”¨å­¦ä¹ åˆ°çš„æ•ˆæœé€‰æ‹©å·¥å…·
        if hasattr(self, 'player_type') and self.player_type in ["ILAI", "RILAI"]:
            selected_tool = self._select_tool_by_learning(target_type)
            return selected_tool
        
        # å…¶ä»–ç©å®¶ä½¿ç”¨é¢„è®¾æ˜ å°„ï¼ˆå¦‚æœå·¥å…·æœ‰target_typeå±æ€§ï¼‰
        for tool in getattr(self, 'tools', []):
            if hasattr(tool, 'target_type') and tool.target_type == target_type:
                return tool
        return None
    
    def _select_tool_by_learning(self, target_type):
        """åŸºäºå­¦ä¹ ç»éªŒé€‰æ‹©å·¥å…· - é¼“åŠ±æ¢ç´¢è€Œéç›´æ¥ç»™å‡ºæœ€ä¼˜è§£"""
        import random  # å¯¼å…¥éšæœºæ¨¡å—ç”¨äºæ¢ç´¢æœºåˆ¶
        
        tools = getattr(self, 'tools', [])
        if not tools:
            return None
        
        # ğŸ§  æ ¸å¿ƒå­¦ä¹ æœºåˆ¶ï¼šåŸºäºå†å²ç»éªŒé€‰æ‹©å·¥å…·
        if hasattr(self, 'tool_effectiveness') and self.tool_effectiveness:
            # è®¡ç®—æ¯ä¸ªå·¥å…·å¯¹å½“å‰ç›®æ ‡çš„å­¦ä¹ åˆ°çš„æ•ˆæœ
            tool_scores = {}
            for tool in tools:
                tool_key = getattr(tool, 'name', tool.__class__.__name__)
                experience_key = (tool_key, target_type)
                
                if experience_key in self.tool_effectiveness:
                    effectiveness = self.tool_effectiveness[experience_key]
                    # åŸºäºæˆåŠŸç‡å’Œå°è¯•æ¬¡æ•°è®¡ç®—åˆ†æ•°
                    success_rate = effectiveness.get('effectiveness', 0.5)
                    attempts = effectiveness.get('attempts', 0)
                    
                    # ğŸ² å¢å¼ºæ¢ç´¢æœºåˆ¶ - æ›´å¼ºçš„æ¢ç´¢å¥–åŠ±
                    exploration_bonus = max(0, (15 - attempts) * 0.08)  # å‰15æ¬¡å°è¯•æœ‰æ›´é«˜æ¢ç´¢å¥–åŠ±
                    # æ·»åŠ éšæœºæ€§ï¼Œé¿å…å®Œå…¨ç¡®å®šæ€§é€‰æ‹©
                    randomness = (random.random() - 0.5) * 0.2  # Â±0.1çš„éšæœºæ³¢åŠ¨
                    tool_scores[tool] = success_rate + exploration_bonus + randomness
                else:
                    # æœªå°è¯•è¿‡çš„å·¥å…·ç»™äºˆæ›´é«˜æ¢ç´¢ä»·å€¼
                    exploration_value = 0.9 + random.random() * 0.2  # 0.9-1.1ä¹‹é—´çš„éšæœºå€¼
                    tool_scores[tool] = exploration_value  # å¼ºçƒˆé¼“åŠ±å°è¯•æ–°å·¥å…·
            
            # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„å·¥å…·
            if tool_scores:
                best_tool = max(tool_scores.keys(), key=lambda t: tool_scores[t])
                return best_tool
        
        # ğŸ² å¦‚æœæ²¡æœ‰ç»éªŒæ•°æ®ï¼Œä½¿ç”¨å¥½å¥‡å¿ƒé©±åŠ¨çš„éšæœºé€‰æ‹©
        if hasattr(self, 'tool_experiment_counts'):
            # ä¼˜å…ˆé€‰æ‹©å°è¯•æ¬¡æ•°è¾ƒå°‘çš„å·¥å…·ï¼ˆå¥½å¥‡å¿ƒæœºåˆ¶ï¼‰
            min_experiments = min(self.tool_experiment_counts.values()) if self.tool_experiment_counts else 0
            least_tried_tools = []
            
            for tool in tools:
                tool_key = getattr(tool, 'name', tool.__class__.__name__)
                experiment_count = self.tool_experiment_counts.get(tool_key, 0)
                if experiment_count <= min_experiments + 2:  # å…è®¸ä¸€å®šçš„å¹³è¡¡
                    least_tried_tools.append(tool)
            
            if least_tried_tools:
                import random
                selected_tool = random.choice(least_tried_tools)
                # æ›´æ–°å®éªŒè®¡æ•°
                tool_key = getattr(selected_tool, 'name', selected_tool.__class__.__name__)
                self.tool_experiment_counts[tool_key] = self.tool_experiment_counts.get(tool_key, 0) + 1
                return selected_tool
        
        # ğŸ¯ æœ€åå¤‡é€‰ï¼šéšæœºé€‰æ‹©ï¼ˆå®Œå…¨æ¢ç´¢ï¼‰
        import random
        return random.choice(tools)
    
    def _calculate_tool_effectiveness(self, tool, target_type):
        """è®¡ç®—å·¥å…·å¯¹ç›®æ ‡çš„çœŸå®æ•ˆæœï¼ˆç‰©ç†æ¨¡æ‹Ÿï¼‰"""
        tool_properties = {
            'Spear': {'reach': 3, 'penetration': 4, 'precision': 3, 'speed': 2},
            'Stone': {'reach': 2, 'penetration': 2, 'precision': 2, 'speed': 4}, 
            'Bow': {'reach': 5, 'penetration': 3, 'precision': 5, 'speed': 3},
            'Basket': {'reach': 1, 'penetration': 1, 'precision': 1, 'speed': 1},
            'Shovel': {'reach': 2, 'penetration': 4, 'precision': 2, 'speed': 2},
            'Stick': {'reach': 3, 'penetration': 2, 'precision': 2, 'speed': 3}
        }
        
        target_characteristics = {
            'predator': {'size': 4, 'speed': 3, 'armor': 3, 'aggression': 5},
            'prey': {'size': 2, 'speed': 3, 'armor': 1, 'aggression': 1},
            'bird': {'size': 1, 'speed': 5, 'armor': 1, 'aggression': 1},
            'ground_plant': {'size': 1, 'speed': 0, 'armor': 1, 'aggression': 0},
            'underground_plant': {'size': 2, 'speed': 0, 'armor': 2, 'aggression': 0},
            'tree_plant': {'size': 3, 'speed': 0, 'armor': 2, 'aggression': 0}
        }
        
        # å…¼å®¹ä¸åŒçš„å·¥å…·ç±»å‹å±æ€§å
        tool_type_attr = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.__class__.__name__
        
        if tool_type_attr not in tool_properties or target_type not in target_characteristics:
            return 10, 0.5  # é»˜è®¤å€¼
        
        tool_stats = tool_properties[tool_type_attr]
        target_stats = target_characteristics[target_type]
        
        # è®¡ç®—åŒ¹é…åº¦ï¼ˆåŸºäºç‰©ç†åŸç†ï¼‰
        reach_match = tool_stats['reach'] / max(target_stats['speed'], 1)
        penetration_match = tool_stats['penetration'] / max(target_stats['armor'], 1)
        precision_match = tool_stats['precision'] / max(target_stats['size'], 1)
        speed_match = tool_stats['speed'] / max(target_stats['aggression'], 1)
        
        # ç»¼åˆåŒ¹é…åº¦
        total_match = (reach_match + penetration_match + precision_match + speed_match) / 4
        
        # è½¬æ¢ä¸ºä¼¤å®³å’ŒæˆåŠŸç‡
        base_damage = int(10 + total_match * 20)  # 10-30ä¼¤å®³èŒƒå›´
        success_rate = max(0.1, min(0.95, 0.3 + total_match * 0.6))  # 0.1-0.95æˆåŠŸç‡
        
        return base_damage, success_rate
    
    def _add_actionable_rule_from_experience(self, rule_type, conditions, predictions, confidence=0.7):
        """æ·»åŠ å¯æ‰§è¡Œçš„å†³ç­–è§„å¾‹ï¼Œä¾›å†³ç­–åº“å’ŒWBMç³»ç»Ÿä½¿ç”¨"""
        try:
            import time
            
            # åˆ›å»ºå†³ç­–è§„å¾‹
            actionable_rule = {
                'rule_id': f"{rule_type}_{int(time.time())}_{random.randint(1000, 9999)}",
                'rule_type': rule_type,
                'conditions': conditions.copy(),
                'predictions': predictions.copy(),
                'confidence': confidence,
                'usage_count': 0,
                'success_count': 0,
                'created_time': time.time(),
                'applicable_contexts': ['resource_acquisition', 'survival']
            }
            
            # æ·»åŠ åˆ°å†³ç­–è§„å¾‹åº“
            if not hasattr(self, 'actionable_rules'):
                self.actionable_rules = []
            self.actionable_rules.append(actionable_rule)
            
            # ç»´æŠ¤è§„å¾‹åº“å¤§å°
            if len(self.actionable_rules) > 50:  # é™åˆ¶è§„å¾‹æ•°é‡
                self.actionable_rules.pop(0)
            
            # å°†è§„å¾‹æ·»åŠ åˆ°äº”åº“ç³»ç»Ÿ
            if hasattr(self, 'five_library_system'):
                try:
                    self.five_library_system.add_rule(
                        rule_type=rule_type,
                        conditions=conditions,
                        predictions=predictions,
                        confidence=confidence,
                        source='actionable_experience'
                    )
                except Exception as e:
                    logger.log(f"{self.name} äº”åº“è§„å¾‹æ·»åŠ å¤±è´¥: {str(e)}")
            
            logger.log(f"{self.name} ğŸ¯ æ·»åŠ å¯æ‰§è¡Œè§„å¾‹: {rule_type} (ç½®ä¿¡åº¦: {confidence:.2f})")
            
        except Exception as e:
            logger.log(f"{self.name} å¯æ‰§è¡Œè§„å¾‹æ·»åŠ å¤±è´¥: {str(e)}")
    
    def _find_applicable_rule_for_situation(self, situation_context):
        """æ ¹æ®å½“å‰æƒ…å†µæŸ¥æ‰¾é€‚ç”¨çš„è§„å¾‹"""
        try:
            if not hasattr(self, 'actionable_rules'):
                return None
            
            best_rule = None
            best_score = 0
            
            for rule in self.actionable_rules:
                # è®¡ç®—è§„å¾‹åŒ¹é…åˆ†æ•°
                match_score = 0
                rule_conditions = rule.get('conditions', {})
                
                # æ£€æŸ¥æ¡ä»¶åŒ¹é…
                for condition, value in rule_conditions.items():
                    if condition in situation_context:
                        if situation_context[condition] == value:
                            match_score += 1
                        elif value is None and situation_context[condition] is None:
                            match_score += 1
                
                # è€ƒè™‘ç½®ä¿¡åº¦
                total_score = match_score * rule.get('confidence', 0.5)
                
                if total_score > best_score:
                    best_score = total_score
                    best_rule = rule
            
            # åªè¿”å›åŒ¹é…åº¦è¶³å¤Ÿé«˜çš„è§„å¾‹
            if best_score >= 0.5:
                return best_rule
            
            return None
            
        except Exception as e:
            logger.log(f"{self.name} è§„å¾‹æŸ¥æ‰¾å¤±è´¥: {str(e)}")
            return None


#
# DQN ç©å®¶â€”â€”ç­–ç•¥å†³ç­–ç¨å¾®åå‘æœé›†é£Ÿç‰©(å½“ä½äºé˜ˆå€¼æ—¶ä¸»åŠ¨ç§»åŠ¨ç‰©
#
    # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ç»Ÿè®¡å±æ€§çš„propertyæ–¹æ³•ï¼Œè¿”å›å®é™…ç»Ÿè®¡æ•°æ®
    @property
    def exploration_rate(self):
        """è®¡ç®—æ¢ç´¢ç‡ï¼šå·²æ¢ç´¢æ ¼å­æ•° / æ€»æ ¼å­æ•°"""
        if hasattr(self, '_game_map') and self._game_map:
            total_cells = self._game_map.width * self._game_map.height
            explored_cells = len(getattr(self, 'explored_cells', set()))
            return explored_cells / total_cells if total_cells > 0 else 0
        return 0

    @property
    def found_plants(self):
        """è¿”å›å‘ç°æ¤ç‰©æ•°é‡"""
        return getattr(self, 'found_plants_count', 0)

    @property
    def encountered_animals(self):
        """è¿”å›é­é‡åŠ¨ç‰©æ•°é‡"""
        return getattr(self, 'encountered_animals_count', 0)

    @property
    def found_big_tree(self):
        """è¿”å›å‘ç°å¤§æ ‘æ¬¡æ•°"""
        return getattr(self, 'found_big_tree_count', 0)

    @property
    def explored_cave(self):
        """è¿”å›æ¢ç´¢æ´ç©´æ¬¡æ•°"""
        return getattr(self, 'explored_cave_count', 0)

    @property
    def shared_info(self):
        """è¿”å›åˆ†äº«ä¿¡æ¯æ¬¡æ•°"""
        return getattr(self, 'shared_info_count', 0)
    @property
    def novelty_discoveries(self):
        """è¿”å›æ–°é¢–å‘ç°æ€»æ•°"""
        return getattr(self, 'novelty_discoveries_count', 0)
    
    def increment_novelty_discovery(self, discovery_type='experience'):
        """å¢åŠ æ–°é¢–å‘ç°è®¡æ•°"""
        if not hasattr(self, 'novelty_discoveries_count'):
            self.novelty_discoveries_count = 0
        if not hasattr(self, 'new_experiences_count'):
            self.new_experiences_count = 0
        if not hasattr(self, 'new_rules_count'):
            self.new_rules_count = 0
            
        self.novelty_discoveries_count += 1
        
        if discovery_type == 'experience':
            self.new_experiences_count += 1
        elif discovery_type == 'rule':
            self.new_rules_count += 1

    def _record_exploration(self, current_cell=None):
        """ğŸ”§ ä¿®å¤ï¼šè®°å½•æ¢ç´¢æ´»åŠ¨"""
        if hasattr(self, 'explored_cells'):
            self.explored_cells.add((self.x, self.y))
        
        # æ£€æŸ¥ç‰¹æ®Šåœ°å½¢
        if current_cell:
            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®åŒ¹é…åœ°å½¢ç¬¦å·ï¼ˆåŒ¹é…åœ°å›¾ç”Ÿæˆçš„"big_tree"ï¼‰
            if current_cell in ["big_tree", "tree", "T"] and hasattr(self, 'found_big_tree_count'):
                # å‘ç°å¤§æ ‘
                if (self.x, self.y) not in getattr(self, '_found_trees', set()):
                    self.found_big_tree_count += 1
                    if not hasattr(self, '_found_trees'):
                        self._found_trees = set()
                    self._found_trees.add((self.x, self.y))
                    logger.log(f"{self.name} discovered a big tree at ({self.x}, {self.y})")
            
            elif current_cell in ["cave", "C"] and hasattr(self, 'explored_cave_count'):
                # æ¢ç´¢æ´ç©´
                if (self.x, self.y) not in getattr(self, '_explored_caves', set()):
                    self.explored_cave_count += 1
                    if not hasattr(self, '_explored_caves'):
                        self._explored_caves = set()
                    self._explored_caves.add((self.x, self.y))
                    logger.log(f"{self.name} explored a cave at ({self.x}, {self.y})")

    def _record_plant_discovery(self, plant):
        """ğŸ”§ ä¿®å¤ï¼šè®°å½•å‘ç°æ¤ç‰©ï¼ˆä¸æ˜¯é‡‡é›†ï¼‰"""
        if hasattr(self, 'found_plants_count'):
            plant_id = id(plant)  # ä½¿ç”¨æ¤ç‰©å¯¹è±¡IDç¡®ä¿ä¸é‡å¤è®¡æ•°
            if not hasattr(self, '_discovered_plants'):
                self._discovered_plants = set()
            
            if plant_id not in self._discovered_plants:
                self.found_plants_count += 1
                self._discovered_plants.add(plant_id)
                logger.log(f"{self.name} discovered a plant at ({plant.x}, {plant.y})")

    def _record_animal_encounter(self, animal):
        """ğŸ”§ ä¿®å¤ï¼šè®°å½•é­é‡åŠ¨ç‰©"""
        if hasattr(self, 'encountered_animals_count'):
            # é¿å…é‡å¤è®¡æ•°åŒä¸€æ¬¡é­é‡
            encounter_key = f"{animal.type}_{animal.x}_{animal.y}_{self.x}_{self.y}"
            if not hasattr(self, '_recorded_encounters'):
                self._recorded_encounters = set()
            
            if encounter_key not in self._recorded_encounters:
                self.encountered_animals_count += 1
                self._recorded_encounters.add(encounter_key)
                logger.log(f"{self.name} encountered {animal.type} at ({animal.x}, {animal.y})")

    def _record_info_sharing(self, recipients_count=1):
        """ğŸ”§ ä¿®å¤ï¼šè®°å½•ä¿¡æ¯åˆ†äº«"""
        if hasattr(self, 'shared_info_count'):
            self.shared_info_count += recipients_count
            logger.log(f"{self.name} shared information with {recipients_count} other players")

class DQNPlayer(Player):
    def __init__(self, name, game_map):
        super().__init__(name, "DQN", game_map)

    def take_turn(self, game):
        if self.food < 30:
            directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
            dx, dy = random.choice(directions)
            self.move(dx, dy, game.game_map)
            logger.log(f"{self.name} (DQN) seeks food")
        else:
            super().take_turn(game)


#
# PPO ç©å®¶â€”â€”ç­–ç•¥å†³ç­–ç¨å¾®åå‘æœé›†æ°´"
#
class PPOPlayer(Player):
    def __init__(self, name, game_map):
        super().__init__(name, "PPO", game_map)

    def take_turn(self, game):
        if self.water < 30:
            directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
            dx, dy = random.choice(directions)
            self.move(dx, dy, game.game_map)
            logger.log(f"{self.name} (PPO) seeks water")
        else:
            super().take_turn(game)


#
# RL ç©å®¶åŸºç±»
#
class RLPlayer(Player):
    def __init__(self, name, player_type, game_map):
        super().__init__(name, player_type, game_map)
        # å®šä¹‰åŠ¨ç‰©ç©ºé—´
        self.actions = {
            0: "up",
            1: "down",
            2: "left",
            3: "right",
            4: "drink",
            5: "collect",
            6: "attack"
        }
        self.num_actions = len(self.actions)
        self.state_size = 78  # 3 (ç©å®¶çŠ¶æ€ + 5*5*3 (è§†é‡èŒƒå›´å†…çš„ä¿¡æ¯)
        self.last_attack_reward = 0  # è®°å½•ä¸Šä¸€æ¬¡æ”»å‡»çš„å¥–åŠ±

    def get_state(self, game):
        """è·å–å½“å‰çŠ¶æ€"""
        state = []
        
        # æ·»åŠ ç©å®¶è‡ªèº«çŠ¶æ€(å½’ä¸€åŒ–)
        state.extend([
            self.hp/100,  # ç”Ÿå‘½å€¼
            self.food/100,  # é£Ÿç‰©
            self.water/100  # æ°´åˆ†
        ])
        
        # è·å–5x5è§†é‡èŒƒå›´å†…çš„ç¯å¢ƒä¿¡æ¯
        vision_range = 2
        for dy in range(-vision_range, vision_range + 1):
            for dx in range(-vision_range, vision_range + 1):
                x, y = self.x + dx, self.y + dy
                if game.game_map.is_within_bounds(x, y):
                    # åœ°å½¢ç¼–ç 
                    terrain_encoding = {
                        "plain": 0.1,
                        "rock": 0.2,
                        "river": 0.3,
                        "puddle": 0.4
                    }
                    state.append(terrain_encoding.get(game.game_map.grid[y][x], 0))
                    
                    # æ£€æŸ¥æ¤ç‰©
                    has_plant = False
                    for plant in game.game_map.plants:
                        if plant.x == x and plant.y == y and plant.alive and not plant.collected:
                            state.append(0.6 if plant.toxic else 0.5)
                            has_plant = True
                            break
                    if not has_plant:
                        state.append(0)
                    
                    # æ£€æŸ¥åŠ¨ç‰©
                    has_animal = False
                    for animal in game.game_map.animals:
                        if animal.x == x and animal.y == y and animal.alive:
                            # æ›´ç»†è‡´çš„åŠ¨ç‰©çŠ¶æ€ç¼–ç 
                            if hasattr(animal, 'is_predator') and animal.is_predator:
                                state.append(0.9)  # æ•é£Ÿè€…
                            else:
                                # æ ¹æ®åŠ¨ç‰©è¡€é‡å†³å®šä»·"
                                health_ratio = animal.hp / animal.food  # ä½¿ç”¨foodä½œä¸ºæœ€å¤§HP
                                if health_ratio < 0.3:  # é‡ä¼¤åŠ¨ç‰©
                                    state.append(0.8)
                                elif health_ratio < 0.7:  # å—ä¼¤åŠ¨ç‰©
                                    state.append(0.7)
                                else:  # å¥å…¨åŠ¨ç‰©
                                    state.append(0.6)
                            has_animal = True
                            break
                    if not has_animal:
                        state.append(0)
                else:
                    # è¶…å‡ºåœ°å›¾èŒƒå›´çš„æ ¼å­
                    state.extend([0, 0, 0])
        
        return np.array(state, dtype=np.float32)

    def attack(self, target):
        """é‡å†™æ”»å‡»æ–¹æ³•,è®°å½•ä¼¤å®³"""
        old_target_hp = target.hp
        super().attack(target)
        damage_dealt = old_target_hp - target.hp
        
        # æ ¹æ®é€ æˆçš„ä¼¤å®³å’Œç›®æ ‡ç±»å‹è®¡ç®—å¥–åŠ±
        if not target.alive:  # å‡»æ€
            self.last_attack_reward = 100 if hasattr(target, 'is_predator') and target.is_predator else 50
            self.food += 30  # å‡»æ€è·å¾—é£Ÿç‰©
        elif damage_dealt > 0:  # é€ æˆä¼¤å®³
            self.last_attack_reward = 20 if hasattr(target, 'is_predator') and target.is_predator else 10
        else:  # æœªé€ æˆä¼¤å®³
            self.last_attack_reward = -5

    def execute_action(self, action_name, game):
        """æ‰§è¡ŒåŠ¨ç‰©å¹¶è¿”å›å¥–åŠ±"""
        old_state = {
            'hp': self.hp,
                'food': self.food,
                'water': self.water,
            'kills': self.killed_animals
        }
        
        reward = 0
        self.last_attack_reward = 0  # é‡ç½®æ”»å‡»å¥–åŠ±
        
        if action_name == "up":
            self.move(0, -1, game.game_map)
        elif action_name == "down":
            self.move(0, 1, game.game_map)
        elif action_name == "left":
            self.move(-1, 0, game.game_map)
        elif action_name == "right":
            self.move(1, 0, game.game_map)
        elif action_name == "drink":
            current_cell = game.game_map.grid[self.y][self.x]
            if current_cell in ["river", "puddle"]:
                self.water = min(100, self.water + 30)
                reward += 20  # å¢åŠ é¥®æ°´å¥–åŠ±
        elif action_name == "collect":
            for plant in game.game_map.plants:
                if plant.x == self.x and plant.y == self.y and plant.alive and not plant.collected:
                    old_food = self.food
                    self.collect_plant(plant)
                    if self.food > old_food:
                        reward += 30  # å¢åŠ é‡‡é›†å¥–åŠ±
                    break
        elif action_name == "attack":
            # æ£€æŸ¥å‘¨å›´ä¸€æ ¼èŒƒå›´å†…çš„åŠ¨ç‰©
            nearest_animal = None
            nearest_distance = float('inf')
            
            # å¯»æ‰¾æœ€è¿‘çš„åŠ¨ç‰©
            for animal in game.game_map.animals:
                if animal.alive:
                    distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                    if distance <= 1 and distance < nearest_distance:
                        nearest_animal = animal
                        nearest_distance = distance
            
            # å¦‚æœæ‰¾åˆ°ç›®æ ‡,è¿›è¡Œæ”»å‡»
            if nearest_animal:
                self.attack(nearest_animal)
                reward += self.last_attack_reward
            else:
                reward -= 5  # æƒ©ç½šæ— æ•ˆçš„æ”»å‡»è¡Œä¸º
        
        # è®¡ç®—åŸºç¡€å¥–åŠ±
        base_reward = self.calculate_reward(old_state)
        
        return reward + base_reward

    def calculate_reward(self, old_state):
        """è®¡ç®—å¥–åŠ±"""
        reward = 0.0
        
        # ç”Ÿå­˜å¥–åŠ±
        if self.alive:
            reward += 0.1
        else:
            return -100.0  # æ­»äº¡æƒ©ç½š
        
        # çŠ¶æ€å˜åŒ–å¥–åŠ±
        hp_change = self.hp - old_state['hp']
        food_change = self.food - old_state['food']
        water_change = self.water - old_state['water']
        kills_change = self.killed_animals - old_state['kills']
        
        # è¡€é‡å˜åŒ–å¥–åŠ±
        if hp_change > 0:
            reward += 0.5
        elif hp_change < 0:
            reward -= 0.5
            
        # é£Ÿç‰©å˜åŒ–å¥–åŠ±
        if food_change > 0:
            reward += 0.3
        elif food_change < 0:
            reward -= 0.2
            
        # æ°´åˆ†å˜åŒ–å¥–åŠ±
        if water_change > 0:
            reward += 0.3
        elif water_change < 0:
            reward -= 0.2
            
        # å‡»æ€å¥–åŠ±
        if kills_change > 0:
            reward += 5.0
            
        # çŠ¶æ€è¿‡ä½æƒ©ç½š
        if self.hp < 30:
            reward -= 0.5
        if self.food < 30:
            reward -= 0.5
        if self.water < 30:
            reward -= 0.5
            
        return float(reward)  # ç¡®ä¿è¿”å›floatç±»å‹

    def take_turn(self, game):
        if not self.alive:
            return
            
        # é¦–å…ˆæ‰§è¡Œçˆ¶ç±»çš„take_turn,ç¡®ä¿èµ„æºæ¶ˆè€—
        super().take_turn(game)
        
        # å¦‚æœå·²ç»æ­»äº¡,ç›´æ¥è¿”å›
        if not self.alive:
            return
            
        try:
            # è·å–å½“å‰çŠ¶æ€
            current_state = self.get_state(game)
            
            # é€‰æ‹©åŠ¨ä½œ
            action = self.select_action(current_state)
            
            # å¤„ç†åŠ¨ä½œæ ¼å¼ï¼šç¡®ä¿action_stræ˜¯åŠ¨ä½œå­—ç¬¦ä¸²ï¼Œaction_idxæ˜¯åŠ¨ä½œç´¢å¼•
            if isinstance(action, str):
                # actionæ˜¯å­—ç¬¦ä¸²ï¼ˆæ¥è‡ªDQNç­‰ï¼‰ï¼Œéœ€è¦è½¬æ¢ä¸ºç´¢å¼•
                action_str = action
                if action_str in self.actions.values():
                    # æ‰¾åˆ°å¯¹åº”çš„ç´¢å¼•
                    action_idx = None
                    for idx, act in self.actions.items():
                        if act == action_str:
                            action_idx = idx
                            break
                else:
                    # æ— æ•ˆåŠ¨ä½œï¼Œä½¿ç”¨éšæœºåŠ¨ä½œ
                    action_idx = random.choice(list(self.actions.keys()))
                    action_str = self.actions[action_idx]
            else:
                # actionæ˜¯ç´¢å¼•ï¼ˆæ¥è‡ªPPOç­‰ï¼‰
                action_idx = action
                if action_idx in self.actions:
                    action_str = self.actions[action_idx]
                else:
                    # æ— æ•ˆç´¢å¼•ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œ
                    action_idx = random.choice(list(self.actions.keys()))
                    action_str = self.actions[action_idx]
            
            # æ‰§è¡ŒåŠ¨ä½œ
            reward = self.execute_action(action_str, game)
            
            # è·å–æ–°çŠ¶æ€
            next_state = self.get_state(game)
            
            # å­˜å‚¨ç»éªŒï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
            self.remember(current_state, action_idx, reward, next_state, not self.alive)
            
            # è®­ç»ƒç½‘ç»œ
            self.train()
        except Exception as e:
            logger.log(f"RLè¡Œä¸ºæ‰§è¡Œå¤±è´¥: {str(e)}")
            # å¦‚æœAIè¡Œä¸ºå¤±è´¥,æ‰§è¡Œéšæœºç§»åŠ¨
            try:
                directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
                dx, dy = random.choice(directions)
                self.move(dx, dy, game.game_map)
            except Exception as fallback_e:
                logger.log(f"RLåº”æ€¥ç§»åŠ¨ä¹Ÿå¤±è´¥: {str(fallback_e)}")
        
    def remember(self, state, action, reward, next_state, done):
        """å­˜å‚¨ç»éªŒ - å…¼å®¹DQNå’ŒPPO"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç½‘ç»œå­˜åœ¨ï¼ˆDQNä½¿ç”¨q_networkï¼ŒPPOä½¿ç”¨policy_networkï¼‰
        has_network = hasattr(self, 'q_network') and self.q_network is not None
        has_policy_network = hasattr(self, 'policy_network') and self.policy_network is not None
        
        if has_network or has_policy_network:
            if hasattr(self, 'memory'):
                self.memory.append((state, action, reward, next_state, done))
            elif hasattr(self, 'trajectory'):
                # PPOä½¿ç”¨trajectoryå­˜å‚¨
                pass  # PPOæœ‰è‡ªå·±çš„å­˜å‚¨æœºåˆ¶
            
    def train(self):
        """è®­ç»ƒç½‘ç»œ - å…¼å®¹DQNå’ŒPPO"""
        # DQNè®­ç»ƒ
        if hasattr(self, 'q_network') and self.q_network is not None:
            if not hasattr(self, 'memory') or len(self.memory) < getattr(self, 'batch_size', 32):
                return
                
            try:
                batch = random.sample(self.memory, getattr(self, 'batch_size', 32))
                states = np.array([x[0] for x in batch])
                actions = np.array([x[1] for x in batch])
                rewards = np.array([x[2] for x in batch])
                next_states = np.array([x[3] for x in batch])
                dones = np.array([x[4] for x in batch])
                
                # è®¡ç®—ç›®æ ‡Qå€¼
                if hasattr(self, 'target_network') and self.target_network is not None:
                    target_q_values = self.target_network.predict(next_states, verbose=0)
                    max_target_q = np.max(target_q_values, axis=1)
                    targets = rewards + getattr(self, 'gamma', 0.95) * max_target_q * (1 - dones)
                    
                    # è®­ç»ƒç½‘ç»œ
                    q_values = self.q_network.predict(states, verbose=0)
                    for i in range(len(batch)):
                        q_values[i][actions[i]] = targets[i]
                    self.q_network.fit(states, q_values, verbose=0)
            except Exception as e:
                logger.log(f"DQNè®­ç»ƒå¤±è´¥: {str(e)}")
        
        # PPOè®­ç»ƒ
        elif hasattr(self, 'policy_network') and self.policy_network is not None:
            # PPOæœ‰è‡ªå·±çš„update_policyæ–¹æ³•
            if hasattr(self, 'update_policy'):
                try:
                    self.update_policy()
                except Exception as e:
                    logger.log(f"PPOè®­ç»ƒå¤±è´¥: {str(e)}")
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°±ä»€ä¹ˆéƒ½ä¸åš
        else:
            pass


class DQNPlayer(RLPlayer):
    def __init__(self, name, game_map):
        super().__init__(name, "DQN", game_map)
        self.epsilon = 0.1  # æ¢ç´¢ç‡
        self.gamma = 0.95  # æŠ˜æ‰£å› å­
        self.learning_rate = 0.01  # å°†å­¦ä¹ ç‡ä».001æé«˜ä».01
        self.memory = deque(maxlen=10000)  # ç»éªŒå›æ”¾ç¼“å†²åŒº
        self.batch_size = 32
        
        # åˆ›å»ºæˆ–åŠ è½½æ¨¡å‹
        model_path = os.path.join(MODELS_DIR, f"dqn_model_{name}.keras")
        if os.path.exists(model_path):
            try:
                self.q_network = tf.keras.models.load_model(model_path)
                self.target_network = tf.keras.models.load_model(model_path)
                logger.log(f"DQNç©å®¶ {name} åŠ è½½å·²æœ‰æ¨¡å‹")
            except Exception as e:
                logger.log(f"åŠ è½½DQNæ¨¡å‹å¤±è´¥: {str(e)}, åˆ›å»ºæ–°æ¨¡å‹")
                self.q_network = self.build_network()
                self.target_network = self.build_network()
        else:
            self.q_network = self.build_network()
            self.target_network = self.build_network()
            
    def save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        if self.q_network:
            try:
                # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨
                if not os.path.exists(MODELS_DIR):
                    os.makedirs(MODELS_DIR)
                
                model_path = os.path.join(MODELS_DIR, f"dqn_model_{self.name}.keras")
                self.q_network.save(model_path)
                
                # éªŒè¯æ¨¡å‹æ˜¯å¦ç¡®å®ä¿å­˜æˆåŠŸ
                if os.path.exists(model_path):
                    logger.log(f"âœ… DQNæ¨¡å‹ {self.name} ä¿å­˜æˆåŠŸ: {model_path}")
                else:
                    logger.log(f"âš ï¸ DQNæ¨¡å‹ {self.name} ä¿å­˜éªŒè¯å¤±è´¥")
            except Exception as e:
                logger.log(f"âŒ ä¿å­˜DQNæ¨¡å‹å¤±è´¥: {str(e)}")
                
    def build_network(self):
        """æ„å»ºç¥ç»ç½‘ç»œ"""
        try:
            model = Sequential()
            # å¢åŠ æ¨¡å‹å¤æ‚åº¦,æ·»åŠ Dropoutä»¥é¿å…è¿‡æ‹Ÿåˆ
            model.add(Dense(128, input_dim=self.state_size, activation='relu'))
            model.add(Dropout(0.2))
            model.add(Dense(256, activation='relu'))
            model.add(Dropout(0.2))
            model.add(Dense(128, activation='relu'))
            model.add(Dense(self.num_actions, activation='linear'))
            model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
            return model
        except Exception as e:
            import traceback
            logger.log(f"{self.name} æ„å»ºç½‘ç»œå¤±è´¥: {str(e)}")
            logger.log(traceback.format_exc())
            return None
    
    def select_action(self, state):
        """ä½¿ç”¨ epsilon-greedy ç­–ç•¥é€‰æ‹©åŠ¨ç‰©"""
        try:
            # ç¡®ä¿ç½‘ç»œå·²åˆå§‹åŒ–
            if self.q_network is None:
                logger.log(f"{self.name} Qç½‘ç»œæœªåˆå§‹åŒ–,å°è¯•åˆå§‹åŒ–...")
                if not self.initialize_networks():
                    logger.log(f"{self.name} æ— æ³•åˆå§‹åŒ–ç½‘ç»œ,å›é€€åˆ°ILAIç­–ç•¥")
                    return self._select_ilai_action()
            
            # ä»¥epsilonçš„æ¦‚ç‡éšæœºé€‰æ‹©åŠ¨ç‰©
            if np.random.rand() <= self.epsilon:
                action_idx = random.randrange(self.num_actions)
                logger.log(f"{self.name} æ¢ç´¢:éšæœºé€‰æ‹©åŠ¨ç‰© {self.actions[action_idx]}")
                return self.actions[action_idx]
            
            # å¦åˆ™é€‰æ‹©Qå€¼æœ€å¤§çš„åŠ¨ç‰©
            act_values = self.q_network.predict(state.reshape(1, -1), verbose=0)
            action_idx = np.argmax(act_values[0])
            logger.log(f"{self.name} åˆ©ç”¨:é€‰æ‹©Qå€¼æœ€å¤§çš„åŠ¨ç‰© {self.actions[action_idx]}")
            return self.actions[action_idx]
        except Exception as e:
            import traceback
            logger.log(f"{self.name} é€‰æ‹©åŠ¨ç‰©å¤±è´¥: {str(e)}")
            logger.log(traceback.format_exc())
            logger.log(f"{self.name} å›é€€åˆ°ILAIç­–ç•¥")
            return self._select_ilai_action()
    
    def _select_ilai_action(self):
        """å›é€€ä½¿ç”¨ILAIç­–ç•¥é€‰æ‹©åŠ¨ç‰©"""
        # è¿™é‡Œè°ƒç”¨åŸæ¥çš„ILAIå†³ç­–é€»è¾‘
        try:
            x, y = self.current_pos
            # æ£€æŸ¥æ°´é‡ä¸è¶³æ—¶å¯»æ‰¾æ°´æº
            if self.water < 30:
                water_sources = [resource for resource in self.game_map.resources if resource.type == "water"]
                if water_sources:
                    nearest_water = min(water_sources, key=lambda w: ((w.position[0] - x) ** 2 + (w.position[1] - y) ** 2) ** 0.5)
                    wx, wy = nearest_water.position
                    if (wx, wy) == (x, y):
                        return "drink"
                    elif abs(wx - x) > abs(wy - y):
                        return "right" if wx > x else "left"
                    else:
                        return "down" if wy > y else "up"
            
            # æ£€æŸ¥é£Ÿç‰©ä¸è¶³æ—¶å¯»æ‰¾é£Ÿç‰©
            if self.food < 30:
                food_sources = [resource for resource in self.game_map.resources if resource.type == "berry"]
                if food_sources:
                    nearest_food = min(food_sources, key=lambda f: ((f.position[0] - x) ** 2 + (f.position[1] - y) ** 2) ** 0.5)
                    fx, fy = nearest_food.position
                    if (fx, fy) == (x, y):
                        return "collect"
                    elif abs(fx - x) > abs(fy - y):
                        return "right" if fx > x else "left"
                    else:
                        return "down" if fy > y else "up"
            
            # å±é™©æ—¶èº²é¿æ•é£Ÿè€…
            for predator in self.game_map.predators:
                px, py = predator.position
                distance = ((px - x) ** 2 + (py - y) ** 2) ** 0.5
                if distance < 3:  # å½“æ•é£Ÿè€…è·ç¦»å°äº3æ ¼æ—¶èº²é¿
                    # å‘è¿œç¦»æ•é£Ÿè€…çš„æ–¹å‘ç§»åŠ¨
                    if abs(px - x) > abs(py - y):
                        return "left" if px > x else "right"
                    else:
                        return "up" if py > y else "down"
            
            # é»˜è®¤éšæœºç§»åŠ¨
            return random.choice(["up", "down", "left", "right"])
        except Exception as e:
            logger.log(f"{self.name} ILAIå†³ç­–å¤±è´¥: {str(e)}")
            # å®Œå…¨å¤±è´¥æ—¶éšæœºé€‰æ‹©
            return random.choice(["up", "down", "left", "right"])
        
    def take_turn(self, game):
        if not self.alive:
            return
            
        # é¦–å…ˆæ‰§è¡Œçˆ¶ç±»çš„take_turn,ç¡®ä¿èµ„æºæ¶ˆè€—
        super().take_turn(game)
        
        # å¦‚æœå·²ç»æ­»äº¡,ç›´æ¥è¿”å›
        if not self.alive:
            return
            
        try:
            # è·å–å½“å‰çŠ¶æ€
            current_state = self.get_state(game)
            
            # é€‰æ‹©åŠ¨ä½œ
            action_str = self.select_action(current_state)
            
            # ç¡®ä¿action_stræ˜¯æœ‰æ•ˆçš„åŠ¨ä½œå­—ç¬¦ä¸²
            if action_str not in self.actions.values():
                logger.log(f"{self.name} æ— æ•ˆåŠ¨ä½œ: {action_str}, ä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                action_str = random.choice(list(self.actions.values()))
            
            # è·å–åŠ¨ä½œç´¢å¼•ï¼ˆä»å­—å…¸å€¼æ‰¾åˆ°å¯¹åº”çš„é”®ï¼‰
            action_idx = None
            for idx, action in self.actions.items():
                if action == action_str:
                    action_idx = idx
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”ç´¢å¼•ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œ
            if action_idx is None:
                action_idx = random.choice(list(self.actions.keys()))
                action_str = self.actions[action_idx]
            
            # æ‰§è¡ŒåŠ¨ä½œ
            reward = self.execute_action(action_str, game)
            
            # è·å–æ–°çŠ¶æ€
            next_state = self.get_state(game)
            
            # å­˜å‚¨ç»éªŒ
            self.remember(current_state, action_idx, reward, next_state, not self.alive)
            
            # è®­ç»ƒç½‘ç»œ
            self.train()
        except Exception as e:
            logger.log(f"DQNè¡Œä¸ºæ‰§è¡Œå¤±è´¥: {str(e)}")
            # å¦‚æœAIè¡Œä¸ºå¤±è´¥,æ‰§è¡Œéšæœºç§»åŠ¨
            try:
                directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
                dx, dy = random.choice(directions)
                self.move(dx, dy, game.game_map)
            except Exception as fallback_e:
                logger.log(f"{self.name} åº”æ€¥ç§»åŠ¨ä¹Ÿå¤±è´¥: {str(fallback_e)}")


class PPOPlayer(RLPlayer):
    def __init__(self, name, game_map):
        super().__init__(name, "PPO", game_map)
        self.gamma = 0.99
        self.clip_ratio = 0.2
        self.policy_learning_rate = 0.003  # å°†ç­–ç•¥å­¦ä¹ ç‡ä».0003æé«˜ä».003
        self.value_learning_rate = 0.01  # å°†ä»·å€¼å­¦ä¹ ç‡ä».001æé«˜ä».01
        
        # åˆ›å»ºæˆ–åŠ è½½æ¨¡å‹
        policy_path = os.path.join(MODELS_DIR, f"ppo_policy_{name}.keras")
        value_path = os.path.join(MODELS_DIR, f"ppo_value_{name}.keras")
        
        if os.path.exists(policy_path) and os.path.exists(value_path):
            try:
                self.policy_network = tf.keras.models.load_model(policy_path)
                self.value_network = tf.keras.models.load_model(value_path)
                logger.log(f"PPOç©å®¶ {name} åŠ è½½å·²æœ‰æ¨¡å‹")
            except Exception as e:
                logger.log(f"åŠ è½½PPOæ¨¡å‹å¤±è´¥: {str(e)}, åˆ›å»ºæ–°æ¨¡å‹")
                self.policy_network = self.build_policy_network()
                self.value_network = self.build_value_network()
        else:
            self.policy_network = self.build_policy_network()
            self.value_network = self.build_value_network()
            
        self.trajectory = []
            
    def save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        if self.policy_network and self.value_network:
            try:
                # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨
                if not os.path.exists(MODELS_DIR):
                    os.makedirs(MODELS_DIR)
                
                policy_path = os.path.join(MODELS_DIR, f"ppo_policy_{self.name}.keras")
                value_path = os.path.join(MODELS_DIR, f"ppo_value_{self.name}.keras")
                self.policy_network.save(policy_path)
                self.value_network.save(value_path)
                
                # éªŒè¯æ¨¡å‹æ˜¯å¦ç¡®å®ä¿å­˜æˆåŠŸ
                if os.path.exists(policy_path) and os.path.exists(value_path):
                    logger.log(f"âœ… PPOæ¨¡å‹ {self.name} ä¿å­˜æˆåŠŸ: {policy_path}, {value_path}")
                else:
                    logger.log(f"âš ï¸ PPOæ¨¡å‹ {self.name} ä¿å­˜éªŒè¯å¤±è´¥")
            except Exception as e:
                logger.log(f"âŒ ä¿å­˜PPOæ¨¡å‹å¤±è´¥: {str(e)}")
                
    def build_policy_network(self):
        """æ„å»ºç­–ç•¥ç½‘ç»œ"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(self.num_actions, activation='softmax')
        ])
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.policy_learning_rate))
        return model
        
    def build_value_network(self):
        """æ„å»ºä»·å€¼ç½‘ç»œ"""
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.value_learning_rate),
                     loss='mse')
        return model
        
    def select_action(self, state):
        """ä½¿ç”¨ç­–ç•¥ç½‘ç»œé€‰æ‹©åŠ¨ç‰©"""
        if not self.policy_network:
            return random.randint(0, self.num_actions - 1), 0
            
        try:
            action_probs = self.policy_network.predict(state.reshape(1, -1), verbose=0)[0]
            action = np.random.choice(self.num_actions, p=action_probs)
            log_prob = np.log(action_probs[action])
            return action, log_prob
        except Exception as e:
            logger.log(f"PPOåŠ¨ç‰©é€‰æ‹©å¤±è´¥: {str(e)}")
            return random.randint(0, self.num_actions - 1), 0
        
    def take_turn(self, game):
        if not self.alive:
            return
            
        # é¦–å…ˆæ‰§è¡Œçˆ¶ç±»çš„take_turn,ç¡®ä¿èµ„æºæ¶ˆè€—
        super().take_turn(game)
        
        # å¦‚æœå·²ç»æ­»äº¡,ç›´æ¥è¿”å›
        if not self.alive:
            return
            
        try:
            # è·å–å½“å‰çŠ¶æ€
            current_state = self.get_state(game)
            
            # é€‰æ‹©åŠ¨ä½œ
            action, log_prob = self.select_action(current_state)
            
            # ç¡®ä¿actionåœ¨æœ‰æ•ˆèŒƒå›´å†…
            if action < 0 or action >= len(self.actions):
                logger.log(f"{self.name} æ— æ•ˆåŠ¨ä½œç´¢å¼•: {action}, ä½¿ç”¨éšæœºåŠ¨ä½œ")
                action = random.randint(0, len(self.actions) - 1)
                log_prob = 0  # é‡ç½®log_prob
            
            # è·å–å½“å‰çŠ¶æ€çš„ä»·å€¼ä¼°è®¡
            if self.value_network:
                try:
                    value = self.value_network.predict(current_state.reshape(1, -1), verbose=0)[0][0]
                except Exception as value_e:
                    logger.log(f"{self.name} ä»·å€¼ç½‘ç»œé¢„æµ‹å¤±è´¥: {str(value_e)}")
                    value = 0
            else:
                value = 0
            
            # æ‰§è¡ŒåŠ¨ä½œ
            action_str = self.actions[action]
            reward = self.execute_action(action_str, game)
            
            # å­˜å‚¨è½¨è¿¹
            if self.policy_network and self.value_network:
                self.trajectory.append((current_state, action, reward, value, log_prob))
            
                # æ¯100æ­¥æ›´æ–°ä¸€æ¬¡ç­–ç•¥
                if len(self.trajectory) >= 100:
                    self.update_policy()
                    self.clear_trajectory()
        except Exception as e:
            logger.log(f"PPOè¡Œä¸ºæ‰§è¡Œå¤±è´¥: {str(e)}")
            # å¦‚æœAIè¡Œä¸ºå¤±è´¥,æ‰§è¡Œéšæœºç§»åŠ¨
            try:
                directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
                dx, dy = random.choice(directions)
                self.move(dx, dy, game.game_map)
            except Exception as fallback_e:
                logger.log(f"{self.name} åº”æ€¥ç§»åŠ¨ä¹Ÿå¤±è´¥: {str(fallback_e)}")
            
    def update_policy(self):
        """æ›´æ–°ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œ"""
        if not self.policy_network or not self.value_network:
            return
            
        # æ£€æŸ¥è½¨è¿¹æ˜¯å¦ä¸ºç©º
        if not self.trajectory:
            return
            
        try:
            # è®¡ç®—ä¼˜åŠ¿å‡½æ•°
            returns = []
            advantages = []
            R = 0
            
            # ä¿®å¤å…ƒç»„è§£åŒ…ï¼šè½¨è¿¹æ ¼å¼æ˜¯(state, action, reward, value, log_prob)
            for state, action, reward, value, log_prob in reversed(self.trajectory):
                R = reward + self.gamma * R
                advantage = R - value
                returns.append(R)
                advantages.append(advantage)
            returns.reverse()
            advantages.reverse()
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œæ·»åŠ å½¢çŠ¶éªŒè¯
            states = np.array([x[0] for x in self.trajectory])
            actions = np.array([x[1] for x in self.trajectory])
            old_log_probs = np.array([x[4] for x in self.trajectory])
            
            # éªŒè¯çŠ¶æ€å½¢çŠ¶
            if len(states) == 0 or (len(states) > 0 and len(states[0]) == 0):
                logger.log(f"PPOç­–ç•¥æ›´æ–°è·³è¿‡: çŠ¶æ€æ•°æ®ä¸ºç©º")
                return
                
            # ç¡®ä¿çŠ¶æ€å½¢çŠ¶æ­£ç¡®
            if len(states.shape) == 1:
                # å¦‚æœçŠ¶æ€æ˜¯1ç»´çš„ï¼Œéœ€è¦é‡æ–°è°ƒæ•´å½¢çŠ¶
                logger.log(f"PPOç­–ç•¥æ›´æ–°è·³è¿‡: çŠ¶æ€å½¢çŠ¶å¼‚å¸¸ {states.shape}")
                return
            
            returns = np.array(returns)
            advantages = np.array(advantages)
            
            # æ ‡å‡†åŒ–ä¼˜åŠ¿å‡½æ•°
            if len(advantages) > 1:
                advantages = (advantages - np.mean(advantages)) / (np.std(advantages) + 1e-8)
            
            # æ›´æ–°ç­–ç•¥ç½‘ç»œ
            with tf.GradientTape() as tape:
                # è®¡ç®—æ–°çš„åŠ¨ä½œæ¦‚ç‡
                action_probs = self.policy_network(states)
                new_log_probs = tf.math.log(tf.gather(action_probs, actions, batch_dims=1))
                
                # è®¡ç®—æ¯”ç‡
                ratio = tf.exp(new_log_probs - old_log_probs)
                
                # è®¡ç®—è£å‰ªåçš„ç›®æ ‡å‡½æ•°
                clip_advantage = tf.clip_by_value(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * advantages
                policy_loss = -tf.reduce_mean(tf.minimum(ratio * advantages, clip_advantage))
            
            # æ›´æ–°ç­–ç•¥ç½‘ç»œ
            grads = tape.gradient(policy_loss, self.policy_network.trainable_variables)
            self.policy_network.optimizer.apply_gradients(zip(grads, self.policy_network.trainable_variables))
            
            # æ›´æ–°ä»·å€¼ç½‘ç»œ
            self.value_network.fit(states, returns, verbose=0)
            
        except Exception as e:
            logger.log(f"PPOç­–ç•¥æ›´æ–°å¤±è´¥: {str(e)}")
        
    def clear_trajectory(self):
        """æ¸…ç©ºè½¨è¿¹"""
        self.trajectory = []


#
# å©´å„¿å­¦ä¹  AI ç©å®¶(ILAI)â€”â€”å…·æœ‰å±‚çº§è®¤çŸ¥ã€å‘è‚²è®¤çŸ¥ã€åŠ¨æ€å¤šå¤´æ³¨æ„åŠ›ã€ç¤¾ä¼šåŒ–å†³ç­–åŠé€»è¾‘æ¨ç†æœºåˆ¶
# æ ¹æ®æ¸¸æˆè¿›ç¨‹(åˆæœŸã€ä¸­æœŸã€åæœŸ)è°ƒæ•´å†³ç­–ç­–ç•¥
#
class ILAIPlayer(Player):
    def __init__(self, name, game_map):
        super().__init__(name, "ILAI", game_map)
        # ä¿å­˜game_mapå¼•ç”¨,ç”¨äºç§»åŠ¨æ–¹æ³•
        self.game_map = game_map
        
        # è®¾ç½®ç©å®¶ç±»å‹
        self.player_type = "ILAI"
        
        # é¦–å…ˆåˆ›å»ºloggerå®ä¾‹
        self.logger = Logger()
        logger = self.logger
        
        # åˆå§‹åŒ–å¤šå±‚æ¬¡è®°å¿†ç³»ç»Ÿ(æ›¿æ¢åŸæœ‰çš„ç®€å•ç»éªŒåº“)
        self.memory_system = MultiLayerMemorySystem()
        
        # === 1.4.0ç‰ˆæœ¬æ–°å¢:æœ¨æ¡¥æ¨¡å‹é›†æˆ===
        self.wooden_bridge_model = WoodenBridgeModel(logger=logger)
        
        # === 2.0.0ç‰ˆæœ¬æ–°å¢:BMPè§„å¾‹ç”Ÿæˆç³»ç»Ÿé›†æˆ===
        try:
            # ä½¿ç”¨å®Œæ•´çš„BloomingAndPruningModelç³»ç»Ÿ
            self.bpm = BloomingAndPruningModel(logger=logger)
            
            if logger:
                logger.log(f"{name} ğŸ”¥ BMPè§„å¾‹ç”Ÿæˆç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            if logger:
                logger.log(f"ä»{name} BMPæ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}")
            self.bpm = None
        except Exception as e:
            if logger:
                logger.log(f"{name} BMPåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.bpm = None
        self.eocar_experiences = []  # EOCATRç»éªŒå­˜å‚¨
        self.knowledge_evolution_stats = {
            'evolution_cycles': 0,
            'successful_adaptations': 0,
            'failed_adaptations': 0
        }
        
        # === 2.0.1ç‰ˆæœ¬æ–°å¢:BPMé›†æˆç®¡ç†å™¨===
        try:
            self.bmp_integration = BPMIntegrationManager(logger=logger)
            self.bmp_integration_active = True
            
            # BPMé›†æˆç»Ÿè®¡
            self.bmp_integration_stats = {
                'candidate_rules_generated': 0,
                'rules_validated': 0,
                'integration_cycles': 0,
                'last_integration_time': 0.0
            }
            
            if logger:
                logger.log(f"{name} BPMé›†æˆç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ - æ”¯æŒ15ç§EOCARç»„åˆè§„å¾‹ç”Ÿæˆ")
        except ImportError as e:
            if logger:
                logger.log(f"{name} BPMé›†æˆç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {str(e)}")
            self.bmp_integration = None
            self.bmp_integration_active = False
        except Exception as e:
            if logger:
                logger.log(f"{name} BPMé›†æˆç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.bmp_integration = None
            self.bmp_integration_active = False
        
        # === 2.1.0ç‰ˆæœ¬æ–°å¢:è§„å¾‹éªŒè¯ç³»ç»Ÿé›†æˆ===
        self.rule_validation_system = RuleValidationSystem(logger=logger)
        self.validation_opportunities = []  # éªŒè¯æœºä¼šé˜Ÿåˆ—
        self.validated_rules = []  # å·²éªŒè¯è§„å¾‹åº“
        self.validation_stats = {
            'total_validations': 0,
            'successful_validations': 0,
            'failed_validations': 0,
            'high_confidence_rules': 0,
            'medium_confidence_rules': 0,
            'low_confidence_rules': 0
        }
        
        if logger:
            logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆè§„å¾‹éªŒè¯ç³»ç»Ÿ")
        
        # === æ–°å¢:åŠ¨æ€å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶é›†æˆ ===
        self.dmha = DynamicMultiHeadAttention(logger=logger)
        
        # === SSMåœºæ™¯ç¬¦å·åŒ–æœºåˆ¶é›†æˆ===
        # åˆ›å»ºSSMå®ä¾‹
        self.ssm = SceneSymbolizationMechanism(logger=logger)
        
        # ç»éªŒåº“å‡çº§ä¸ºE-O-C-A-T-Ræ ¼å¼
        self.eocar_experience_base = []  # E-O-C-A-T-Ræ ¼å¼çš„ç»éªŒåº“
        self.eocar_indirect_experience_base = []  # é—´æ¥E-O-C-A-T-Rç»éªŒåº“
        
        # ä¿æŒå…¼å®¹æ€§çš„ä¼ ç»Ÿç»éªŒåº“
        self.direct_experience_base = []  # ç›´æ¥ç»éªŒåº“
        self.indirect_experience_base = []  # é—´æ¥ç»éªŒåº“
        self.congenital_knowledge = []  # å…ˆå¤©çŸ¥è¯†åº“
        self.rule_base = []  # è§„åˆ™åº“
        
        # SSMç›¸å…³æ—¶é—´æˆ³
        self.current_timestamp = 0.0
        
        # å½“å‰E-O-C-A-T-Rç¬¦å·åŒ–åœºæ™¯(ç”¨äºå†³ç­–)
        self.current_eocar_scene = []
        
        # è®¾ç½®ç»éªŒåº“å®¹é‡
        self.max_eocar_experiences = 300  # E-O-C-A-T-Rç»éªŒå®¹é‡
        
        if logger:
            logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆSSMåœºæ™¯ç¬¦å·åŒ–æœºåˆ¶")
        
        # === æ•°æ®æ ¼å¼ç»Ÿä¸€åŒ–å™¨é›†æˆ ===
        # åˆ›å»ºæ•°æ®æ ¼å¼ç»Ÿä¸€åŒ–å™¨å®ä¾‹
        self.data_format_unifier = create_data_format_unifier(logger=logger)
        
        # ç»Ÿä¸€æ ¼å¼ç»éªŒåº“
        self.unified_experiences = []  # ç»Ÿä¸€æ ¼å¼çš„ç»éªŒåº“
        self.max_unified_experiences = 500  # ç»Ÿä¸€ç»éªŒåº“å®¹é‡
        
        # æ•°æ®æ ¼å¼ç»Ÿè®¡
        self.format_conversion_stats = {
            'total_conversions': 0,
            'successful_conversions': 0,
            'format_types_encountered': set()
        }
        
        if logger:
            logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆæ•°æ®æ ¼å¼ç»Ÿä¸€åŒ–å™¨")
        
        # === ç»Ÿä¸€çŸ¥è¯†å†³ç­–ç³»ç»Ÿé›†æˆ ===
        if UNIFIED_KNOWLEDGE_AVAILABLE:
            try:
                self.unified_knowledge_system = UnifiedKnowledgeDecisionSystem()
                self.ukds_active = True
                
                # ç»Ÿä¸€çŸ¥è¯†å†³ç­–ç³»ç»Ÿç›¸å…³ç»Ÿè®¡
                self.ukds_stats = {
                    'decisions_made': 0,
                    'rules_generated': 0,
                    'scenarios_analyzed': 0,
                    'successful_predictions': 0,
                    'failed_predictions': 0
                }
                
                if logger:
                    logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆç»Ÿä¸€çŸ¥è¯†å†³ç­–ç³»ç»Ÿ")
            except Exception as e:
                if logger:
                    logger.log(f"ILAIç©å®¶ {name} ç»Ÿä¸€çŸ¥è¯†å†³ç­–ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.unified_knowledge_system = None
                self.ukds_active = False
        else:
            self.unified_knowledge_system = None
            self.ukds_active = False
        
        # === äº”åº“çŸ¥è¯†ç®¡ç†ç³»ç»Ÿé›†æˆ ===
        try:
            from five_library_system import FiveLibrarySystem
            # ä¸ºæ¯ä¸ªç©å®¶åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“æ–‡ä»¶
            db_path = f"player_{name}_four_library.db"
            self.five_library_system = FiveLibrarySystem()
            self.five_library_system_active = True
            
            if logger:
                logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆäº”åº“çŸ¥è¯†ç®¡ç†ç³»ç»Ÿ(DB: {db_path})")
        except ImportError as e:
            if logger:
                logger.log(f"{self.name} äº”åº“ç³»ç»Ÿå¯¼å…¥å¤±è´¥: {str(e)}")
            self.five_library_system = None
            self.five_library_system_active = False
        except Exception as e:
            if logger:
                logger.log(f"{self.name} äº”åº“ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.five_library_system = None
            self.five_library_system_active = False
        
        # === ç»Ÿä¸€å†³ç­–ç³»ç»Ÿé›†æˆ ===
        try:
            self.unified_decision_system = UnifiedDecisionSystem(logger=logger)
            self.unified_decision_system.bmp_generator = SimplifiedBMPGenerator(logger=logger)
            self.unified_decision_active = True
            
            if logger:
                logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆç»Ÿä¸€å†³ç­–ç³»ç»Ÿ(EOCATRæ ‡å‡†åŒ–)")
        except Exception as e:
            if logger:
                logger.log(f"ILAIç©å®¶ {name} ç»Ÿä¸€å†³ç­–ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.unified_decision_system = None
            self.unified_decision_active = False
        
        # === æ•´åˆå†³ç­–ç³»ç»Ÿé›†æˆ ===
        if INTEGRATED_DECISION_AVAILABLE:
            try:
                # ç¡®ä¿BMPç³»ç»Ÿå·²åˆå§‹åŒ–,å¦‚æœæ²¡æœ‰åˆ™è®¾ä¸ºNone
                bmp_system = getattr(self, 'bpm', None)
                
                self.integrated_decision_system = IntegratedDecisionSystem(
                    five_library_system=self.five_library_system,
                    wooden_bridge_model=self.wooden_bridge_model,
                    bmp_system=bmp_system,
                    logger=logger
                )
                self.integrated_decision_active = True
                
                if logger:
                    logger.log(f"ILAIç©å®¶ {name} å·²é›†æˆæ•´åˆå†³ç­–ç³»ç»Ÿ(V3å†³ç­–åº“åŒ¹é…+ WBMè§„å¾‹æ„å»º)")
                    logger.log(f"   äº”åº“ç³»ç»Ÿ: {self.five_library_system is not None}")
                    logger.log(f"   æœ¨æ¡¥æ¨¡å‹: {self.wooden_bridge_model is not None}")
                    logger.log(f"   BMPç³»ç»Ÿ: {bmp_system is not None}")
            except Exception as e:
                if logger:
                    logger.log(f"ILAIç©å®¶ {name} æ•´åˆå†³ç­–ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    import traceback
                    logger.log(traceback.format_exc())
                self.integrated_decision_system = None
                self.integrated_decision_active = False
        else:
            self.integrated_decision_system = None
            self.integrated_decision_active = False
        
        # === 1.3.0ç‰ˆæœ¬ç»„ä»¶é›†æˆ ===
        try:
            from curiosity_driven_learning import CuriosityDrivenLearning
            from enhanced_multi_reward_system import EnhancedMultiRewardSystem
            
            self.curiosity_driven_learning = CuriosityDrivenLearning(logger=logger)
            self.enhanced_multi_reward_system = EnhancedMultiRewardSystem(logger=logger)
            
            # é›†æˆçŠ¶æ€è·Ÿ"
            self.cdl_active = True
            self.emrs_active = True
            
            if logger:
                logger.log(f"{self.name} æˆåŠŸé›†æˆCDLå’ŒEMRSç³»ç»Ÿ")
        except ImportError as e:
            if logger:
                logger.log(f"{self.name} CDL/EMRSæ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}")
            self.cdl_active = False
            self.emrs_active = False
        
        # ä¿ç•™åŸæœ‰çš„é˜¶æ®µä¿¡æ¯
        self.phase = "åˆæœŸ"
        
        # === æœ¨æ¡¥æ¨¡å‹ç›¸å…³çŠ¶æ€===
        self.current_goals = []  # å½“å‰æ´»è·ƒç›®æ ‡
        self.active_bridge_plan = None  # å½“å‰æ‰§è¡Œçš„æ¡¥æ¢æ–¹æ³•
        self.bridge_execution_state = {
            'current_step': 0,
            'total_steps': 0,
            'step_results': []
        }
        
        # è§„å¾‹åº“(ä»BPMå’Œç»éªŒä¸­åŠ¨æ€æ„å»º)
        self.available_rules = []
        self.rule_performance_tracker = {}
        
        # å‘è‚²é˜¶æ®µè·Ÿè¸ª(ç”¨äºCDLå’Œæœ¨æ¡¥æ¨¡å‹)
        self.developmental_stage = 0.0  # 0.0=å©´å„¿æœŸ,1.0=æˆç†ŸæœŸ
        self.life_experience_count = 0
        
        # === CDLç›¸å…³å±æ€§===
        self.visited_positions = set()  # è®°å½•è®¿é—®è¿‡çš„ä½ç½®,ç”¨äºCDLæ¢ç´¢
        
        # === ä¿ç•™åŸæœ‰RLç›¸å…³å‚æ•° ===
        # æ˜¯å¦å¯ç”¨å¼ºåŒ–å­¦ä¹ 
        self.use_reinforcement_learning = False
        
        # å¼ºåŒ–å­¦ä¹ ç›¸å…³å‚æ•°
        self.memory = deque(maxlen=10000)  # ç»éªŒå›æ”¾ç¼“å†²åŒº
        self.gamma = 0.95  # æŠ˜æ‰£å› å­
        self.epsilon = 0.2  # åˆå§‹æ¢ç´¢ç‡
        self.epsilon_min = 0.05  # æœ€å°æ¢ç´¢ç‡
        self.epsilon_decay = 0.995  # æ¢ç´¢ç‡è¡°å‡
        self.learning_rate = 0.001  # å­¦ä¹ ç‡
        self.batch_size = 32  # æ‰¹é‡å­¦ä¹ å¤§å°
        self.state_size = 78  # çŠ¶æ€å‘é‡å¤§å°
        self.num_actions = 7  # åŠ¨ç‰©æ•°é‡
        self.train_frequency = 5  # æ¯æ‰§è¡Œè¿™ä¹ˆå¤šæ­¥éª¤è¿›è¡Œä¸€æ¬¡è®­"
        self.target_update_frequency = 20  # æ›´æ–°ç›®æ ‡ç½‘ç»œçš„é¢‘"
        self.step_counter = 0  # è®°å½•æ­¥æ•°
        self.actions = {
            0: "up",
            1: "down",
            2: "left", 
            3: "right",
            4: "drink",
            5: "collect",
            6: "attack"
        }
        
        # RLçŠ¶æ€è·Ÿè¸ª
        self.last_action = None
        self.last_state = None
        self.last_reward = 0
        
        # Qç½‘ç»œå’Œç›®æ ‡ç½‘ç»œåˆå§‹ä¸ºNone,å»¶è¿Ÿåˆå§‹åŒ–
        self.q_network = None
        self.target_network = None
        
        # åˆå§‹åŒ–EMRS v2.0äº”ç»´è¯„ä»·ç³»ç»Ÿ
        try:
            from enhanced_multi_reward_system_v2 import EnhancedMultiRewardSystemV2
            self.enhanced_multi_reward_system = EnhancedMultiRewardSystemV2(
                logger=logger, 
                development_stage=getattr(self, 'development_stage', 'child')
            )
            self.emrs_active = True
            if logger:
                logger.log(f"{self.name} EMRS v2.0äº”ç»´è¯„ä»·ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            if logger:
                logger.log(f"{self.name} EMRS v2.0åˆå§‹åŒ–å¤±è´¥,å›é€€åˆ°åŸç³»ç»Ÿ: {str(e)}")
            try:
                self.enhanced_multi_reward_system = EnhancedMultiRewardSystem(logger=logger)
                self.emrs_active = True
                # åŒ…è£…EMRSå®ä¾‹ä»¥æä¾›å…¼å®¹æ€§
                self.enhanced_multi_reward_system = wrap_emrs_for_compatibility(self.enhanced_multi_reward_system)
            except Exception as e2:
                if logger:
                    logger.log(f"{self.name} EMRSç³»ç»Ÿå®Œå…¨åˆå§‹åŒ–å¤±è´¥: {str(e2)}")
                self.emrs_active = False

        # === ç¤¾äº¤å­¦ä¹ æœºåˆ¶åˆå§‹åŒ–===
        # åˆå§‹åŒ–å¢å¼ºçš„é—´æ¥ç»éªŒåº“åŠŸèƒ½(ä»…é™ILAIå’ŒRILAI"
        try:
            self.initialize_social_learning()
            if logger:
                logger.log(f"{self.name} é—´æ¥ç»éªŒåº“åŠŸèƒ½å¢å¼ºå®Œæˆ")
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ç¤¾äº¤å­¦ä¹ åˆå§‹åŒ–å¤±è´¥: {str(e)}")

        # === ä½ç½®è·Ÿè¸ªæœºåˆ¶ ===
        # åˆå§‹åŒ–ä½ç½®è·Ÿè¸ª(ç¤¾äº¤å­¦ä¹ å¿…éœ€)
        self.current_pos = (self.x, self.y)
        self.last_pos = (self.x, self.y)
        self.visited_positions = set()
        self.visited_positions.add(self.current_pos)
        
        if logger:
            logger.log(f"{self.name} ä½ç½®è·Ÿè¸ªæœºåˆ¶å·²åˆå§‹åŒ–: {self.current_pos}")
        
        # === EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆæœºåˆ¶(æ–°å¢) ===
        self.eocatr_initialized = False
        self.eocatr_generation_stats = {
            'total_generated': 0,
            'generation_time': 0.0,
            'last_generation_timestamp': 0.0
        }
        
        # åˆå§‹åŒ–ç³»ç»Ÿæ€§EOCATRè§„å¾‹ç”Ÿæˆ
        try:
            if (self.five_library_system_active and self.five_library_system and
                hasattr(self, 'bpm') and self.bpm is not None):
                
                # 1. äº”åº“ç³»ç»Ÿé…ç½®EOCATRçŸ©é˜µ
                trigger_result = self.five_library_system.trigger_systematic_eocatr_rule_generation()
                
                if trigger_result['status'] == 'success':
                    # 2. BPMç³»ç»Ÿç”Ÿæˆç³»ç»Ÿæ€§è§„å¾‹
                    matrix_config = trigger_result['matrix_config']
                    systematic_rules = self.bmp.generate_systematic_eocatr_rules(matrix_config)
                    
                    # 3. å°†ç”Ÿæˆçš„è§„å¾‹æ·»åŠ åˆ°BMPå€™é€‰è§„å¾‹åº“
                    for rule in systematic_rules:
                        self.bmp.candidate_rules[rule.rule_id] = rule
                    
                    # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self.eocatr_generation_stats = {
                        'total_generated': len(systematic_rules),
                        'generation_time': trigger_result.get('generation_time', 0.0),
                        'last_generation_timestamp': time.time(),
                        'expected_total': trigger_result['total_expected'],
                        'matrix_config_id': trigger_result['config_decision_id']
                    }
                    
                    self.eocatr_initialized = True
                    
                    if logger:
                        logger.log(f"{self.name} EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆå®Œæˆ")
                        logger.log(f"   ç”Ÿæˆè§„å¾‹æ•°é‡: {len(systematic_rules)}")
                        logger.log(f"   é¢„æœŸè§„å¾‹æ€»æ•°: {trigger_result['total_expected']}")
                        logger.log(f"   é…ç½®å†³ç­–ID: {trigger_result['config_decision_id']}")
                        
                        # è·å–BMPç»Ÿè®¡ä¿¡æ¯è¿›è¡ŒéªŒè¯
                        bmp_stats = self.bmp.get_eocatr_generation_statistics()
                        if 'systematic_eocatr_rules' in bmp_stats:
                            sys_stats = bmp_stats['systematic_eocatr_rules']
                            logger.log(f"   BMPç³»ç»Ÿæ€§è§„å¾‹ç»Ÿä» å€™ä»{sys_stats.get('candidate', 0)}, å·²éªŒä»{sys_stats.get('validated', 0)}")
                        
                        # äº”åº“ç³»ç»Ÿå®Œæ•´æ€§éªŒ"
                        completeness = self.five_library_system.validate_eocatr_matrix_completeness(bmp_stats)
                        if 'completeness_check' in completeness:
                            coverage = completeness['completeness_check'].get('coverage_percentage', 0)
                            logger.log(f"   çŸ©é˜µè¦†ç›–ç‡: {coverage:.2f}%")
                else:
                    if logger:
                        logger.log(f"{self.name} EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆè§¦å‘å¤±è´¥: {trigger_result['message']}")
            else:
                if logger:
                    missing_components = []
                    if not self.five_library_system_active:
                        missing_components.append("äº”åº“ç³»ç»Ÿ")
                    if not hasattr(self, 'bmp') or self.bmp is None:
                        missing_components.append("BMPç³»ç»Ÿ")
                    
                    logger.log(f"âš ï¸ {self.name} EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆè·³è¿‡,ç¼ºå°‘ç»„ä»¶: {', '.join(missing_components)}")
        except Exception as e:
            if logger:
                logger.log(f"{self.name} EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
                import traceback
                logger.log(traceback.format_exc())

        # === WBMå†…å­˜åŒæ­¥åŠŸèƒ½é›†æˆ ===
        # å¯ç”¨å†…å­˜åˆ°äº”åº“ç³»ç»Ÿçš„è‡ªåŠ¨åŒæ­¥åŠŸèƒ½
        try:
            from wbm_memory_to_database_sync import apply_memory_sync_patch
            self.memory_sync = apply_memory_sync_patch(self)
            if logger:
                logger.log(f"âœ… {self.name} WBMå†…å­˜åŒæ­¥åŠŸèƒ½å·²å¯ç”¨")
        except Exception as e:
            if logger:
                logger.log(f"âš ï¸ {self.name} WBMå†…å­˜åŒæ­¥åŠŸèƒ½å¯ç”¨å¤±è´¥: {str(e)}")
            self.memory_sync = None

        # === ğŸ”§ åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ ===
        # åˆå§‹åŒ–å·¥å…·åˆ—è¡¨
        self.tools = []
        
        # === ğŸ”§ é»˜è®¤å·¥å…·è£…å¤‡ç³»ç»Ÿ ===
        # è‡ªåŠ¨è£…å¤‡æ‰€æœ‰6ç§å·¥å…·ï¼Œç®€åŒ–å­¦ä¹ ä¸“æ³¨äºå¤šè§„å¾‹åä½œ
        self._equip_default_tools()
        
        # ğŸ§  åˆå§‹åŒ–å­¦ä¹ æœºåˆ¶æ•°æ®ç»“æ„
        self.tool_effectiveness = {}  # å­˜å‚¨å·¥å…·æ•ˆæœç»éªŒ: (tool_name, target_type) -> {'effectiveness': float, 'attempts': int}
        self.tool_experiment_counts = {}  # å·¥å…·å®éªŒæ¬¡æ•°: tool_name -> count
        self._recorded_encounters = set()  # é¿å…é‡å¤è®°å½•é­é‡
        
        # === ğŸ—“ï¸ é•¿é“¾å†³ç­–è®°å¿†ç®¡ç†ç³»ç»Ÿ ===
        # å½“å‰æ‰§è¡Œçš„å¤šæ—¥è®¡åˆ’
        self.current_multi_day_plan = None
        # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ å¤©ï¼ˆä»1å¼€å§‹ï¼‰
        self.plan_current_day = 0
        # è®¡åˆ’åˆ¶å®šæ—¶çš„ç¯å¢ƒçŠ¶æ€å¿«ç…§
        self.plan_initial_state = None
        # æ¯æ—¥æ‰§è¡Œè®°å½•
        self.daily_execution_log = []
        # è®¡åˆ’è°ƒæ•´å†å²
        self.plan_adjustment_history = []
        # è®¡åˆ’å¤±è´¥åŸå› è®°å½•
        self.plan_failure_reasons = []
        # è®¡åˆ’æˆåŠŸå®Œæˆæ¬¡æ•°
        self.plan_completion_stats = {
            'total_started': 0,
            'total_completed': 0,
            'total_interrupted': 0,
            'total_adjusted': 0
        }
        
        if logger:
            logger.log(f"ILAIç©å®¶ {name} é•¿é“¾å†³ç­–è®°å¿†ç®¡ç†ç³»ç»Ÿå·²åˆå§‹åŒ–")

    def _equip_default_tools(self):
        """é»˜è®¤è£…å¤‡æ‰€æœ‰6ç§å·¥å…·ï¼Œç®€åŒ–å­¦ä¹ ä¸“æ³¨äºå¤šè§„å¾‹åä½œ"""
        try:
            # å¯¼å…¥å·¥å…·ç±»
            from animals_plants_tools_expansion import Spear, Stone, Bow, Basket, Shovel, Stick
            
            # åˆ›å»ºæ‰€æœ‰å·¥å…·å®ä¾‹å¹¶æ·»åŠ åˆ°å·¥å…·åº“
            default_tools = [
                ("é•¿çŸ›", Spear),    # ç”¨äºçŒ›å…½(Tiger, BlackBear)
                ("çŸ³å¤´", Stone),    # ç”¨äºçŒç‰©(Rabbit, Boar)  
                ("å¼“ç®­", Bow),      # ç”¨äºé¸Ÿç±»(Pheasant, Dove)
                ("ç¯®å­", Basket),   # ç”¨äºåœ°é¢æ¤ç‰©(Strawberry, Mushroomç­‰)
                ("é“é”¹", Shovel),   # ç”¨äºåœ°ä¸‹æ¤ç‰©(Potato, SweetPotato)
                ("æ£å­", Stick)     # ç”¨äºæ ‘ä¸Šæ¤ç‰©(Acorn, Chestnut)
            ]
            
            for tool_name_cn, tool_class in default_tools:
                # åˆ›å»ºå·¥å…·å®ä¾‹
                tool = tool_class()
                # æ·»åŠ åˆ°å·¥å…·åº“
                self.tools.append(tool)
            
            if self.logger:
                self.logger.log(f"{self.name} ğŸ”§ å·²è£…å¤‡æ‰€æœ‰6ç§å·¥å…·ï¼šé•¿çŸ›ã€çŸ³å¤´ã€å¼“ç®­ã€ç¯®å­ã€é“é”¹ã€æ£å­")
            
            # === ğŸ§  åˆå§‹åŒ–å·¥å…·æ•ˆæœå­¦ä¹ ç³»ç»Ÿ ===
            self._initialize_tool_learning_system()
            
        except ImportError as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·ç±»å¯¼å…¥å¤±è´¥: {str(e)}")
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç®€å•çš„å·¥å…·å¯¹è±¡
            self._create_simple_tools()
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·è£…å¤‡å¤±è´¥: {str(e)}")
            self._create_simple_tools()

    def _create_simple_tools(self):
        """åˆ›å»ºç®€å•çš„å·¥å…·å¯¹è±¡ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        class SimpleTool:
            def __init__(self, name):
                self.name = name
                self.__class__.__name__ = name.replace("Simple", "")
        
        simple_tools = ["é•¿çŸ›", "çŸ³å¤´", "å¼“ç®­", "ç¯®å­", "é“é”¹", "æ£å­"]
        for tool_name in simple_tools:
            tool = SimpleTool(tool_name)
            self.tools.append(tool)
        
        if self.logger:
            self.logger.log(f"{self.name} ğŸ”§ å·²è£…å¤‡ç®€å•å·¥å…·ç‰ˆæœ¬ï¼š{', '.join(simple_tools)}")
        
        # åˆå§‹åŒ–åŸºç¡€å­¦ä¹ ç³»ç»Ÿ
        self.tool_effectiveness = {}
        self.tool_usage_history = []

    def _initialize_tool_learning_system(self):
        """åˆå§‹åŒ–å·¥å…·æ•ˆæœå­¦ä¹ ç³»ç»Ÿ"""
        # å·¥å…·æ•ˆæœè®°å½•ï¼š{(tool_type, target_type): {'successes': int, 'attempts': int, 'effectiveness': float}}
        self.tool_effectiveness = {}
        
        # å·¥å…·ä½¿ç”¨å†å²
        self.tool_usage_history = []
        
        # å®éªŒè®¡æ•°å™¨ï¼Œç¡®ä¿æ¯ç§å·¥å…·éƒ½è¢«å°è¯•
        self.tool_experiment_counts = {}
        for tool in self.tools:
            # å…¼å®¹ä¸åŒçš„å·¥å…·ç±»å‹å±æ€§å
            tool_type = getattr(tool, 'tool_type', None) or getattr(tool, 'type', None) or tool.__class__.__name__
            self.tool_experiment_counts[tool_type] = 0
        
        if self.logger:
            self.logger.log(f"{self.name} ğŸ§  å·¥å…·æ•ˆæœå­¦ä¹ ç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # === å¤šæ­¥è§„åˆ’ç³»ç»Ÿé›†æˆ ===
        # å¤šæ­¥è§„åˆ’çŠ¶æ€ç®¡ç†
        self.current_plan = None  # å½“å‰æ‰§è¡Œçš„å¤šæ­¥è®¡åˆ’
        self.current_plan_step = 0  # å½“å‰è®¡åˆ’æ‰§è¡Œåˆ°çš„æ­¥éª¤
        self.plan_execution_history = []  # è®¡åˆ’æ‰§è¡Œå†å²
        self.plan_failure_count = 0  # è®¡åˆ’å¤±è´¥æ¬¡æ•°
        self.last_plan_validation_turn = 0  # ä¸Šæ¬¡è®¡åˆ’éªŒè¯çš„å›åˆ
        
        # å¤šæ­¥è§„åˆ’ç»Ÿè®¡
        self.multi_step_stats = {
            'plans_created': 0,
            'plans_completed': 0,
            'plans_abandoned': 0,
            'average_plan_length': 0.0,
            'plan_success_rate': 0.0
        }
        
        if self.logger:
            self.logger.log(f"{self.name} ğŸ—ºï¸ å¤šæ­¥è§„åˆ’ç³»ç»Ÿå·²åˆå§‹åŒ–")

    def _select_ilai_action(self):
        """ILAIç­–ç•¥é€‰æ‹©åŠ¨ç‰© - ä¼˜å…ˆä½¿ç”¨V3å¢å¼ºå†³ç­–"""
        # é¦–å…ˆå°è¯•ä½¿ç”¨V3å¢å¼ºå†³ç­–
        if self.five_library_system_active and self.five_library_system:
            try:
                # è·å–å½“å‰æ¸¸æˆå¯¹è±¡
                game = getattr(self, 'current_game', None)
                if not game:
                    # å¦‚æœæ²¡æœ‰å­˜å‚¨çš„æ¸¸æˆå¯¹è±¡,å°è¯•ä»è°ƒç”¨æ ˆè·å–
                    import inspect
                    frame = inspect.currentframe()
                    try:
                        while frame:
                            if 'game' in frame.f_locals and hasattr(frame.f_locals['game'], 'players'):
                                game = frame.f_locals['game']
                                break
                            frame = frame.f_back
                    finally:
                        del frame
                
                if game:
                    v3_action = self._make_v3_enhanced_decision(game)
                    if v3_action and v3_action != self._get_default_exploration_action():
                        if logger:
                            logger.log(f"{self.name} ä½¿ç”¨V3å¢å¼ºå†³ç­–: {v3_action}")
                        return v3_action
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} V3å¢å¼ºå†³ç­–å¤±è´¥,å›é€€åˆ°ä¼ ç»ŸILAI: {str(e)}")
        
        # å›é€€ä½¿ç”¨ä¼ ç»ŸILAIå†³ç­–é€»è¾‘
        try:
            x, y = self.current_pos
            # æ£€æŸ¥æ°´é‡ä¸è¶³æ—¶å¯»æ‰¾æ°´æº
            if self.water < 30:
                water_sources = [resource for resource in self.game_map.resources if resource.type == "water"]
                if water_sources:
                    nearest_water = min(water_sources, key=lambda w: ((w.position[0] - x) ** 2 + (w.position[1] - y) ** 2) ** 0.5)
                    wx, wy = nearest_water.position
                    if (wx, wy) == (x, y):
                        return "drink"
                    elif abs(wx - x) > abs(wy - y):
                        return "right" if wx > x else "left"
                    else:
                        return "down" if wy > y else "up"
            
            # æ£€æŸ¥é£Ÿç‰©ä¸è¶³æ—¶å¯»æ‰¾é£Ÿç‰©
            if self.food < 30:
                food_sources = [resource for resource in self.game_map.resources if resource.type == "berry"]
                if food_sources:
                    nearest_food = min(food_sources, key=lambda f: ((f.position[0] - x) ** 2 + (f.position[1] - y) ** 2) ** 0.5)
                    fx, fy = nearest_food.position
                    if (fx, fy) == (x, y):
                        return "collect"
                    elif abs(fx - x) > abs(fy - y):
                        return "right" if fx > x else "left"
                    else:
                        return "down" if fy > y else "up"
            
            # å±é™©æ—¶èº²é¿æ•é£Ÿè€…
            for predator in self.game_map.predators:
                px, py = predator.position
                distance = ((px - x) ** 2 + (py - y) ** 2) ** 0.5
                if distance < 3:  # å½“æ•é£Ÿè€…è·ç¦»å°äº3æ ¼æ—¶èº²é¿
                    # å‘è¿œç¦»æ•é£Ÿè€…çš„æ–¹å‘ç§»åŠ¨
                    if abs(px - x) > abs(py - y):
                        return "left" if px > x else "right"
                    else:
                        return "up" if py > y else "down"
            
            # é»˜è®¤éšæœºç§»åŠ¨
            return random.choice(["up", "down", "left", "right"])
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ILAIå†³ç­–å¤±è´¥: {str(e)}")
            # å®Œå…¨å¤±è´¥æ—¶éšæœºé€‰æ‹©
            return random.choice(["up", "down", "left", "right"])

    def add_experience_to_direct_library(self, action, result, context=None):
        """æ·»åŠ EOCATRæ ¼å¼ç»éªŒåˆ°äº”åº“ç³»ç»Ÿ"""
        if not self.five_library_system_active or not self.five_library_system:
            if logger:
                logger.log(f"{self.name} äº”åº“ç³»ç»Ÿæœªæ¿€æ´», active={getattr(self, 'five_library_system_active', False)}, system={getattr(self, 'five_library_system', None) is not None}")
            return
        
        try:
            from five_library_system import EOCATRExperience
            
            # å®‰å…¨åœ°è·å–å¹¶è½¬æ¢å„ä¸ªå­—æ®µä¸ºå­—ç¬¦ä¸²
            def safe_convert_to_string(value, default="unknown"):
                """å®‰å…¨åœ°å°†ä»»ä½•å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                if value is None:
                    return default
                elif isinstance(value, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–æœ‰æ„ä¹‰çš„ä¿¡æ¯
                    if 'type' in value:
                        return str(value['type'])
                    elif 'name' in value:
                        return str(value['name'])
                    elif 'value' in value:
                        return str(value['value'])
                    else:
                        # å°†å­—å…¸è½¬æ¢ä¸ºç®€åŒ–çš„é”®å€¼å¯¹å­—ç¬¦ä¸²
                        return "_".join([f"{k}_{v}" for k, v in value.items() if isinstance(v, (str, int, float, bool))][:3])
                elif isinstance(value, (list, tuple)):
                    # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œè¿æ¥æˆå­—ç¬¦ä¸²
                    return "_".join([str(item) for item in value if isinstance(item, (str, int, float, bool))][:3])
                else:
                    return str(value)
            
            # æ„å»ºå®Œæ•´EOCATRç»éªŒå¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å­—ç¬¦ä¸²
            environment_raw = self._get_current_environment_detailed(context)
            object_raw = self._get_current_object_detailed(context)
            characteristics_raw = self._get_current_characteristics_detailed(context)
            tools_raw = self._get_current_tools_detailed(context)
            result_raw = self._enhance_result_detailed(result, action, context)
            
            experience = EOCATRExperience(
                environment=safe_convert_to_string(environment_raw, "å¼€é˜”åœ°"),
                object=safe_convert_to_string(object_raw, "æœªçŸ¥"),
                characteristics=safe_convert_to_string(characteristics_raw, "æ­£å¸¸"),
                action=safe_convert_to_string(action, "æœªçŸ¥åŠ¨ä½œ"),
                tools=safe_convert_to_string(tools_raw, "æ— "),
                result=safe_convert_to_string(result_raw, "æœªçŸ¥ç»“æœ"),
                player_id=str(self.name),
                timestamp=float(time.time()),
                success=self._evaluate_action_success(action, result, context),
                metadata={
                    'position': (int(self.x), int(self.y)),
                    'health': int(self.health),
                    'food': int(self.food),
                    'water': int(self.water),
                    'action_type': safe_convert_to_string(self._classify_action_type(action), "Other"),
                    'context_details': str(context) if context else "{}",
                    'decision_source': getattr(self, '_last_decision_source', 'unknown')
                }
            )
            
            # æ·»åŠ åˆ°äº”åº“ç³»ç»Ÿ
            add_result = self.five_library_system.add_experience_to_direct_library(experience)
            
            if logger:
                # æ˜¾ç¤ºå®Œæ•´çš„EOCATRæ ¼å¼ç»éªŒï¼ˆåŒ…å«å†³ç­–æ¥æºï¼‰
                decision_source = getattr(self, '_last_decision_source', 'unknown')
                eocatr_format = f"E:{experience.environment}, O:{experience.object}, C:{experience.characteristics}, A:{experience.action}, T:{experience.tools}, R:{experience.result}"
                logger.log(f"{self.name} æ·»åŠ ç»éªŒåˆ°äº”åº“ç³»ç»Ÿ [{eocatr_format}] -> {add_result}")
                logger.log(f"{self.name} ğŸ¯ å†³ç­–æ¥æº: {decision_source}")
                if not add_result.get('success'):
                    logger.log(f"{self.name} äº”åº“ç»éªŒæ·»åŠ ç»“æœ: {add_result}")
            
            # ğŸ”§ ä¿®å¤ï¼šåœ¨ç»éªŒæ·»åŠ åæ¸…ç†å·¥å…·ä½¿ç”¨çŠ¶æ€
            # é¿å…ä¸‹æ¬¡è¡ŒåŠ¨æ—¶ä»ç„¶ä½¿ç”¨ä¸Šæ¬¡çš„å·¥å…·è®°å½•
            if hasattr(self, 'current_selected_tool'):
                self.current_selected_tool = None
            if hasattr(self, '_last_used_tool'):
                self._last_used_tool = None
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} äº”åº“ç³»ç»Ÿç»éªŒæ·»åŠ å¤±è´¥: {str(e)}")
                import traceback
                logger.log(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    def _make_v3_enhanced_decision(self, game):
        """ä½¿ç”¨ç»Ÿä¸€å†³ç­–ç³»ç»Ÿçš„å¢å¼ºå†³ç­–æ–¹æ³•"""
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€å†³ç­–ç³»ç»Ÿ
        if hasattr(self, 'unified_decision_active') and self.unified_decision_active and hasattr(self, 'unified_decision_system'):
            try:
                # æ„å»ºEOCATRä¸Šä¸‹æ–‡
                current_context = {
                    'environment': self._get_current_environment_detailed(),
                    'object': self._get_current_object_detailed(),
                    'characteristics': self._get_current_characteristics_detailed(),
                    'player_id': self.name,
                    'urgency_level': self._calculate_urgency_level()
                }
                
                # ä½¿ç”¨ç»Ÿä¸€å†³ç­–ç³»ç»Ÿè¿›è¡Œå†³ç­–
                decision = self.unified_decision_system.make_decision(current_context)
                
                if decision and decision.recommended_action:
                    action = decision.recommended_action
                    confidence = decision.combined_confidence
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ç»Ÿä¸€å†³ç­–ç³»ç»Ÿå»ºè®®: {action} (ç½®ä¿¡åº¦: {confidence:.2f})")
                    
                    return action
                    
            except Exception as e:
                if self.logger:
                    self.logger.log(f"{self.name} ç»Ÿä¸€å†³ç­–ç³»ç»Ÿå¤±è´¥,å›é€€åˆ°äº”åº“ç³»ç»Ÿ: {str(e)}")
        
        # æ¬¡ä¼˜ä½¿ç”¨æ•´åˆå†³ç­–ç³»ç»Ÿ
        if hasattr(self, 'integrated_decision_active') and self.integrated_decision_active and self.integrated_decision_system:
            try:
                # æ„å»ºå†³ç­–ä¸Šä¸‹"""
                context = DecisionContext(
                    hp=self.hp,
                    food=self.food,
                    water=self.water,
                    position=(self.x, self.y),
                    day=getattr(game, 'current_day', 1),
                    environment=self._get_current_environment_type(game),
                    threats_nearby=len(self.detect_threats(game.game_map)) > 0,
                    resources_nearby=self._get_nearby_resources(game),
                    urgency_level=self._calculate_urgency_level()
                )
                
                # ä½¿ç”¨æ•´åˆå†³ç­–ç³»ç»Ÿè¿›è¡Œå†³ç­–
                decision_result = self.integrated_decision_system.make_integrated_decision(context, game)
                
                if decision_result.get('success') and decision_result.get('action'):
                    action = decision_result['action']
                    decision_source = decision_result.get('source', 'unknown')
                    confidence = decision_result.get('confidence', 0)
                    
                    if self.logger:
                        self.logger.log(f"{self.name} æ•´åˆå†³ç­–ç³»ç»Ÿå»ºè®®è¡ŒåŠ¨: {action} (æ¥æº: {decision_source}, ç½®ä¿¡åº¦: {confidence:.2f})")
                    
                    return action
                    
            except Exception as e:
                if self.logger:
                    self.logger.log(f"{self.name} æ•´åˆå†³ç­–ç³»ç»Ÿå¤±è´¥,å›é€€åˆ°äº”åº“ç³»ç»Ÿ: {str(e)}")
        
        # å›é€€åˆ°åŸæœ‰çš„äº”åº“ç³»ç»Ÿå†³ç­–
        if not self.five_library_system_active or not self.five_library_system:
            return self._get_default_exploration_action()
        
        try:
            # è·å–å½“å‰çŠ¶æ€
            current_context = {
                'hp': self.hp,
                'food': self.food,
                'water': self.water,
                'position': (self.x, self.y),
                'day': getattr(game, 'current_day', 1)
            }
            
            # ä»äº”åº“ç³»ç»Ÿè·å–å†³ç­–æ”¯"
            decision_result = self.five_library_system.generate_decision_from_context(
                context=current_context, 
                source='hybrid'
            )
            
            # åŸºäºäº”åº“ç³»ç»Ÿçš„å†³ç­–è¿›è¡Œè¡Œ"
            if decision_result.get('success') and decision_result.get('decision'):
                decision = decision_result['decision']
                action = decision.action
                confidence = decision_result.get('confidence', 0)
                decision_id = decision_result.get('decision_id')
                
                if self.logger:
                    self.logger.log(f"{self.name} äº”åº“ç³»ç»Ÿå»ºè®®è¡ŒåŠ¨: {action} (ç½®ä¿¡åº¦: {confidence:.2f})")
                
                # è®°å½•å†³ç­–å‰çŠ¶æ€
                pre_decision_state = {
                    'hp': self.hp,
                    'food': self.food, 
                    'water': self.water,
                    'position': (self.x, self.y)
                }
                
                # æ‰§è¡Œè¡ŒåŠ¨å¹¶è®°å½•ç»“"
                executed_action = action
                
                # ç®€åŒ–çš„å†³ç­–æˆåŠŸæ€§è¯„ä¼°(åŸºäºç”Ÿå­˜æŒ‡æ ‡å˜åŒ–"
                try:
                    # æ¨¡æ‹Ÿæ‰§è¡Œåçš„çŠ¶æ€è¯„"
                    decision_success = self._evaluate_decision_success_simple(action, current_context)
                    
                    # æ›´æ–°å†³ç­–åº“å"
                    if decision_id:
                        feedback_result = self.five_library_system.update_decision_feedback(
                            decision_id=decision_id,
                            success=decision_success,
                            result=f"è¡ŒåŠ¨:{action}, ä¸Šä¸‹ä»hp={self.hp},food={self.food},water={self.water}"
                        )
                        
                        if self.logger and feedback_result.get('success'):
                            self.logger.log(f"{self.name} å†³ç­–åé¦ˆå·²æ›´æ–°: {decision_id[:8]}... æˆåŠŸ:{decision_success}")
                
                except Exception as feedback_error:
                    if self.logger:
                        self.logger.log(f"{self.name} å†³ç­–åé¦ˆæ›´æ–°å¤±è´¥: {str(feedback_error)}")
                
                return executed_action
            
            # å¦‚æœæ²¡æœ‰å»ºè®®,ä½¿ç”¨é»˜è®¤æ¢"
            return self._get_default_exploration_action()
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} äº”åº“ç³»ç»Ÿå†³ç­–å¤±è´¥: {str(e)}")
            return self._get_default_exploration_action()
    
    def _get_nearby_resources(self, game):
        """è·å–é™„è¿‘çš„èµ„æºåˆ—è¡¨"""
        try:
            resources = []
            # æ£€æŸ¥é™„è¿‘çš„æ¤ç‰©
            for plant in game.game_map.plants:
                distance = max(abs(self.x - plant.x), abs(self.y - plant.y))
                if distance <= 3:  # 3æ ¼èŒƒå›´å†…
                    resources.append(plant.__class__.__name__)
            return resources
        except:
            return []
    
    def _calculate_urgency_level(self):
        """è®¡ç®—ç´§æ€¥ç¨‹åº¦(0.0-1.0)"""
        try:
            # åŸºäºç”Ÿå­˜æŒ‡æ ‡è®¡ç®—ç´§æ€¥ç¨‹åº¦
            hp_urgency = max(0, (50 - self.hp) / 50)  # è¡€é‡è¶Šä½è¶Šç´§æ€¥
            food_urgency = max(0, (30 - self.food) / 30)  # é£Ÿç‰©è¶Šå°‘è¶Šç´§æ€¥
            water_urgency = max(0, (30 - self.water) / 30)  # æ°´è¶Šå°‘è¶Šç´§æ€¥
            # å–æœ€é«˜ç´§æ€¥ç¨‹åº¦
            return max(hp_urgency, food_urgency, water_urgency)
        except:
            return 0.5  # é»˜è®¤ä¸­ç­‰ç´§æ€¥ç¨‹åº¦
    def _evaluate_decision_success_simple(self, action, context):
        """ç®€åŒ–çš„å†³ç­–æˆåŠŸæ€§è¯„ä¼°"""
        try:
            # åŸºäºè¡ŒåŠ¨ç±»å‹å’Œå½“å‰çŠ¶æ€çš„ç®€å•è¯„ä¼°
            if 'collect' in action.lower() or 'æ”¶é›†' in action:
                # æ”¶é›†è¡ŒåŠ¨:å¦‚æœé£Ÿç‰©æˆ–æ°´è¾ƒä½,è®¤ä¸ºæ˜¯å¥½å†³ç­–
                return context.get('food', 50) < 70 or context.get('water', 50) < 70
            
            elif 'explore' in action.lower() or 'æ¢ç´¢' in action:
                # æ¢ç´¢è¡ŒåŠ¨:å¦‚æœç”Ÿå­˜æŒ‡æ ‡è¾ƒå¥½,è®¤ä¸ºæ˜¯å¥½å†³ç­–
                return context.get('hp', 50) > 30 and context.get('food', 50) > 20
            
            elif 'drink' in action.lower() or 'å–æ°´' in action:
                # å–æ°´è¡ŒåŠ¨:å¦‚æœæ°´åˆ†è¾ƒä½,è®¤ä¸ºæ˜¯å¥½å†³ç­–
                return context.get('water', 50) < 50
            
            elif 'rest' in action.lower() or 'ä¼‘æ¯' in action:
                # ä¼‘æ¯è¡ŒåŠ¨:å¦‚æœè¡€é‡è¾ƒä½,è®¤ä¸ºæ˜¯å¥½å†³ç­–
                return context.get('hp', 50) < 60
            
            else:
                # å…¶ä»–è¡ŒåŠ¨:é»˜è®¤50%æˆåŠŸ
                import random
                return random.random() > 0.5
                
        except Exception as e:
            # è¯„ä¼°å¤±è´¥æ—¶é»˜è®¤ä¸ºæˆåŠŸ
            return True

    def enable_reinforcement_learning(self):
        """å¯ç”¨å¼ºåŒ–å­¦ä¹ ç»„ä»¶"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œå…¨åˆå§‹åŒ–ï¼ˆæ ‡å¿—ä¸ºTrueä¸”ç½‘ç»œå·²å­˜åœ¨ï¼‰
        if (self.use_reinforcement_learning and 
            self.q_network is not None and 
            self.target_network is not None):
            return True  # å·²ç»å®Œå…¨åˆå§‹åŒ–ï¼Œè¿”å›True
            
        try:
            self.logger.log(f"{self.name} å¯ç”¨å¼ºåŒ–å­¦ä¹ ç»„ä»¶")
            self.use_reinforcement_learning = True
            self.player_type = "RILAI"  # ä¿®æ”¹ç©å®¶ç±»å‹
            
            # åˆå§‹åŒ–ç½‘ç»œ
            network_init_result = self.initialize_networks()
            if not network_init_result:
                raise Exception("ç¥ç»ç½‘ç»œåˆå§‹åŒ–å¤±è´¥")
            
            # å°è¯•ä»ç£ç›˜åŠ è½½å·²æœ‰æ¨¡å‹
            self._load_model()
            
            self.logger.log(f"{self.name} å¼ºåŒ–å­¦ä¹ ç»„ä»¶å¯ç”¨æˆåŠŸ")
            return True
        except Exception as e:
            import traceback
            self.logger.log(f"{self.name} å¯ç”¨å¼ºåŒ–å­¦ä¹ ç»„ä»¶å¤±è´¥: {str(e)}")
            self.logger.log(traceback.format_exc())
            self.use_reinforcement_learning = False
            self.q_network = None
            self.target_network = None
            return False

    # === å¢å¼ºé—´æ¥ç»éªŒåº“åŠŸä»===
    
    def build_network(self):
        """æ„å»ºç¥ç»ç½‘ç»œï¼ˆRILAIå¼ºåŒ–å­¦ä¹ éƒ¨åˆ†ï¼‰"""
        try:
            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Dense, Dropout
            from tensorflow.keras.optimizers import Adam
            
            model = Sequential()
            # å¢åŠ æ¨¡å‹å¤æ‚åº¦ï¼Œæ·»åŠ Dropoutä»¥é¿å…è¿‡æ‹Ÿåˆ
            model.add(Dense(128, input_dim=self.state_size, activation='relu'))
            model.add(Dropout(0.2))
            model.add(Dense(256, activation='relu'))
            model.add(Dropout(0.2))
            model.add(Dense(128, activation='relu'))
            model.add(Dense(self.num_actions, activation='linear'))
            model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
            return model
        except Exception as e:
            import traceback
            self.logger.log(f"{self.name} æ„å»ºç¥ç»ç½‘ç»œå¤±è´¥: {str(e)}")
            self.logger.log(traceback.format_exc())
            return None

    def initialize_networks(self):
        """åˆå§‹åŒ–Qç½‘ç»œå’Œç›®æ ‡ç½‘ç»œ"""
        if self.q_network is not None and self.target_network is not None:
            return True  # å·²åˆå§‹åŒ–
            
        try:
            self.logger.log(f"{self.name} åˆå§‹åŒ–ç¥ç»ç½‘ç»œ...")
            
            # åˆ›å»ºQç½‘ç»œ
            self.q_network = self.build_network()
            if self.q_network is None:
                raise Exception("Qç½‘ç»œåˆ›å»ºå¤±è´¥")
            
            # åˆ›å»ºç›®æ ‡ç½‘ç»œ
            self.target_network = self.build_network()
            if self.target_network is None:
                raise Exception("ç›®æ ‡ç½‘ç»œåˆ›å»ºå¤±è´¥")
            
            # å¤åˆ¶Qç½‘ç»œæƒé‡åˆ°ç›®æ ‡ç½‘ç»œ
            self.target_network.set_weights(self.q_network.get_weights())
            
            self.logger.log(f"{self.name} ç¥ç»ç½‘ç»œåˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            import traceback
            self.logger.log(f"{self.name} ç¥ç»ç½‘ç»œåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.logger.log(traceback.format_exc())
            self.q_network = None
            self.target_network = None
            return False

    def select_action(self, state):
        """ä½¿ç”¨ epsilon-greedy ç­–ç•¥é€‰æ‹©åŠ¨ä½œï¼ˆRILAIå¼ºåŒ–å­¦ä¹ éƒ¨åˆ†ï¼‰"""
        try:
            # ç¡®ä¿ç½‘ç»œå·²åˆå§‹åŒ–
            if self.q_network is None:
                self.logger.log(f"{self.name} Qç½‘ç»œæœªåˆå§‹åŒ–,å°è¯•åˆå§‹åŒ–...")
                if not self.initialize_networks():
                    self.logger.log(f"{self.name} æ— æ³•åˆå§‹åŒ–ç½‘ç»œ,å›é€€åˆ°ILAIç­–ç•¥")
                    return self._select_ilai_action()
            
            # ä»¥epsilonçš„æ¦‚ç‡éšæœºé€‰æ‹©åŠ¨ä½œ
            if np.random.rand() <= self.epsilon:
                action_idx = random.randrange(self.num_actions)
                self.logger.log(f"{self.name} RLæ¢ç´¢:éšæœºé€‰æ‹©åŠ¨ä½œ {self.actions[action_idx]}")
                return self.actions[action_idx]
            
            # å¦åˆ™é€‰æ‹©Qå€¼æœ€å¤§çš„åŠ¨ä½œ
            act_values = self.q_network.predict(state.reshape(1, -1), verbose=0)
            action_idx = np.argmax(act_values[0])
            self.logger.log(f"{self.name} RLåˆ©ç”¨:é€‰æ‹©Qå€¼æœ€å¤§çš„åŠ¨ä½œ {self.actions[action_idx]}")
            return self.actions[action_idx]
        except Exception as e:
            import traceback
            self.logger.log(f"{self.name} RLé€‰æ‹©åŠ¨ä½œå¤±è´¥: {str(e)}")
            self.logger.log(traceback.format_exc())
            self.logger.log(f"{self.name} å›é€€åˆ°ILAIç­–ç•¥")
            return self._select_ilai_action()
    
    def initialize_social_learning(self):
        """åˆå§‹åŒ–ç¤¾äº¤å­¦ä¹ æœºåˆ¶"""
        # ä¿¡ä»»ç½‘ç»œ:è®°å½•å¯¹å…¶ä»–æ™ºèƒ½ä½“çš„ä¿¡ä»»åº¦
        self.trust_network = {}  # {agent_name: trust_score}
        
        # ç¤¾äº¤å­¦ä¹ é…ç½®
        self.social_learning_config = {
            'communication_range': 5,  # é€šä¿¡èŒƒå›´
            'min_trust_threshold': 0.3,  # æ¥å—ä¿¡æ¯çš„æœ€ä½ä¿¡ä»»é˜ˆå€¼
            'experience_share_probability': 0.3,  # åˆ†äº«ç»éªŒçš„æ¦‚ç‡
            'trust_decay_rate': 0.98,  # ä¿¡ä»»åº¦è¡°å‡ç‡
            'max_shared_experiences': 3,  # æ¯æ¬¡æœ€å¤šåˆ†äº«çš„ç»éªŒæ•°
        }
        
        # é—´æ¥ç»éªŒè´¨é‡è·Ÿè¸ª
        self.indirect_experience_quality = {}  # {experience_id: quality_metrics}
        
        # ç¤¾äº¤å­¦ä¹ ç»Ÿè®¡
        self.social_learning_stats = {
            'experiences_shared': 0,
            'experiences_received': 0,
            'trust_updates': 0,
            'successful_applications': 0,
            'failed_applications': 0
        }
        
        if self.logger:
            self.logger.log(f"{self.name} ç¤¾äº¤å­¦ä¹ æœºåˆ¶åˆå§‹åŒ–å®Œæˆ")

    def find_nearby_learners(self, game):
        """å¯»æ‰¾é™„è¿‘çš„å­¦ä¹ å‹æ™ºèƒ½ä½“(ILAI/RILAI)"""
        if not hasattr(self, 'current_pos'):
            return []
            
        nearby_learners = []
        communication_range = self.social_learning_config['communication_range']
        
        for player in game.players:
            if (player != self and 
                player.is_alive() and 
                hasattr(player, 'indirect_experience_base') and  # ç¡®ä¿æ˜¯å­¦ä¹ å‹æ™ºèƒ½ä½“
                                    (isinstance(player, ILAIPlayer) or player.player_type in ["ILAI", "RILAI"])):
                
                # è®¡ç®—è·ç¦»
                if hasattr(player, 'current_pos'):
                    distance = max(abs(self.current_pos[0] - player.current_pos[0]),
                                 abs(self.current_pos[1] - player.current_pos[1]))
                    
                    if distance <= communication_range:
                        nearby_learners.append((player, distance))
        
        # æŒ‰è·ç¦»æ’åº,ä¼˜å…ˆä¸è¿‘è·ç¦»æ™ºèƒ½ä½“äº¤äº’
        nearby_learners.sort(key=lambda x: x[1])
        return [player for player, _ in nearby_learners]

    def select_experiences_to_share(self):
        """é€‰æ‹©æœ‰ä»·å€¼çš„ç»éªŒè¿›è¡Œåˆ†äº«"""
        experiences_to_share = []
        max_share = self.social_learning_config['max_shared_experiences']
        
        # ä»ç›´æ¥ç»éªŒåº“ä¸­é€‰æ‹©é«˜ä»·å€¼ç»éªŒ
        if self.direct_experience_base:
            # è®¡ç®—æ¯ä¸ªç»éªŒçš„åˆ†äº«ä»·å€¼
            scored_experiences = []
            for exp in self.direct_experience_base[-20:]:  # åªè€ƒè™‘æœ€è¿‘çš„20ä¸ªç»éªŒ
                score = self._calculate_experience_share_value(exp)
                if score > 0.5:  # åªåˆ†äº«é«˜ä»·å€¼ç»éªŒ
                    scored_experiences.append((exp, score))
            
            # æŒ‰åˆ†äº«ä»·å€¼æ’åº
            scored_experiences.sort(key=lambda x: x[1], reverse=True)
            
            # é€‰æ‹©å‰Nä¸ªç»éªŒåˆ†äº«
            for exp, score in scored_experiences[:max_share]:
                exp_to_share = exp.copy()
                exp_to_share['share_value'] = score
                exp_to_share['source'] = self.name
                exp_to_share['timestamp'] = len(self.direct_experience_base)
                experiences_to_share.append(exp_to_share)
        
        return experiences_to_share

    def _calculate_experience_share_value(self, experience):
        """è®¡ç®—ç»éªŒçš„åˆ†äº«ä»·å€¼"""
        base_value = 0.0
        
        # æˆåŠŸç»éªŒæ›´æœ‰ä»·å€¼
        if experience.get('result', {}).get('success', False):
            base_value += 0.4
        
        # ç¨€æœ‰ç»éªŒ(å¾ˆå°‘é‡åˆ°çš„æƒ…å†µ)æ›´æœ‰ä»·å€¼
        object_type = experience.get('object', '')
        action_type = experience.get('action', '')
        
        # è®¡ç®—è¯¥ç±»å‹ç»éªŒçš„ç¨€æœ‰åº¦
        similar_count = sum(1 for exp in self.direct_experience_base 
                          if exp.get('object') == object_type and exp.get('action') == action_type)
        
        if similar_count <= 3:  # ç¨€æœ‰ç»"
            base_value += 0.3
        elif similar_count <= 10:  # è¾ƒç¨€æœ‰ç»éªŒ
            base_value += 0.2
        
        # è¿‘æœŸç»éªŒæ›´æœ‰ä»·å€¼
        recent_bonus = 0.1 if experience.get('timestamp', 0) > len(self.direct_experience_base) - 10 else 0
        base_value += recent_bonus
        
        # æ¶‰åŠå±é™©æƒ…å†µçš„ç»éªŒæ›´æœ‰ä»·å€¼
        if 'danger' in str(experience.get('context', '')).lower():
            base_value += 0.2
        
        return min(base_value, 1.0)  # æœ€å¤§å€¼ä¸º1.0

    def share_information_with(self, nearby_learners):
        """ä¸é™„è¿‘çš„å­¦ä¹ å‹æ™ºèƒ½ä½“åˆ†äº«ä¿¡æ¯"""
        if not nearby_learners:
            return
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šçŸ¥è¯†åˆ†äº«é¢‘ç‡æ§åˆ¶
        if not hasattr(self, 'last_knowledge_share_round'):
            self.last_knowledge_share_round = 0
        if not hasattr(self, 'knowledge_share_count_this_round'):
            self.knowledge_share_count_this_round = 0
        
        current_round = getattr(self, 'current_round', 1)
        
        # é‡ç½®æ¯å›åˆçš„åˆ†äº«è®¡æ•°
        if current_round != self.last_knowledge_share_round:
            self.knowledge_share_count_this_round = 0
            self.last_knowledge_share_round = current_round
        
        # æ¯5å›åˆæ‰å…è®¸åˆ†äº«ï¼Œæ¯å›åˆæœ€å¤š2æ¬¡
        if current_round % 5 != 0 or self.knowledge_share_count_this_round >= 2:
            return
        
        self.knowledge_share_count_this_round += 1
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ†äº«ä¿¡æ¯
        import random
        if random.random() > self.social_learning_config['experience_share_probability']:
            return
        
        experiences_to_share = self.select_experiences_to_share()
        if not experiences_to_share:
            return
        
        shared_count = 0
        for learner in nearby_learners:
            if shared_count >= len(experiences_to_share):
                break
                
            # é€‰æ‹©ä¸è¯¥æ™ºèƒ½ä½“åˆ†äº«çš„ç»éªŒ
            for experience in experiences_to_share:
                if hasattr(learner, 'receive_information'):
                    learner.receive_information(self, experience)
                    shared_count += 1
                    
                    # ä¿®å¤:ä½¿ç”¨å…¨å±€loggerè€Œä¸æ˜¯self.logger
                    if logger:
                        logger.log(f"{self.name} ä»{learner.name} åˆ†äº«ç»éªŒ: {experience.get('object', '')}+{experience.get('action', '')}")
        
        # æ›´æ–°ç»Ÿè®¡
        self.social_learning_stats['experiences_shared'] += shared_count
        
        # ğŸ”§ ä¿®å¤ï¼šè®°å½•ä¿¡æ¯åˆ†äº«ç»Ÿè®¡
        if shared_count > 0:
            self._record_info_sharing(shared_count)
            
            # çŸ¥è¯†åˆ†äº«ç»Ÿè®¡å·²åœ¨æ–¹æ³•å¼€å¤´æ›´æ–°

    def receive_information(self, sender, information):
        """æ¥æ”¶å…¶ä»–æ™ºèƒ½ä½“åˆ†äº«çš„ä¿¡æ¯"""
        # ç¡®ä¿å‘é€è€…æ˜¯å­¦ä¹ å‹æ™ºèƒ½ä½“
        if not (isinstance(sender, ILAIPlayer) or sender.player_type in ["ILAI", "RILAI"]):
            return
        
        # è¯„ä¼°ä¿¡æ¯å¯ä¿¡åº¦
        credibility = self._evaluate_information_credibility(sender, information)
        
        # å¦‚æœå¯ä¿¡åº¦è¶³å¤Ÿé«˜,æ·»åŠ åˆ°é—´æ¥ç»éªŒåº“
        min_trust = self.social_learning_config['min_trust_threshold']
        if credibility >= min_trust:
            # æ·»åŠ å‘é€è€…å’Œå¯ä¿¡åº¦ä¿¡æ¯
            enhanced_info = information.copy()
            enhanced_info['source'] = sender.name
            enhanced_info['credibility'] = credibility
            enhanced_info['received_timestamp'] = len(self.indirect_experience_base)
            enhanced_info['verification_status'] = 'pending'
            
            # æ£€æŸ¥é‡å¤
            if not self._is_duplicate_information(enhanced_info):
                self.indirect_experience_base.append(enhanced_info)
                
                # é™åˆ¶é—´æ¥ç»éªŒåº“å¤§å°
                if len(self.indirect_experience_base) > 200:
                    # ç§»é™¤æœ€æ—§çš„ä½å¯ä¿¡åº¦ç»éªŒ
                    self.indirect_experience_base.sort(key=lambda x: (x.get('credibility', 0), x.get('received_timestamp', 0)))
                    self.indirect_experience_base = self.indirect_experience_base[50:]  # ä¿ç•™é«˜è´¨é‡çš„150ä¸ªç»éªŒ
                # æ›´æ–°ç»Ÿè®¡
                self.social_learning_stats['experiences_received'] += 1
                
                # ä¿®å¤:ä½¿ç”¨å…¨å±€loggerè€Œä¸æ˜¯self.logger
                if logger:
                    logger.log(f"{self.name} æ¥å—æ¥è‡ª {sender.name} çš„ç»éªŒ,å¯ä¿¡åº¦: {credibility:.2f}")
            
            # æ›´æ–°å¯¹å‘é€è€…çš„ä¿¡ä»»åº¦
            self._update_trust_score(sender.name, credibility)

    def _evaluate_information_credibility(self, sender, information):
        """è¯„ä¼°æ¥æ”¶ä¿¡æ¯çš„å¯ä¿¡åº¦"""
        base_credibility = 0.5  # åŸºç¡€å¯ä¿¡åº¦
        # åŸºäºå†å²ä¿¡ä»»åº¦
        trust_score = self.trust_network.get(sender.name, 0.5)
        base_credibility = 0.3 * base_credibility + 0.7 * trust_score
        
        # åŸºäºå‘é€è€…çš„ç”Ÿå­˜è¡¨ç°
        if hasattr(sender, 'health') and hasattr(sender, 'food') and hasattr(sender, 'water'):
            survival_score = (sender.health + sender.food + sender.water) / 300.0  # å‡è®¾æœ€å¤§å€¼å„ä¸ª00
            base_credibility += 0.1 * survival_score
        
        # åŸºäºä¿¡æ¯å†…å®¹çš„åˆç†"
        content_credibility = self._assess_information_content(information)
        base_credibility = 0.7 * base_credibility + 0.3 * content_credibility
        
        # åŸºäºä¿¡æ¯çš„å…·ä½“ç¨‹åº¦(è¶Šå…·ä½“å¯ä¿¡åº¦è¶Šé«˜"
        if information.get('context') and information.get('result'):
            base_credibility += 0.1
        
        return max(0.0, min(1.0, base_credibility))

    def _assess_information_content(self, information):
        """è¯„ä¼°ä¿¡æ¯å†…å®¹çš„åˆç†æ€§"""
        credibility = 0.5
        
        # æ£€æŸ¥ä¿¡æ¯ç»“æ„å®Œæ•´"""
        required_fields = ['object', 'action', 'context', 'result']
        present_fields = sum(1 for field in required_fields if field in information)
        credibility += 0.1 * (present_fields / len(required_fields))
        
        # æ£€æŸ¥ç»“æœçš„åˆç†"
        result = information.get('result', {})
        if isinstance(result, dict):
            # æˆåŠŸç‡ä¸åº”è¯¥å¼‚å¸¸"
            if result.get('success') and information.get('share_value', 0) < 0.9:
                credibility += 0.1
            
            # æ£€æŸ¥æ•°å€¼çš„åˆç†"
            health_change = result.get('health_change', 0)
            if -50 <= health_change <= 50:  # åˆç†çš„å¥åº·å˜åŒ–èŒƒ"
                credibility += 0.1
        
        return max(0.0, min(1.0, credibility))

    def _is_duplicate_information(self, new_info):
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤ä¿¡æ¯"""
        for existing_info in self.indirect_experience_base:
            if (existing_info.get('object') == new_info.get('object') and
                existing_info.get('action') == new_info.get('action') and
                existing_info.get('source') == new_info.get('source')):
                
                # å¦‚æœæ–°ä¿¡æ¯å¯ä¿¡åº¦æ›´é«˜,å…è®¸æ›´"""
                if new_info.get('credibility', 0) > existing_info.get('credibility', 0):
                    self.indirect_experience_base.remove(existing_info)
                    return False
                return True
        return False

    def _update_trust_score(self, agent_name, interaction_result):
        """æ›´æ–°å¯¹ç‰¹å®šæ™ºèƒ½ä½“çš„ä¿¡ä»»åº¦"""
        current_trust = self.trust_network.get(agent_name, 0.5)
        
        # åŸºäºäº¤äº’ç»“æœè°ƒæ•´ä¿¡ä»»åº¦
        if interaction_result > 0.7:
            # é«˜è´¨é‡ä¿¡æ¯,å¢åŠ ä¿¡ä»»
            new_trust = current_trust + 0.1 * (1.0 - current_trust)
        elif interaction_result > 0.5:
            # ä¸­ç­‰è´¨é‡ä¿¡æ¯,å°å¹…å¢åŠ ä¿¡"""
            new_trust = current_trust + 0.05 * (1.0 - current_trust)
        else:
            # ä½è´¨é‡ä¿¡æ¯,é™ä½ä¿¡ä»»
            new_trust = current_trust * 0.9
        
        self.trust_network[agent_name] = max(0.1, min(1.0, new_trust))
        self.social_learning_stats['trust_updates'] += 1

    def decay_trust_scores(self):
        """å®šæœŸè¡°å‡ä¿¡ä»»åº¦(æ¨¡æ‹Ÿæ—¶é—´å¯¹ä¿¡ä»»çš„å½±å“)"""
        decay_rate = self.social_learning_config['trust_decay_rate']
        for agent_name in self.trust_network:
            self.trust_network[agent_name] *= decay_rate
            self.trust_network[agent_name] = max(0.1, self.trust_network[agent_name])

    def get_relevant_indirect_experiences(self, context_filter=None, min_credibility=0.6):
        """è·å–ç›¸å…³çš„é—´æ¥ç»éªŒ"""
        relevant_experiences = []
        
        for exp in self.indirect_experience_base:
            # æ£€æŸ¥å¯ä¿¡åº¦
            if exp.get('credibility', 0) < min_credibility:
                continue
            
            # æ£€æŸ¥ä¸Šä¸‹æ–‡åŒ¹é…
            if context_filter:
                if not self._matches_context(exp, context_filter):
                    continue
            
            relevant_experiences.append(exp)
        
        # æŒ‰å¯ä¿¡åº¦å’Œæ—¶é—´æ’"""
        relevant_experiences.sort(
            key=lambda x: (x.get('credibility', 0), x.get('received_timestamp', 0)),
            reverse=True
        )
        
        return relevant_experiences

    def _matches_context(self, experience, context_filter):
        """æ£€æŸ¥ç»éªŒæ˜¯å¦åŒ¹é…ç»™å®šä¸Šä¸‹æ–‡"""
        exp_context = experience.get('context', {})
        
        if isinstance(context_filter, dict) and isinstance(exp_context, dict):
            # æ£€æŸ¥å…³é”®å­—æ®µåŒ¹"""
            for key, value in context_filter.items():
                if key in exp_context and exp_context[key] != value:
                    return False
            return True
        
        # ç®€å•å­—ç¬¦ä¸²åŒ¹é…
        return str(context_filter).lower() in str(exp_context).lower()

    def integrate_indirect_experiences_in_decision(self, current_context):
        """åœ¨å†³ç­–è¿‡ç¨‹ä¸­æ•´åˆé—´æ¥ç»éªŒ"""
        if not self.indirect_experience_base:
            return {}
        
        # è·å–ç›¸å…³çš„é—´æ¥ç»"""
        relevant_experiences = self.get_relevant_indirect_experiences(current_context)
        
        if not relevant_experiences:
            return {}
        
        # ç»Ÿè®¡é—´æ¥ç»éªŒçš„è¡ŒåŠ¨å"
        action_preferences = {}
        total_weight = 0
        
        for exp in relevant_experiences[:10]:  # åªè€ƒè™‘ä¸ª0ä¸ªæœ€ç›¸å…³çš„ç»"
            action = exp.get('action', '')
            credibility = exp.get('credibility', 0)
            success = exp.get('result', {}).get('success', False)
            
            # è®¡ç®—æƒé‡(å¯ä¿¡åº¦ Ã— æˆåŠŸç‡)
            weight = credibility * (1.5 if success else 0.5)
            
            if action in action_preferences:
                action_preferences[action] += weight
            else:
                action_preferences[action] = weight
            
            total_weight += weight
        
        # å½’ä¸€åŒ–æƒ"
        if total_weight > 0:
            for action in action_preferences:
                action_preferences[action] /= total_weight
        
        return action_preferences

    def perform_social_learning_update(self, game):
        """æ‰§è¡Œç¤¾äº¤å­¦ä¹ æ›´æ–°(æ¯å›åˆè°ƒç”¨)"""
        if not hasattr(self, 'trust_network'):
            self.initialize_social_learning()
        
        # å¯»æ‰¾é™„è¿‘çš„å­¦ä¹ å‹æ™ºèƒ½ä½“
        nearby_learners = self.find_nearby_learners(game)
        
        # åˆ†äº«ä¿¡æ¯
        if nearby_learners:
            self.share_information_with(nearby_learners)
        
        # å®šæœŸè¡°å‡ä¿¡ä»»åº¦
        if len(self.direct_experience_base) % 10 == 0:  # æ¯10ä¸ªç»éªŒå‘¨æœŸæ‰§è¡Œä¸€æ¬¡
            self.decay_trust_scores()

    def get_social_learning_statistics(self):
        """è·å–ç¤¾äº¤å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        if not hasattr(self, 'social_learning_stats'):
            return {}
        
        stats = self.social_learning_stats.copy()
        stats['indirect_experience_count'] = len(self.indirect_experience_base)
        stats['trust_network_size'] = len(getattr(self, 'trust_network', {}))
        stats['average_trust'] = sum(self.trust_network.values()) / len(self.trust_network) if self.trust_network else 0
        
        return stats
            
    # === åŸæœ‰æ–¹æ³•ç»§ç»­ ===

    def update_phase(self, current_day):
        if current_day <= 20:
            self.phase = "åˆæœŸ"
        elif current_day <= 80:
            self.phase = "ä¸­æœŸ"
        else:
            self.phase = "åæœŸ"

    def act(self):
        """æ‰§è¡ŒåŠ¨ç‰©:æ··åˆå†³ç­–æœºåˆ¶,ç»“åˆRLå’Œè§„åˆ™æ–¹æ³•"""
        try:
            # è®°å½•æ—§ä½ç½®
            if hasattr(self, 'current_pos'):
                self.last_pos = self.current_pos
            
            # åˆå§‹åŒ–æ¢ç´¢åœ°å›¾(å¦‚æœä¸å­˜åœ¨)
            if not hasattr(self, 'exploration_map'):
                self.exploration_map = set()
                if hasattr(self, 'current_pos'):
                    self.exploration_map.add(self.current_pos)
            
            # å¦‚æœæ˜¯RILAIç©å®¶ä¸”RLç»„ä»¶å·²å¯ç”¨
            if self.player_type == "RILAI" and self.use_reinforcement_learning:
                # æ£€æŸ¥å±é™©çŠ¶æ€,å†³å®šæ˜¯å¦ä½¿ç”¨ILAIé€»è¾‘
                danger_situation = self._check_danger_situation()
                
                if danger_situation:
                    logger.log(f"{self.name} æ£€æµ‹åˆ°å±é™©æƒ…å†µ,ä½¿ç”¨ILAIç­–ç•¥")
                    action = self._select_ilai_action()
                    logger.log(f"{self.name} ILAIé€‰æ‹©åŠ¨ç‰©: {action}")
                    # æ ‡è®°å†³ç­–æ¥æºä¸ºILAI
                    self._last_decision_source = "ilai_danger_response"
                else:
                    # ä½¿ç”¨RLç­–ç•¥
                    try:
                        # è·å–å½“å‰çŠ¶æ€
                        state = self.get_state()
                        # é€‰æ‹©åŠ¨ç‰©
                        action = self.select_action(state)
                        logger.log(f"{self.name} RLé€‰æ‹©åŠ¨ç‰©: {action}")
                        # æ ‡è®°å†³ç­–æ¥æºä¸ºå¼ºåŒ–å­¦ä¹ 
                        self._last_decision_source = "reinforcement_learning"
                    except Exception as e:
                        logger.log(f"{self.name} RLè¡Œä¸ºæ‰§è¡Œå¤±è´¥: {str(e)}")
                        # å›é€€åˆ°ILAIç­–ç•¥
                        action = self._select_ilai_action()
                        logger.log(f"{self.name} å›é€€åˆ°ILAI,é€‰æ‹©åŠ¨ç‰©: {action}")
                        # æ ‡è®°å†³ç­–æ¥æºä¸ºILAIå›é€€
                        self._last_decision_source = "ilai_fallback"
                
                # æ‰§è¡Œé€‰å®šçš„åŠ¨ç‰©
                self._execute_action(action)
                
                # è·å–æ–°çŠ¶æ€å’Œå¥–åŠ±
                next_state = self.get_state()
                reward = self.calculate_reward(action)
                
                # åˆ¤æ–­æ˜¯å¦æ¸¸æˆç»“æŸ
                done = self.health <= 0
                
                # å¦‚æœä¸Šä¸€ä¸ªçŠ¶æ€å­˜åœ¨,å­˜å‚¨ç»éªŒ
                if hasattr(self, 'last_state') and self.last_state is not None:
                    self.remember(self.last_state, self.last_action, self.last_reward, state, False)
                
                # æ›´æ–°çŠ¶æ€
                self.last_state = state
                self.last_action = action
                self.last_reward = reward
                
                # è®­ç»ƒæ¨¡å‹
                if self.step_counter % self.train_frequency == 0:
                    self.replay()
            else:
                # çº¯ILAIç©å®¶ä½¿ç”¨åŸå§‹ç­–ç•¥
                action = self._select_ilai_action()
                # æ ‡è®°å†³ç­–æ¥æºä¸ºILAI
                self._last_decision_source = "ilai_standard"
                self._execute_action(action)
        except Exception as e:
            import traceback
            logger.log(f"{self.name} è¡ŒåŠ¨å¤±è´¥: {str(e)}")
            logger.log(traceback.format_exc())
            # åº”æ€¥è¡ŒåŠ¨:éšæœºç§»åŠ¨
            self._execute_random_move()
    
    def _check_danger_situation(self):
        """æ£€æŸ¥æ˜¯å¦å¤„äºå±é™©æƒ…å†µ(åº”è¯¥ä½¿ç”¨ILAIå†³ç­–)"""
        try:
            # æ£€æŸ¥å¥åº·çŠ¶æ€
            health_danger = self.health < 30
            
            # æ£€æŸ¥èµ„æºçŠ¶æ€
            water_danger = self.water < 20
            food_danger = self.food < 20
            
            # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰æ•é£Ÿè€…
            predator_danger = False
            if hasattr(self, 'current_pos'):
                x, y = self.current_pos
                for predator in self.game_map.predators:
                    px, py = predator.position
                    distance = ((px - x) ** 2 + (py - y) ** 2) ** 0.5
                    if distance < 3:  # 3æ ¼ä»¥å†…æœ‰æ•é£Ÿè€…è§†ä¸ºå±"""
                        predator_danger = True
                        break
            
            # ä»»ä½•ä¸€é¡¹å±é™©éƒ½ä½¿ç”¨ILAI
            return health_danger or water_danger or food_danger or predator_danger
        except Exception as e:
            logger.log(f"{self.name} æ£€æŸ¥å±é™©çŠ¶æ€å¤±è´¥: {str(e)}")
            return True  # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ä¸ºå±é™©
    
    def _execute_action(self, action):
        """æ‰§è¡ŒæŒ‡å®šçš„åŠ¨ç‰©"""
        # è®°å½•è¡ŒåŠ¨å‰çŠ¶æ€
        pre_action_state = {
            'health': self.health,
            'food': self.food,
            'water': self.water,
            'position': (self.x, self.y)
        }
        
        action_success = False
        
        try:
            if action == "up":
                old_y = self.y
                self.move_up()
                action_success = (self.y != old_y)
            elif action == "down":
                old_y = self.y
                self.move_down()
                action_success = (self.y != old_y)
            elif action == "left":
                old_x = self.x
                self.move_left()
                action_success = (self.x != old_x)
            elif action == "right":
                old_x = self.x
                self.move_right()
                action_success = (self.x != old_x)
            elif action == "drink":
                old_water = self.water
                self.drink_water()
                action_success = (self.water > old_water)
            elif action == "collect":
                # ä½¿ç”¨æ–°çš„ä¸»åŠ¨é‡‡é›†æ¤ç‰©æ–¹æ³•
                action_success = self.action_collect_plant(game)
            elif action == "attack":
                # ä¼˜å…ˆæ”»å‡»åŠ¨ç‰©ï¼Œå…¶æ¬¡æ”»å‡»æ•Œå¯¹ç©å®¶
                action_success = self.action_attack_animal(game)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŠ¨ç‰©ï¼Œå°è¯•æ”»å‡»æ•Œå¯¹ç©å®¶
                if not action_success and hasattr(self, 'current_pos'):
                    x, y = self.current_pos
                    enemy = None
                    min_dist = float('inf')
                    
                    for player in getattr(self.game_map, 'players', []):
                        if player != self and self.check_is_enemy(player):
                            if hasattr(player, 'current_pos') and player.current_pos is not None:
                                px, py = player.current_pos
                                dist = ((px - x) ** 2 + (py - y) ** 2) ** 0.5
                                if dist < min_dist and dist <= 1:  # åªæ”»å‡»ç›¸é‚»æ ¼å­çš„æ•Œäºº
                                    min_dist = dist
                                    enemy = player
                    
                    if enemy is not None:
                        old_enemy_health = enemy.health if hasattr(enemy, 'health') else 100
                        self.attack_player(enemy)
                        new_enemy_health = enemy.health if hasattr(enemy, 'health') else 100
                        action_success = (new_enemy_health < old_enemy_health)
            else:
                # æœªçŸ¥åŠ¨ç‰©,éšæœºç§»åŠ¨
                self._execute_random_move()
                action_success = False
                
        except Exception as e:
            logger.log(f"{self.name} æ‰§è¡ŒåŠ¨ç‰© {action} å¤±è´¥: {str(e)}")
            # åº”æ€¥è¡ŒåŠ¨:éšæœºç§»åŠ¨
            self._execute_random_move()
            action_success = False
        
        # === 2.0.0ç‰ˆæœ¬æ–°å¢:è®°å½•EOCATRç»éªŒåˆ°BPMç³»ç»Ÿ ===
        try:
            # è®°å½•è¡ŒåŠ¨åçŠ¶æ€
            post_action_state = {
                'health': self.health,
                'food': self.food,
                'water': self.water,
                'position': (self.x, self.y)
            }
            
            # è®¡ç®—è¡ŒåŠ¨ç»“æœ
            result = {
                'success': action_success,
                'health_change': post_action_state['health'] - pre_action_state['health'],
                'food_change': post_action_state['food'] - pre_action_state['food'],
                'water_change': post_action_state['water'] - pre_action_state['water'],
                'position_change': (
                    post_action_state['position'][0] - pre_action_state['position'][0],
                    post_action_state['position'][1] - pre_action_state['position'][1]
                )
            }
            
            # æ·»åŠ EOCATRç»éªŒï¼ˆåŒ…å«å†³ç­–æ¥æºæ ‡è¯†ï¼‰
            decision_source = getattr(self, '_last_decision_source', 'action_execution')
            self.add_eocar_experience(action, result, source=decision_source)
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®°å½•EOCATRç»éªŒå¤±è´¥: {str(e)}")
    
    def _execute_random_move(self):
        """æ‰§è¡Œéšæœºç§»åŠ¨(åº”æ€¥ç­–ç•¥)"""
        try:
            move_action = random.choice(["up", "down", "left", "right"])
            if move_action == "up":
                self.move_up()
            elif move_action == "down":
                self.move_down()
            elif move_action == "left":
                self.move_left()
            elif move_action == "right":
                self.move_right()
        except Exception as e:
            logger.log(f"{self.name} éšæœºç§»åŠ¨ä¹Ÿå¤±è´¥äº†: {str(e)}")
            # å®åœ¨æ²¡åŠæ³•äº†,æ”¾å¼ƒæœ¬å›åˆè¡ŒåŠ¨
            pass
    
    def move_up(self):
        """å‘ä¸Šç§»åŠ¨"""
        old_pos = (self.x, self.y)
        # ä½¿ç”¨å­˜å‚¨çš„game_mapå¼•ç”¨,å¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»å·²çŸ¥ä½ç½®æ¨æ–­
        if hasattr(self, 'game_map') and self.game_map:
            success = self.move(0, -1, self.game_map)
        else:
            # ç›´æ¥æ›´æ–°ä½ç½®,ä¸è¿›è¡Œè¾¹ç•Œæ£€æŸ¥(å…œåº•ç­–ç•¥)
            self.y = max(0, self.y - 1)
            success = True
        
        # æ›´æ–°ä½ç½®è·Ÿè¸ª
        if success and (self.x, self.y) != old_pos:
            self.last_pos = old_pos
            self.current_pos = (self.x, self.y)
            if hasattr(self, 'visited_positions'):
                self.visited_positions.add(self.current_pos)
    
    def move_down(self):
        """å‘ä¸‹ç§»åŠ¨"""
        old_pos = (self.x, self.y)
        if hasattr(self, 'game_map') and self.game_map:
            success = self.move(0, 1, self.game_map)
        else:
            self.y = self.y + 1
            success = True
        
        # æ›´æ–°ä½ç½®è·Ÿè¸ª
        if success and (self.x, self.y) != old_pos:
            self.last_pos = old_pos
            self.current_pos = (self.x, self.y)
            if hasattr(self, 'visited_positions'):
                self.visited_positions.add(self.current_pos)
    
    def move_left(self):
        """å‘å·¦ç§»åŠ¨"""
        old_pos = (self.x, self.y)
        if hasattr(self, 'game_map') and self.game_map:
            success = self.move(-1, 0, self.game_map)
        else:
            self.x = max(0, self.x - 1)
            success = True
        
        # æ›´æ–°ä½ç½®è·Ÿè¸ª
        if success and (self.x, self.y) != old_pos:
            self.last_pos = old_pos
            self.current_pos = (self.x, self.y)
            if hasattr(self, 'visited_positions'):
                self.visited_positions.add(self.current_pos)
    
    def move_right(self):
        """å‘å³ç§»åŠ¨"""
        old_pos = (self.x, self.y)
        if hasattr(self, 'game_map') and self.game_map:
            success = self.move(1, 0, self.game_map)
        else:
            self.x = self.x + 1
            success = True
        
        # æ›´æ–°ä½ç½®è·Ÿè¸ª
        if success and (self.x, self.y) != old_pos:
            self.last_pos = old_pos
            self.current_pos = (self.x, self.y)
            if hasattr(self, 'visited_positions'):
                self.visited_positions.add(self.current_pos)
    
    def check_is_enemy(self, player):
        """åˆ¤æ–­å¦ä¸€ä¸ªç©å®¶æ˜¯å¦æ˜¯æ•Œäºº"""
        # ç®€å•å®ç°:ä¿¡èª‰ä½äº30çš„è§†ä¸ºæ•Œäºº
        return player.reputation < 30

    def collect_food(self):
        """å…¼å®¹æ€§æ–¹æ³•ï¼šé‡‡é›†é£Ÿç‰©ï¼ˆå·²å¼ƒç”¨ï¼Œä½¿ç”¨action_collect_plantä»£æ›¿ï¼‰"""
        logger.log(f"{self.name} attempts to use deprecated collect_food method")
        pass

    def drink_water(self):
        """å–æ°´æ–¹æ³•"""
        # æ£€æŸ¥å½“å‰ä½ç½®æ˜¯å¦æœ‰æ°´æº
        if hasattr(self, 'game_map') and self.game_map:
            current_cell = self.game_map.grid[self.y][self.x]
            if current_cell in ["river", "puddle"]:
                old_water = self.water
                self.water = min(100, self.water + 30)
                return self.water > old_water
        return False

    def take_turn(self, game):
        """ä¼˜åŒ–çš„ILAIå†³ç­–æµç¨‹ - èµ„æºé€‚åº”æ€§å†³ç­–"""
        if not self.is_alive():
            return
        
        # === å¤šæ­¥è§„åˆ’æ‰§è¡Œé€»è¾‘ ===
        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„è®¡åˆ’
        if self.current_plan is not None:
            if logger:
                logger.log(f"{self.name} ğŸ—ºï¸ ç»§ç»­æ‰§è¡Œå¤šæ­¥è®¡åˆ’ (æ­¥éª¤ {self.current_plan_step + 1}/{len(self.current_plan.get('steps', []))})")
            
            plan_result = self._execute_next_plan_step(game)
            if plan_result['status'] == 'completed':
                if logger:
                    logger.log(f"{self.name} âœ… å¤šæ­¥è®¡åˆ’æ‰§è¡Œå®Œæˆ")
                self.multi_step_stats['plans_completed'] += 1
                self._reset_plan_state()
                return  # è®¡åˆ’å®Œæˆï¼Œç»“æŸæœ¬å›åˆ
            elif plan_result['status'] == 'failed':
                if logger:
                    logger.log(f"{self.name} âŒ å¤šæ­¥è®¡åˆ’æ‰§è¡Œå¤±è´¥: {plan_result['reason']}")
                self.multi_step_stats['plans_abandoned'] += 1
                self._reset_plan_state()
                # ç»§ç»­æ‰§è¡Œæ­£å¸¸å†³ç­–æµç¨‹
            elif plan_result['status'] == 'continue':
                if logger:
                    logger.log(f"{self.name} â­ï¸ å¤šæ­¥è®¡åˆ’æ­¥éª¤æ‰§è¡ŒæˆåŠŸï¼Œç­‰å¾…ä¸‹å›åˆç»§ç»­")
                return  # æœ¬æ­¥éª¤æˆåŠŸï¼Œç­‰å¾…ä¸‹å›åˆ
        
        # æ£€æŸ¥è®¡åˆ’æ˜¯å¦ä»ç„¶æœ‰æ•ˆï¼ˆç¯å¢ƒå˜åŒ–æ£€æµ‹ï¼‰
        if self.current_plan is not None and not self._is_plan_still_valid(game):
            if logger:
                logger.log(f"{self.name} âš ï¸ å½“å‰è®¡åˆ’å·²å¤±æ•ˆï¼Œé‡æ–°è§„åˆ’")
            self.multi_step_stats['plans_abandoned'] += 1
            self._reset_plan_state()
        
        # ğŸ”§ ä¿®å¤ï¼šé¦–å…ˆæ‰§è¡ŒåŸºç¡€Playerè¡Œä¸ºï¼ŒåŒ…æ‹¬åœ°å½¢æ¢ç´¢è®°å½•
        try:
            # æ¯å›åˆæ¶ˆè€—
            self.food = max(0, self.food - 1)
            self.water = max(0, self.water - 1)
            
            # æ£€æŸ¥å½“å‰æ ¼å­åœ°å½¢å¹¶è®°å½•æ¢ç´¢
            current_cell = game.game_map.grid[self.y][self.x]
            self._record_exploration(current_cell)
            
            # æ£€æŸ¥æ°´æºï¼Œè‡ªåŠ¨å–æ°´
            if current_cell in ["river", "puddle"]:
                old_water = self.water
                self.water = min(100, self.water + 30)
                if self.water > old_water and logger:
                    logger.log(f"{self.name} drinks water at {current_cell}")
            
            # å¦‚æœé£Ÿç‰©æˆ–æ°´åˆ†ä¸º0,å‡å°‘ç”Ÿå‘½å€¼
            if self.food == 0 or self.water == 0:
                self.hp = max(0, self.hp - 10)
                
            # æ£€æŸ¥æ˜¯å¦æ­»äº¡
            if self.hp <= 0:
                self.alive = False
                if logger:
                    logger.log(f"{self.name} æ­»äº¡")
                return
        except Exception as e:
            if logger:
                logger.log(f"{self.name} åŸºç¡€ç”Ÿå­˜æ£€æŸ¥å¼‚å¸¸: {str(e)}")
        
        # === ç¬¬ä¸€æ­¥:åˆ¤æ–­è‡ªèº«çŠ¶æ€===
        self_state = self._analyze_current_state(game)
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘çŠ¶æ€æ—¥å¿—é¢‘ç‡
        if logger and self.life_experience_count % 5 == 0:  # æ¯5å›åˆè®°å½•ä¸€æ¬¡çŠ¶æ€
            logger.log(f"{self.name} ğŸ” çŠ¶æ€è¯„ä¼°: {self_state['status']} | å¥åº·:{self.health} é£Ÿç‰©:{self.food} æ°´:{self.water}")
        
        try:
            # æ›´æ–°å‘è‚²é˜¶æ®µ
            self.life_experience_count += 1
            self.developmental_stage = min(1.0, self.life_experience_count / 100.0)
            
            # === ç¬¬äºŒæ­¥:ä¸‰é˜¶æ®µå†³ç­–è§¦å‘æœºåˆ¶ ===
            decision_stage = self._determine_decision_stage(game)
            
            if logger:
                logger.log(f"{self.name} ğŸ¯ å†³ç­–é˜¶æ®µ: {decision_stage['stage']} | åŸå› : {decision_stage['reason']}")
            
            if decision_stage['stage'] == 'instinct':
                # é˜¶æ®µä¸€: æœ¬èƒ½å†³ç­–é˜¶æ®µ - ç›´æ¥å“åº”ç´§æ€¥æƒ…å†µ
                if logger:
                    logger.log(f"{self.name} âš¡ æœ¬èƒ½å±‚æ¿€æ´»: {decision_stage['trigger_reason']}")
                
                instinct_action = self._execute_instinct_decision(game, decision_stage['trigger_type'])
                if instinct_action:
                    return  # æœ¬èƒ½å†³ç­–å®Œæˆï¼Œç›´æ¥è¿”å›
                    
            elif decision_stage['stage'] == 'dmha':
                # é˜¶æ®µäºŒ: DMHAå†³ç­–é˜¶æ®µ - ç›®æ ‡å¯¼å‘å†³ç­–
                if logger:
                    logger.log(f"{self.name} ğŸ¯ DMHAå±‚æ¿€æ´»: è¿›å…¥ç›®æ ‡å¯¼å‘å†³ç­–æ¨¡å¼")
                    
            elif decision_stage['stage'] == 'cdl':
                # é˜¶æ®µä¸‰: CDLå†³ç­–é˜¶æ®µ - å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢
                if logger:
                    logger.log(f"{self.name} ğŸ§  CDLå±‚æ¿€æ´»: å¯åŠ¨å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢")
                
                action_result = self._enhanced_cdl_exploration_with_tools(game) or self._execute_cdl_exploration_cycle(game)
                if action_result and action_result.get('action_taken'):
                    return  # CDLæˆåŠŸæ‰§è¡Œï¼Œå®Œæˆå›åˆ
            
            # å¦‚æœCDLæœªæ‰§è¡Œæˆ–å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œç›®æ ‡å¯¼å‘å†³ç­–
            if logger:
                logger.log(f"{self.name} ğŸ¯ è¿›å…¥ç›®æ ‡å¯¼å‘å†³ç­–æ¨¡å¼")
            
            # === ç¬¬ä¸‰æ­¥:ä¸‰é˜¶æ®µååŒç›®æ ‡ç¡®å®š ===
            # ğŸ”§ ç¬¬2æ­¥ä¿®å¤ï¼šä½¿ç”¨æ–°çš„ä¸‰é˜¶æ®µç›®æ ‡ç¡®å®šæœºåˆ¶
            target_goal = self._collaborative_goal_determination(game, decision_stage, self_state)
            
            if logger:
                stage_name = {"instinct": "æœ¬èƒ½", "dmha": "DMHA", "cdl": "CDL"}[decision_stage['stage']]
                logger.log(f"{self.name} ğŸ¯ {stage_name}å±‚ç¡®å®šç›®æ ‡: {target_goal['type']} (ç´§æ€¥åº¦: {target_goal['urgency']:.2f})")
            
            # === ç¬¬å››æ­¥:å†³ç­–åº“åŒ¹ä»===
            # ğŸ”§ ä¿®å¤ï¼šåˆå§‹åŒ–action_to_executeå˜é‡
            action_to_execute = None
            decision_source = "æœªç¡®å®š"
            
            decision_match = self._decision_library_matching(target_goal, game)
            
            if decision_match and decision_match.get('success'):
                if logger:
                    logger.log(f"{self.name} ğŸ“š å†³ç­–åº“åŒ¹é…æˆåŠŸ: {decision_match['action']} (åŒ¹é…åº¦: {decision_match['confidence']:.2f})")
                action_to_execute = decision_match['action']
                decision_source = "å†³ç­–åº“åŒ¹é…"
            else:
                # === ç¬¬å››ç‚¹äº”æ­¥:ğŸ”§ ç¬¬4æ­¥ä¿®å¤ï¼šé•¿é“¾æœºåˆ¶æ‰§è¡Œç®¡ç†===
                # é•¿é“¾æœºåˆ¶ä¸“æ³¨äºå†³ç­–æ–¹æ¡ˆå®æ–½ç®¡ç†ï¼Œä¸åˆ¶å®šæ–°ç›®æ ‡
                long_chain_result = self._long_chain_execution_management(game, target_goal, logger)
                if long_chain_result and long_chain_result.get('action'):
                    action_to_execute = long_chain_result['action']
                    decision_source = long_chain_result.get('source', 'é•¿é“¾æ‰§è¡Œç®¡ç†')
                    if logger:
                        status = long_chain_result.get('status', 'unknown')
                        logger.log(f"{self.name} ğŸ—“ï¸ é•¿é“¾æ‰§è¡Œç®¡ç†: {status} - æ‰§è¡Œ {action_to_execute}")
                
                # === ç¬¬äº”æ­¥:WBMæœºåˆ¶ç”Ÿæˆæ–°å†³ç­–===
                if action_to_execute is None:
                    if logger:
                        logger.log(f"{self.name} ğŸŒ‰ å†³ç­–åº“æ— åŒ¹é…,å¯åŠ¨WBMè§„å¾‹å†³ç­–æœºåˆ¶")
                    
                    wbm_decision = self._wbm_rule_based_decision(target_goal, game, logger)
                    if wbm_decision and wbm_decision.get('action'):
                        action_to_execute = wbm_decision['action']
                        decision_source = "WBMè§„å¾‹å†³ç­–"
                        if 'multi_day_plan' in wbm_decision:
                            decision_source = "WBMé•¿é“¾å†³ç­–"
                        if logger:
                            logger.log(f"{self.name} ğŸ”¨ WBMç”Ÿæˆå†³ç­–: {action_to_execute}")
                    else:
                        action_to_execute = self._get_default_exploration_action()
                        decision_source = "é»˜è®¤æ¢ç´¢"
                        if logger:
                            logger.log(f"{self.name} âš ï¸ WBMå†³ç­–å¤±è´¥,ä½¿ç”¨é»˜è®¤æ¢ç´¢")
            
            # === ç¬¬å…­æ­¥:æ‰§è¡Œè¡ŒåŠ¨å¹¶è®°å½•çŠ¶æ€===
            pre_action_state = self._capture_current_state()
            
            execution_result = self._execute_planned_action(action_to_execute, game)
            
            post_action_state = self._capture_current_state()
            
            # === ç¬¬ä¸ƒæ­¥:EMRSæœºåˆ¶è¯„ä»·å†³ç­– ===
            if logger:
                logger.log(f"{self.name} ğŸ“Š EMRSå¯åŠ¨å†³ç­–è¯„ä»·")
            
            emrs_evaluation = self._emrs_evaluate_decision(
                action=action_to_execute,
                goal=target_goal,
                pre_state=pre_action_state,
                post_state=post_action_state,
                execution_result=execution_result
            )
            
            if logger:
                score = emrs_evaluation.get('quality_score', 0)
                logger.log(f"{self.name} ğŸ“ˆ EMRSå†³ç­–è¯„ä»·: {score:.2f} ({'ä¼˜ç§€' if score > 0.7 else 'è‰¯å¥½' if score > 0.4 else 'éœ€æ”¹è¿›'})")
            
            # === ç¬¬å…«æ­¥:SSMæœºåˆ¶è®°å½•EOCATRç»éªŒ ===
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šSSMç¬¦å·åŒ–é¢‘ç‡æ§åˆ¶
            if not hasattr(self, 'last_ssm_symbolization_round'):
                self.last_ssm_symbolization_round = 0
            
            current_round = getattr(game, 'current_day', 1)
            
            # æ¯3å›åˆæ‰è¿›è¡Œä¸€æ¬¡SSMç¬¦å·åŒ–
            if current_round - self.last_ssm_symbolization_round >= 3:
                if logger:
                    logger.log(f"{self.name} ğŸ”¤ SSMè®°å½•EOCATRç»éªŒ")
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šè°ƒç”¨SSMç¬¦å·åŒ–ç”ŸæˆEOCATRå…ƒç»„
                try:
                    self.symbolize_scene(game)
                    self.last_ssm_symbolization_round = current_round
                    if logger:
                        logger.log(f"{self.name} ğŸ”¤ SSMç¬¦å·åŒ–å®Œæˆï¼Œç”Ÿæˆäº†{len(self.current_eocar_scene) if hasattr(self, 'current_eocar_scene') else 0}ä¸ªEOCATRå…ƒç»„")
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} âŒ SSMç¬¦å·åŒ–å¤±è´¥: {str(e)}")
            else:
                if logger:
                    logger.log(f"{self.name} ğŸ”¤ SSMç¬¦å·åŒ–è·³è¿‡ (è·ç¦»ä¸Šæ¬¡{current_round - self.last_ssm_symbolization_round}å›åˆï¼Œéœ€ç­‰å¾…5å›åˆ)")
            
            # ğŸ”§ ä¿®å¤ï¼šå°†SSMç”Ÿæˆçš„EOCATRç»éªŒä¿å­˜åˆ°äº”åº“ç³»ç»Ÿ
            has_scene = hasattr(self, 'current_eocar_scene')
            scene_exists = self.current_eocar_scene if has_scene else None
            scene_count = len(scene_exists) if scene_exists else 0
            if logger:
                logger.log(f"{self.name} ğŸ”§ SSMæ¡ä»¶æ£€æŸ¥: has_scene={has_scene}, scene_count={scene_count}")
            
            if has_scene and scene_exists and scene_count > 0:
                if logger:
                    logger.log(f"{self.name} ğŸ”§ SSMå¼€å§‹è°ƒç”¨ä¿å­˜æ–¹æ³•ï¼Œå…ƒç»„æ•°é‡: {scene_count}")
                try:
                    self._save_eocar_tuples_to_five_libraries(scene_exists)
                    if logger:
                        logger.log(f"{self.name} âœ… SSMæˆåŠŸä¿å­˜{scene_count}ä¸ªEOCATRå…ƒç»„")
                except AttributeError as e:
                    if logger:
                        logger.log(f"{self.name} âŒ SSMä¿å­˜æ–¹æ³•ä¸å­˜åœ¨: {str(e)}")
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} âŒ SSMä¿å­˜å¼‚å¸¸: {str(e)}")
            else:
                if logger:
                    logger.log(f"{self.name} âŒ SSMä¿å­˜è·³è¿‡: has_scene={has_scene}, scene_exists={scene_exists is not None}, scene_count={scene_count}")
            
            # è°ƒç”¨ç°æœ‰çš„add_eocar_experienceæ–¹æ³•
            eocar_result = {
                'success': execution_result.get('success', False),
                'action_type': action_to_execute,
                'decision_source': decision_source,
                'evaluation': emrs_evaluation
            }
            self.add_eocar_experience(action_to_execute, eocar_result, source="optimized_decision_flow")
            
            # === ç¬¬ä¹æ­¥:BPMæœºåˆ¶ç”Ÿæˆå’ŒéªŒè¯è§„ä»===
            # æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½BPMæ—¥å¿—é¢‘ç‡
            if logger and self.life_experience_count % 3 == 0:
                logger.log(f"{self.name} ğŸŒ¸ BPMå¯åŠ¨è§„å¾‹ç”Ÿæˆ")
            
            # BPMå¤„ç† (ä½¿ç”¨ç°æœ‰çš„BPMç³»ç»Ÿ)
            if hasattr(self, 'bpm') and self.bpm and len(self.eocar_experiences) > 3:
                try:
                    recent_experiences = self.eocar_experiences[-5:]
                    if recent_experiences:
                        latest_experience = recent_experiences[-1]
                        historical_batch = recent_experiences[:-1] if len(recent_experiences) > 1 else []
                        
                        # ç”Ÿæˆæ–°è§„"
                        new_candidate_rules = self.bpm.process_experience(latest_experience, historical_batch)
                        
                        # éªŒè¯è§„å¾‹
                        validation_experiences = self.eocar_experiences[-3:]
                        validated_rule_ids = self.bpm.validation_phase(validation_experiences)
                        
                        # ğŸ”§ è‡ªåŠ¨ä¿å­˜éªŒè¯é€šè¿‡çš„è§„å¾‹åˆ°äº”åº“ç³»ç»Ÿ
                        if validated_rule_ids and hasattr(self, 'five_library_system'):
                            saved_rules_count = 0
                            for rule_id in validated_rule_ids:
                                if hasattr(self.bpm, 'validated_rules') and rule_id in self.bpm.validated_rules:
                                    bmp_rule = self.bpm.validated_rules[rule_id]
                                    
                                    # è½¬æ¢BMPè§„å¾‹æ ¼å¼ä¸ºäº”åº“ç³»ç»Ÿæ ¼å¼
                                    try:
                                        save_result = self.five_library_system.add_rule(
                                            rule_type=bmp_rule.rule_type.value if hasattr(bmp_rule.rule_type, 'value') else str(bmp_rule.rule_type),
                                            conditions=bmp_rule.conditions,
                                            predictions=bmp_rule.predictions,
                                            confidence=bmp_rule.confidence,
                                            support_count=len(bmp_rule.evidence.supporting_experiences) if hasattr(bmp_rule, 'evidence') else 1,
                                            contradiction_count=len(bmp_rule.evidence.contradicting_experiences) if hasattr(bmp_rule, 'evidence') else 0,
                                            creator_id=self.name,
                                            validation_status='validated'
                                        )
                                        
                                        if save_result.get('success', False):
                                            saved_rules_count += 1
                                            if logger:
                                                logger.log(f"  âœ… BMPéªŒè¯è§„å¾‹å·²ä¿å­˜åˆ°äº”åº“: {rule_id}")
                                        else:
                                            if logger:
                                                logger.log(f"  âŒ BMPéªŒè¯è§„å¾‹ä¿å­˜å¤±è´¥: {rule_id} - {save_result.get('error', 'Unknown error')}")
                                    
                                    except Exception as e:
                                        if logger:
                                            logger.log(f"  âŒ BMPéªŒè¯è§„å¾‹ä¿å­˜å¼‚å¸¸: {rule_id} - {str(e)}")
                            
                            if saved_rules_count > 0 and logger:
                                logger.log(f"{self.name} ğŸ’¾ å·²ä¿å­˜{saved_rules_count}æ¡BMPéªŒè¯è§„å¾‹åˆ°äº”åº“ç³»ç»Ÿ")
                        
                        # å‰ªæä½è´¨é‡è§„"
                        pruned_rules = self.bpm.pruning_phase()
                        
                        if logger and (new_candidate_rules or validated_rule_ids):
                            logger.log(f"{self.name} ğŸ“‹ ç”Ÿæˆ{len(new_candidate_rules)}æ¡å€™é€‰è§„å¾‹, éªŒè¯{len(validated_rule_ids)}æ¡è§„å¾‹")
                            
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} BPMè§„å¾‹å¤„ç†å¤±è´¥: {str(e)}")
            
            # === ç¬¬ä¹ç‚¹äº”æ­¥:æ›´æ–°å¤šæ—¥è®¡åˆ’æ‰§è¡Œç»“æœ ===
            if (hasattr(self, 'current_multi_day_plan') and self.current_multi_day_plan and 
                decision_source in ["WBMé•¿é“¾å†³ç­–ç»§ç»­", "WBMé•¿é“¾å†³ç­–"]):
                if logger:
                    logger.log(f"{self.name} ğŸ“‹ æ›´æ–°å¤šæ—¥è®¡åˆ’æ‰§è¡Œç»“æœ")
                
                self._update_daily_execution_result(execution_result, logger)
            
            # === ç¬¬åæ­¥:å†æ¬¡çŠ¶æ€åˆ¤æ–­,å®Œæˆå¾ªç¯ ===
            final_state = self._analyze_current_state(game)
            if logger:
                logger.log(f"{self.name} ğŸ”„ å›åˆç»“æŸçŠ¶æ€ {final_state['status']} | å†³ç­–æ¥æº: {decision_source}")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ä»å†³ç­–æµç¨‹å¼‚å¸¸: {str(e)}")
            # å¼‚å¸¸æƒ…å†µä¸‹çš„å®‰å…¨è¡ŒåŠ¨
            try:
                safe_action = self._get_default_exploration_action()
                self._execute_action(safe_action)
                if logger:
                    logger.log(f"{self.name} ğŸ›¡ä»æ‰§è¡Œå®‰å…¨è¡ŒåŠ¨: {safe_action}")
            except:
                pass
        
        # è®°å½•å›åˆå¼€å§‹çŠ¶æ€
        if hasattr(self, 'memory_system') and self.memory_system:
            try:
                self.memory_system.store_memory(
                    content=f"ç¬¬{game.current_day}å¤©å¼€å§‹,å¥åº·:{self.health}, é£Ÿç‰©:{self.food}, ä»{self.water}",
                    memory_type="episodic",
                    importance=1,
                    tags=["çŠ¶æ€", "å›åˆå¼€å§‹", f"ç¬¬{game.current_day}å¤©"]
                )
            except:
                pass

    def detect_threats(self, game_map):
            if logger:
                logger.log(f"{self.name} take_turnæ‰§è¡Œå¤±è´¥: {str(e)}")
            # åº”æ€¥å¤„ç†:æ‰§è¡Œéšæœºç§»åŠ¨
            self._execute_random_move()
    
    def detect_threats(self, game_map):
        """æ£€æµ‹å‘¨å›´çš„å¨èƒ,è¿”å›æ‰€æœ‰å¨èƒå¯¹è±¡çš„åˆ—è¡¨"""
        threats = []
        threat_detection_range = 10  # å¢å¤§å¨èƒæ£€æµ‹èŒƒ"""
        for animal in game_map.animals:
            if animal.alive and animal.type in ["Tiger", "BlackBear"]:
                dist = abs(animal.x - self.x) + abs(animal.y - self.y)
                if dist <= threat_detection_range:
                    # è®¡ç®—å¨èƒç¨‹åº¦(åŸºäºè·ç¦»å’ŒåŠ¨ç‰©ç±»å‹"
                    threat_level = self.calculate_threat_level(animal, dist)
                    if threat_level > 0:
                        threats.append(animal)
        
        return threats

    def calculate_threat_level(self, animal, distance):
        """è®¡ç®—ç‰¹å®šå¨èƒçš„å±é™©ç¨‹åº¦"""
        base_threat = 100 if animal.type == "Tiger" else 70  # è€è™æ¯”é»‘ç†Šæ›´å±é™©
        distance_factor = max(0, 1 - (distance / 10))  # è·ç¦»è¶Šè¿‘å¨èƒè¶Šå¤§
        return base_threat * distance_factor

    def calculate_escape_direction(self, threats, game_map):
        """è®¡ç®—æœ€ä¼˜é€ƒè·‘æ–¹å‘"""
        # è®¡ç®—æ‰€æœ‰å¯èƒ½çš„ç§»åŠ¨æ–¹å‘
        possible_moves = []
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                new_x = self.x + dx
                new_y = self.y + dy
                if game_map.is_within_bounds(new_x, new_y):
                    safety_score = self.evaluate_position_safety(new_x, new_y, threats, game_map)
                    possible_moves.append((dx, dy, safety_score))
        
        if not possible_moves:
            return None
        
        # é€‰æ‹©å®‰å…¨åˆ†æ•°æœ€é«˜çš„ç§»åŠ¨æ–¹å‘
        best_move = max(possible_moves, key=lambda x: x[2])
        return (best_move[0], best_move[1])

    def evaluate_position_safety(self, x, y, threats, game_map):
        """è¯„ä¼°ç‰¹å®šä½ç½®çš„å®‰å…¨ç¨‹åº¦"""
        safety_score = 100
        
        # è€ƒè™‘ä¸æ‰€æœ‰å¨èƒçš„è·ç¦»
        for threat in threats:
            dist = abs(x - threat.x) + abs(y - threat.y)
            if dist == 0:
                return 0  # ä¸å¨èƒé‡å ,å®Œå…¨ä¸å®‰"""
            threat_level = self.calculate_threat_level(threat, dist)
            safety_score -= threat_level
        
        # è€ƒè™‘åœ°å½¢å› ç´ 
        if game_map.grid[y][x] in ["big_tree", "bush"]:
            safety_score += 20  # æ ‘æœ¨å’ŒçŒæœ¨æä¾›æ©"
        elif game_map.grid[y][x] in ["river", "puddle"]:
            safety_score += 10  # æ°´åŸŸæä¾›ä¸€å®šä¿"
        # è€ƒè™‘æ˜¯å¦é è¿‘åœ°å›¾è¾¹ç¼˜(å¯èƒ½è¢«å›°)
        if x <= 1 or x >= game_map.width - 2 or y <= 1 or y >= game_map.height - 2:
            safety_score -= 30
        
        return max(0, safety_score)  # ç¡®ä¿å®‰å…¨åˆ†æ•°ä¸ä¸º"
    def apply_reasoning(self):
        """ä½¿ç”¨å¤šå±‚æ¬¡è®°å¿†ç³»ç»Ÿè¿›è¡Œæ¨ç†å†³ç­–"""
        try:
            # æœç´¢å±é™©ç›¸å…³çš„è®°"""
            danger_memories = self.memory_system.search_memories(
                tags=["å±é™©", "å¨èƒ", "æ”»å‡»", "å—ä¼¤"],
                memory_types=["episodic", "semantic"],
                max_results=5
            )
            
            # æœç´¢æˆåŠŸç»éªŒçš„è®°"
            success_memories = self.memory_system.search_memories(
                tags=["æˆåŠŸ", "èƒœåˆ©", "æ”¶è·", "å®‰å…¨"],
                memory_types=["episodic", "semantic"],
                max_results=5
            )
            
            # è®¡ç®—å±é™©å’ŒæˆåŠŸè®°å¿†çš„æƒé‡
            danger_weight = sum(memory.strength for memory in danger_memories)
            success_weight = sum(memory.strength for memory in success_memories)
            
            # åŸºäºè®°å¿†å¼ºåº¦åšå†³"
            if danger_weight > success_weight * 1.5:  # å±é™©è®°å¿†æ˜æ˜¾æ›´å¼º
                # è®°å½•æ¨ç†è¿‡ç¨‹
                self.memory_system.store_memory(
                    content="åŸºäºå±é™©è®°å¿†é€‰æ‹©é€ƒè·‘ç­–ç•¥",
                    memory_type="procedural",
                    importance=3,
                    tags=["æ¨ç†", "å†³ç­–", "é€ƒè·‘"]
                )
                return "flee"
            elif success_weight > danger_weight:  # æˆåŠŸè®°å¿†æ›´å¼º
                # è®°å½•æ¨ç†è¿‡ç¨‹
                self.memory_system.store_memory(
                    content="åŸºäºæˆåŠŸè®°å¿†é€‰æ‹©æ”»å‡»ç­–ç•¥",
                    memory_type="procedural", 
                    importance=3,
                    tags=["æ¨ç†", "å†³ç­–", "æ”»å‡»"]
                )
                return "attack"
            else:
                # è®°å¿†ä¸è¶³æˆ–å¹³è¡¡,ä½¿ç”¨ä¿å®ˆç­–ç•¥
                self.memory_system.store_memory(
                    content="è®°å¿†ä¸è¶³,é€‰æ‹©ä¿å®ˆç­–ç•¥",
                    memory_type="procedural",
                    importance=2,
                    tags=["æ¨ç†", "å†³ç­–", "ä¿å®ˆ"]
                )
                return "flee"  # é»˜è®¤ä¿å®ˆ
                
        except Exception as e:
            # æ¨ç†å¤±è´¥,è®°å½•é”™è¯¯å¹¶ä½¿ç”¨é»˜è®¤ç­–ç•¥
            self.memory_system.store_memory(
                content=f"æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}",
                memory_type="episodic",
                importance=2,
                tags=["é”™è¯¯", "æ¨ç†", "å¼‚å¸¸"]
            )
            return "attack"  # é»˜è®¤æ”»å‡»

    def find_nearest_animal(self, game_map):
        nearest = None
        min_distance = 999
        for animal in game_map.animals:
            if animal.alive:
                dist = abs(animal.x - self.x) + abs(animal.y - self.y)
                if dist < min_distance:
                    min_distance = dist
                    nearest = animal
        return nearest

    def find_nearest_plant(self, game_map):
        """å¯»æ‰¾æœ€è¿‘çš„æœªè¢«é‡‡é›†çš„æ¤ç‰©"""
        nearest_plant = None
        min_distance = float('inf')
        
        for plant in game_map.plants:
            if plant.alive and not plant.collected and not plant.toxic:
                dist = abs(plant.x - self.x) + abs(plant.y - self.y)
                if dist < min_distance:
                    min_distance = dist
                    nearest_plant = plant
        
        return nearest_plant

    def find_nearest_water(self, game_map):
        """å¯»æ‰¾æœ€è¿‘çš„æ°´æº(æ²³æµæˆ–æ°´å‘)"""
        nearest_water = None
        min_distance = float('inf')
        
        for y in range(game_map.height):
            for x in range(game_map.width):
                if game_map.grid[y][x] in ["river", "puddle"]:
                    dist = abs(x - self.x) + abs(y - self.y)
                    if dist < min_distance:
                        min_distance = dist
                        nearest_water = (x, y)
        
        return nearest_water

    def find_path_to_water(self, target, game_map):
        """ä½¿ç”¨A*ç®—æ³•å¯»æ‰¾åˆ°æ°´æºçš„æœ€ä½³è·¯å¾„"""
        from heapq import heappush, heappop
        
        def heuristic(a, b):
            return abs(a[0] - b[0]) + abs(a[1] - b[1])
        
        def get_neighbors(pos):
            x, y = pos
            neighbors = []
            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
                new_x, new_y = x + dx, y + dy
                if (0 <= new_x < game_map.width and 
                    0 <= new_y < game_map.height and
                    game_map.grid[new_y][new_x] != "rock"):  # é¿å¼€å²©çŸ³
                    neighbors.append((new_x, new_y))
            return neighbors
        
        start = (self.x, self.y)
        goal = target
        
        frontier = []
        heappush(frontier, (0, start))
        came_from = {start: None}
        cost_so_far = {start: 0}
        
        while frontier:
            current = heappop(frontier)[1]
            
            if current == goal:
                break
                
            for next_pos in get_neighbors(current):
                new_cost = cost_so_far[current] + 1
                
                if next_pos not in cost_so_far or new_cost < cost_so_far[next_pos]:
                    cost_so_far[next_pos] = new_cost
                    priority = new_cost + heuristic(goal, next_pos)
                    heappush(frontier, (priority, next_pos))
                    came_from[next_pos] = current
        
        # é‡å»ºè·¯å¾„
        if goal not in came_from:
            return None
            
        path = []
        current = goal
        while current != start:
            path.append(current)
            current = came_from[current]
        path.append(start)
        path.reverse()
        
        return path[1:] if len(path) > 1 else None

    def get_state(self):
        """è·å–å½“å‰çŠ¶æ€è¡¨ç¤º"""
        try:
            if hasattr(self, 'current_pos') and self.current_pos is not None:
                x, y = self.current_pos
            else:
                x, y = 0, 0  # é»˜è®¤ä½ç½®
                
            # åŸºç¡€ä¿¡æ¯
            state = [
                self.health / 100.0,  # è¡€é‡(å½’ä¸€åŒ–)
                self.water / 100.0,   # æ°´é‡(å½’ä¸€åŒ–)
                self.food / 100.0,    # é£Ÿç‰©(å½’ä¸€åŒ–)
                x / self.game_map.width,      # xä½ç½®(å½’ä¸€åŒ–)
                y / self.game_map.height      # yä½ç½®(å½’ä¸€åŒ–)
            ]
            
            # é‚»è¿‘èµ„æºå’Œæ•Œäººä¿¡"""
            resource_info = []
            predator_info = []
            
            # æ‰«æå‘¨å›´10æ ¼èŒƒ"
            scan_radius = 10
            
            # å¡«å……é‚»è¿‘èµ„æºä¿¡æ¯
            for resource in self.game_map.resources:
                res_x, res_y = resource.position
                distance = ((x - res_x)**2 + (y - res_y)**2)**0.5
                
                if distance <= scan_radius:
                    # æ¯ä¸ªèµ„æº4ä¸ªå€¼:ç›¸å¯¹x,ç›¸å¯¹y,è·ç¦»,ç±»å‹
                    resource_info.append([
                        (res_x - x) / scan_radius,  # ç›¸å¯¹xä½ç½®(å½’ä¸€åŒ–)
                        (res_y - y) / scan_radius,  # ç›¸å¯¹yä½ç½®(å½’ä¸€åŒ–)
                        distance / scan_radius,     # è·ç¦»(å½’ä¸€åŒ–)
                        0.5 if resource.type == "berry" else 1.0  # ç±»å‹(berry=0.5, water=1.0"
                    ])
            
            # å¡«å……æœ€ä»ä¸ªé‚»è¿‘èµ„"
            resource_info = resource_info[:5]
            while len(resource_info) < 5:
                resource_info.append([0, 0, 1.0, 0])  # æ·»åŠ å¡«å……"
            # å¡«å……é‚»è¿‘æ•é£Ÿè€…ä¿¡"
            for predator in self.game_map.predators:
                pred_x, pred_y = predator.position
                distance = ((x - pred_x)**2 + (y - pred_y)**2)**0.5
                
                if distance <= scan_radius:
                    # æ¯ä¸ªæ•é£Ÿè€…ä¸ªå€¼:ç›¸å¯¹x,ç›¸å¯¹y,è·ä» å¥åº·"
                    predator_info.append([
                        (pred_x - x) / scan_radius,  # ç›¸å¯¹xä½ç½®(å½’ä¸€åŒ–)
                        (pred_y - y) / scan_radius,  # ç›¸å¯¹yä½ç½®(å½’ä¸€åŒ–)
                        distance / scan_radius,      # è·ç¦»(å½’ä¸€åŒ–)
                        predator.health / 100.0      # æ•é£Ÿè€…å¥åº·åº¦(å½’ä¸€åŒ–)
                    ])
            
            # å¡«å……æœ€ä»ä¸ªé‚»è¿‘æ•é£Ÿè€…
            predator_info = predator_info[:5]
            while len(predator_info) < 5:
                predator_info.append([0, 0, 1.0, 0])  # æ·»åŠ å¡«å……"
            # é‚»è¿‘ç©å®¶ä¿¡æ¯
            player_info = []
            for player in self.game_map.players:
                if player != self:
                    if hasattr(player, 'current_pos') and player.current_pos is not None:
                        player_x, player_y = player.current_pos
                        distance = ((x - player_x)**2 + (y - player_y)**2)**0.5
                        
                        if distance <= scan_radius:
                            # æ¯ä¸ªç©å®¶5ä¸ªå€¼:ç›¸å¯¹x, ç›¸å¯¹y, è·ç¦», ä¿¡èª‰ä» æ˜¯å¦ä¸ºæ•Œ"
                            player_info.append([
                                (player_x - x) / scan_radius,      # ç›¸å¯¹xä½ç½®(å½’ä¸€åŒ–)
                                (player_y - y) / scan_radius,      # ç›¸å¯¹yä½ç½®(å½’ä¸€åŒ–)
                                distance / scan_radius,            # è·ç¦»(å½’ä¸€åŒ–)
                                player.reputation / 100.0,         # ä¿¡èª‰åº¦(å½’ä¸€åŒ–)
                                1.0 if self.check_is_enemy(player) else 0.0  # æ˜¯å¦ä¸ºæ•Œ"
                            ])
            
            # å¡«å……æœ€ä»ä¸ªé‚»è¿‘ç©"
            player_info = player_info[:5]
            while len(player_info) < 5:
                player_info.append([0, 0, 1.0, 0, 0])  # æ·»åŠ å¡«å……"
            # æ‰å¹³åŒ–æ•°ç»„å¹¶æ·»åŠ åˆ°çŠ¶æ€
            for info in resource_info:
                state.extend(info)  # æ·»åŠ 5ä¸ªèµ„æº,æ¯ä¸ª4ä¸ªä»= 20ä¸ª"
            for info in predator_info:
                state.extend(info)  # æ·»åŠ 5ä¸ªæ•é£Ÿè€…,æ¯ä¸ª4ä¸ªä»= 20ä¸ª"
            for info in player_info:
                state.extend(info)  # æ·»åŠ 5ä¸ªç©å®¶,æ¯ä¸ª5ä¸ªä»= 25ä¸ª"
            # ç¯å¢ƒæ—¶é—´å’Œæ¡ä»¶ä¿¡æ¯(ä»ä¸ªç‰¹å¾)
            state.extend([
                self.game_map.current_round / self.game_map.max_rounds,  # å½“å‰å›åˆ(å½’ä¸€åŒ–)
                1.0 if self.water < 30 else 0.0,  # ç¼ºæ°´æ ‡å¿—
                1.0 if self.food < 30 else 0.0,   # ç¼ºé£Ÿç‰©æ ‡"
                1.0 if self.health < 30 else 0.0, # ä½å¥åº·æ ‡"
                len(self.game_map.players) / 20.0,  # å­˜æ´»ç©å®¶æ•°(å½’ä¸€åŒ–)
                len(self.game_map.predators) / 50.0,  # æ•é£Ÿè€…æ•°é‡(å½’ä¸€åŒ–)
                len(self.game_map.resources) / 100.0,  # èµ„æºæ•°é‡(å½’ä¸€åŒ–)
                1.0 if self.health < 50 and (self.water < 30 or self.food < 30) else 0.0  # å±é™©çŠ¶æ€æ ‡"
            ])
            
            # ç¡®ä¿çŠ¶æ€å‘é‡å¤§å°ç¬¦åˆé¢„"
            assert len(state) == self.state_size, f"çŠ¶æ€å‘é‡å¤§å°ä¸åŒ¹é…:{len(state)} vs {self.state_size}"
            
            return np.array(state)
        except Exception as e:
            import traceback
            logger.log(f"{self.name} è·å–çŠ¶æ€å¤±ä» {str(e)}")
            logger.log(traceback.format_exc())
            # è¿”å›é›¶å‘é‡ä½œä¸ºé»˜è®¤çŠ¶æ€
            return np.zeros(self.state_size)

    def calculate_reward(self, action):
        """è®¡ç®—æ‰§è¡ŒåŠ¨ç‰©åçš„å¥–åŠ±"""
        try:
            reward = 0
            
            # åŸºç¡€å¥–åŠ±:å­˜æ´»å¥–åŠ±
            reward += 0.1
            
            # å¥åº·çŠ¶æ€å˜åŒ–å¥–åŠ±
            health_change = self.health - self.last_health if hasattr(self, 'last_health') else 0
            reward += health_change * 0.05  # å¥åº·æé«˜ç»™äºˆå¥–åŠ±,é™ä½ç»™äºˆæƒ©"""
            # ç”Ÿå­˜èµ„æºå¥–åŠ±
            # å¦‚æœä¹‹å‰ç¼ºæ°´ç°åœ¨æ”¹å–„"
            if hasattr(self, 'last_water') and self.last_water < 30 and self.water >= 30:
                reward += 1.0
            # å¦‚æœä¹‹å‰ç¼ºé£Ÿç‰©ç°åœ¨æ”¹å–„äº†
            if hasattr(self, 'last_food') and self.last_food < 30 and self.food >= 30:
                reward += 1.0
                
            # æ”¶é›†èµ„æºå¥–åŠ±
            if action == "collect" and hasattr(self, 'last_food'):
                food_change = self.food - self.last_food
                if food_change > 0:
                    reward += 0.5
                    
            # å–æ°´å¥–åŠ±
            if action == "drink" and hasattr(self, 'last_water'):
                water_change = self.water - self.last_water
                if water_change > 0:
                    reward += 0.5
            
            # èº²é¿æ•é£Ÿè€…å¥–åŠ±æƒ©ç½š
            if hasattr(self, 'current_pos') and hasattr(self, 'last_pos'):
                x, y = self.current_pos
                last_x, last_y = self.last_pos
                
                # è®¡ç®—ä¸æœ€è¿‘æ•é£Ÿè€…çš„è·ç¦»å˜åŒ–
                nearest_pred_dist = float('inf')
                nearest_pred_last_dist = float('inf')
                
                for predator in self.game_map.predators:
                    px, py = predator.position
                    curr_dist = ((px - x) ** 2 + (py - y) ** 2) ** 0.5
                    last_dist = ((px - last_x) ** 2 + (py - last_y) ** 2) ** 0.5
                    
                    if curr_dist < nearest_pred_dist:
                        nearest_pred_dist = curr_dist
                    if last_dist < nearest_pred_last_dist:
                        nearest_pred_last_dist = last_dist
                
                # å¦‚æœåŸæœ¬å¾ˆè¿‘,ç°åœ¨è·ç¦»å¢åŠ äº†,ç»™å¥–åŠ±
                if nearest_pred_last_dist < 5 and nearest_pred_dist > nearest_pred_last_dist:
                    reward += 0.5
                # å¦‚æœé è¿‘æ•é£Ÿè€…,ç»™æƒ©"
                elif nearest_pred_dist < 3:
                    reward -= 0.5
            
            # æˆ˜æ–—å¥–åŠ±/æƒ©ç½š
            if action == "attack":
                # æ”»å‡»æ•ŒäººæˆåŠŸçš„å¥–åŠ±åœ¨æ”»å‡»æ–¹æ³•ä¸­å¤„"
                # è¿™é‡Œç»™äºˆå°æƒ©ç½šé¿å…æ— æ„ä¹‰æ”»å‡»
                reward -= 0.1
            
            # æ¢ç´¢å¥–åŠ±
            if hasattr(self, 'exploration_map'):
                if (x, y) not in self.exploration_map:
                    reward += 0.2
                    self.exploration_map.add((x, y))
            
            # è¾¹ç•Œæ¢æµ‹,é¿å…é è¿‘è¾¹"
            if x < 5 or y < 5 or x > self.game_map.width - 5 or y > self.game_map.height - 5:
                reward -= 0.2
            
            # æç«¯æƒ…å†µçš„æƒ©"
            if self.health < 20:
                reward -= 0.5  # å¥åº·æä½çš„æƒ©"
            if self.water < 10:
                reward -= 0.3  # æåº¦ç¼ºæ°´çš„æƒ©"
            if self.food < 10:
                reward -= 0.3  # æåº¦é¥¥é¥¿çš„æƒ©"
            # è®°å½•å½“å‰çŠ¶æ€ä¸ºä¸‹æ¬¡è®¡ç®—çš„åŸºç¡€
            self.last_health = self.health
            self.last_water = self.water
            self.last_food = self.food
            self.last_pos = self.current_pos
            
            logger.log(f"{self.name} æ‰§è¡ŒåŠ¨ç‰© {action} è·å¾—å¥–åŠ±: {reward}")
            return reward
        except Exception as e:
            logger.log(f"{self.name} è®¡ç®—å¥–åŠ±å¤±è´¥: {str(e)}")
            return 0.0
    
    def remember(self, state, action, reward, next_state, done):
        """å­˜å‚¨ç»éªŒåˆ°å›æ”¾ç¼“å†²åŒº"""
        try:
            action_idx = list(self.actions.keys())[list(self.actions.values()).index(action)]
            self.memory.append((state, action_idx, reward, next_state, done))
            logger.log(f"{self.name} è®°å¿†ç»éªŒ:åŠ¨ç‰©{action}, å¥–åŠ±={reward}, å®Œæˆ={done}")
        except Exception as e:
            logger.log(f"{self.name} å­˜å‚¨ç»éªŒå¤±è´¥: {str(e)}")
    
    def replay(self):
        """è®­ç»ƒç½‘ç»œ:ä»è®°å¿†ä¸­éšæœºæŠ½å–æ‰¹æ¬¡è¿›è¡Œå­¦ä¹ ç‡"""
        try:
            if not self.use_reinforcement_learning:
                return
                
            if len(self.memory) < self.batch_size:
                logger.log(f"{self.name} ç»éªŒä¸è¶³,è·³è¿‡è®­ç»ƒ")
                return
                
            if self.q_network is None or self.target_network is None:
                logger.log(f"{self.name} ç½‘ç»œæœªåˆå§‹åŒ–,è·³è¿‡è®­ç»ƒ")
                return
            
            # å®ç°ä¼˜å…ˆç»éªŒå›æ”¾:ä¼˜å…ˆé€‰æ‹©å¥–åŠ±å¤§çš„ç»éªŒ
            experience_list = list(self.memory)
            experience_rewards = np.array([exp[2] for exp in experience_list])
            
            # æ­£è§„åŒ–å¥–åŠ±ä¸ºæ¦‚ç‡(åŠ ä¸Šåç§»é‡é¿å…è´Ÿæ•°"
            probs = np.abs(experience_rewards) + 0.01
            probs = probs / probs.sum()
            
            # æŒ‰æ¦‚ç‡æŠ½"
            indices = np.random.choice(
                len(experience_list), 
                size=min(self.batch_size, len(experience_list)), 
                p=probs, 
                replace=False
            )
            
            minibatch = [experience_list[idx] for idx in indices]
            
            # ä¸ºæ‰¹æ¬¡ä¸­çš„çŠ¶æ€å’Œä¸‹ä¸€çŠ¶æ€åˆ›å»ºæ•°"
            states = np.array([experience[0] for experience in minibatch])
            next_states = np.array([experience[3] for experience in minibatch])
            
            # é¢„æµ‹å½“å‰çŠ¶æ€å’Œä¸‹ä¸€çŠ¶æ€çš„Q"
            q_values = self.q_network.predict(states, verbose=0)
            next_q_values = self.target_network.predict(next_states, verbose=0)
            
            # æ›´æ–°ç›®æ ‡Q"
            for i, (_, action, reward, _, done) in enumerate(minibatch):
                if done:
                    q_values[i, action] = reward
                else:
                    q_values[i, action] = reward + self.gamma * np.max(next_q_values[i])
            
            # è®­ç»ƒQç½‘ç»œ
            self.q_network.fit(states, q_values, verbose=0)
            logger.log(f"{self.name} å®Œæˆæ‰¹æ¬¡è®­ç»ƒ,æ ·æœ¬æ•°ä» {len(minibatch)}")
            
            # å‡å°æ¢ç´¢ç‡
            if self.epsilon > self.epsilon_min:
                self.epsilon *= self.epsilon_decay
                
            # æ›´æ–°æ­¥æ•°è®¡æ•°"
            self.step_counter += 1
            
            # å®šæœŸæ›´æ–°ç›®æ ‡ç½‘ç»œ
            if self.step_counter % self.target_update_frequency == 0:
                self.target_network.set_weights(self.q_network.get_weights())
                logger.log(f"{self.name} æ›´æ–°ç›®æ ‡ç½‘ç»œ")
                
            # å®šæœŸä¿å­˜æ¨¡å‹
            if self.step_counter % 100 == 0:
                self._save_model()
                
            return True
        except Exception as e:
            import traceback
            logger.log(f"{self.name} è®­ç»ƒç½‘ç»œå¤±è´¥: {str(e)}")
            logger.log(traceback.format_exc())
            return False
            
    def _save_model(self):
        """ä¿å­˜æ¨¡å‹åˆ°ç£ç›˜ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        try:
            if self.q_network is not None:
                # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹ä¿å­˜ç›®å½•å’Œæ ¼å¼
                if not os.path.exists(MODELS_DIR):
                    os.makedirs(MODELS_DIR)
                
                model_path = os.path.join(MODELS_DIR, f"rilai_rl_{self.name}.keras")
                self.q_network.save(model_path)
                logger.log(f"{self.name} å¼ºåŒ–å­¦ä¹ æ¨¡å‹å·²ä¿å­˜: {model_path}")
                return True
            return False
        except Exception as e:
            logger.log(f"{self.name} ä¿å­˜å¼ºåŒ–å­¦ä¹ æ¨¡å‹å¤±è´¥: {str(e)}")
            return False
    
    def save_model(self):
        """ä¿å­˜æ¨¡å‹ï¼ˆä¾›æ¸¸æˆä¸»å¾ªç¯è°ƒç”¨ï¼‰"""
        if self.use_reinforcement_learning:
            return self._save_model()
        return True  # ILAIéƒ¨åˆ†ä¸éœ€è¦ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨äº”åº“ç³»ç»Ÿï¼‰
            
    def _load_model(self):
        """ä»ç£ç›˜åŠ è½½æ¨¡å‹"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹ä¿å­˜ç›®å½•å’Œæ ¼å¼
            model_path = os.path.join(MODELS_DIR, f"rilai_rl_{self.name}.keras")
            if os.path.exists(model_path):
                # åŠ è½½ç½‘ç»œ
                self.q_network = tf.keras.models.load_model(model_path)
                # å¤åˆ¶åˆ°ç›®æ ‡ç½‘ç»œ
                if self.target_network is not None:
                    self.target_network.set_weights(self.q_network.get_weights())
                logger.log(f"{self.name} å¼ºåŒ–å­¦ä¹ æ¨¡å‹å·²åŠ è½½: {model_path}")
                return True
            else:
                logger.log(f"{self.name} æœªæ‰¾åˆ°å¼ºåŒ–å­¦ä¹ æ¨¡å‹æ–‡ä»¶: {model_path}")
                return False
        except Exception as e:
            logger.log(f"{self.name} åŠ è½½å¼ºåŒ–å­¦ä¹ æ¨¡å‹å¤±è´¥: {str(e)}")
            return False

    def _convert_eocatr_action_to_goal_type(self, action):
        """å°†EOCATRåŠ¨ä½œè½¬æ¢ä¸ºWBMç›®æ ‡ç±»å‹"""
        from wooden_bridge_model import GoalType
        
        action_to_goal_mapping = {
            'hunt': GoalType.RESOURCE_ACQUISITION,
            'gather': GoalType.RESOURCE_ACQUISITION,
            'move': GoalType.EXPLORATION,
            'explore': GoalType.EXPLORATION,
            'observe': GoalType.EXPLORATION,
            'analyze': GoalType.EXPLORATION,
            'seek': GoalType.RESOURCE_ACQUISITION,
            'search': GoalType.EXPLORATION,
            'avoid': GoalType.THREAT_AVOIDANCE,
            'escape': GoalType.THREAT_AVOIDANCE,
            'rest': GoalType.SURVIVAL,
            'heal': GoalType.SURVIVAL
        }
        
        return action_to_goal_mapping.get(action.lower(), GoalType.EXPLORATION)

    def make_decision_with_wooden_bridge(self, game):
        """ä½¿ç”¨æœ¨æ¡¥æ¨¡å‹è¿›è¡Œå†³ç­–(å¢å¼ºç‰ˆ - é›†æˆæ•´åˆå†³ç­–ç³»ç»Ÿ, BPMç³»ç»Ÿå’Œè§„å¾‹éªŒè¯)"""
        try:
            # === æœ€é«˜ä¼˜å…ˆçº§:æ•´åˆå†³ç­–ç³»ç»Ÿ===
            # ä¼˜å…ˆä½¿ç”¨æ•´åˆå†³ç­–ç³»ç»Ÿè¿›è¡Œå†³ç­–
            if hasattr(self, 'integrated_decision_active') and self.integrated_decision_active and self.integrated_decision_system:
                try:
                    # æ„å»ºå†³ç­–ä¸Šä¸‹"""
                    context = DecisionContext(
                        hp=self.hp,
                        food=self.food,
                        water=self.water,
                        position=(self.x, self.y),
                        day=getattr(game, 'current_day', 1),
                        environment=self._get_current_environment_type(game),
                        threats_nearby=len(self.detect_threats(game.game_map)) > 0,
                        resources_nearby=self._get_nearby_resources(game),
                        urgency_level=self._calculate_urgency_level()
                    )
                    
                    # ä½¿ç”¨æ•´åˆå†³ç­–ç³»ç»Ÿè¿›è¡Œå†³ç­–
                    decision_result = self.integrated_decision_system.make_integrated_decision(context, game)
                    
                    if decision_result.get('success') and decision_result.get('action'):
                        action = decision_result['action']
                        decision_source = decision_result.get('source', 'unknown')
                        confidence = decision_result.get('confidence', 0)
                        
                        if logger:
                            logger.log(f"{self.name} ğŸ—ä»æ•´åˆå†³ç­–ç³»ç»Ÿå»ºè®®è¡ŒåŠ¨: {action} (æ¥æº: {decision_source}, ç½®ä¿¡ä» {confidence:.2f})")
                        
                        return action
                        
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} æ•´åˆå†³ç­–ç³»ç»Ÿå¤±è´¥,å›é€€åˆ°æœ¨æ¡¥æ¨¡ä» {str(e)}")
            
            # ğŸ¯ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆå»ºç«‹EOCATRç›®æ ‡ï¼Œå†å»ºç«‹å¸¸è§„ç›®æ ‡
            self.current_goals = self._establish_current_goals_with_eocatr(game)
            
            # === CDLå‹å¥½æ¨¡å¼ ===
            # å¦‚æœèµ„æºå……è¶³ä¸”æ²¡æœ‰ç´§æ€¥å¨èƒ,å…è®¸CDLæ¥ç®¡å†³ç­–
            if (self.food > 60 and self.water > 60 and self.health > 70 and 
                not self.detect_threats(game.game_map)):
                # æ£€æŸ¥æ˜¯å¦æœ‰é«˜ç´§æ€¥åº¦çš„ç›®"
                high_urgency_goals = [g for g in self.current_goals if g.urgency > 0.7] if self.current_goals else []
                if not high_urgency_goals:
                    if logger:
                        logger.log(f"{self.name} ğŸŒ‰ æœ¨æ¡¥æ¨¡å‹:èµ„æºå……è¶³æ— ç´§æ€¥ç›®æ ‡,è®©ä½ç»™CDLæ¢ç´¢")
                    return None  # è¿”å›Noneè®©CDLæ¥ç®¡
            
            # å¦‚æœæ²¡æœ‰ç›®æ ‡,ä½¿ç”¨æ¢ç´¢è¡Œ"
            if not self.current_goals:
                return self._get_default_exploration_action()
            
            # é€‰æ‹©æœ€é‡è¦çš„ç›®"
            primary_goal = max(self.current_goals, key=lambda g: g.calculate_importance())
            
            # === æ–°å¢:è·å–éªŒè¯è§„å¾‹çš„è¡ŒåŠ¨å»ºè®® ===
            current_context = {
                'health_level': 'low' if self.health < 30 else 'medium' if self.health < 70 else 'high',
                'resource_status': 'depleted' if self.food < 30 or self.water < 30 else 'adequate',
                'environment': self._get_current_environment_type(game),
                'position': (self.x, self.y),
                'threats_nearby': len(self.detect_threats(game.game_map)) > 0
            }
            
            validated_rules_suggestions = self.get_validated_rules_for_action_suggestion(current_context)
            if validated_rules_suggestions:
                # é€‰æ‹©æœ€é«˜ç½®ä¿¡åº¦çš„è§„å¾‹å»º"
                best_rule = max(validated_rules_suggestions, key=lambda x: x.get('confidence', 0.0))
                suggested_action = best_rule.get('action_recommendation', '')
                
                if suggested_action and logger:
                    confidence = best_rule.get('confidence', 0.0)
                    logger.log(f"æ–°BPMç³»ç»Ÿå»ºè®®è¡ŒåŠ¨: {suggested_action} (ç½®ä¿¡ä» {confidence:.2f})")
                
                # éªŒè¯å»ºè®®çš„è¡ŒåŠ¨æ˜¯å¦å¯æ‰§è¡Œ
                if self._is_action_executable(suggested_action, game):
                    return suggested_action
            
            # ä»BPMç³»ç»Ÿè·å–å€™é€‰è§„"
            # === å¢å¼ºï¼šä»BMPç³»ç»Ÿè·å–EOCATRå€™é€‰è§„å¾‹ ===
            try:
                if hasattr(self, 'bmp') and self.bmp:
                    # å°è¯•è§¦å‘EOCATRç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆ
                    eocatr_config = self._build_eocatr_matrix_config(game, primary_goal)
                    systematic_rules = self.bmp.generate_systematic_eocatr_rules(eocatr_config)
                    
                    if systematic_rules:
                        # ç­›é€‰ä¸å½“å‰ç›®æ ‡ç›¸å…³çš„è§„å¾‹
                        goal_relevant_rules = []
                        for rule in systematic_rules:
                            if self._is_rule_applicable_to_goal(rule, primary_goal):
                                goal_relevant_rules.append(rule)
                        
                        if goal_relevant_rules:
                            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„è§„å¾‹
                            best_rule = max(goal_relevant_rules, key=lambda r: r.confidence)
                            
                            # å°è¯•å°†BMPè§„å¾‹è½¬æ¢ä¸ºWBMå¯æ‰§è¡Œçš„è¡ŒåŠ¨
                            wbm_action = self._convert_bmp_rule_to_action(best_rule, primary_goal, game)
                            
                            if wbm_action and self._is_action_executable(wbm_action, game):
                                if logger:
                                    logger.log(f"{self.name} ğŸŒ¸ BMP-EOCATRè§„å¾‹å»ºè®®è¡ŒåŠ¨: {wbm_action} (ç½®ä¿¡åº¦: {best_rule.confidence:.3f})")
                                return wbm_action
                        
                        if logger:
                            logger.log(f"{self.name} ğŸŒ¸ BMPç”Ÿæˆ{len(systematic_rules)}ä¸ªEOCATRè§„å¾‹ï¼Œ{len(goal_relevant_rules)}ä¸ªä¸ç›®æ ‡ç›¸å…³")
                
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} BMP-EOCATRè§„å¾‹è·å–å¤±è´¥: {str(e)}")
            
            # === å¤šæ­¥è§„åˆ’å†³ç­– ===
            # å°è¯•ç”Ÿæˆå¤šæ­¥è§„åˆ’æ¥å®ç°ç›®æ ‡
            if primary_goal:
                multi_step_plan = self._generate_multi_step_plan(primary_goal, game)
                if multi_step_plan and len(multi_step_plan.get('steps', [])) > 1:
                    # åˆ›å»ºå¹¶æ¿€æ´»å¤šæ­¥è®¡åˆ’
                    self.current_plan = multi_step_plan
                    self.current_plan_step = 0
                    self.plan_failure_count = 0
                    self.multi_step_stats['plans_created'] += 1
                    
                    if logger:
                        steps_count = len(multi_step_plan['steps'])
                        logger.log(f"{self.name} ğŸ—ºï¸ ç”Ÿæˆå¤šæ­¥è®¡åˆ’: {steps_count}æ­¥è¾¾æˆç›®æ ‡ '{primary_goal.description}'")
                        for i, step in enumerate(multi_step_plan['steps']):
                            logger.log(f"  æ­¥éª¤{i+1}: {step.get('action', 'unknown')}")
                    
                    # æ‰§è¡Œç¬¬ä¸€æ­¥
                    first_step_result = self._execute_next_plan_step(game)
                    if first_step_result['status'] == 'continue':
                        return None  # ç¬¬ä¸€æ­¥æˆåŠŸï¼Œç­‰å¾…ä¸‹å›åˆç»§ç»­
                    elif first_step_result['status'] == 'completed':
                        self.multi_step_stats['plans_completed'] += 1
                        self._reset_plan_state()
                        return None  # è®¡åˆ’æ„å¤–åœ°åœ¨ç¬¬ä¸€æ­¥å°±å®Œæˆäº†
                    else:
                        # ç¬¬ä¸€æ­¥å¤±è´¥ï¼Œé‡ç½®è®¡åˆ’çŠ¶æ€ï¼Œç»§ç»­ä½¿ç”¨é»˜è®¤è¡ŒåŠ¨
                        self._reset_plan_state()
            
            # å¦‚æœæ²¡æœ‰å¯ç”¨çš„è¡ŒåŠ¨å»ºè®®,ä½¿ç”¨é»˜è®¤çš„æ¢ç´¢è¡Œ"
            return self._get_default_exploration_action()
        except Exception as e:
            if logger:
                logger.log(f"{self.name} æœ¨æ¡¥æ¨¡å‹å†³ç­–å¤±è´¥: {str(e)}")
            return self._select_ilai_action()
    
    def _establish_current_goals_with_eocatr(self, game):
        """å»ºç«‹å½“å‰ç›®æ ‡(æ”¯æŒEOCATRæ ¼å¼ï¼Œä¼˜å…ˆçº§ï¼šEOCATRç›®æ ‡ > å¸¸è§„ç›®æ ‡)"""
        goals = []
        
        # ğŸ¯ CDLç®€åŒ–æœºåˆ¶ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨CDLä¼ é€’çš„EOCATRç›®æ ‡
        if hasattr(self, '_pending_cdl_goal') and self._pending_cdl_goal:
            cdl_goal = self._pending_cdl_goal
            
            # ä¼˜å…ˆå¤„ç†æ–°çš„cdl_explorationç±»å‹
            if cdl_goal.get('type') == 'cdl_exploration' and 'eocatr_goal' in cdl_goal:
                eocatr_goal = cdl_goal['eocatr_goal']
                
                # ğŸ¯ ç›´æ¥å°†CDLçš„EOCATRç›®æ ‡è½¬æ¢ä¸ºWBMç›®æ ‡
                from wooden_bridge_model import GoalType
                wbm_goal = self.wooden_bridge_model.establish_goal(
                    self._convert_eocatr_action_to_goal_type(eocatr_goal.get('action', 'explore')),
                    f"CDLæ¢ç´¢: {eocatr_goal.get('action', 'unknown')} {eocatr_goal.get('object', '')}",
                    priority=min(0.9, cdl_goal.get('urgency', 0.5) + 0.3),  # CDLæ¢ç´¢ç›®æ ‡é«˜ä¼˜å…ˆçº§
                    urgency=cdl_goal.get('urgency', 0.5),
                    context={
                        'eocatr_environment': eocatr_goal.get('environment', 'unknown'),
                        'eocatr_object': eocatr_goal.get('object', 'unknown'),
                        'eocatr_action': eocatr_goal.get('action', 'unknown'),
                        'eocatr_expected_result': eocatr_goal.get('expected_result', 'unknown'),
                        'eocatr_tool': eocatr_goal.get('tool', None),
                        'source': 'cdl_simplified',
                        'novelty_score': cdl_goal.get('novelty_score', 0.5),
                        'current_position': (self.x, self.y)
                    }
                )
                goals.append(wbm_goal)
                
                if logger:
                    novelty = cdl_goal.get('novelty_score', 0.0)
                    logger.log(f"{self.name} ğŸ¯ CDLç®€åŒ–ç›®æ ‡: {eocatr_goal.get('action')} â†’ {eocatr_goal.get('object')} (æ–°å¥‡åº¦:{novelty:.2f})")
                
                # ğŸ·ï¸ è®°å½•å°è¯•çš„è¡Œä¸ºï¼Œç”¨äºæ–°å¥‡åº¦è·Ÿè¸ª
                self._record_attempted_action(eocatr_goal)
                
                # æ¸…ç†å¾…å¤„ç†çš„CDLç›®æ ‡
                self._pending_cdl_goal = None
                
            # å…¼å®¹æ—§ç‰ˆCDLç›®æ ‡æ ¼å¼
            elif 'eocatr_goal' in cdl_goal:
                eocatr_goal = cdl_goal['eocatr_goal']
                
                from wooden_bridge_model import GoalType
                wbm_goal = self.wooden_bridge_model.establish_goal(
                    self._convert_eocatr_action_to_goal_type(eocatr_goal.get('action', 'explore')),
                    f"EOCATR: {eocatr_goal.get('action', 'unknown')} {eocatr_goal.get('object', '')}",
                    priority=cdl_goal.get('urgency', 0.5) + 0.2,
                    urgency=cdl_goal.get('urgency', 0.5),
                    context={
                        'eocatr_environment': eocatr_goal.get('environment', 'unknown'),
                        'eocatr_object': eocatr_goal.get('object', 'unknown'),
                        'eocatr_action': eocatr_goal.get('action', 'unknown'),
                        'eocatr_expected_result': eocatr_goal.get('expected_result', 'unknown'),
                        'eocatr_tool': eocatr_goal.get('tool', None),
                        'source': 'cdl_legacy',
                        'current_position': (self.x, self.y)
                    }
                )
                goals.append(wbm_goal)
                
                if logger:
                    logger.log(f"{self.name} ğŸ¯ å»ºç«‹EOCATRç›®æ ‡: {eocatr_goal.get('action')} â†’ {eocatr_goal.get('object')}")
                
                self._pending_cdl_goal = None
        
        # ğŸ”„ ç¬¬äºŒæ­¥ï¼šå»ºç«‹å¸¸è§„ç›®æ ‡ï¼ˆä»…åœ¨æ²¡æœ‰CDLæ¢ç´¢ç›®æ ‡æ—¶ï¼‰
        if not goals:  # å¦‚æœæ²¡æœ‰CDLç›®æ ‡ï¼Œæ‰å»ºç«‹å¸¸è§„ç›®æ ‡
            goals.extend(self._establish_current_goals(game))
        
        return goals
    
    def _establish_current_goals(self, game):
        """å»ºç«‹å½“å‰ç›®æ ‡(åŸºäºç¯å¢ƒçŠ¶æ€å’Œå†…åœ¨éœ€æ±‚)"""
        goals = []
        
        # åŸºäºç”Ÿå­˜éœ€æ±‚ç¡®ç«‹ç›®"""
        if self.health < 50:
            goals.append(self.wooden_bridge_model.establish_goal(
                GoalType.SURVIVAL,
                "ç´§æ€¥ç”Ÿå­˜éœ€",
                priority=0.9,
                urgency=0.8,
                context={
                    'current_health': self.health,
                    'current_position': (self.x, self.y),
                    'difficulty': 0.7
                }
            ))
        
        if self.water < 30:
            goals.append(self.wooden_bridge_model.establish_goal(
                GoalType.RESOURCE_ACQUISITION,
                "å¯»æ‰¾æ°´æº",
                priority=0.8,
                urgency=0.9,
                context={
                    'resource_type': 'water',
                    'current_amount': self.water,
                    'current_position': (self.x, self.y)
                }
            ))
        
        if self.food < 30:
            goals.append(self.wooden_bridge_model.establish_goal(
                GoalType.RESOURCE_ACQUISITION,
                "å¯»æ‰¾é£Ÿç‰©",
                priority=0.7,
                urgency=0.8,
                context={
                    'resource_type': 'food',
                    'current_amount': self.food,
                    'current_position': (self.x, self.y)
                }
            ))
        
        # æ£€æŸ¥å¨èƒæƒ…"
        threats = self.detect_threats(game.game_map)
        if threats:
            goals.append(self.wooden_bridge_model.establish_goal(
                GoalType.THREAT_AVOIDANCE,
                "è§„é¿å¨èƒ",
                priority=1.0,
                urgency=1.0,
                context={
                    'threats': threats,
                    'current_position': (self.x, self.y),
                    'threat_count': len(threats)
                }
            ))
        
        # æ¢ç´¢ç›®æ ‡(å½“åŸºæœ¬éœ€æ±‚æ»¡è¶³æ—¶"
        if self.health > 60 and self.water > 50 and self.food > 50 and not threats:
            goals.append(self.wooden_bridge_model.establish_goal(
                GoalType.EXPLORATION,
                "æ¢ç´¢ç¯å¢ƒ",
                priority=0.4,
                urgency=0.3,
                context={
                    'current_position': (self.x, self.y),
                    'exploration_radius': 5,
                    'difficulty': 0.3
                }
            ))
        
        return goals
    
    def _extract_rules_from_experience(self, goal):
        """ä»BPMç»éªŒä¸­æå–é€‚ç”¨äºç›®æ ‡çš„è§„å¾‹"""
        rules = []
        
        # === 2.0.0ç‰ˆæœ¬æ–°å¢:ä»BPMç³»ç»Ÿè·å–åŠ¨æ€ç”Ÿæˆçš„è§„å¾‹ ===
        if hasattr(self, 'bpm') and self.bpm and len(self.eocar_experiences) > 5:
            try:
                # æ€’æ”¾é˜¶æ®µ:ç”Ÿæˆæ–°çš„å€™é€‰è§„"""
                if len(self.eocar_experiences) >= 3:  # é™ä½æ€’æ”¾é—¨æ§›ä»ä¸ªç»"
                    recent_experiences = self.eocar_experiences[-5:]
                    # ä¿®å¤:ä½¿ç”¨å¤‡ä»½æ–‡ä»¶ä¸­çš„æ­£ç¡®è°ƒç”¨æ–¹æ³•
                    if recent_experiences:
                        latest_experience = recent_experiences[-1]
                        historical_batch = recent_experiences[:-1] if len(recent_experiences) > 1 else []
                        new_rules = self.bpm.process_experience(latest_experience, historical_batch)
                    else:
                        new_rules = []
                    if new_rules and logger:
                        logger.log(f"{self.name} ğŸŒ¸ BPMæ€’æ”¾é˜¶æ®µ:åŸºäº{len(recent_experiences)}ä¸ªç»éªŒç”Ÿæˆ{len(new_rules)}ä¸ªå€™é€‰è§„å¾‹")
                        for i, rule in enumerate(new_rules[:2]):  # æ˜¾ç¤ºä»ä¸ªè§„"
                            rule_type_content = getattr(rule, "generation_method", "unknown")
                            pattern_str = " + ".join([getattr(elem, "name", str(elem)) for elem in rule.pattern_elements])
                            logger.log(f"  å€™é€‰è§„å¾‹{i+1}: [{rule_type_content}] {pattern_str[:50]}... (ç½®ä¿¡ä» {rule.confidence:.3f})")
                    elif logger:
                        logger.log(f"{self.name} ğŸŒ¸ BPMæ€’æ”¾é˜¶æ®µ:åŸºäº{len(recent_experiences)}ä¸ªç»éªŒ,æœªç”Ÿæˆæ–°è§„å¾‹")
                
                # éªŒè¯é˜¶æ®µ:éªŒè¯ç°æœ‰è§„"
                validation_experiences = self.eocar_experiences[-3:] if len(self.eocar_experiences) >= 3 else self.eocar_experiences
                validated_rules = self.bpm.validation_phase(validation_experiences)
                
                # ğŸ”§ ä¿®å¤ï¼šå°†éªŒè¯é€šè¿‡çš„è§„å¾‹æ·»åŠ åˆ°ç©å®¶çš„validated_rulesåˆ—è¡¨
                if validated_rules:
                    for rule_id in validated_rules:
                        if hasattr(self.bpm, 'validated_rules') and rule_id in self.bpm.validated_rules:
                            bmp_rule = self.bpm.validated_rules[rule_id]
                            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶æ·»åŠ åˆ°ç©å®¶çš„éªŒè¯è§„å¾‹åˆ—è¡¨
                            rule_dict = {
                                'rule_id': rule_id,
                                'rule_type': bmp_rule.rule_type.value if hasattr(bmp_rule.rule_type, 'value') else str(bmp_rule.rule_type),
                                'conditions': bmp_rule.conditions,
                                'predictions': bmp_rule.predictions,
                                'confidence': bmp_rule.confidence,
                                'context': getattr(bmp_rule, 'context', {}),
                                'source': 'bmp_validation'
                            }
                            self._update_validated_rules(rule_dict)
                
                # ğŸ”§ æ–°å¢ï¼šè‡ªåŠ¨ä¿å­˜éªŒè¯é€šè¿‡çš„è§„å¾‹åˆ°äº”åº“ç³»ç»Ÿ
                if validated_rules and hasattr(self, 'five_library_system'):
                    saved_rules_count = 0
                    for rule_id in validated_rules:
                        if hasattr(self.bpm, 'validated_rules') and rule_id in self.bpm.validated_rules:
                            bmp_rule = self.bpm.validated_rules[rule_id]
                            
                            # è½¬æ¢BMPè§„å¾‹æ ¼å¼ä¸ºäº”åº“ç³»ç»Ÿæ ¼å¼
                            try:
                                save_result = self.five_library_system.add_rule(
                                    rule_type=bmp_rule.rule_type.value if hasattr(bmp_rule.rule_type, 'value') else str(bmp_rule.rule_type),
                                    conditions=bmp_rule.conditions,
                                    predictions=bmp_rule.predictions,
                                    confidence=bmp_rule.confidence,
                                    support_count=len(bmp_rule.evidence.supporting_experiences),
                                    contradiction_count=len(bmp_rule.evidence.contradicting_experiences),
                                    creator_id=self.name,
                                    validation_status='validated'
                                )
                                
                                if save_result.get('success', False):
                                    saved_rules_count += 1
                                    if logger:
                                        logger.log(f"  âœ… è§„å¾‹å·²ä¿å­˜åˆ°äº”åº“: {rule_id}")
                                else:
                                    if logger:
                                        logger.log(f"  âŒ è§„å¾‹ä¿å­˜å¤±è´¥: {rule_id} - {save_result.get('error', 'Unknown error')}")
                            
                            except Exception as e:
                                if logger:
                                    logger.log(f"  âŒ è§„å¾‹ä¿å­˜å¼‚å¸¸: {rule_id} - {str(e)}")
                    
                    if saved_rules_count > 0 and logger:
                        logger.log(f"{self.name} ğŸ’¾ å·²ä¿å­˜{saved_rules_count}æ¡éªŒè¯è§„å¾‹åˆ°äº”åº“ç³»ç»Ÿ")
                
                if validated_rules and logger:
                    logger.log(f"{self.name} ğŸ“Š BPMéªŒè¯é˜¶æ®µ:éªŒè¯äº†{len(validated_rules)}ä¸ªè§„å¾‹")
                    for rule_id in validated_rules[:2]:  # æ˜¾ç¤ºå‰ä¸ªéªŒè¯è§„å¾‹
                        if hasattr(self.bpm, 'validated_rules') and rule_id in self.bpm.validated_rules:
                            rule = self.bpm.validated_rules[rule_id]
                            logger.log(f"  éªŒè¯è§„å¾‹: {rule.pattern[:50]}... (ç½®ä¿¡ä» {rule.confidence:.3f})")
                elif logger:
                    logger.log(f"{self.name} ğŸ“Š BPMéªŒè¯é˜¶æ®µ:åŸºäº{len(validation_experiences)}ä¸ªç»éªŒ,æ— è§„å¾‹é€šè¿‡éªŒè¯")
                
                # å‰ªæé˜¶æ®µ:ç§»é™¤ä½è´¨é‡è§„å¾‹
                pruned_rules = self.bpm.pruning_phase()
                if pruned_rules and logger:
                    logger.log(f"{self.name} âœ‚ï¸ BPMå‰ªæé˜¶æ®µ:ç§»é™¤äº†{len(pruned_rules)}ä¸ªä½è´¨é‡è§„å¾‹")
                
                # è·å–é€‚ç”¨äºå½“å‰ç›®æ ‡çš„è§„å¾‹
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„EOCATRå…ƒç»„ç”¨äºè§„å¾‹åŒ¹é…
                current_context = {
                    'goal_type': goal.goal_type.value,
                    'health': self.health,
                    'position': (self.x, self.y),
                    'urgency': goal.urgency
                }
                
                # ä»BPMè·å–é€‚ç”¨çš„è§„å¾‹å¹¶è½¬æ¢ä¸ºæœ¨æ¡¥æ¨¡å‹æ ¼å¼
                bmp_rules = self.bpm.get_all_validated_rules()
                for candidate_rule in bmp_rules:
                    if self._is_rule_applicable_to_goal(candidate_rule, goal):
                        # è½¬æ¢CandidateRuleä¸ºæœ¨æ¡¥æ¨¡å‹çš„Ruleæ ¼å¼
                        wbm_rule = self._convert_candidate_rule_to_wbm_rule(candidate_rule, goal)
                        if wbm_rule:
                            rules.append(wbm_rule)
                
                # æ›´æ–°çŸ¥è¯†æ¼”åŒ–ç»Ÿè®¡
                if not hasattr(self, 'knowledge_evolution_stats'):
                    self.knowledge_evolution_stats = {
                        'rules_generated': 0, 
                        'rules_validated': 0,
                        'evolution_cycles': 0,
                        'successful_adaptations': 0
                    }
                
                # å®‰å…¨åœ°å¢åŠ evolution_cyclesè®¡æ•°
                if not hasattr(self, 'knowledge_evolution_stats'):
                    self.knowledge_evolution_stats = {
                        'rules_generated': 0, 
                        'rules_validated': 0,
                        'evolution_cycles': 0,
                        'successful_adaptations': 0,
                        'rules_pruned': 0
                    }
                self.knowledge_evolution_stats['evolution_cycles'] = self.knowledge_evolution_stats.get('evolution_cycles', 0) + 1
                
                if logger:
                    logger.log(f"{self.name} ä»BPMè·å– {len([r for r in rules if 'bpm_' in r.rule_id])} ä¸ªé€‚ç”¨è§„å¾‹")
                        
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} BPMè§„å¾‹æå–å¤±è´¥: {str(e)}")
        
        # ä»å¤šå±‚æ¬¡è®°å¿†ç³»ç»Ÿä¸­æå–ç›¸å…³è§„"
        if hasattr(self, 'memory_system') and self.memory_system:
            try:
                # è·å–ç›¸å…³çš„æƒ…æ™¯è®°"
                context_key = f"{goal.goal_type.value}_{goal.description}"
                relevant_memories = self.memory_system.get_relevant_memories(
                    query=context_key,
                    memory_type="episodic",
                    limit=10
                )
                
                # å°†è®°å¿†è½¬æ¢ä¸ºè§„å¾‹
                for memory in relevant_memories:
                    rule = self._memory_to_rule(memory, goal)
                    if rule:
                        rules.append(rule)
                        
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} ä»è®°å¿†ç³»ç»Ÿæå–è§„å¾‹å¤±ä» {str(e)}")
        
        # === æ–°å¢:ä»é—´æ¥ç»éªŒåº“ä¸­æå–è§„å¾‹ ===
        # æ•´åˆæ¥è‡ªå…¶ä»–æ™ºèƒ½ä½“çš„é«˜è´¨é‡ç»"
        try:
            # æ„å»ºå½“å‰ä¸Šä¸‹æ–‡ç”¨äºåŒ¹é…ç›¸å…³é—´æ¥ç»"
            current_context = {
                'goal_type': goal.goal_type.value,
                'description': goal.description,
                'health': self.health,
                'food': self.food, 
                'water': self.water,
                'position': (self.x, self.y),
                'urgency': goal.urgency,
                'priority': goal.priority
            }
            
            # è·å–ç›¸å…³çš„é—´æ¥ç»éªŒå"
            indirect_preferences = self.integrate_indirect_experiences_in_decision(current_context)
            
            if indirect_preferences:
                # å°†é—´æ¥ç»éªŒåå¥½è½¬æ¢ä¸ºæœ¨æ¡¥æ¨¡å‹è§„å¾‹
                for action, weight in indirect_preferences.items():
                    if weight > 0.3:  # åªè€ƒè™‘æƒé‡è¾ƒé«˜çš„è¡ŒåŠ¨å"
                        # åˆ›å»ºåŸºäºé—´æ¥ç»éªŒçš„è§„"
                        from wooden_bridge_model import Rule  # å¯¼å…¥Rule"
                        indirect_rule = Rule(
                            rule_id=f"indirect_{goal.goal_type.value}_{action}_{int(weight*100)}",
                            rule_type="indirect_experience",
                            conditions={
                                'goal_type': goal.goal_type.value,
                                'action_type': action,
                                'confidence': weight
                            },
                            predictions={
                                'action': action,
                                'success_probability': weight,
                                'source': 'indirect_experience'
                            },
                            confidence=weight,
                            usage_count=int(weight * 10),  # åŸºäºæƒé‡ä¼°ç®—ä½¿ç”¨æ¬¡æ•°
                            success_count=int(weight * weight * 10),  # ä¼°ç®—æˆåŠŸæ¬¡æ•°
                            applicable_contexts=[goal.goal_type.value]
                        )
                        rules.append(indirect_rule)
                        
                        if logger:
                            logger.log(f"{self.name} ä»é—´æ¥ç»éªŒåº“æå–è§„å¾‹: {action} (æƒé‡: {weight:.2f})")
                
            # è·å–é«˜å¯ä¿¡åº¦çš„å…·ä½“é—´æ¥ç»"
            relevant_indirect = self.get_relevant_indirect_experiences(
                context_filter=current_context,
                min_credibility=0.7
            )
            
            for indirect_exp in relevant_indirect[:5]:  # é™åˆ¶æœ€ä»ä¸ªé—´æ¥ç»"
                try:
                    # å°†é—´æ¥ç»éªŒè½¬æ¢ä¸ºè§„å¾‹
                    action = indirect_exp.get('action', '')
                    credibility = indirect_exp.get('credibility', 0)
                    success = indirect_exp.get('result', {}).get('success', False)
                    source = indirect_exp.get('source', 'unknown')
                    
                    if action and credibility > 0.6:
                        from wooden_bridge_model import Rule  # å¯¼å…¥Rule"
                        indirect_rule = Rule(
                            rule_id=f"indirect_exp_{source}_{action}_{int(credibility*100)}",
                            rule_type="indirect_experience",
                            conditions={
                                'context': indirect_exp.get('context', {}),
                                'source_agent': source,
                                'credibility': credibility
                            },
                            predictions={
                                'action': action,
                                'success_probability': credibility * (1.0 if success else 0.5),
                                'source': f'indirect_from_{source}'
                            },
                            confidence=credibility * 0.8,  # é—´æ¥ç»éªŒç½®ä¿¡åº¦ç¨å¾®é™"
                            usage_count=1,
                            success_count=1 if success else 0,
                            applicable_contexts=[goal.goal_type.value]
                        )
                        rules.append(indirect_rule)
                        
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} é—´æ¥ç»éªŒè½¬æ¢è§„å¾‹å¤±è´¥: {str(e)}")
                        
            if logger and len([r for r in rules if 'indirect' in r.rule_id]) > 0:
                indirect_count = len([r for r in rules if 'indirect' in r.rule_id])
                logger.log(f"{self.name} ä»é—´æ¥ç»éªŒåº“è·å– {indirect_count} ä¸ªè§„å¾‹")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} é—´æ¥ç»éªŒåº“è§„å¾‹æå–å¤±ä» {str(e)}")
        
        # æ·»åŠ åŸºç¡€è§„å¾‹(ç¡¬ç¼–ç çš„åŸºæœ¬ç”Ÿå­˜è§„å¾‹)
        basic_rules = self._get_basic_survival_rules(goal)
        rules.extend(basic_rules)
        
        return rules
    
    def _memory_to_rule(self, memory, goal):
        """å°†è®°å¿†è½¬æ¢ä¸ºè§„å¾‹"""
        try:
            # ä»è®°å¿†ä¸­æå–æ¡ä»¶å’Œç»“"""
            memory_content = memory.get('content', {})
            memory_context = memory.get('context', {})
            memory_outcome = memory.get('outcome', {})
            
            # æ„å»ºè§„å¾‹æ¡ä»¶
            conditions = {}
            if 'situation' in memory_context:
                conditions['situation'] = memory_context['situation']
            if 'health_level' in memory_context:
                conditions['health_level'] = memory_context['health_level']
            if 'resource_level' in memory_context:
                conditions['resource_level'] = memory_context['resource_level']
            
            # æ„å»ºè§„å¾‹é¢„æµ‹
            predictions = {}
            if 'action_taken' in memory_content:
                predictions['action'] = memory_content['action_taken']
            if 'success_rate' in memory_outcome:
                predictions['success_probability'] = memory_outcome['success_rate']
            
            # è®¡ç®—è§„å¾‹ç½®ä¿¡"
            confidence = memory.get('reliability', 0.5)
            success_count = memory_outcome.get('success_count', 0)
            total_count = memory_outcome.get('total_count', 1)
            
            rule = Rule(
                rule_id=f"memory_{memory.get('id', 'unknown')}_{time.time()}",
                rule_type="experiential",
                conditions=conditions,
                predictions=predictions,
                confidence=confidence,
                usage_count=total_count,
                success_count=success_count,
                applicable_contexts=[goal.goal_type.value]
            )
            
            return rule
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®°å¿†è½¬è§„å¾‹å¤±ä» {str(e)}")
            return None
    
    def _get_basic_survival_rules(self, goal):
        """è·å–åŸºç¡€ç”Ÿå­˜è§„å¾‹"""
        rules = []
        
        if goal.goal_type == GoalType.SURVIVAL:
            # ç”Ÿå­˜è§„å¾‹:ä¼˜å…ˆå¯»æ‰¾æ°´å’Œé£Ÿ"""
            rules.append(Rule(
                rule_id="survival_water_priority",
                rule_type="action",
                conditions={"health_level": "low", "resource_type": "water"},
                predictions={"action": "search", "priority": "high"},
                confidence=0.8,
                applicable_contexts=["survival"]
            ))
            
            rules.append(Rule(
                rule_id="survival_food_priority",
                rule_type="action", 
                conditions={"health_level": "low", "resource_type": "food"},
                predictions={"action": "collect", "priority": "high"},
                confidence=0.8,
                applicable_contexts=["survival"]
            ))
        
        elif goal.goal_type == GoalType.THREAT_AVOIDANCE:
            # å¨èƒè§„é¿è§„å¾‹
            rules.append(Rule(
                rule_id="threat_escape",
                rule_type="action",
                conditions={"threat_present": True, "threat_distance": "close"},
                predictions={"action": "escape", "direction": "away_from_threat"},
                confidence=0.9,
                applicable_contexts=["threat_avoidance"]
            ))
        
        elif goal.goal_type == GoalType.RESOURCE_ACQUISITION:
            # èµ„æºè·å–è§„å¾‹
            rules.append(Rule(
                rule_id="resource_search",
                rule_type="action",
                conditions={"resource_needed": True, "resource_available": True},
                predictions={"action": "collect", "success_rate": 0.7},
                confidence=0.7,
                applicable_contexts=["resource_acquisition"]
            ))
        
        elif goal.goal_type == GoalType.EXPLORATION:
            # æ¢ç´¢è§„å¾‹
            rules.append(Rule(
                rule_id="exploration_systematic",
                rule_type="action",
                conditions={"safety_level": "high", "exploration_needed": True},
                predictions={"action": "move", "pattern": "systematic"},
                confidence=0.6,
                applicable_contexts=["exploration"]
            ))
        
        return rules
    
    def _update_rule_performance(self, bridge_plan, execution_result):
        """æ›´æ–°è§„å¾‹æ€§èƒ½è®°å½•"""
        success = execution_result['success']
        
        for rule in bridge_plan.rules_used:
            rule_id = rule.rule_id
            
            if rule_id not in self.rule_performance_tracker:
                self.rule_performance_tracker[rule_id] = {
                    'usage_count': 0,
                    'success_count': 0,
                    'total_utility': 0.0,
                    'contexts_used': set()
                }
            
            tracker = self.rule_performance_tracker[rule_id]
            tracker['usage_count'] += 1
            
            if success:
                tracker['success_count'] += 1
            
            # è®°å½•ä½¿ç”¨ä¸Šä¸‹"""
            tracker['contexts_used'].add(bridge_plan.goal.goal_type.value)
            
            # æ›´æ–°æ€»æ•ˆ"
            utility = bridge_plan.calculate_utility()
            tracker['total_utility'] += utility
            
            # åŒæ­¥æ›´æ–°å†…å­˜ç³»ç»Ÿä¸­çš„è§„å¾‹æ•ˆæœ
            if hasattr(self, 'memory_system') and self.memory_system:
                try:
                    # å°†utilityä½œä¸ºeffectiveness_scoreä»-1èŒƒå›´"
                    effectiveness_score = min(1.0, max(0.0, utility / 2.0))  # å°†utilityç¼©æ”¾ä»-1èŒƒå›´
                    
                    # æ„å»ºoutcomeå­—å…¸
                    outcome = {
                        'success': success,
                        'utility': utility,
                        'context': bridge_plan.goal.context,
                        'rule_id': rule_id,
                        'timestamp': time.time()
                    }
                    
                    self.memory_system.update_rule_effectiveness(
                        rule_id=rule_id,
                        effectiveness_score=effectiveness_score,
                        outcome=outcome
                    )
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} æ›´æ–°è®°å¿†ç³»ç»Ÿè§„å¾‹æ•ˆæœå¤±è´¥: {str(e)}")
    
    def _convert_bridge_to_game_action(self, bridge_plan, execution_result):
        """å°†æ¡¥æ¢æ–¹æ¡ˆè½¬æ¢ä¸ºå…·ä½“çš„æ¸¸æˆåŠ¨ç‰©"""
        # è·å–æ¡¥æ¢æ–¹æ¡ˆçš„ç¬¬ä¸€ä¸ªè¡Œ"""
        if bridge_plan.action_sequence:
            action = bridge_plan.action_sequence[0]
            
            # å°†æŠ½è±¡è¡ŒåŠ¨æ˜ å°„åˆ°å…·ä½“æ¸¸æˆåŠ¨ç‰©
            action_mapping = {
                "search": "move",  # æœç´¢è½¬æ¢ä¸ºç§»"
                "collect": "collect",  # æ”¶é›†ä¿æŒä¸å˜
                "escape": "move",  # é€ƒè„±è½¬æ¢ä¸ºç§»"
                "assess_threats": "observe",  # è¯„ä¼°å¨èƒè½¬æ¢ä¸ºè§‚"
                "secure_resources": "collect",  # ç¡®ä¿èµ„æºè½¬æ¢ä¸ºæ”¶"
                "approach": "move",  # æ¥è¿‘è½¬æ¢ä¸ºç§»"
                "observe": "observe",  # è§‚å¯Ÿä¿æŒä¸å˜
                "move": "move",  # ç§»åŠ¨ä¿æŒä¸å˜
                "drink": "drink",  # é¥®æ°´ä¿æŒä¸å˜
                "attack": "attack"  # æ”»å‡»ä¿æŒä¸å˜
            }
            
            mapped_action = action_mapping.get(action, "move")
            
            if logger:
                logger.log(f"{self.name} æœ¨æ¡¥æ–¹æ¡ˆæ‰§è¡ŒæˆåŠŸ,åŠ¨ç‰© {action} -> {mapped_action}")
            
            return mapped_action
        
        return "move"  # é»˜è®¤åŠ¨ç‰©
    
    def _process_learning_needs(self, learning_needs, game):
        """å¤„ç†å­¦ä¹ éœ€æ±‚(ä¸CDLç³»ç»Ÿé›†æˆ)"""
        try:
            if self.cdl_active and hasattr(self, 'curiosity_driven_learning'):
                # å°†å­¦ä¹ éœ€æ±‚è½¬å‘ç»™CDLç³»ç»Ÿå¤„ç†
                from curiosity_driven_learning import ContextState
                
                context_state = ContextState(
                    symbolized_scene=[
                        {'object': 'agent', 'characteristics': {'type': 'self'}},
                        {'object': 'environment', 'characteristics': {'type': 'current'}}
                    ],
                    agent_internal_state={
                        'health': self.health,
                        'food': self.food,
                        'water': self.water,
                        'position': (self.x, self.y)
                    },
                    environmental_factors={
                        'terrain': 'unknown',
                        'weather': 'unknown'
                    },
                    social_context={
                        'entities': [],
                        'missing_rules': learning_needs.get('missing_rules', [])
                    },
                    timestamp=time.time()
                )
                
                # è¯„ä¼°ä¸Šä¸‹æ–‡æ–°é¢–"""
                novelty_score = self.curiosity_driven_learning.evaluate_context_novelty(context_state)
                
                # ç”Ÿæˆæ¢ç´¢ç­–ç•¥
                exploration_strategy = self.curiosity_driven_learning.generate_exploration_strategy(
                    context=context_state,
                    available_actions=['move', 'observe', 'collect', 'search'],
                    development_stage=self.phase.lower() if hasattr(self, 'phase') else 'child'
                )
                
                if logger:
                    logger.log(f"{self.name} CDLå¤„ç†å­¦ä¹ éœ€æ±‚,æ–°é¢–ä» {novelty_score:.2f}")
                
                # åŸºäºCDLåé¦ˆè°ƒæ•´è¡Œä¸º
                if exploration_strategy.get('should_explore', False):
                    return self._trigger_exploration_learning(game)
                    
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¤„ç†å­¦ä¹ éœ€æ±‚å¤±ä» {str(e)}")
    
    def _trigger_exploration_learning(self, game):
        """è§¦å‘æ¢ç´¢å­¦ä¹ """
        # ä¸CDLç³»ç»Ÿåä½œè¿›è¡Œæ¢ç´¢
        exploration_action = "move"  # é»˜è®¤æ¢ç´¢åŠ¨ç‰©
        
        if self.cdl_active and hasattr(self, 'curiosity_driven_learning'):
            try:
                from curiosity_driven_learning import ContextState
                
                context_state = ContextState(
                    agent_internal_state={'position': (self.x, self.y)},
                    environmental_factors={'exploration_needed': True},
                    timestamp=time.time()
                )
                
                exploration_strategy = self.curiosity_driven_learning.generate_exploration_strategy(
                    context=context_state,
                    available_actions=['move', 'observe', 'search'],
                    development_stage=getattr(self, 'phase', 'child').lower()
                )
                
                strategy_type = exploration_strategy.get('strategy', 'random_walk')
                if strategy_type == 'novelty_seeking':
                    exploration_action = "observe"
                elif strategy_type == 'systematic_scan':
                    exploration_action = "search"
                else:
                    exploration_action = "move"
                    
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} CDLæ¢ç´¢ç­–ç•¥ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return exploration_action
    
    def _get_current_game_state(self, game):
        """è·å–å½“å‰æ¸¸æˆçŠ¶æ€"""
        return {
            'turn': getattr(game, 'turn', 0),
            'day': getattr(game, 'day', 0),
            'players_alive': len([p for p in game.players if p.is_alive()]),
            'map_size': (game.game_map.width, game.game_map.height),
            'resource_abundance': len(game.game_map.plants),
            'threat_level': len([a for a in game.game_map.animals if hasattr(a, 'is_predator') and a.is_predator])
        }

    def _is_rule_applicable_to_goal(self, candidate_rule, goal):
        """æ£€æŸ¥BPMå€™é€‰è§„å¾‹æ˜¯å¦é€‚ç”¨äºå½“å‰ç›®æ ‡"""
        try:
            # æ ¹æ®è§„å¾‹ç±»å‹å’Œç›®æ ‡ç±»å‹è¿›è¡ŒåŒ¹"""
            rule_type = candidate_rule.rule_type
            goal_type = goal.goal_type
            
            # ç±»å‹åŒ¹é…è§„åˆ™
            type_compatibility = {
                RuleType.SPATIAL: [GoalType.EXPLORATION, GoalType.RESOURCE_ACQUISITION],
                RuleType.CONDITIONAL: [GoalType.SURVIVAL, GoalType.THREAT_AVOIDANCE],
                RuleType.SEQUENTIAL: [GoalType.EXPLORATION, GoalType.LEARNING],
                RuleType.CAUSAL: [GoalType.SURVIVAL, GoalType.THREAT_AVOIDANCE, GoalType.RESOURCE_ACQUISITION]
            }
            
            # æ£€æŸ¥è§„å¾‹ç±»å‹æ˜¯å¦ä¸ç›®æ ‡ç±»å‹å…¼å®¹
            compatible_goals = type_compatibility.get(rule_type, [])
            if goal_type not in compatible_goals:
                return False
            
            # æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆ"
            if candidate_rule.confidence < 0.3:
                return False
            
            # æ£€æŸ¥é€‚ç”¨ä¸Šä¸‹æ–‡(å¦‚æœæœ‰çš„è¯)
            if hasattr(candidate_rule, 'context') and candidate_rule.context:
                # ç®€å•çš„ä¸Šä¸‹æ–‡åŒ¹é…é€»è¾‘
                rule_context = candidate_rule.context
                if 'health_threshold' in rule_context:
                    if self.health < rule_context['health_threshold'] and goal_type != GoalType.SURVIVAL:
                        return False
            
            return True
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è§„å¾‹é€‚ç”¨æ€§æ£€æŸ¥å¤±ä» {str(e)}")
            return False
    
    def _convert_candidate_rule_to_wbm_rule(self, candidate_rule, goal):
        """å°†BPMçš„CandidateRuleè½¬æ¢ä¸ºæœ¨æ¡¥æ¨¡å‹çš„Ruleæ ¼å¼"""
        try:
            # æ„å»ºæ¡ä»¶
            conditions = {}
            if hasattr(candidate_rule, 'antecedent') and candidate_rule.antecedent:
                # ä»å‰ä»¶ä¸­æå–æ¡ä»¶
                for key, value in candidate_rule.antecedent.items():
                    conditions[key] = value
            
            # æ·»åŠ ç›®æ ‡ç›¸å…³çš„æ¡"""
            conditions['goal_type'] = goal.goal_type.value
            conditions['urgency_level'] = 'high' if goal.urgency > 0.7 else 'normal'
            
            # æ„å»ºé¢„æµ‹
            predictions = {}
            if hasattr(candidate_rule, 'consequent') and candidate_rule.consequent:
                # ä»åä»¶ä¸­æå–é¢„æµ‹
                for key, value in candidate_rule.consequent.items():
                    predictions[key] = value
            
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„è¡ŒåŠ¨é¢„æµ‹,æ ¹æ®è§„å¾‹ç±»å‹æ¨æ–­
            if 'action' not in predictions:
                action_mapping = {
                    RuleType.SPATIAL: 'move',
                    RuleType.CONDITIONAL: 'assess',
                    RuleType.SEQUENTIAL: 'explore',
                    RuleType.CAUSAL: 'execute'
                }
                predictions['action'] = action_mapping.get(candidate_rule.rule_type, 'move')
            
            # åˆ›å»ºæœ¨æ¡¥æ¨¡å‹è§„å¾‹
            wbm_rule = Rule(
                rule_id=f"bpm_{candidate_rule.rule_id}_{int(time.time())}",
                rule_type="bpm_generated",
                conditions=conditions,
                predictions=predictions,
                confidence=candidate_rule.confidence,
                usage_count=getattr(candidate_rule, 'usage_count', 0),
                success_count=getattr(candidate_rule, 'success_count', 0),
                applicable_contexts=[goal.goal_type.value],
                creation_time=time.time()
            )
            
            return wbm_rule
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} BPMè§„å¾‹è½¬æ¢å¤±è´¥: {str(e)}")
            return None
    
    def add_eocar_experience(self, action_taken, result_obtained, source="direct"):
        """æ·»åŠ EOCATRç»éªŒåˆ°BMPç³»ç»Ÿ(å¢å¼ºç‰ˆ - è§¦å‘çŸ¥è¯†æ¼”åŒ–)"""
        import time
        
        # ğŸ”§ åŠ¨ä½œç»Ÿä¸€ï¼šå°†left/right/up/downç»Ÿä¸€ä¸ºmove
        def unify_action_name(action_name):
            """ç»Ÿä¸€åŠ¨ä½œåç§°"""
            if action_name in ['left', 'right', 'up', 'down']:
                return 'move'
            return action_name
        
        def enhance_action_data(original_action, position_change=None):
            """å¢å¼ºåŠ¨ä½œæ•°æ®ï¼Œä¿ç•™åŸå§‹ä¿¡æ¯"""
            unified_action = unify_action_name(original_action)
            
            enhanced_data = {
                'type': unified_action,
                'original_action': original_action,
                'target': None,
                'parameters': {}
            }
            
            # å¦‚æœæ˜¯æ–¹å‘æ€§åŠ¨ä½œï¼Œæ·»åŠ æ–¹å‘ä¿¡æ¯
            if original_action in ['left', 'right', 'up', 'down']:
                enhanced_data['direction'] = original_action
                enhanced_data['parameters']['movement_type'] = 'directional'
                
                # å¦‚æœæœ‰ä½ç½®å˜åŒ–ä¿¡æ¯ï¼Œä¹Ÿä¿å­˜ä¸‹æ¥
                if position_change:
                    enhanced_data['parameters']['position_change'] = position_change
            
            return enhanced_data
        
        # åº”ç”¨åŠ¨ä½œç»Ÿä¸€
        position_change = None
        if isinstance(result_obtained, dict) and 'position_change' in result_obtained:
            position_change = result_obtained['position_change']
            
        if isinstance(action_taken, str):
            enhanced_action_data = enhance_action_data(action_taken, position_change)
        elif isinstance(action_taken, dict) and 'type' in action_taken:
            original_action = action_taken['type']
            enhanced_action_data = action_taken.copy()
            enhanced_action_data['type'] = unify_action_name(original_action)
            enhanced_action_data['original_action'] = original_action
            if original_action in ['left', 'right', 'up', 'down']:
                enhanced_action_data['direction'] = original_action
                enhanced_action_data['parameters'] = enhanced_action_data.get('parameters', {})
                enhanced_action_data['parameters']['movement_type'] = 'directional'
                if position_change:
                    enhanced_action_data['parameters']['position_change'] = position_change
        else:
            enhanced_action_data = action_taken
        
        # åˆ›å»ºç»éªŒå­—å…¸
        if isinstance(action_taken, str):
            # å¦‚æœaction_takenæ˜¯å­—ç¬¦ä¸²,åˆ›å»ºå®Œæ•´çš„ç»éªŒå­—å…¸
            experience_dict = {
                'environment': {
                    'position': (self.x, self.y),
                    'health': self.health,
                    'food': self.food,
                    'water': self.water,
                    'timestamp': time.time()
                },
                'observation': {
                    'visible_threats': 0,  # å¯ä»¥åç»­å¢å¼º
                    'visible_resources': 'unknown',
                    'terrain_type': 'unknown'
                },
                'cognition': {
                    'goal_active': len(getattr(self, 'current_goals', [])) > 0,
                    'reasoning_strategy': 'active',
                    'attention_focus': 'survival'
                },
                'action': enhanced_action_data,  # ä½¿ç”¨å¢å¼ºçš„åŠ¨ä½œæ•°æ®
                'result': result_obtained if isinstance(result_obtained, dict) else {'success': bool(result_obtained)},
                'source': source,
                'timestamp': time.time()
            }
        else:
            # å¦‚æœaction_takenå·²ç»æ˜¯å­—å…¸,ç›´æ¥ä½¿ç”¨
            experience_dict = action_taken.copy()
            if 'timestamp' not in experience_dict:
                experience_dict['timestamp'] = time.time()
            if 'source' not in experience_dict:
                experience_dict['source'] = source

        # ç¡®ä¿å­˜åœ¨eocar_experiencesåˆ—è¡¨
        if not hasattr(self, 'eocar_experiences'):
            self.eocar_experiences = []
            
        # å°†å­—å…¸è½¬æ¢ä¸ºEOCAR_Tupleå¯¹è±¡
        eocar_tuple = self._convert_dict_to_eocar_tuple(experience_dict)
        
        # æ·»åŠ åˆ°EOCATRç»éªŒ"""
        self.eocar_experiences.append(eocar_tuple)
        
        # === æ–°å¢:å­˜å‚¨åˆ°äº”åº“ç³»ç»Ÿ ===
        try:
            self.add_experience_to_direct_library(action_taken, result_obtained, experience_dict)
            if logger:
                logger.log(f"äº”åº“ç»éªŒå­˜å‚¨æˆåŠŸ: {action_taken}")
        except Exception as e:
            if logger:
                logger.log(f"äº”åº“ç³»ç»Ÿç»éªŒæ·»åŠ å¤±è´¥: {str(e)}")
        
        # ç»´æŠ¤å®¹é‡é™åˆ¶
        if len(self.eocar_experiences) > getattr(self, 'max_eocar_experiences', 100):
            self.eocar_experiences.pop(0)
            
        # æ¯å½“æ·»åŠ æ–°ç»éªŒæ—¶,è§¦å‘å°è§„æ¨¡çŸ¥è¯†æ¼”åŒ–(é™ä½é—¨æ§›)
        if hasattr(self, 'bpm') and self.bpm and len(self.eocar_experiences) > 2:
            if len(self.eocar_experiences) % 2 == 0:  # ä»ä¸ªç»éªŒè§¦å‘ä¸€"
                # ä½¿ç”¨æœ€è¿‘çš„ç»éªŒè¿›è¡Œå°è§„æ¨¡çŸ¥è¯†ç”Ÿæˆ(ä¼ é€’EOCAR_Tupleå¯¹è±¡"
                recent_experiences = self.eocar_experiences[-3:] if len(self.eocar_experiences) >= 3 else self.eocar_experiences
                try:
                    # ä¿®å¤:ä½¿ç”¨å¤‡ä»½æ–‡ä»¶ä¸­çš„æ­£ç¡®è°ƒç”¨æ–¹æ³•
                    if recent_experiences:
                        latest_experience = recent_experiences[-1]
                        historical_batch = recent_experiences[:-1] if len(recent_experiences) > 1 else []
                        new_rules = self.bpm.process_experience(latest_experience, historical_batch)
                    else:
                        new_rules = []
                    
                    if new_rules:
                        if not hasattr(self, 'knowledge_evolution_stats'):
                            self.knowledge_evolution_stats = {
                                'rules_generated': 0, 
                                'rules_validated': 0,
                                'evolution_cycles': 0,
                                'successful_adaptations': 0,
                                'rules_pruned': 0
                            }
                        
                        # å®‰å…¨åœ°å¢åŠ rules_generatedè®¡æ•°
                        self.knowledge_evolution_stats['rules_generated'] = self.knowledge_evolution_stats.get('rules_generated', 0) + len(new_rules)
                        if logger:
                            logger.log(f"{self.name} ğŸŒ¸ BPMæ€’æ”¾é˜¶æ®µ:åŸºäº{len(recent_experiences)}ä¸ªç»éªŒç”Ÿæˆ{len(new_rules)}ä¸ªå€™é€‰è§„å¾‹")
                            for i, rule in enumerate(new_rules[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªè§„"
                                rule_type_content = getattr(rule, "generation_method", "unknown")
                                pattern_str = " + ".join([getattr(elem, "name", str(elem)) for elem in rule.pattern_elements])
                                logger.log(f"  å€™é€‰è§„å¾‹{i+1}: [{rule_type_content}] {pattern_str[:50]}... (ç½®ä¿¡ä» {rule.confidence:.3f})")
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} BPMæ€’æ”¾é˜¶æ®µå¤±è´¥: {str(e)}")
        
        # === æ–°å¢:BPMé›†æˆç®¡ç†å™¨å¤„ç† ===
        if hasattr(self, 'bmp_integration') and self.bmp_integration:
            try:
                # ä½¿ç”¨æ–°çš„15ç§ç»„åˆè§„å¾‹ç”Ÿæˆ
                new_candidate_rules = self.bmp_integration.process_eocar_experience(eocar_tuple)
                
                if new_candidate_rules:
                    if not hasattr(self, 'bmp_integration_stats'):
                        self.bmp_integration_stats = {
                            'candidate_rules_generated': 0,
                            'rules_validated': 0,
                            'integration_cycles': 0,
                            'last_integration_time': 0.0
                        }
                    
                    self.bmp_integration_stats['candidate_rules_generated'] += len(new_candidate_rules)
                    self.bmp_integration_stats['integration_cycles'] += 1
                    self.bmp_integration_stats['last_integration_time'] = time.time()
                    
                    if logger:
                        logger.log(f"{self.name} ğŸŒ¸ æ–°BPMé›†æˆ:ç”Ÿæˆ{len(new_candidate_rules)}ä¸ª15ç§ç»„åˆè§„å¾‹")
                        
                        # ğŸ”¥ æ”¹è¿›ï¼šå…ˆè¿›è¡Œè§„å¾‹å»é‡ï¼Œå†æ˜¾ç¤ºåˆ†å¸ƒ
                        type_counts = {}
                        formatted_rules = []
                        seen_patterns = set()  # ç”¨äºå»é‡çš„æ¨¡å¼é›†åˆ
                        
                        for rule in new_candidate_rules:
                            rule_format = self._format_rule_to_standard_pattern(rule)
                            # ç¡®ä¿ä¸æ˜¯UNKNOWNä¸”æ²¡æœ‰é‡å¤
                            if rule_format != 'UNKNOWN' and rule_format not in seen_patterns:
                                seen_patterns.add(rule_format)
                                type_counts[rule_format] = type_counts.get(rule_format, 0) + 1
                                formatted_rules.append((rule, rule_format))
                        
                        # å¦‚æœå¤§éƒ¨åˆ†è§„å¾‹éƒ½æ˜¯UNKNOWNï¼Œå°è¯•ä¸åŒçš„æ ¼å¼åŒ–æ–¹æ³•
                        if len(formatted_rules) < len(new_candidate_rules) * 0.3:  # å¦‚æœ70%ä»¥ä¸Šæ˜¯UNKNOWN
                            # ä½¿ç”¨å¤‡ç”¨æ ¼å¼åŒ–æ–¹æ³•ï¼ŒåŒæ ·è¿›è¡Œå»é‡
                            type_counts = {}
                            formatted_rules = []
                            seen_patterns = set()
                            
                            for rule in new_candidate_rules:
                                rule_format = None
                                # å°è¯•ä»è§„å¾‹å¯¹è±¡ç›´æ¥è·å–ä¿¡æ¯
                                if hasattr(rule, 'combination_type'):
                                    rule_format = f"{rule.combination_type.value}"
                                elif hasattr(rule, 'condition_text') and hasattr(rule, 'expected_result'):
                                    rule_format = f"{rule.condition_text} â†’ {rule.expected_result}"
                                else:
                                    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ - ä½¿ç”¨è§„å¾‹å†…å®¹è€Œä¸æ˜¯åºå·
                                    rule_format = f"è§„å¾‹_{'_'.join([str(v) for v in rule.conditions.values()][:2])}" if hasattr(rule, 'conditions') else f"è§„å¾‹_{rule.rule_id[:8]}"
                                
                                # ğŸ”¥ å»é‡æ£€æŸ¥
                                if rule_format and rule_format not in seen_patterns:
                                    seen_patterns.add(rule_format)
                                    type_counts[rule_format] = type_counts.get(rule_format, 0) + 1
                                    formatted_rules.append((rule, rule_format))
                        
                        # æ˜¾ç¤ºå»é‡åçš„è§„å¾‹ç±»å‹åˆ†å¸ƒ
                        unique_rule_count = len(formatted_rules)
                        total_rule_count = len(new_candidate_rules)
                        logger.log(f"   è§„å¾‹ç±»å‹åˆ†å¸ƒ: {dict(list(type_counts.items())[:10])}")  # æ˜¾ç¤ºå‰10ç§
                        logger.log(f"   ğŸ”¥ å»é‡æ•ˆæœ: {total_rule_count}ä¸ªåŸå§‹è§„å¾‹ -> {unique_rule_count}ä¸ªå”¯ä¸€è§„å¾‹")
                        
                        # æ˜¾ç¤ºå…·ä½“çš„å”¯ä¸€è§„å¾‹
                        display_count = min(len(formatted_rules), 10)  # æ˜¾ç¤ºå‰10ä¸ªè§„å¾‹
                        for i in range(display_count):
                            rule, rule_format = formatted_rules[i]
                            logger.log(f"   è§„å¾‹{i+1}: {rule_format}")
                
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} BPMé›†æˆç®¡ç†å™¨å¤„ç†å¤±è´¥: {str(e)}")
                    import traceback
                    logger.log(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        # éªŒè¯ç°æœ‰è§„å¾‹
        if hasattr(self, 'bpm') and self.bpm and self.eocar_experiences:
            try:
                validated_rules = self.bpm.validation_phase([eocar_tuple])  # ä¼ é€’EOCAR_Tupleå¯¹è±¡
                if validated_rules:
                    if not hasattr(self, 'knowledge_evolution_stats'):
                        self.knowledge_evolution_stats = {
                            'rules_generated': 0, 
                            'rules_validated': 0,
                            'evolution_cycles': 0,
                            'successful_adaptations': 0,
                            'rules_pruned': 0
                        }
                    
                    # å®‰å…¨åœ°å¢åŠ rules_validatedè®¡æ•°
                    self.knowledge_evolution_stats['rules_validated'] = self.knowledge_evolution_stats.get('rules_validated', 0) + len(validated_rules)
            except Exception as e:
                if logger:
                    logger.log(f"BPMéªŒè¯é˜¶æ®µå¤±è´¥: {str(e)}")
        
        # === æ–°å¢:è§„å¾‹éªŒè¯ç³»ç»Ÿå¤„ä»===
        if hasattr(self, 'rule_validation_system') and self.rule_validation_system:
            try:
                # ä»BPMç³»ç»Ÿè·å–å€™é€‰è§„"
                if hasattr(self, 'bpm') and self.bpm:
                    candidate_rules = list(self.bpm.candidate_rules.values()) if hasattr(self.bpm, 'candidate_rules') else []
                    
                    if candidate_rules:
                        # è·å–éªŒè¯å»ºè®®
                        player_state = {
                            'health': self.health,
                            'food': self.food,
                            'water': self.water,
                            'position': (self.x, self.y)
                        }
                        
                        validation_suggestions = self.rule_validation_system.get_validation_suggestions(
                            eocar_tuple, candidate_rules, player_state
                        )
                        
                        if validation_suggestions:
                            # å¤„ç†éªŒè¯å»ºè®®
                            for rule, strategy in validation_suggestions[:1]:  # åªå¤„ç†ç¬¬ä¸€ä¸ªå»º"
                                if logger:
                                    logger.log(f"æ–°BPMç³»ç»Ÿå‘ç°éªŒè¯æœºä¼š: {rule.rule_id} ({strategy.name})")
                                
                                # æ¨¡æ‹ŸéªŒè¯ç»“æœ(åŸºäºå½“å‰ç»éªŒ)
                                actual_result = {
                                    'success': getattr(eocar_tuple.result, "success", getattr(eocar_tuple.result, "content", str(eocar_tuple.result)) == "success"),
                                    'hp_change': getattr(eocar_tuple.result, "hp_change", 0),
                                    'food_change': getattr(eocar_tuple.result, "food_change", 0),
                                    'water_change': getattr(eocar_tuple.result, "water_change", 0)
                                }
                                
                                # æ‰§è¡ŒéªŒè¯
                                validation_attempt = self.rule_validation_system.validate_rule(
                                    rule, eocar_tuple, actual_result, strategy
                                )
                                
                                if validation_attempt:
                                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                                    self.validation_stats['total_validations'] += 1
                                    if validation_attempt.validation_result.name == 'SUCCESS':
                                        self.validation_stats['successful_validations'] += 1
                                    elif validation_attempt.validation_result.name == 'FAILURE':
                                        self.validation_stats['failed_validations'] += 1
                                    
                                    # æ›´æ–°å·²éªŒè¯è§„å¾‹åº“
                                    rule_dict = {
                                        'rule_id': rule.rule_id,
                                        'confidence': rule.confidence,
                                        'action_recommendation': getattr(rule, 'action_type', 'unknown'),
                                        'context': {
                                            'environment': getattr(eocar_tuple.environment, "content", getattr(eocar_tuple.environment, "name", str(eocar_tuple.environment))),
                                            'object': getattr(eocar_tuple.object, "content", getattr(eocar_tuple.object, "name", str(eocar_tuple.object)))
                                        }
                                    }
                                    self._update_validated_rules(rule_dict)
                                    
                                    if logger:
                                        logger.log(f"æ–°BPMç³»ç»Ÿæ›´æ–°è§„å¾‹ç½®ä¿¡ä» {rule.rule_id} -> {rule.confidence:.2f}")
                
            except Exception as e:
                if logger:
                    logger.log(f"è§„å¾‹éªŒè¯ç³»ç»Ÿå¤„ç†å¤±è´¥: {str(e)}")
        
        if logger:
            action_name = experience_dict.get('action', {}).get('type', action_taken) if isinstance(experience_dict.get('action'), dict) else str(action_taken)
            logger.log(f"{self.name} æ·»åŠ {source}E-O-C-A-T-Rç»éªŒ: {action_name} -> {result_obtained}")
            
            # æ·»åŠ BPMç³»ç»ŸçŠ¶æ€æ—¥"
            logger.log(f"{self.name} BPMçŠ¶æ€æ£€ä» hasattr(bpm)={hasattr(self, 'bpm')}, bpm_obj={getattr(self, 'bpm', None) is not None}")
            logger.log(f"{self.name} EOCATRç»éªŒçŠ¶æ€ å½“å‰æ•°é‡={len(self.eocar_experiences)}, è§¦å‘é—¨æ§›=5")
            
            if hasattr(self, 'bpm') and self.bpm:
                logger.log(f"{self.name} ä»BPMå¯¹è±¡å·²åˆå§‹åŒ–")
                if len(self.eocar_experiences) >= 5:
                    # è®¡ç®—æ–°ç»éªŒæ¨¡å¼æ•°"
                    unique_patterns = set()
                    for exp in self.eocar_experiences[-5:]:  # æ£€æŸ¥æœ€ä»ä¸ªç»"
                        if hasattr(exp, 'action') and hasattr(exp.action, 'content'):
                            unique_patterns.add(exp.action.content)
                        elif isinstance(exp, dict) and 'action' in exp:
                            action_type = exp['action'].get('type', 'unknown') if isinstance(exp['action'], dict) else str(exp['action'])
                            unique_patterns.add(action_type)
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°BMPè§¦å‘é˜ˆå€¼
                    bmp_threshold = 5  # ä½¿ç”¨æ­£ç¡®çš„BMPè§¦å‘é˜ˆå€¼
                    if len(unique_patterns) >= bmp_threshold:
                        logger.log(f"{self.name} ğŸš¨ BPMè§¦å‘æ¡ä»¶æ»¡è¶³: å‘ç°{len(unique_patterns)}ç§æ–°ç»éªŒæ¨¡å¼ (é—¨æ§›:{bmp_threshold})")
                    # å®é™…æ‰§è¡ŒBMPç»½æ”¾é˜¶æ®µ
                    try:
                        recent_experiences = self.eocar_experiences[-10:] if len(self.eocar_experiences) >= 10 else self.eocar_experiences
                        # ä¿®å¤:ä½¿ç”¨å¤‡ä»½æ–‡ä»¶ä¸­çš„æ­£ç¡®è°ƒç”¨æ–¹æ³•
                        if recent_experiences:
                            latest_experience = recent_experiences[-1]
                            historical_batch = recent_experiences[:-1] if len(recent_experiences) > 1 else []
                            new_rules = self.bpm.process_experience(latest_experience, historical_batch)
                        else:
                            new_rules = []
                        if new_rules:
                            logger.log(f"{self.name} ğŸŒ¸ BMPæ€’æ”¾é˜¶æ®µ:åŸºäº{len(recent_experiences)}ä¸ªç»éªŒç”Ÿæˆ{len(new_rules)}ä¸ªå€™é€‰è§„å¾‹")
                            for i, rule in enumerate(new_rules[:3]):  # æ˜¾ç¤ºä»ä¸ªè§„"
                                rule_type_content = getattr(rule, "generation_method", "unknown")
                                # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°è®¿é—®pattern_elements
                                pattern_parts = []
                                if hasattr(rule, 'pattern_elements') and rule.pattern_elements:
                                    for elem in rule.pattern_elements:
                                        if hasattr(elem, 'content'):
                                            pattern_parts.append(str(getattr(elem, "name", str(elem))))
                                        elif isinstance(elem, str):
                                            pattern_parts.append(elem)
                                        else:
                                            pattern_parts.append(str(elem))
                                pattern_str = " + ".join(pattern_parts) if pattern_parts else "æ— æ¨¡å¼"
                                logger.log(f"  å€™é€‰è§„å¾‹{i+1}: [{rule_type_content}] {pattern_str[:50]}... (ç½®ä¿¡ä» {rule.confidence:.3f})")
                        else:
                            logger.log(f"{self.name} ğŸŒ¸ BMPæ€’æ”¾é˜¶æ®µ:åŸºäº{len(recent_experiences)}ä¸ªç»éªŒ,æœªç”Ÿæˆæ–°è§„å¾‹")
                    except Exception as e:
                        logger.log(f"{self.name} ä»BMPæ€’æ”¾é˜¶æ®µæ‰§è¡Œå¤±è´¥: {str(e)}")
                else:
                    logger.log(f"{self.name} ä»BPMç­‰å¾…æ›´å¤šç»éªŒ: {len(self.eocar_experiences)} < 5")
            else:
                logger.log(f"{self.name} ä»BPMå¯¹è±¡æœªåˆå§‹åŒ–æˆ–ä¸ºNone")

    def _format_rule_to_standard_pattern(self, rule) -> str:
        """åŸºäºè§„å¾‹çš„å®é™…EOCATRå†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼"""
        try:
            # è·å–è§„å¾‹çš„å®é™…ç»éªŒå†…å®¹
            condition_elements = getattr(rule, 'condition_elements', [])
            condition_text = getattr(rule, 'condition_text', '')
            pattern = getattr(rule, 'pattern', '')
            
            # æå–è§„å¾‹ä¸­çš„å®é™…EOCATRå†…å®¹
            actual_content = self._extract_rule_content(rule, condition_elements, condition_text, pattern)
            
            # æ ¹æ®å®é™…å†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼
            return self._generate_content_based_pattern(actual_content)
                
        except Exception as e:
            return f"å†…å®¹æ ¼å¼åŒ–å¤±è´¥: {str(e)}"
    
    def _extract_rule_content(self, rule, condition_elements, condition_text, pattern):
        """æå–è§„å¾‹ä¸­çš„å®é™…EOCATRå†…å®¹"""
        content = {
            'environment': None,
            'object': None, 
            'characteristics': [],
            'action': None,
            'tool': None,
            'result': None
        }
        
        # ğŸ”¥ ä¼˜å…ˆä»è§„å¾‹çš„conditionså­—å…¸ä¸­æå–å†…å®¹
        if hasattr(rule, 'conditions') and rule.conditions:
            for key, value in rule.conditions.items():
                if 'environment' in key.lower():
                    content['environment'] = value
                elif 'object' in key.lower():
                    content['object'] = value
                elif 'action' in key.lower():
                    content['action'] = value
                elif 'tool' in key.lower():
                    content['tool'] = value
                elif 'characteristic' in key.lower():
                    if isinstance(value, list):
                        content['characteristics'].extend(value)
                    else:
                        content['characteristics'].append(value)
        
        # ğŸ”¥ ä»predictionså­—å…¸ä¸­æå–ç»“æœä¿¡æ¯
        if hasattr(rule, 'predictions') and rule.predictions:
            for key, value in rule.predictions.items():
                if 'result' in key.lower() or 'success' in key.lower():
                    if isinstance(value, bool):
                        content['result'] = 'success' if value else 'failure'
                    else:
                        content['result'] = str(value)
                    break
        
        # ä»è§„å¾‹çš„æ¡ä»¶æ–‡æœ¬å’Œæ¨¡å¼ä¸­æå–å®é™…å†…å®¹
        all_text = f"{condition_text} {pattern}"
        
        # å°è¯•ä»æ¡ä»¶å…ƒç´ ä¸­æå–å†…å®¹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
        if not any([content['environment'], content['object'], content['action']]):
            for element in condition_elements:
                if hasattr(element, 'content'):
                    element_content = element.content.lower()
                    element_type = getattr(element, 'symbol_type', None)
                    
                    if element_type:
                        type_name = element_type.value.lower() if hasattr(element_type, 'value') else str(element_type).lower()
                        if 'environment' in type_name:
                            content['environment'] = element.content
                        elif 'object' in type_name:
                            content['object'] = element.content
                        elif 'character' in type_name:
                            content['characteristics'].append(element.content)
                        elif 'action' in type_name:
                            content['action'] = element.content
                        elif 'tool' in type_name:
                            content['tool'] = element.content
                        elif 'result' in type_name:
                            content['result'] = element.content
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æå–åˆ°ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­è§£æ
        if not any([content['environment'], content['object'], content['action']]):
            parsed_content = self._parse_content_from_text(all_text)
            for key, value in parsed_content.items():
                if content[key] is None or (key == 'characteristics' and not content[key]):
                    content[key] = value
        
        return content
    
    def _parse_content_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­è§£æEOCATRå†…å®¹"""
        content = {
            'environment': None,
            'object': None, 
            'characteristics': [],
            'action': None,
            'tool': None,
            'result': None
        }
        
        text_lower = text.lower()
        
        # è§£æç¯å¢ƒ - æ”¯æŒä¸­è‹±æ–‡
        env_keywords = [
            'open_field', 'forest', 'water_source', 'danger_zone', 'safe_area',
            'å¼€é˜”åœ°', 'æ£®æ—', 'æ°´åŸŸ', 'å±é™©åŒºåŸŸ', 'å®‰å…¨åŒºåŸŸ', 'æ°´æºåŒºåŸŸ'
        ]
        for env in env_keywords:
            if env in text_lower:
                content['environment'] = env
                break
        
        # è§£æå¯¹è±¡ - æ”¯æŒä¸­è‹±æ–‡
        obj_keywords = [
            'berry', 'mushroom', 'tiger', 'rabbit', 'unknown', 'strawberry', 'potato',
            'è‰è“', 'è˜‘è‡', 'è€è™', 'å…”å­', 'é‡çŒª', 'é»‘ç†Š', 'æœªçŸ¥'
        ]
        for obj in obj_keywords:
            if obj in text_lower:
                content['object'] = obj
                break
        
        # è§£æç‰¹å¾ - æ”¯æŒä¸­è‹±æ–‡
        char_keywords = [
            'ripe', 'dangerous', 'safe', 'normal', 'toxic', 'near', 'far', 'healthy',
            'æˆç†Ÿ', 'å±é™©', 'å®‰å…¨', 'æ­£å¸¸', 'æœ‰æ¯’', 'è·ç¦»è¿‘', 'è·ç¦»è¿œ', 'å¥åº·',
            'å¯é£Ÿç”¨', 'è¥å…»ä¸°å¯Œ', 'è¡€é‡é«˜', 'è¡€é‡ä½'
        ]
        for char in char_keywords:
            if char in text_lower:
                content['characteristics'].append(char)
        
        # è§£æè¡ŒåŠ¨ - æ”¯æŒä¸­è‹±æ–‡
        action_keywords = [
            'explore', 'collect', 'move', 'attack', 'flee', 'right', 'left', 'up', 'down',
            'æ¢ç´¢', 'é‡‡é›†', 'ç§»åŠ¨', 'æ”»å‡»', 'é€ƒè·‘', 'è§‚å¯Ÿ', 'è·Ÿè¸ª', 'é€ƒé¿'
        ]
        for action in action_keywords:
            if action in text_lower:
                content['action'] = action
                break
        
        # è§£æå·¥å…· - æ”¯æŒä¸­è‹±æ–‡
        tool_keywords = [
            'basket', 'spear', 'axe', 'knife', 'rope',
            'ç¯®å­', 'é•¿çŸ›', 'æ–§å¤´', 'åˆ€', 'ç»³å­', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±'
        ]
        for tool in tool_keywords:
            if tool in text_lower:
                content['tool'] = tool
                break
        if 'none' in text_lower or 'æ— å·¥å…·' in text_lower:
            content['tool'] = 'none'
        
        # è§£æç»“æœ - æ”¯æŒä¸­è‹±æ–‡ï¼Œæ›´å…·ä½“çš„ç»“æœæè¿°
        result_keywords = [
            'success', 'failure', 'discovery', 'escape', 'damage', 'food_gained', 'water_gained',
            'position_changed', 'damage_dealt', 'health+', 'food+', 'water+', 'health-', 'food-', 'water-',
            'æˆåŠŸ', 'å¤±è´¥', 'å‘ç°', 'é€ƒè„±', 'ä¼¤å®³', 'è·å¾—é£Ÿç‰©', 'è·å¾—æ°´åˆ†', 'æ”¶é›†æˆåŠŸ', 
            'æ”»å‡»ç”Ÿæ•ˆ', 'æ•ˆç‡æå‡', 'å—åˆ°ä¼¤å®³', 'è·å¾—å¥–åŠ±', 'é£Ÿç‰©å¢åŠ ', 'æ°´åˆ†å¢åŠ ', 'è¡€é‡å¢åŠ ',
            'é£Ÿç‰©å‡å°‘', 'æ°´åˆ†å‡å°‘', 'è¡€é‡å‡å°‘', 'ç§»åŠ¨æˆåŠŸ', 'é‡‡é›†æˆåŠŸ', 'æ”»å‡»æˆåŠŸ', 'æ¢ç´¢æˆåŠŸ',
            'ç§»åŠ¨å¤±è´¥', 'é‡‡é›†å¤±è´¥', 'æ”»å‡»å¤±è´¥', 'æ¢ç´¢å¤±è´¥', 'ä½ç½®æ”¹å˜', 'é€ æˆä¼¤å®³'
        ]
        for result in result_keywords:
            if result in text_lower:
                content['result'] = result
                break
        
        return content
    
    def _generate_content_based_pattern(self, content):
        """æ ¹æ®å®é™…å†…å®¹ç”Ÿæˆå…·ä½“çš„ç»éªŒæ ¼å¼"""
        pattern_parts = []
        type_parts = []
        
        # æŒ‰ç…§EOCATRé¡ºåºæ£€æŸ¥å®é™…å†…å®¹
        if content['environment']:
            pattern_parts.append(content['environment'])
            type_parts.append('E')
        
        if content['object']:
            pattern_parts.append(content['object'])
            type_parts.append('O')
        
        if content['characteristics']:
            char_count = len(content['characteristics'])
            if char_count == 1:
                pattern_parts.append(content['characteristics'][0])
                type_parts.append('C1')
            elif char_count == 2:
                pattern_parts.append(','.join(content['characteristics']))
                type_parts.append('C2')
            else:
                pattern_parts.append(','.join(content['characteristics'][:3]))
                type_parts.append('C3')
        
        # Aå’ŒTè‡³å°‘è¦æœ‰ä¸€ä¸ª
        if content['action'] and content['tool'] and content['tool'] != 'none':
            # å¦‚æœåŒæ—¶æœ‰è¡ŒåŠ¨å’Œå·¥å…·ï¼Œä¼˜å…ˆæ˜¾ç¤ºå·¥å…·
            pattern_parts.append(content['tool'])
            type_parts.append('T')
        elif content['tool'] and content['tool'] != 'none':
            pattern_parts.append(content['tool'])
            type_parts.append('T')
        elif content['action']:
            pattern_parts.append(content['action'])
            type_parts.append('A')
        
        # ç»“æœ - ç›´æ¥ä½¿ç”¨å…·ä½“ç»“æœï¼Œä¸ä½¿ç”¨æŠ½è±¡çš„"result"
        if content['result'] and content['result'] != 'result':
            pattern_parts.append(content['result'])
            type_parts.append('R')
        else:
            # å¦‚æœæ²¡æœ‰å…·ä½“ç»“æœï¼Œä½¿ç”¨"æ— ç»“æœ"è€Œä¸æ˜¯æ¨æ–­
            pattern_parts.append('æ— ç»“æœ')
            type_parts.append('R')
        
        # ç”Ÿæˆæœ€ç»ˆæ ¼å¼ï¼šå®é™…å†…å®¹-ç±»å‹æ ‡è¯†
        if len(pattern_parts) >= 2:
            content_pattern = '-'.join(pattern_parts)
            type_pattern = '-'.join(type_parts)
            return f"{content_pattern} ({type_pattern})"
        else:
            return 'UNKNOWN'
    


    def _convert_dict_to_eocar_tuple(self, experience_dict) -> 'EOCAR_Tuple':
        """å°†å­—å…¸æ ¼å¼çš„ç»éªŒè½¬æ¢ä¸ºEOCAR_Tupleå¯¹è±¡,æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼"""
        try:
            from symbolic_core_v3 import (
                EOCATR_Tuple as EOCAR_Tuple, 
                SymbolicElement, SymbolType, AbstractionLevel
            )
            
            # ğŸ”§ æ•°æ®ç±»å‹æ£€æŸ¥å’Œè½¬æ¢
            if isinstance(experience_dict, str):
                # å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²,å°è¯•è½¬æ¢ä¸ºåŸºæœ¬ç»“æ„
                experience_dict = {
                    'action': {'type': experience_dict, 'content': experience_dict},
                    'result': {'success': True, 'content': 'æ‰§è¡ŒåŠ¨ç‰©'}
                }
            elif not isinstance(experience_dict, dict):
                # å¦‚æœè¾“å…¥ä¸æ˜¯å­—å…¸ä¹Ÿä¸æ˜¯å­—ç¬¦ä¸²,è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†å¤„ç†
                experience_dict = {
                    'action': {'type': str(experience_dict), 'content': str(experience_dict)},
                    'result': {'success': False, 'content': 'æœªçŸ¥ç»“æœ'}
                }
            
            # åˆ›å»ºç¯å¢ƒç¬¦å·å…ƒç´  - ä½¿ç”¨å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—"""
            env_data = experience_dict.get('environment', {})
            if isinstance(env_data, dict):
                # å¦‚æœæ˜¯å­—å…¸,è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                position = env_data.get('position', (self.x, self.y))
                health = env_data.get('health', self.health)
                
                # æ ¹æ®å¥åº·çŠ¶æ€å’Œä½ç½®ç¡®å®šç¯å¢ƒç±»å‹
                if health < 30:
                    env_content = "å±é™©åŒºåŸŸ"
                elif hasattr(self, 'game_map') and self.game_map:
                    env_content = "å¼€é˜”åœ°"
                else:
                    env_content = "æœªçŸ¥åŒºåŸŸ"
            else:
                # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²,ç›´æ¥ä½¿"
                env_content = str(env_data)
            
            # ç®€åŒ–ç¯å¢ƒå¤„ç†,é¿å…å¤æ‚çš„å­—å…¸æ“"
            water_nearby = False
            if isinstance(env_data, dict):
                for water in getattr(self.game_map, 'water_sources', []):
                    if abs(water.x - position[0]) <= 1 and abs(water.y - position[1]) <= 1:
                        water_nearby = True
                        break
                if water_nearby:
                    env_content = "æ°´æºåŒºåŸŸ"
                elif health < 30:
                    env_content = "å±é™©åŒºåŸŸ"
                else:
                    env_content = "å¼€é˜”åœ°"
            else:
                env_content = "å¼€é˜”åœ°"
                env_tags = ["å¼€", "ä¸­", "æ¢ç´¢"]
            
           
            # ç¡®ä¿env_tagsåœ¨æ‰€æœ‰åˆ†æ”¯ä¸­éƒ½æœ‰å®šä¹‰
            if "env_tags" not in locals():
                if water_nearby:
                    env_tags = ["æ°´æº", "èµ„æº", "è¡¥ç»™", "é‡è¦"]
                elif health < 30:
                    env_tags = ["å±é™©", "å¨èƒ", "è­¦æˆ’", "é¿å…"]
                else:
                    env_tags = ["å¼€", "ä¸­", "æ¢ç´¢", "å®‰å…¨"]

            environment = SymbolicElement(
                symbol_id="",
                symbol_type=SymbolType.ENVIRONMENT,
                content=env_content,
                abstraction_level=AbstractionLevel.CATEGORY,
                semantic_tags=env_tags
            )
            
            # åˆ›å»ºå¯¹è±¡ç¬¦å·å…ƒç´ 
            # ğŸ”§ å®‰å…¨çš„å­—æ®µæ"
            if isinstance(experience_dict, dict):
                action_data = experience_dict.get('action', {})
                if isinstance(action_data, dict):
                    obj = experience_dict.get('object', action_data.get('type', 'unknown'))
                else:
                    obj = experience_dict.get('object', 'unknown')
            else:
                obj = 'unknown'
                
            if obj == 'plant' or obj == 'edible_plant':
                obj_content = "å¯é£Ÿç”¨æ¤"
                obj_tags = ["æ¤ç‰©", "å¯é£Ÿ", "è¥å…»", "èµ„æº"]
            elif obj == 'dangerous_animal':
                obj_content = "å±é™©åŠ¨ç‰©"
                obj_tags = ["åŠ¨ç‰©", "å±é™©", "å¨èƒ", "çŒé£Ÿè€…"]
            elif obj == 'water':
                obj_content = "æ°´æº"
                obj_tags = ["", "èµ„æº", "ç”Ÿå­˜å¿…éœ€", "è¡¥ç»™"]
            elif obj == 'poisonous_plant':
                obj_content = "æœ‰æ¯’æ¤ç‰©"
                obj_tags = ["æ¤ç‰©", "æœ‰æ¯’", "å±é™©", "é™·é˜±"]
            else:
                obj_content = "æœªçŸ¥èµ„æº"
                obj_tags = ["æœªçŸ¥", "èµ„æº", "æ¢ç´¢"]
            
            object_elem = SymbolicElement(
                symbol_id="",
                symbol_type=SymbolType.OBJECT,
                content=obj_content,
                abstraction_level=AbstractionLevel.CATEGORY,
                semantic_tags=obj_tags
            )
            
            # åˆ›å»ºå¯¹è±¡ç‰¹å¾ç¬¦å·å…ƒç´ 
            # ğŸ”§ å®‰å…¨çš„ç‰¹å¾æ•°æ®æ"
            if isinstance(experience_dict, dict):
                char_data = experience_dict.get('characteristics', {})
                if isinstance(char_data, dict):
                    distance = char_data.get('distance', 1.0)
                    edible = char_data.get('edible', obj in ['plant', 'edible_plant'])
                    poisonous = char_data.get('poisonous', obj == 'poisonous_plant')
                    dangerous = char_data.get('dangerous', obj == 'dangerous_animal')
                else:
                    distance = 1.0
                    edible = obj in ['plant', 'edible_plant']
                    poisonous = obj == 'poisonous_plant'
                    dangerous = obj == 'dangerous_animal'
            else:
                distance = 1.0
                edible = False
                poisonous = False
                dangerous = False
            
            # æ„å»ºç‰¹å¾æè¿°
            char_features = []
            if distance <= 1:
                char_features.append("è¿‘è·ç¦»")
            elif distance <= 3:
                char_features.append("ä¸­è·ç¦»")
            else:
                char_features.append("è¿œè·ç¦»")
                
            if edible:
                char_features.extend(["å¯é£Ÿ", "è¥å…»ä¸°å¯Œ"])
            if poisonous:
                char_features.extend(["æœ‰æ¯’", "å±é™©"])
            if dangerous:
                char_features.extend(["æ”»å‡»", "å¨èƒ"])
                
            # ğŸ”§ å®‰å…¨çš„è¥å…»å€¼æ"
            if isinstance(char_data, dict):
                nutrition_value = char_data.get('nutrition_value', 10)
            else:
                nutrition_value = 10
                
            if nutrition_value > 15:
                char_features.append("é«˜è¥å…»")
            elif nutrition_value > 5:
                char_features.append("ä¸­ç­‰è¥å…»")
            else:
                char_features.append("ä½è¥å…»")
            
            character_elem = SymbolicElement(
                symbol_id="",
                symbol_type=SymbolType.CHARACTER,
                content=", ".join(char_features),
                abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=char_features
            )
            
            # åˆ›å»ºåŠ¨ç‰©ç¬¦å·å…ƒç´ 
            # ğŸ”§ å®‰å…¨çš„åŠ¨ç‰©æ•°æ®æ"
            if isinstance(experience_dict, dict):
                action_data = experience_dict.get('action', {})
                if isinstance(action_data, dict):
                    action_type = action_data.get('type', 'unknown')
                else:
                    action_type = experience_dict.get('action', 'unknown')
            else:
                action_type = 'unknown'
            if action_type in ['collect', 'gather']:
                action_content = "æ”¶é›†èµ„æº"
                action_tags = ["æ”¶é›†", "è·å–", "èµ„æº", "ä¸»åŠ¨"]
            elif action_type == 'drink':
                action_content = "é¥®æ°´"
                action_tags = ["é¥®æ°´", "è¡¥ç»™", "ç”Ÿå­˜", "æ¢å¤"]
            elif action_type in ['escape', 'avoid']:
                action_content = "é€ƒé¿"
                action_tags = ["é€ƒé¿", "é˜²å¾¡", "å®‰å…¨", "è¢«åŠ¨"]
            elif action_type == 'attack':
                action_content = "æ”»å‡»"
                action_tags = ["æ”»å‡»", "æˆ˜æ–—", "ä¸»åŠ¨", "é£é™©"]
            elif action_type in ['move', 'move_up', 'move_down', 'move_left', 'move_right']:
                action_content = "ç§»åŠ¨"
                action_tags = ["ç§»åŠ¨", "ä½ç½®å˜åŒ–", "æ¢ç´¢", "åŸºç¡€"]
            else:
                action_content = "æ¢ç´¢"
                action_tags = ["æ¢ç´¢", "å‘ç°", "å­¦ä¹ ", "ä¸»åŠ¨"]
            
            action_elem = SymbolicElement(
                symbol_id="",
                symbol_type=SymbolType.ACTION,
                content=action_content,
                abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=action_tags
            )
            
            # åˆ›å»ºå·¥å…·ç¬¦å·å…ƒç´ (å¯é€‰)
            # ğŸ”§ å®‰å…¨çš„å·¥å…·æ•°æ®æ"
            if isinstance(experience_dict, dict):
                tool_data = experience_dict.get('tool', {})
                if isinstance(tool_data, dict):
                    tool_content = tool_data.get('name', 'å¾’æ‰‹')
                else:
                    tool_content = 'å¾’æ‰‹'
            else:
                tool_data = {}
                tool_content = 'å¾’æ‰‹'
                
            if tool_data or action_type in ['attack', 'collect']:
                tool_tags = ["å·¥å…·", "è¾…åŠ©", "æ•ˆç‡"]
                if tool_content == 'å¾’æ‰‹':
                    tool_tags.extend(["åŸºç¡€", "æ— è£…å¤‡"])
                else:
                    tool_tags.extend(["è£…å¤‡", "å¢å¼º"])
                    
                tool_elem = SymbolicElement(
                    symbol_id="",
                    symbol_type=SymbolType.TOOL,
                    content=tool_content,
                    abstraction_level=AbstractionLevel.CONCRETE,
                    semantic_tags=tool_tags
                )
            else:
                tool_elem = None
            
            # åˆ›å»ºç»“æœç¬¦å·å…ƒç´ 
            # ğŸ”§ å®‰å…¨çš„ç»“æœæ•°æ®æ"
            if isinstance(experience_dict, dict):
                result_data = experience_dict.get('result', {})
                if isinstance(result_data, dict):
                    success = result_data.get('success', False)
                    reward = result_data.get('reward', 0.0)
                    hp_change = result_data.get('hp_change', result_data.get('health_change', 0))
                    food_change = result_data.get('food_change', 0)
                    water_change = result_data.get('water_change', 0)
                else:
                    success = False
                    reward = 0.0
                    hp_change = 0
                    food_change = 0
                    water_change = 0
            else:
                success = False
                reward = 0.0
                hp_change = 0
                food_change = 0
                water_change = 0
            
            result_features = []
            if success:
                result_features.append("æˆåŠŸ")
            else:
                result_features.append("å¤±è´¥")
                
            if reward > 0:
                result_features.append("æ­£å‘å¥–åŠ±")
            elif reward < 0:
                result_features.append("è´Ÿå‘æƒ©ç½š")
            else:
                result_features.append("ä¸­æ€§ç»“æœ")
                
            if hp_change > 0:
                result_features.append("è¡€é‡å¢åŠ ")
            elif hp_change < 0:
                result_features.append("è¡€é‡å‡å°‘")
                
            if food_change > 0:
                result_features.append("é£Ÿç‰©å¢åŠ ")
            elif food_change < 0:
                result_features.append("é£Ÿç‰©å‡å°‘")
                
            if water_change > 0:
                result_features.append("æ°´åˆ†å¢åŠ ")
            elif water_change < 0:
                result_features.append("æ°´åˆ†å‡å°‘")
            
            result_elem = SymbolicElement(
                symbol_id="",
                symbol_type=SymbolType.RESULT,
                content=", ".join(result_features),
                abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=result_features
            )
            
            # åˆ›å»ºEOCATR_Tuple
            # ğŸ”§ å®‰å…¨çš„ç½®ä¿¡åº¦æå–
            if isinstance(experience_dict, dict):
                confidence = experience_dict.get('confidence', 1.0)
            else:
                confidence = 1.0
                
            eocar_tuple = EOCAR_Tuple(
                environment=environment,
                object=object_elem,
                character=character_elem,
                action=action_elem,
                tool=tool_elem,
                result=result_elem,
                confidence=confidence
            )
            
            return eocar_tuple
            
        except Exception as e:
            if logger:
                logger.log(f"EOCARè½¬æ¢å¤±è´¥: {str(e)}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„EOCAR_Tuple
            from symbolic_core_v3 import (
                EOCATR_Tuple as EOCAR_Tuple, 
                SymbolicElement, SymbolType, AbstractionLevel
            )
            
            # åˆ›å»ºé»˜è®¤ç¬¦å·å…ƒç´ 
            default_env = SymbolicElement(
                symbol_id="", symbol_type=SymbolType.ENVIRONMENT,
                content="å¼€é˜”åœ°", abstraction_level=AbstractionLevel.CATEGORY,
                semantic_tags=["å¼€", "ä¸­", "æ¢ç´¢"]
            )
            default_obj = SymbolicElement(
                symbol_id="", symbol_type=SymbolType.OBJECT,
                content="æœªçŸ¥èµ„æº", abstraction_level=AbstractionLevel.CATEGORY,
                semantic_tags=["æœªçŸ¥", "èµ„æº", "æ¢ç´¢"]
            )
            default_char = SymbolicElement(
                symbol_id="", symbol_type=SymbolType.CHARACTER,
                content="ä¸­è·ä» æœªçŸ¥ç‰¹å¾", abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=["ä¸­è·", "æœªçŸ¥ç‰¹å¾"]
            )
            default_action = SymbolicElement(
                symbol_id="", symbol_type=SymbolType.ACTION,
                content="æ¢ç´¢", abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=["æ¢ç´¢", "å‘ç°", "å­¦ä¹ ç‡", "ä¸»åŠ¨"]
            )
            default_result = SymbolicElement(
                symbol_id="", symbol_type=SymbolType.RESULT,
                content="ä¸­æ€§ç»“", abstraction_level=AbstractionLevel.CONCRETE,
                semantic_tags=["ä¸­æ€§ç»“"]
            )
            
            return EOCAR_Tuple(
                environment=default_env,
                object=default_obj,
                character=default_char,
                action=default_action,
                tool=None,
                result=default_result,
                confidence=0.5
            )

    def get_bpm_statistics(self) -> dict:
        """è·å–BPMç³»ç»Ÿçš„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if hasattr(self, 'bpm') and self.bpm:
                bpm_stats = self.bpm.get_statistics()
                bpm_stats.update(self.knowledge_evolution_stats)
                return bpm_stats
            return {}
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è·å–BPMç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}
    
    def get_knowledge_quality_report(self) -> dict:
        """è·å–çŸ¥è¯†è´¨é‡æŠ¥å‘Š"""
        try:
            if hasattr(self, 'bpm') and self.bmp:
                bmp_stats = self.bmp.get_statistics()
                
                # ç¡®ä¿knowledge_evolution_statså­˜åœ¨ä¸”æœ‰å¿…è¦çš„é”®
                if not hasattr(self, 'knowledge_evolution_stats'):
                    self.knowledge_evolution_stats = {
                        'rules_generated': 0, 
                        'rules_validated': 0,
                        'evolution_cycles': 0,
                        'successful_adaptations': 0
                    }
                
                # å®‰å…¨è·å–ç»Ÿè®¡æ•°æ®
                evolution_cycles = self.knowledge_evolution_stats.get('evolution_cycles', 1)
                successful_adaptations = self.knowledge_evolution_stats.get('successful_adaptations', 0)
                
                return {
                    'total_experiences': len(self.eocar_experiences),
                    'total_rules': bmp_stats['current_candidate_rules'] + bmp_stats['current_validated_rules'],
                    'rule_validation_rate': bmp_stats['total_rules_validated'] / max(bmp_stats['total_rules_generated'], 1),
                    'rule_survival_rate': 1 - (bmp_stats['total_rules_pruned'] / max(bmp_stats['total_rules_generated'], 1)),
                    'average_confidence': bmp_stats['average_rule_confidence'],
                    'rule_distribution': bmp_stats['rule_types_distribution'],
                    'quality_distribution': bmp_stats['quality_score_distribution'],
                    'evolution_cycles': evolution_cycles,
                    'successful_adaptations': successful_adaptations,
                    'rules_per_cycle': bmp_stats['total_rules_generated'] / max(evolution_cycles, 1),
                    'knowledge_growth_rate': len(self.eocar_experiences) / max(evolution_cycles, 1)
                }
            return {}
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è·å–çŸ¥è¯†è´¨é‡æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return {}

    def _get_default_exploration_action(self) -> str:
        """è·å–é»˜è®¤çš„æ¢ç´¢è¡ŒåŠ¨"""
        return random.choice(["up", "down", "left", "right"])
    
    def _build_attention_context(self, game) -> AttentionContext:
        """æ„å»ºDMHAæ³¨æ„åŠ›ä¸Šä¸‹æ–‡"""
        # è·å–å‘¨å›´èµ„æº
        resources_nearby = []
        for plant in game.game_map.plants:
            distance = abs(plant.x - self.x) + abs(plant.y - self.y)  # æ›¼å“ˆé¡¿è·"""
            if distance <= 5:  # è§†é‡èŒƒå›´å¤§
                # ä½¿ç”¨æ¤ç‰©ç±»å‹åç§°è€Œä¸æ˜¯nameå±"
                plant_type = plant.__class__.__name__
                value = 2.0 if plant_type in ["Strawberry", "Mushroom"] else 0.5
                resources_nearby.append({
                    'distance': distance,
                    'value': value,
                    'type': plant_type
                })
        
        # è·å–å±é™©åŠ¨ç‰©
        dangers_detected = []
        for animal in game.game_map.animals:
            distance = abs(animal.x - self.x) + abs(animal.y - self.y)
            if distance <= 5:  # è§†é‡èŒƒå›´å¤§
                # ä½¿ç”¨åŠ¨ç‰©ç±»å‹åç§°
                animal_type = animal.__class__.__name__
                if animal_type in ["Tiger", "BlackBear"]:
                    threat_level = 3.0 if animal_type == "Tiger" else 2.5
                    dangers_detected.append({
                        'distance': distance,
                        'threat_level': threat_level,
                        'type': animal_type
                    })
        
        # è·å–ç¤¾äº¤å®ä½“(å…¶ä»–ç©å®¶)
        social_entities = []
        for player in game.players:
            if player != self and player.is_alive():
                distance = abs(player.x - self.x) + abs(player.y - self.y)
                if distance <= 5:  # è§†é‡èŒƒå›´å¤§
                    social_value = 1.5 if distance < 3 else 1.0
                    social_entities.append({
                        'distance': distance,
                        'social_value': social_value,
                        'type': player.player_type
                    })
        
        # è·å–æœªæ¢ç´¢åŒº"
        unexplored_areas = []
        if not hasattr(self, 'visited_positions'):
            self.visited_positions = set()
        
        self.visited_positions.add((self.x, self.y))  # è®°å½•å½“å‰ä½ç½®
        
        for dx in range(-5, 6):  # è§†é‡èŒƒå›´
            for dy in range(-5, 6):
                check_x = self.x + dx
                check_y = self.y + dy
                if (game.game_map.is_within_bounds(check_x, check_y) and 
                    (check_x, check_y) not in self.visited_positions):
                    distance = abs(dx) + abs(dy)  # æ›¼å“ˆé¡¿è·"
                    if distance > 0:
                        novelty = 2.0 if distance > 3 else 1.0
                        unexplored_areas.append({
                            'distance': distance,
                            'novelty': novelty,
                            'type': 'unexplored'
                        })
        
        # ç¡®å®šå‘è‚²é˜¶æ®µ
        stage = "infant" if self.life_experience_count < 50 else "adult"
        
        # æ„å»ºæ³¨æ„åŠ›ä¸Šä¸‹æ–‡
        context = AttentionContext(
            resources_nearby=resources_nearby,
            dangers_detected=dangers_detected,
            social_entities=social_entities,
            unexplored_areas=unexplored_areas,
            hp=self.health,
            food=self.food,
            water=self.water,
            development_stage=stage,
            recent_experiences=[],  # ç®€åŒ–ç‰ˆ"
            current_goals=['survival', 'exploration']
        )
        
        return context
    
    def _is_attention_compatible(self, decision: str, attention_bias: str) -> bool:
        """æ£€æŸ¥å†³ç­–æ˜¯å¦ä¸æ³¨æ„åŠ›åå‘å…¼å®¹"""
        compatibility_map = {
            "ä¸“æ³¨èµ„æºè·å–": ["gather", "collect", "ç§»åŠ¨åˆ°èµ„æºä½ç½®"],
            "ä¼˜å…ˆæ”¶é›†èµ„æº": ["gather", "collect"],
            "ç§»åŠ¨åˆ°èµ„æºä½ç½®": ["move", "gather"],
            "ç«‹å³è„±ç¦»å±é™©": ["flee", "escape", "avoid"],
            "å‡†å¤‡é˜²å¾¡æˆ–é€ƒè·‘": ["flee", "escape", "avoid", "attack"],
            "è¯„ä¼°å¨èƒç­‰çº§": ["wait", "observe"],
            "å¯»æ±‚åˆä½œ": ["share", "cooperate", "communicate"],
            "ä¸»åŠ¨è¿›è¡Œç¤¾äº¤": ["share", "cooperate"],
            "æ·±åº¦æ¢ç´¢æ–°åŒºåŸŸ": ["explore", "move"],
            "æ‰§è¡Œæ¢ç´¢è¡ŒåŠ¨": ["explore", "move"],
            "è®¡åˆ’æ¢ç´¢è·¯çº¿": ["explore", "move"]
        }
        
        compatible_actions = compatibility_map.get(attention_bias, [])
        return any(action in decision for action in compatible_actions)
    
    def _apply_attention_bias(self, decision: str, attention_bias: str) -> str:
        """åº”ç”¨æ³¨æ„åŠ›åå‘åˆ°å†³ç­–"""
        attention_enhancements = {
            "ä¸“æ³¨èµ„æºè·å–": lambda d: d if "gather" in d else "gather",
            "ç«‹å³è„±ç¦»å±é™©": lambda d: "flee" if "move" in d else d,
            "æ·±åº¦æ¢ç´¢æ–°åŒºåŸŸ": lambda d: "explore" if "move" in d else d,
            "å¯»æ±‚åˆä½œ": lambda d: d  # ç¤¾äº¤å†³ç­–æš‚æ—¶ä¿æŒåŸæ ·
        }
        
        enhancement_func = attention_enhancements.get(attention_bias)
        if enhancement_func:
            return enhancement_func(decision)
        
        return decision
    
    def get_dmha_statistics(self) -> dict:
        """è·å–DMHAç»Ÿè®¡ä¿¡æ¯"""
        try:
            return self.dmha.get_statistics()
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è·å–DMHAç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}
    
    def get_dmha_attention_state(self) -> dict:
        """è·å–å½“å‰DMHAæ³¨æ„åŠ›çŠ¶æ€"""
        try:
            return self.dmha.get_attention_state()
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è·å–DMHAæ³¨æ„åŠ›çŠ¶æ€å¤±è´¥: {str(e)}")
            return {}
    
    def symbolize_scene(self, game):
        """ä½¿ç”¨SSMè¿›è¡Œåœºæ™¯ç¬¦å·åŒ–,è¿”å›E-O-C-A-T-Rå…ƒç»„åˆ—è¡¨"""
        self.current_timestamp += 1.0  # å¢åŠ æ—¶é—´æˆ³
        # ä½¿ç”¨SSMè¿›è¡Œç¬¦å·åŒ–
        eocar_tuples = self.ssm.symbolize_scene(game, self)
        
        # ä¸ºæ¯ä¸ªå…ƒç»„è®¾ç½®æ—¶é—´æˆ³
        for eocar in eocar_tuples:
            eocar.timestamp = self.current_timestamp
        
        # ä¿æŒå‘åå…¼å®¹æ€§,è½¬æ¢ä¸ºä¼ ç»Ÿæ ¼"
        traditional_symbols = []
        for eocar in eocar_tuples:
            symbol = {
                "object": eocar.object.content,
                "position": {"x": 0, "y": 0},  # é»˜è®¤ä½ç½®,å› ä¸ºæ–°ç»“æ„ä¸­ä½ç½®ä¿¡æ¯åœ¨character"
                "characteristics": {
                    "distance": 1.0,  # é»˜è®¤è·ç¦»
                    "edible": "å¯é£Ÿç”¨" in eocar.character.content,
                    "poisonous": "æœ‰æ¯’" in eocar.character.content,
                    "dangerous": "å±é™©" in eocar.character.content,
                    "nutrition_value": 10,  # é»˜è®¤è¥å…»"
                    "water_value": 0,  # é»˜è®¤æ°´åˆ†"
                    "player_type": None,  # é»˜è®¤ç©å®¶ç±»å‹
                    "health_state": "normal"  # é»˜è®¤å¥åº·çŠ¶æ€
                }
            }
            traditional_symbols.append(symbol)
        
        if logger:
                            logger.log(f"SSMç¬¦å·åŒ–å®Œæˆ,å¤„ç†{len(eocar_tuples)}æ¡ç»éªŒç”Ÿæˆ{len(eocar_tuples)}ä¸ªE-O-C-A-T-Rå…ƒç»„,{len(traditional_symbols)}ä¸ªä¼ ç»Ÿç¬¦å·")
        
        # å­˜å‚¨å½“å‰çš„E-O-C-A-T-Rç¬¦å·åŒ–ç»“æœç”¨äºå†³ç­–
        self.current_eocar_scene = eocar_tuples
        
        return traditional_symbols

    def _save_eocar_tuples_to_five_libraries(self, eocar_tuples):
        """å°†SSMç”Ÿæˆçš„EOCATRå…ƒç»„ä¿å­˜åˆ°äº”åº“ç³»ç»Ÿ"""
        try:
            if not self.five_library_system_active or not self.five_library_system:
                if logger:
                    logger.log(f"{self.name} äº”åº“ç³»ç»Ÿæœªå¯ç”¨ï¼Œè·³è¿‡EOCATRä¿å­˜")
                return
            
            saved_count = 0
            for eocar_tuple in eocar_tuples:
                try:
                    # æ„å»ºç»éªŒæ•°æ®å­—å…¸
                    experience_data = {
                        'environment': eocar_tuple.environment.content if hasattr(eocar_tuple.environment, 'content') else str(eocar_tuple.environment),
                        'object': eocar_tuple.object.content if hasattr(eocar_tuple.object, 'content') else str(eocar_tuple.object),
                        'characteristics': eocar_tuple.character.content if hasattr(eocar_tuple.character, 'content') else str(eocar_tuple.character),
                        'action': eocar_tuple.action.content if hasattr(eocar_tuple.action, 'content') else str(eocar_tuple.action),
                        'tools': eocar_tuple.tool.content if hasattr(eocar_tuple.tool, 'content') else str(eocar_tuple.tool),
                        'result': eocar_tuple.result.content if hasattr(eocar_tuple.result, 'content') else str(eocar_tuple.result),
                        'success': 'success' in str(eocar_tuple.result).lower(),
                        'player_id': self.name,
                        'timestamp': getattr(eocar_tuple, 'timestamp', time.time()),
                        'source': 'ssm_symbolization'
                    }
                    
                    # åˆ›å»ºEOCATRExperienceå¯¹è±¡
                    from five_library_system import EOCATRExperience
                    experience_obj = EOCATRExperience(
                        environment=experience_data['environment'],
                        object=experience_data['object'],
                        characteristics=experience_data['characteristics'],
                        action=experience_data['action'],
                        tools=experience_data['tools'],
                        result=experience_data['result'],
                        player_id=experience_data['player_id'],
                        timestamp=experience_data['timestamp'],
                        success=experience_data['success'],
                        metadata={'source': experience_data['source']}
                    )
                    
                    # ä¿å­˜åˆ°ç›´æ¥ç»éªŒåº“
                    add_result = self.five_library_system.add_experience_to_direct_library(experience_obj)
                    if add_result['success']:
                        saved_count += 1
                    else:
                        if logger:
                            logger.log(f"{self.name} EOCATRä¿å­˜å¤±è´¥: {add_result.get('reason', 'æœªçŸ¥åŸå› ')}")
                    
                except Exception as e:
                    if logger:
                        logger.log(f"{self.name} å•ä¸ªEOCATRå…ƒç»„ä¿å­˜å¤±è´¥: {str(e)}")
            
            if logger:
                logger.log(f"{self.name} ğŸ’¾ SSMæˆåŠŸä¿å­˜{saved_count}/{len(eocar_tuples)}ä¸ªEOCATRå…ƒç»„åˆ°äº”åº“ç³»ç»Ÿ")
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ EOCATRå…ƒç»„æ‰¹é‡ä¿å­˜å¤±è´¥: {str(e)}")
    
    def add_unified_experience(self, action_data: Any, state_before: dict = None, 
                              state_after: dict = None, result_data: dict = None, 
                              experience_type: str = "direct") -> UnifiedExperience:
        """æ·»åŠ ç»Ÿä¸€æ ¼å¼çš„ç»éªŒ"""
        try:
            # ç”Ÿæˆç»éªŒID
            experience_id = f"{self.name}_exp_{int(time.time() * 1000)}_{len(self.unified_experiences)}"
            
            # è½¬æ¢åŠ¨ç‰©ä¸ºç»Ÿä¸€æ ¼å¼
            unified_action = self.data_format_unifier.convert_action_to_unified(action_data)
            
            # è½¬æ¢çŠ¶æ€ä¸ºç»Ÿä¸€æ ¼å¼
            if state_before is None:
                state_before = self._get_current_state_dict()
            if state_after is None:
                state_after = self._get_current_state_dict()
            
            unified_state_before = self.data_format_unifier.convert_state_to_unified(state_before)
            unified_state_after = self.data_format_unifier.convert_state_to_unified(state_after)
            
            # è½¬æ¢ç»“æœä¸ºç»Ÿä¸€æ ¼å¼
            if result_data is None:
                result_data = {"success": True, "effects": {}}
            
            unified_result = UnifiedResult(
                success=result_data.get("success", True),
                effects=result_data.get("effects", {}),
                rewards=result_data.get("rewards", {})
            )
            
            # åˆ›å»ºç»Ÿä¸€ç»éªŒ
            unified_experience = UnifiedExperience(
                experience_id=experience_id,
                action=unified_action,
                state_before=unified_state_before,
                state_after=unified_state_after,
                result=unified_result,
                experience_type=ExperienceType(experience_type) if experience_type in [e.value for e in ExperienceType] else ExperienceType.DIRECT,
                importance=0.5,
                tags=[experience_type, unified_action.action_type.value]
            )
            
            # æ·»åŠ åˆ°ç»Ÿä¸€ç»éªŒåº“
            self.unified_experiences.append(unified_experience)
            
            # ç»´æŠ¤å®¹é‡é™åˆ¶
            if len(self.unified_experiences) > self.max_unified_experiences:
                self.unified_experiences.pop(0)  # ç§»é™¤æœ€æ—§çš„ç»éªŒ
            
            # æ›´æ–°ç»Ÿè®¡
            self.format_conversion_stats['successful_conversions'] += 1
            self.format_conversion_stats['total_conversions'] += 1
            
            if logger:
                logger.log(f"{self.name} æ·»åŠ ç»Ÿä¸€ç»éªŒ: {unified_action.action_type.value}")
            
            return unified_experience
            
        except Exception as e:
            self.format_conversion_stats['total_conversions'] += 1
            if logger:
                logger.log(f"{self.name} ç»Ÿä¸€ç»éªŒæ·»åŠ å¤±è´¥: {str(e)}")
            
            # è¿”å›é»˜è®¤ç»éªŒ
            return UnifiedExperience(
                experience_id="failed_exp",
                action=UnifiedAction(ActionType.UNKNOWN),
                state_before=UnifiedState(),
                state_after=UnifiedState(),
                result=UnifiedResult(success=False)
            )
    
    def _get_current_state_dict(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€çš„å­—å…¸è¡¨ç¤º"""
        return {
            "health": self.health,
            "food": self.food,
            "water": self.water,
            "x": self.x,
            "y": self.y,
            "phase": self.phase,
            "development_stage": self.developmental_stage,
            "survival_days": getattr(self, 'survival_days', 0),
            "reputation": getattr(self, 'reputation', 0)
        }
    
    def convert_legacy_experience_to_unified(self, legacy_exp: dict) -> UnifiedExperience:
        """å°†ä¼ ç»Ÿæ ¼å¼ç»éªŒè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼"""
        try:
            # æ›´æ–°æ ¼å¼ç»Ÿè®¡
            self.format_conversion_stats['format_types_encountered'].add('legacy_dict')
            
            unified_exp = self.data_format_unifier.convert_experience_to_unified(legacy_exp)
            
            # éªŒè¯è½¬æ¢ç»“æœ
            if self.data_format_unifier.validate_unified_data(unified_exp):
                self.format_conversion_stats['successful_conversions'] += 1
                if logger:
                    logger.log(f"{self.name} æˆåŠŸè½¬æ¢ä¼ ç»Ÿç»éªŒä¸ºç»Ÿä¸€æ ¼å¼")
            else:
                if logger:
                    logger.log(f"{self.name} ä¼ ç»Ÿç»éªŒè½¬æ¢éªŒè¯å¤±è´¥")
            
            self.format_conversion_stats['total_conversions'] += 1
            return unified_exp
            
        except Exception as e:
            self.format_conversion_stats['total_conversions'] += 1
            if logger:
                logger.log(f"{self.name} ä¼ ç»Ÿç»éªŒè½¬æ¢å¤±è´¥: {str(e)}")
            return UnifiedExperience(
                experience_id="conversion_failed",
                action=UnifiedAction(ActionType.UNKNOWN),
                state_before=UnifiedState(),
                state_after=UnifiedState(),
                result=UnifiedResult(success=False)
            )
    
    def convert_eocar_to_unified(self, eocar_tuple) -> UnifiedExperience:
        """å°†EOCARæ ¼å¼è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼"""
        try:
            # æ›´æ–°æ ¼å¼ç»Ÿè®¡
            self.format_conversion_stats['format_types_encountered'].add('eocar_tuple')
            
            unified_exp = self.data_format_unifier.convert_eocar_to_unified(eocar_tuple)
            
            # éªŒè¯è½¬æ¢ç»“æœ
            if self.data_format_unifier.validate_unified_data(unified_exp):
                self.format_conversion_stats['successful_conversions'] += 1
                if logger:
                    logger.log(f"{self.name} æˆåŠŸè½¬æ¢EOCATRç»éªŒä¸ºç»Ÿä¸€æ ¼å¼")
            
            self.format_conversion_stats['total_conversions'] += 1
            return unified_exp
            
        except Exception as e:
            self.format_conversion_stats['total_conversions'] += 1
            if logger:
                logger.log(f"{self.name} EOCATRç»éªŒè½¬æ¢å¤±è´¥: {str(e)}")
            return UnifiedExperience(
                experience_id="eocar_conversion_failed",
                action=UnifiedAction(ActionType.UNKNOWN),
                state_before=UnifiedState(),
                state_after=UnifiedState(),
                result=UnifiedResult(success=False)
            )
    
    def get_unified_experiences_by_action(self, action_type: ActionType) -> List[UnifiedExperience]:
        """æ ¹æ®åŠ¨ç‰©ç±»å‹è·å–ç»Ÿä¸€æ ¼å¼ç»éªŒåº“"""
        return [exp for exp in self.unified_experiences if exp.action.action_type == action_type]
    
    def get_unified_experiences_by_success(self, success: bool) -> List[UnifiedExperience]:
        """æ ¹æ®æˆåŠŸçŠ¶æ€è·å–ç»Ÿä¸€æ ¼å¼ç»éªŒåº“"""
        return [exp for exp in self.unified_experiences if exp.result.success == success]
    
    def get_data_format_statistics(self) -> dict:
        """è·å–æ•°æ®æ ¼å¼ç»Ÿè®¡ä¿¡æ¯"""
        unifier_stats = self.data_format_unifier.get_conversion_statistics()
        
        return {
            "unified_experiences_count": len(self.unified_experiences),
            "max_unified_capacity": self.max_unified_experiences,
            "local_conversion_stats": self.format_conversion_stats,
            "unifier_conversion_stats": unifier_stats,
            "format_types_encountered": list(self.format_conversion_stats['format_types_encountered']),
            "conversion_success_rate": (
                self.format_conversion_stats['successful_conversions'] / 
                max(self.format_conversion_stats['total_conversions'], 1)
            )
        }
    
    def validate_data_format_consistency(self) -> dict:
        """éªŒè¯æ•°æ®æ ¼å¼ä¸€è‡´æ€§"""
        validation_results = {
            "total_checked": 0,
            "valid_count": 0,
            "invalid_count": 0,
            "validation_errors": [],
            "consistency_score": 0.0
        }
        
        try:
            # æ£€æŸ¥ç»Ÿä¸€ç»éªŒåº“
            for i, exp in enumerate(self.unified_experiences):
                validation_results["total_checked"] += 1
                
                if self.data_format_unifier.validate_unified_data(exp):
                    validation_results["valid_count"] += 1
                else:
                    validation_results["invalid_count"] += 1
                    validation_results["validation_errors"].append(f"ç»éªŒ{i}: æ ¼å¼æ— æ•ˆ")
            
            # è®¡ç®—ä¸€è‡´æ€§åˆ†"
            if validation_results["total_checked"] > 0:
                validation_results["consistency_score"] = (
                    validation_results["valid_count"] / validation_results["total_checked"]
                )
            
            if logger:
                logger.log(f"{self.name} æ•°æ®æ ¼å¼ä¸€è‡´æ€§æ£€æŸ¥å®Œä» {validation_results['consistency_score']:.2f}")
            
        except Exception as e:
            validation_results["validation_errors"].append(f"éªŒè¯è¿‡ç¨‹é”™è¯¯: {str(e)}")
            if logger:
                logger.log(f"{self.name} æ•°æ®æ ¼å¼éªŒè¯å¤±è´¥: {str(e)}")
        
        return validation_results

    def _build_emrs_action_result(self, action, previous_state):
        """æ„å»ºEMRSç³»ç»Ÿæ‰€éœ€çš„action_resultå‚æ•°"""
        current_state = self._get_current_state_dict()
        
        action_result = {
            'action_type': str(action),
            'success': True,  # é»˜è®¤æˆåŠŸ,å…·ä½“æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        }
        
        # è®¡ç®—çŠ¶æ€å˜åŒ–
        if previous_state:
            health_change = current_state.get('health', 100) - previous_state.get('health', 100)
            food_change = current_state.get('food', 50) - previous_state.get('food', 50)
            water_change = current_state.get('water', 50) - previous_state.get('water', 50)
            
            if health_change != 0:
                action_result['health_change'] = health_change
            if food_change > 0:
                action_result['food_gained'] = food_change
            if water_change > 0:
                action_result['water_gained'] = water_change
        
        # æ ¹æ®åŠ¨ç‰©ç±»å‹æ·»åŠ ç‰¹å®šä¿¡æ¯
        if action == 'collect':
            action_result['resource_collected'] = True
            action_result['food_gained'] = action_result.get('food_gained', 5)
        elif action == 'attack':
            action_result['damage_dealt'] = 10
            action_result['combat_success'] = True
        elif action == 'flee':
            action_result['escape_success'] = True
            action_result['safety_gained'] = True
        elif action in ['move_up', 'move_down', 'move_left', 'move_right']:
            action_result['exploration_progress'] = 1
            action_result['new_areas_discovered'] = 1 if (self.x, self.y) not in self.visited_positions else 0
        
        return action_result
    
    def _build_emrs_context(self, game):
        """æ„å»ºEMRSç³»ç»Ÿæ‰€éœ€çš„contextå‚æ•°"""
        return {
            'current_health': self.health,
            'current_food': self.food,
            'current_water': self.water,
            'position': (self.x, self.y),
            'phase': self.phase,
            'development_stage': getattr(self, 'developmental_stage', 'child'),
            'current_day': getattr(game, 'current_day', 1),
            'threats_nearby': len(self.detect_threats(game.game_map)),
            'resources_nearby': len([plant for plant in game.game_map.plants if 
                                   abs(plant.x - self.x) + abs(plant.y - self.y) <= 2]),
            'survival_days': self.survival_days,
            'reputation': getattr(self, 'reputation', 0),
            'energy_level': (self.health + self.food + self.water) / 3.0
        }
    
    def _get_current_development_stage(self):
        """è·å–å½“å‰å‘è‚²é˜¶æ®µ"""
        if hasattr(self, 'developmental_stage'):
            return self.developmental_stage
        elif hasattr(self, 'age'):
            if self.age < 10:
                return 'infant'
            elif self.age < 50:
                return 'child'
            elif self.age < 150:
                return 'adolescent'
            else:
                return 'adult'
        else:
            return 'child'

    def _update_validated_rules(self, updated_rule):
        """æ›´æ–°å·²éªŒè¯è§„å¾‹åº“"""
        try:
            rule_id = updated_rule.get('rule_id', '')
            confidence = updated_rule.get('confidence', 0.0)
            
            # æŸ¥æ‰¾å¹¶æ›´æ–°ç°æœ‰è§„"""
            for i, existing_rule in enumerate(self.validated_rules):
                if existing_rule.get('rule_id') == rule_id:
                    self.validated_rules[i] = updated_rule
                    break
            else:
                # å¦‚æœæ˜¯æ–°è§„å¾‹,æ·»åŠ åˆ°åº“ä¸­
                self.validated_rules.append(updated_rule)
            
            # æ›´æ–°ç½®ä¿¡åº¦ç»Ÿ"
            if confidence >= 0.8:
                self.validation_stats['high_confidence_rules'] += 1
            elif confidence >= 0.5:
                self.validation_stats['medium_confidence_rules'] += 1
            else:
                self.validation_stats['low_confidence_rules'] += 1
            
            # é™åˆ¶è§„å¾‹åº“å¤§å°,ä¿ç•™é«˜ç½®ä¿¡åº¦è§„å¾‹
            if len(self.validated_rules) > 100:
                self.validated_rules.sort(key=lambda x: x.get('confidence', 0.0), reverse=True)
                self.validated_rules = self.validated_rules[:80]  # ä¿ç•™80ä¸ªé«˜ç½®ä¿¡åº¦è§„å¾‹
        except Exception as e:
            if logger:
                logger.log(f"æ›´æ–°å·²éªŒè¯è§„å¾‹åº“å¤±è´¥: {str(e)}")

    def get_validated_rules_for_action_suggestion(self, current_context=None):
        """è·å–ç”¨äºè¡ŒåŠ¨å»ºè®®çš„é«˜ç½®ä¿¡åº¦è§„å¾‹"""
        try:
            if not hasattr(self, 'validated_rules') or not self.validated_rules:
                return []
            
            # ç­›é€‰é«˜ç½®ä¿¡åº¦è§„å¾‹
            high_confidence_rules = [
                rule for rule in self.validated_rules 
                if rule.get('confidence', 0.0) >= 0.7
            ]
            
            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡,è¿›ä¸€æ­¥ç­›é€‰ç›¸å…³è§„"
            if current_context:
                relevant_rules = []
                for rule in high_confidence_rules:
                    # ç®€å•çš„ä¸Šä¸‹æ–‡åŒ¹é…(å¯ä»¥åç»­å¢å¼º"
                    rule_context = rule.get('context', {})
                    if self._is_context_relevant(rule_context, current_context):
                        relevant_rules.append(rule)
                return relevant_rules
            
            return high_confidence_rules
            
        except Exception as e:
            if logger:
                logger.log(f"è·å–éªŒè¯è§„å¾‹å¤±è´¥: {str(e)}")
            return []

    def _is_context_relevant(self, rule_context, current_context):
        """åˆ¤æ–­è§„å¾‹ä¸Šä¸‹æ–‡æ˜¯å¦ä¸å½“å‰ä¸Šä¸‹æ–‡ç›¸å…³"""
        try:
            # ç®€å•çš„ç›¸å…³æ€§æ£€"""
            if not rule_context or not current_context:
                return False
            
            # æ£€æŸ¥å¥åº·çŠ¶æ€ç›¸å…³"
            rule_health = rule_context.get('health_level', '')
            current_health = current_context.get('health_level', '')
            if rule_health and current_health and rule_health == current_health:
                return True
            
            # æ£€æŸ¥èµ„æºçŠ¶æ€ç›¸å…³"
            rule_resources = rule_context.get('resource_status', '')
            current_resources = current_context.get('resource_status', '')
            if rule_resources and current_resources and rule_resources == current_resources:
                return True
            
            # æ£€æŸ¥ç¯å¢ƒç›¸å…³"
            rule_environment = rule_context.get('environment', '')
            current_environment = current_context.get('environment', '')
            if rule_environment and current_environment and rule_environment == current_environment:
                return True
            
            return False
            
        except Exception as e:
            if logger:
                logger.log(f"ä¸Šä¸‹æ–‡ç›¸å…³æ€§æ£€æŸ¥å¤±ä» {str(e)}")
            return False

    def _get_current_environment_type(self, game):
        """è·å–å½“å‰ç¯å¢ƒç±»å‹"""
        try:
            if not game or not hasattr(game, 'game_map'):
                return 'unknown'
            
            current_cell = game.game_map.grid[self.y][self.x]
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ°´æºé™„è¿‘
            if current_cell in ['river', 'puddle']:
                return 'water_area'
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å±é™©åŒºåŸŸ(é™„è¿‘æœ‰çŒ›å…½"""
            threats = self.detect_threats(game.game_map)
            if threats:
                return 'dangerous_zone'
            
            # æ£€æŸ¥å…¶ä»–ç¯å¢ƒç±»"
            if current_cell == 'cave':
                return 'shelter'
            elif current_cell == 'big_tree':
                return 'forest'
            elif current_cell == 'bush':
                return 'vegetation'
            else:
                return 'open_field'
                
        except Exception as e:
            if logger:
                logger.log(f"è·å–ç¯å¢ƒç±»å‹å¤±è´¥: {str(e)}")
            return 'unknown'

    def _get_current_environment_detailed(self, context=None):
        """è·å–å½“å‰ç¯å¢ƒè¯¦ç»†ä¿¡æ¯"""
        try:
            # åŸºç¡€ç¯å¢ƒç±»å‹
            env_type = getattr(self, '_last_environment_type', 'open_field')
            
            # ä»ä¸Šä¸‹æ–‡è·å–æ›´å¤šä¿¡æ¯
            if context and isinstance(context, dict):
                if 'environment' in context:
                    env_type = context['environment']
                elif 'position' in context:
                    # åŸºäºä½ç½®æ¨æ–­ç¯å¢ƒ
                    x, y = context['position']
                    if hasattr(self, 'game_map'):
                        cell = self.game_map.grid[y][x] if 0 <= x < len(self.game_map.grid[0]) and 0 <= y < len(self.game_map.grid) else 'open_field'
                        if cell == 'river':
                            env_type = 'water_area'
                        elif cell == 'cave':
                            env_type = 'shelter'
                        elif cell == 'big_tree':
                            env_type = 'forest'
                        elif cell == 'bush':
                            env_type = 'vegetation'
                        else:
                            env_type = 'open_field'
            
            return env_type
            
        except Exception as e:
            if logger:
                logger.log(f"è·å–è¯¦ç»†ç¯å¢ƒä¿¡æ¯å¤±è´¥: {str(e)}")
            return 'open_field'

    def _get_current_object_detailed(self, context=None):
        """è·å–å½“å‰å¯¹è±¡è¯¦ç»†ä¿¡æ¯"""
        try:
            # ä»ä¸Šä¸‹æ–‡è·å–å¯¹è±¡ä¿¡æ¯
            if context and isinstance(context, dict):
                if 'target_object' in context:
                    return context['target_object']
                elif 'collected_object' in context:
                    return context['collected_object']
                elif 'encountered_object' in context:
                    return context['encountered_object']
            
            # é»˜è®¤è¿”å›æœªçŸ¥å¯¹è±¡
            return 'unknown'
            
        except Exception as e:
            if logger:
                logger.log(f"è·å–è¯¦ç»†å¯¹è±¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return 'unknown'

    def _get_current_characteristics_detailed(self, context=None):
        """è·å–å½“å‰ç‰¹å¾è¯¦ç»†ä¿¡æ¯"""
        try:
            characteristics = []
            
            # ä»ä¸Šä¸‹æ–‡è·å–ç‰¹å¾ä¿¡æ¯
            if context and isinstance(context, dict):
                if 'object_characteristics' in context:
                    characteristics.append(context['object_characteristics'])
                if 'environment_characteristics' in context:
                    characteristics.append(context['environment_characteristics'])
                if 'action_characteristics' in context:
                    characteristics.append(context['action_characteristics'])
            
            # åŸºäºå½“å‰çŠ¶æ€æ¨æ–­ç‰¹å¾
            if self.health < 50:
                characteristics.append('low_health')
            if self.food < 30:
                characteristics.append('low_food')
            if self.water < 30:
                characteristics.append('low_water')
            
            return ','.join(characteristics) if characteristics else 'normal'
            
        except Exception as e:
            if logger:
                logger.log(f"è·å–è¯¦ç»†ç‰¹å¾ä¿¡æ¯å¤±è´¥: {str(e)}")
            return 'normal'

    def _get_current_tools_detailed(self, context=None):
        """è·å–å½“å‰å·¥å…·è¯¦ç»†ä¿¡æ¯ - ä¿®å¤ç‰ˆæœ¬ï¼šè¿”å›å®é™…ä½¿ç”¨çš„å•ä¸ªå·¥å…·"""
        try:
            # ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼šä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–å®é™…ä½¿ç”¨çš„å·¥å…·
            if context and isinstance(context, dict):
                if 'tool_used' in context:
                    return context['tool_used']
                elif 'selected_tool' in context:
                    return context['selected_tool']
                elif 'active_tool' in context:
                    return context['active_tool']
                elif 'current_tool' in context:
                    return context['current_tool']
                elif 'available_tools' in context:
                    tools = context['available_tools']
                    return tools[0] if tools else 'none'
            
            # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å½“å‰é€‰ä¸­çš„å·¥å…·
            if hasattr(self, 'current_selected_tool') and self.current_selected_tool:
                if hasattr(self.current_selected_tool, 'name'):
                    return self.current_selected_tool.name
                elif hasattr(self.current_selected_tool, 'type'):
                    return self.current_selected_tool.type
                else:
                    return str(self.current_selected_tool)
            
            # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æœ€è¿‘ä½¿ç”¨çš„å·¥å…·è®°å½•
            if hasattr(self, '_last_used_tool') and self._last_used_tool:
                return self._last_used_tool
            
            # ğŸ”§ ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰å…·ä½“å·¥å…·ä½¿ç”¨è®°å½•ï¼Œè¿”å›"none"è€Œä¸æ˜¯å…¨å·¥å…·åˆ—è¡¨
            # è¿™æ ·å¯ä»¥é¿å…"å…¨å·¥å…·å¥—é¤"çš„é—®é¢˜
            return 'none'
            
        except Exception as e:
            if logger:
                logger.log(f"è·å–è¯¦ç»†å·¥å…·ä¿¡æ¯å¤±è´¥: {str(e)}")
            return 'none'

    def _enhance_result_detailed(self, result, action, context=None):
        """å¢å¼ºç»“æœè¯¦ç»†ä¿¡æ¯ï¼Œç”Ÿæˆå…·ä½“çš„ç»“æœæè¿°"""
        try:
            if not result:
                return 'unknown_result'
            
            # å¦‚æœresultå·²ç»æ˜¯å­—å…¸ï¼Œæå–å…·ä½“ä¿¡æ¯
            if isinstance(result, dict):
                result_parts = []
                
                # ä¼˜å…ˆå¤„ç†å…·ä½“çš„æ•°å€¼å˜åŒ–
                if 'hp_change' in result and result['hp_change'] != 0:
                    change = result['hp_change']
                    if change > 0:
                        result_parts.append(f"è¡€é‡+{change}")
                    else:
                        result_parts.append(f"è¡€é‡{change}")
                
                if 'food_change' in result and result['food_change'] != 0:
                    change = result['food_change']
                    if change > 0:
                        result_parts.append(f"é£Ÿç‰©+{change}")
                    else:
                        result_parts.append(f"é£Ÿç‰©{change}")
                
                if 'water_change' in result and result['water_change'] != 0:
                    change = result['water_change']
                    if change > 0:
                        result_parts.append(f"æ°´åˆ†+{change}")
                    else:
                        result_parts.append(f"æ°´åˆ†{change}")
                
                if 'position_change' in result:
                    pos_change = result['position_change']
                    if pos_change != (0, 0):
                        result_parts.append("ä½ç½®æ”¹å˜")
                
                # å¤„ç†å…¶ä»–å˜åŒ–ç±»å‹ï¼ˆå‘åå…¼å®¹ï¼‰
                if 'health_change' in result and result['health_change'] != 0:
                    change = result['health_change']
                    if change > 0:
                        result_parts.append(f"è¡€é‡+{change}")
                    else:
                        result_parts.append(f"è¡€é‡{change}")
                
                if 'item_gained' in result:
                    result_parts.append(f"è·å¾—{result['item_gained']}")
                
                if 'damage_dealt' in result and result['damage_dealt'] > 0:
                    result_parts.append(f"é€ æˆ{result['damage_dealt']}ä¼¤å®³")
                
                # å¦‚æœæœ‰å…·ä½“å˜åŒ–ï¼Œè¿”å›å˜åŒ–æè¿°
                if result_parts:
                    return ','.join(result_parts)
                
                # å¦‚æœæ²¡æœ‰å…·ä½“å˜åŒ–ä½†æœ‰æˆåŠŸçŠ¶æ€ï¼Œè¿”å›æˆåŠŸ/å¤±è´¥
                if 'success' in result:
                    return 'success' if result['success'] else 'failure'
                
                return 'no_change'
            
            # å¦‚æœresultæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•å¢å¼º
            result_str = str(result).lower()
            
            # åŸºäºåŠ¨ä½œç±»å‹å’Œç»“æœçŠ¶æ€ç”Ÿæˆå…·ä½“æè¿°
            action_str = str(action).lower()
            if 'success' in result_str:
                if any(word in action_str for word in ['collect', 'gather', 'é‡‡é›†', 'æ”¶é›†']):
                    return 'è·å¾—èµ„æº'
                elif any(word in action_str for word in ['move', 'up', 'down', 'left', 'right', 'ç§»åŠ¨']):
                    return 'ä½ç½®æ”¹å˜'
                elif any(word in action_str for word in ['attack', 'æ”»å‡»']):
                    return 'é€ æˆä¼¤å®³'
                elif any(word in action_str for word in ['drink', 'å–æ°´']):
                    return 'æ°´åˆ†å¢åŠ '
                elif any(word in action_str for word in ['explore', 'æ¢ç´¢']):
                    return 'å‘ç°ä¿¡æ¯'
                else:
                    return 'success'
            elif 'fail' in result_str:
                return 'failure'
            
            return result_str
            
        except Exception as e:
            if logger:
                logger.log(f"å¢å¼ºç»“æœè¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
            return str(result) if result else 'unknown_result'

    def _select_and_use_tool_for_action(self, action, target_type, context=None):
        """ä¸ºç‰¹å®šè¡ŒåŠ¨é€‰æ‹©å¹¶ä½¿ç”¨å·¥å…· - æ–°å¢æ ¸å¿ƒå‡½æ•°"""
        try:
            # 1. æ ¹æ®ç›®æ ‡ç±»å‹é€‰æ‹©æœ€ä½³å·¥å…·
            selected_tool = self._select_best_tool_for_target(target_type)
            
            if selected_tool:
                # 2. è®¾ç½®å½“å‰é€‰ä¸­çš„å·¥å…·
                self.current_selected_tool = selected_tool
                self._last_used_tool = selected_tool.name if hasattr(selected_tool, 'name') else str(selected_tool)
                
                # 3. æ›´æ–°ä¸Šä¸‹æ–‡ä¿¡æ¯
                if context is None:
                    context = {}
                context['tool_used'] = self._last_used_tool
                context['selected_tool'] = self._last_used_tool
                context['active_tool'] = self._last_used_tool
                
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ”§ é€‰æ‹©å·¥å…·: {self._last_used_tool} ç”¨äº {target_type}")
                
                return selected_tool, context
            else:
                # 4. æ²¡æœ‰åˆé€‚å·¥å…·æ—¶ï¼Œè®°å½•å¾’æ‰‹æ“ä½œ
                self.current_selected_tool = None
                self._last_used_tool = 'hand'
                
                if context is None:
                    context = {}
                context['tool_used'] = 'hand'
                context['selected_tool'] = 'hand'
                
                if self.logger:
                    self.logger.log(f"{self.name} âœ‹ å¾’æ‰‹æ“ä½œ: {action} é’ˆå¯¹ {target_type}")
                
                return None, context
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·é€‰æ‹©å¤±è´¥: {str(e)}")
            return None, context

    def _select_best_tool_for_target(self, target_type):
        """ä¸ºç›®æ ‡é€‰æ‹©æœ€ä½³å·¥å…· - æ™ºèƒ½é€‰æ‹©ç®—æ³•"""
        try:
            if not hasattr(self, 'tools') or not self.tools:
                return None
            
            # ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼šåŸºäºå­¦ä¹ ç»éªŒé€‰æ‹©å•ä¸ªæœ€ä½³å·¥å…·
            if hasattr(self, 'tool_effectiveness') and self.tool_effectiveness:
                best_tool = None
                best_effectiveness = -1
                
                for tool in self.tools:
                    tool_name = tool.name if hasattr(tool, 'name') else str(tool)
                    key = (tool_name, target_type)
                    
                    if key in self.tool_effectiveness:
                        data = self.tool_effectiveness[key]
                        effectiveness = data.get('effectiveness', 0)
                        attempts = data.get('attempts', 0)
                        
                        # åªè€ƒè™‘æœ‰è¶³å¤Ÿå°è¯•æ¬¡æ•°çš„å·¥å…·
                        if attempts >= 2 and effectiveness > best_effectiveness:
                            best_effectiveness = effectiveness
                            best_tool = tool
                
                if best_tool:
                    return best_tool
            
            # ğŸ”§ å›é€€åˆ°åŸºäºç›®æ ‡ç±»å‹çš„é¢„è®¾æ˜ å°„
            tool_target_mapping = {
                'predator': ['Spear', 'é•¿çŸ›'],  # çŒ›å…½ç”¨é•¿çŸ›
                'prey': ['Stone', 'çŸ³å¤´'],      # çŒç‰©ç”¨çŸ³å¤´
                'bird': ['Bow', 'å¼“ç®­'],        # é¸Ÿç±»ç”¨å¼“ç®­
                'ground_plant': ['Basket', 'ç¯®å­'],      # åœ°é¢æ¤ç‰©ç”¨ç¯®å­
                'underground_plant': ['Shovel', 'é“é”¹'], # åœ°ä¸‹æ¤ç‰©ç”¨é“é”¹
                'tree_plant': ['Stick', 'æ£å­']          # æ ‘ä¸Šæ¤ç‰©ç”¨æ£å­
            }
            
            preferred_tools = tool_target_mapping.get(target_type, [])
            
            # å¯»æ‰¾åŒ¹é…çš„å·¥å…·
            for tool in self.tools:
                tool_name = tool.name if hasattr(tool, 'name') else str(tool)
                tool_type = getattr(tool, 'type', tool_name)
                
                if tool_name in preferred_tools or tool_type in preferred_tools:
                    return tool
            
            # ğŸ”§ å¦‚æœæ²¡æœ‰ç†æƒ³å·¥å…·ï¼Œè¿›è¡Œæ¢ç´¢æ€§é€‰æ‹©
            return self._select_tool_for_exploration(target_type)
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·é€‰æ‹©ç®—æ³•å¤±è´¥: {str(e)}")
            return None

    def _select_tool_for_exploration(self, target_type):
        """æ¢ç´¢æ€§å·¥å…·é€‰æ‹© - ä¼˜å…ˆé€‰æ‹©å°è¯•æ¬¡æ•°å°‘çš„å·¥å…·"""
        try:
            if not hasattr(self, 'tools') or not self.tools:
                return None
            
            # ç»Ÿè®¡æ¯ä¸ªå·¥å…·å¯¹è¯¥ç›®æ ‡çš„å°è¯•æ¬¡æ•°
            tool_attempts = []
            for tool in self.tools:
                tool_name = tool.name if hasattr(tool, 'name') else str(tool)
                key = (tool_name, target_type)
                attempts = self.tool_effectiveness.get(key, {}).get('attempts', 0)
                tool_attempts.append((tool, attempts))
            
            # æŒ‰å°è¯•æ¬¡æ•°æ’åºï¼Œä¼˜å…ˆé€‰æ‹©å°è¯•æ¬¡æ•°å°‘çš„
            tool_attempts.sort(key=lambda x: x[1])
            
            # ä»å°è¯•æ¬¡æ•°æœ€å°‘çš„å·¥å…·ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
            min_attempts = tool_attempts[0][1]
            least_tried_tools = [tool for tool, attempts in tool_attempts if attempts == min_attempts]
            
            import random
            return random.choice(least_tried_tools)
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} æ¢ç´¢æ€§å·¥å…·é€‰æ‹©å¤±è´¥: {str(e)}")
            return self.tools[0] if self.tools else None

    def _record_tool_usage_result(self, tool, target_type, action, success, benefit=0):
        """è®°å½•å·¥å…·ä½¿ç”¨ç»“æœ - ç”¨äºå­¦ä¹ """
        try:
            if not tool:
                return
            
            tool_name = tool.name if hasattr(tool, 'name') else str(tool)
            key = (tool_name, target_type)
            
            # åˆå§‹åŒ–è®°å½•
            if key not in self.tool_effectiveness:
                self.tool_effectiveness[key] = {
                    'attempts': 0,
                    'successes': 0,
                    'effectiveness': 0.0,
                    'total_benefit': 0
                }
            
            # æ›´æ–°è®°å½•
            data = self.tool_effectiveness[key]
            data['attempts'] += 1
            if success:
                data['successes'] += 1
                data['total_benefit'] += benefit
            
            # é‡æ–°è®¡ç®—æ•ˆæœå€¼
            data['effectiveness'] = data['successes'] / data['attempts'] if data['attempts'] > 0 else 0
            
            # æ·»åŠ åˆ°ä½¿ç”¨å†å²
            if not hasattr(self, 'tool_usage_history'):
                self.tool_usage_history = []
            
            self.tool_usage_history.append({
                'tool_name': tool_name,
                'target_type': target_type,
                'action': action,
                'success': success,
                'benefit': benefit,
                'timestamp': len(self.tool_usage_history)
            })
            
            if self.logger:
                self.logger.log(f"{self.name} ğŸ”§ å·¥å…·ä½¿ç”¨è®°å½•: {tool_name}â†’{target_type} "
                              f"æˆåŠŸç‡:{data['effectiveness']:.2f} "
                              f"({data['successes']}/{data['attempts']})")
                              
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·ä½¿ç”¨è®°å½•å¤±è´¥: {str(e)}")

    def _determine_plant_type(self, plant):
        """ç¡®å®šæ¤ç‰©ç±»å‹ç”¨äºå·¥å…·é€‰æ‹©"""
        try:
            plant_class = plant.__class__.__name__
            
            # æ ¹æ®æ¤ç‰©ç‰¹æ€§ç¡®å®šç±»å‹
            if hasattr(plant, 'location_type'):
                if plant.location_type == "underground":
                    return 'underground_plant'
                elif plant.location_type == "tree":
                    return 'tree_plant'
                else:
                    return 'ground_plant'
            else:
                # æ ¹æ®æ¤ç‰©ç±»åæ¨æ–­
                if plant_class in ['Potato', 'SweetPotato', 'Carrot']:
                    return 'underground_plant'
                elif plant_class in ['Acorn', 'Chestnut', 'Apple']:
                    return 'tree_plant'
                else:
                    return 'ground_plant'
                    
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} æ¤ç‰©ç±»å‹ç¡®å®šå¤±è´¥: {str(e)}")
            return 'ground_plant'

    def _determine_animal_type(self, animal):
        """ç¡®å®šåŠ¨ç‰©ç±»å‹ç”¨äºå·¥å…·é€‰æ‹©"""
        try:
            animal_class = animal.__class__.__name__
            
            # æ ¹æ®åŠ¨ç‰©ç‰¹æ€§ç¡®å®šç±»å‹
            if hasattr(animal, 'is_predator') and animal.is_predator:
                return 'predator'
            elif animal_class in ['Tiger', 'BlackBear']:
                return 'predator'
            elif animal_class in ['Pheasant', 'Dove']:
                return 'bird'
            elif animal_class in ['Rabbit', 'Boar']:
                return 'prey'
            else:
                # é»˜è®¤æ ¹æ®æ”»å‡»åŠ›åˆ¤æ–­
                if hasattr(animal, 'attack') and animal.attack > 20:
                    return 'predator'
                else:
                    return 'prey'
                    
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} åŠ¨ç‰©ç±»å‹ç¡®å®šå¤±è´¥: {str(e)}")
            return 'prey'

    def _evaluate_action_success(self, action, result, context=None):
        """è¯„ä¼°åŠ¨ä½œæˆåŠŸæ€§"""
        try:
            if isinstance(result, dict):
                return result.get('success', True)
            
            result_str = str(result).lower()
            return 'success' in result_str or 'gained' in result_str or 'collected' in result_str
            
        except Exception as e:
            return True

    def _classify_action_type(self, action):
        """åˆ†ç±»åŠ¨ä½œç±»å‹"""
        try:
            action_str = str(action).lower()
            
            if any(word in action_str for word in ['collect', 'gather', 'harvest']):
                return 'collection'
            elif any(word in action_str for word in ['move', 'up', 'down', 'left', 'right']):
                return 'movement'
            elif any(word in action_str for word in ['attack', 'hunt', 'fight']):
                return 'combat'
            elif any(word in action_str for word in ['explore', 'search', 'investigate']):
                return 'exploration'
            elif any(word in action_str for word in ['drink', 'eat', 'consume']):
                return 'consumption'
            else:
                return 'other'
                
        except Exception as e:
            return 'unknown'

    def _is_action_executable(self, action, game):
        """æ£€æŸ¥å»ºè®®çš„è¡ŒåŠ¨æ˜¯å¦å¯æ‰§è¡Œ"""
        try:
            if not action or not game:
                return False
            
            # æ£€æŸ¥ç§»åŠ¨è¡Œ"""
            if action in ['move_up', 'move_down', 'move_left', 'move_right']:
                direction_map = {
                    'move_up': (0, -1),
                    'move_down': (0, 1),
                    'move_left': (-1, 0),
                    'move_right': (1, 0)
                }
                dx, dy = direction_map[action]
                new_x, new_y = self.x + dx, self.y + dy
                return game.game_map.is_within_bounds(new_x, new_y)
            
            # æ£€æŸ¥é¥®æ°´è¡Œ"
            elif action == 'drink_water':
                current_cell = game.game_map.grid[self.y][self.x]
                return current_cell in ['river', 'puddle']
            
            # æ£€æŸ¥é‡‡é›†è¡Œ"
            elif action in ['collect_plant', 'gather_food']:
                for plant in game.game_map.plants:
                    if (plant.x == self.x and plant.y == self.y and 
                        plant.alive and not plant.collected):
                        return True
                return False
            
            # æ£€æŸ¥æ”»å‡»è¡Œ"
            elif action == 'attack_animal':
                for animal in game.game_map.animals:
                    if (animal.alive and 
                        abs(animal.x - self.x) <= 1 and abs(animal.y - self.y) <= 1):
                        return True
                return False
            
            # æ£€æŸ¥é€ƒè·‘è¡ŒåŠ¨
            elif action in ['escape', 'flee']:
                threats = self.detect_threats(game.game_map)
                return len(threats) > 0
            
            # é»˜è®¤è®¤ä¸ºå…¶ä»–è¡ŒåŠ¨å¯æ‰§"
            return True
            
        except Exception as e:
            if logger:
                logger.log(f"æ£€æŸ¥è¡ŒåŠ¨å¯æ‰§è¡Œæ€§å¤±ä» {str(e)}")
            return False

    # åœ¨ILAIç±»ä¸­æ·»åŠ CDLæ¢ç´¢æ–¹æ³•,åœ¨_trigger_exploration_learningæ–¹æ³•ä¹‹åæ·»åŠ 
    def _execute_cdl_exploration_move(self, game):
        """æ‰§è¡ŒCDLæ¢ç´¢æ€§ç§»åŠ¨"""
        try:
            # å¯»æ‰¾æ–°é¢–çš„ã€æœªè®¿é—®è¿‡çš„ä½ç½®
            directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
            import random
            random.shuffle(directions)
            
            # åˆå§‹åŒ–è®¿é—®ä½ç½®è®°å½•(å¦‚æœä¸å­˜åœ¨)
            if not hasattr(self, 'visited_positions'):
                self.visited_positions = set()
            
            for dx, dy in directions:
                new_x, new_y = self.x + dx, self.y + dy
                if (game.game_map.is_within_bounds(new_x, new_y) and 
                    (new_x, new_y) not in self.visited_positions):
                    if self.move(dx, dy, game.game_map):
                        if self.logger:
                            self.logger.log(f"{self.name} ğŸ” CDLæ–°é¢–æ€§æ¢ç´¢ç§»åŠ¨åˆ° ({new_x}, {new_y})")
                        return True
            
            # å¦‚æœæ²¡æœ‰å®Œå…¨æ–°çš„ä½ç½®,é€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å°‘çš„æ–¹å‘
            direction_scores = []
            for dx, dy in directions:
                new_x, new_y = self.x + dx, self.y + dy
                if game.game_map.is_within_bounds(new_x, new_y):
                    # è®¡ç®—è¯¥æ–¹å‘çš„"æ–°é¢–æ€§åˆ†æ•°
                    novelty_score = 0
                    if (new_x, new_y) not in self.visited_positions:
                        novelty_score += 10
                    
                    # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰æœªæ¢ç´¢çš„åŒºåŸŸ
                    for check_dx in [-1, 0, 1]:
                        for check_dy in [-1, 0, 1]:
                            check_x, check_y = new_x + check_dx, new_y + check_dy
                            if (game.game_map.is_within_bounds(check_x, check_y) and
                                (check_x, check_y) not in self.visited_positions):
                                novelty_score += 1
                    
                    direction_scores.append((dx, dy, novelty_score))
            
            # é€‰æ‹©æœ€é«˜æ–°é¢–æ€§çš„æ–¹å‘
            if direction_scores:
                direction_scores.sort(key=lambda x: x[2], reverse=True)
                best_dx, best_dy, _ = direction_scores[0]
                if self.move(best_dx, best_dy, game.game_map):
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ¯ CDLé€‰æ‹©æœ€ä¼˜æ¢ç´¢æ–¹æ³•({best_dx}, {best_dy})")
                    return True
            
            return False
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} CDLæ¢ç´¢ç§»åŠ¨å¤±è´¥: {str(e)}")
            return False
    
    def _execute_cdl_info_gathering(self, game):
        """æ‰§è¡ŒCDLä¿¡æ¯æ”¶é›†è¡Œä¸º - ğŸ¯ å¢å¼ºï¼šæ”¯æŒç”Ÿç‰©å¤šæ ·æ€§å’Œå·¥å…·æ•ˆèƒ½æµ‹è¯•"""
        try:
            # ğŸ¯ æ–°å¢ï¼šä¼˜å…ˆæ‰§è¡Œé«˜ä»·å€¼æ¢ç´¢ç›®æ ‡
            high_priority_result = self._execute_high_priority_exploration(game)
            if high_priority_result:
                return high_priority_result
            
            # ä¼˜å…ˆæ”¶é›†é™„è¿‘çš„èµ„æºæˆ–ä¸å®ä½“äº¤äº’
            
            # ğŸ¯ æ–°å¢:æ£€æŸ¥é™„è¿‘çš„åŠ¨ç‰©å¹¶å°è¯•æ”»å‡»(ä¼˜å…ˆçº§æœ€é«˜)
            for animal in game.game_map.animals:
                if animal.alive and abs(animal.x - self.x) + abs(animal.y - self.y) <= 1:
                    # åªæ”»å‡»éçŒ›å…½ç±»åŠ¨ç‰©(Rabbit, Boar)ä»¥é¿å…è¿‡é«˜é£é™©
                    if animal.type in ["Rabbit", "Boar"]:
                        old_food = self.food
                        self.attack(animal)
                        if self.food > old_food or not animal.alive:
                            if self.logger:
                                self.logger.log(f"{self.name} ğŸ¹ CDLä¿¡æ¯æ”¶é›†:æˆåŠŸæ”»å‡»{animal.type}")
                            return True
                    # å¯¹äºçŒ›å…½,åªæœ‰åœ¨é£Ÿç‰©ä¸¥é‡ä¸è¶³æ—¶æ‰å†’é™©æ”»å‡»
                    elif animal.type in ["Tiger", "BlackBear"] and self.food < 50:
                        old_food = self.food
                        self.attack(animal)
                        if self.food > old_food or not animal.alive:
                            if self.logger:
                                self.logger.log(f"{self.name} âš”ï¸ CDLä¿¡æ¯æ”¶é›†:å†’é™©æ”»å‡»{animal.type}")
                            return True
            
            # æ£€æŸ¥é™„è¿‘çš„æ¤ç‰©
            for plant in game.game_map.plants:
                if abs(plant.x - self.x) + abs(plant.y - self.y) <= 1:
                    old_food = self.food
                    self.collect_plant(plant)
                    if self.food > old_food:
                        if self.logger:
                            self.logger.log(f"{self.name} ğŸ“Š CDLä¿¡æ¯æ”¶é›†:æˆåŠŸé‡‡é›†æ¤ç‰©")
                        return True
            
            # å¦‚æœåœ¨æ°´æºä½ç½®,è¡¥å……æ°´åˆ†
            current_cell = game.game_map.grid[self.y][self.x]
            if current_cell in ["river", "puddle"] and self.water < 90:
                old_water = self.water
                self.water = min(100, self.water + 30)
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ’§ CDLä¿¡æ¯æ”¶é›†:è¡¥å……æ°´åˆ†{old_water}->{self.water}")
                return True
            
            # å¦‚æœæ²¡æœ‰ç›´æ¥çš„æ”¶é›†æœºä¼š,ç§»åŠ¨åˆ°æœ€è¿‘çš„æœ‰ä»·å€¼ç›®æ ‡
            best_target = None
            best_distance = float('inf')
            target_type = None
            
            # ğŸ¯ æ–°å¢:å¯»æ‰¾æœ€è¿‘çš„å¯æ”»å‡»åŠ¨ç‰©(ä¼˜å…ˆçº§é«˜äºæ¤ç‰©)
            for animal in game.game_map.animals:
                if animal.alive:
                    distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                    # ä¼˜å…ˆè€ƒè™‘å®‰å…¨çš„çŒç‰©
                    if animal.type in ["Rabbit", "Boar"] and distance < best_distance and distance <= 3:
                        best_distance = distance
                        best_target = animal
                        target_type = "animal"
                    # é£Ÿç‰©ä¸è¶³æ—¶è€ƒè™‘çŒ›å…½
                    elif animal.type in ["Tiger", "BlackBear"] and self.food < 40 and distance < best_distance and distance <= 2:
                        best_distance = distance
                        best_target = animal
                        target_type = "predator"
            
            # å¯»æ‰¾æœ€è¿‘çš„æ¤ç‰©(ä½œä¸ºå¤‡é€‰)
            if not best_target:
                for plant in game.game_map.plants:
                    distance = abs(plant.x - self.x) + abs(plant.y - self.y)
                    if distance < best_distance:
                        best_distance = distance
                        best_target = plant
                        target_type = "plant"
            
            # ç§»åŠ¨åˆ°æœ€ä½³ç›®æ ‡
            if best_target and best_distance <= 5:  # åªæœ‰åœ¨åˆç†è·ç¦»å†…æ‰ç§»åŠ¨
                dx = 1 if best_target.x > self.x else -1 if best_target.x < self.x else 0
                dy = 1 if best_target.y > self.y else -1 if best_target.y < self.y else 0
                if dx != 0 or dy != 0:
                    if self.move(dx, dy, game.game_map):
                        if self.logger:
                            action_desc = "å‘åŠ¨ç‰©" if target_type in ["animal", "predator"] else "å‘æ¤ç‰©"
                            self.logger.log(f"{self.name} ğŸš¶ CDLä¿¡æ¯æ”¶é›†:{action_desc}ç§»åŠ¨")
                        return True
            
            return False
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} CDLä¿¡æ¯æ”¶é›†å¤±è´¥: {str(e)}")
            return False
    
    def _trigger_knowledge_sync(self):
        """è§¦å‘çŸ¥è¯†åŒæ­¥æ£€æŸ¥- åŸºäºæ–°é¢–æ€§çš„åŒæ­¥æœºåˆ¶(é‡æ„ç‰ˆ)"""
        if not hasattr(self, 'global_knowledge_sync') or not self.global_knowledge_sync:
            return 0
        
        sync_count = 0  # è®¡æ•°æœ¬æ¬¡åŒæ­¥çš„é¡¹ç›®æ•°"""
        try:
            # ğŸ”§ 1. æ£€æŸ¥äº”åº“ç³»ç»Ÿä¸­çš„æ–°ç»éªŒ(åŸºäºæ–°é¢–æ€§)
            if hasattr(self, 'five_library_system') and self.five_library_system:
                try:
                    # è·å–æœ€è¿‘çš„ç»éªŒè¿›è¡Œæ–°é¢–æ€§æ£€"
                    recent_experiences = self.five_library_system.get_recent_experiences(limit=10)
                    for experience in recent_experiences:
                        # ç”Ÿæˆç»éªŒå“ˆå¸Œæ£€æŸ¥æ–°é¢–"
                        exp_hash = self.global_knowledge_sync._generate_experience_hash(experience)
                        
                        # å¦‚æœæ˜¯å…¨æ–°ç»éªŒ(æœªåœ¨å…¨å±€å“ˆå¸Œé›†åˆä¸­),è§¦å‘åŒ"
                        if exp_hash not in self.global_knowledge_sync.synced_experience_hashes:
                            success, msg = self.global_knowledge_sync.sync_new_experience(self, experience)
                            if success:
                                sync_count += 1
                                if logger:
                                    logger.log(f"ğŸŒŸ {self.name} å‘ç°æ–°é¢–ç»éªŒå¹¶åŒä» {msg}")
                                
                                # ğŸ”§ è§¦å‘BPMæ€’æ”¾é˜¶æ®µ(åŸºäºæ–°ç»éªŒå‘ç°"
                                self._trigger_bmp_blooming_on_new_experience(experience)
                            break  # ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªæ–°ç»éªŒ,é¿å…è¿‡åº¦å¤„"
                except Exception as e:
                    if logger:
                        logger.log(f"âš ï¸ {self.name} äº”åº“ç»éªŒæ–°é¢–æ€§æ£€æŸ¥å¤±ä» {str(e)}")
            
            # ğŸ”§ 2. æ£€æŸ¥äº”åº“ç³»ç»Ÿä¸­çš„æ–°è§„å¾‹(åŸºäºæ–°é¢–æ€§)
            if hasattr(self, 'five_library_system') and self.five_library_system:
                try:
                    # è·å–æœ€è¿‘çš„è§„å¾‹è¿›è¡Œæ–°é¢–æ€§æ£€"
                    recent_rules = self.five_library_system.get_recent_rules(limit=5)
                    for rule in recent_rules:
                        # ç¡®å®šè§„å¾‹ç±»å‹
                        rule_type = self._classify_rule_type(rule)
                        
                        # ç”Ÿæˆè§„å¾‹å“ˆå¸Œæ£€æŸ¥æ–°é¢–"
                        rule_hash = self.global_knowledge_sync._generate_rule_hash(rule, rule_type)
                        
                        # å¦‚æœæ˜¯å…¨æ–°è§„å¾‹(æœªåœ¨å…¨å±€å“ˆå¸Œé›†åˆä¸­),è§¦å‘åŒ"
                        if rule_hash not in self.global_knowledge_sync.synced_rule_hashes:
                            success, msg = self.global_knowledge_sync.sync_new_rule(self, rule, rule_type)
                            if success:
                                sync_count += 1
                                if logger:
                                    logger.log(f"ğŸ† {self.name} å‘ç°æ–°é¢–è§„å¾‹å¹¶åŒä» {msg}")
                            break  # ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªæ–°è§„å¾‹
                except Exception as e:
                    if logger:
                        logger.log(f"âš ï¸ {self.name} äº”åº“è§„å¾‹æ–°é¢–æ€§æ£€æŸ¥å¤±ä» {str(e)}")
            
            # ğŸ”§ 3. æ£€æŸ¥EOCATRç»éªŒçš„æ–°é¢–"
            eocatr_experiences = None
            if hasattr(self, 'eocatr_experiences') and self.eocatr_experiences:
                eocatr_experiences = self.eocatr_experiences
            elif hasattr(self, 'eocar_experiences') and self.eocar_experiences:
                eocatr_experiences = self.eocar_experiences
            
            if eocatr_experiences:
                # æ£€æŸ¥æœ€æ–°çš„EOCATRç»éªŒ
                latest_experience = eocatr_experiences[-1]
                exp_hash = self.global_knowledge_sync._generate_experience_hash(latest_experience)
                
                if exp_hash not in self.global_knowledge_sync.synced_experience_hashes:
                    success, msg = self.global_knowledge_sync.sync_new_experience(self, latest_experience)
                    if success:
                        sync_count += 1
                        if logger:
                            logger.log(f"ğŸŒŸ {self.name} å‘ç°æ–°é¢–EOCATRç»éªŒå¹¶åŒæ­¥")
                        
                        # ğŸ”§ è§¦å‘BPMæ€’æ”¾é˜¶æ®µ
                        self._trigger_bmp_blooming_on_new_experience(latest_experience)
            
            # ğŸ”§ 4. æ£€æŸ¥BPMç”Ÿæˆçš„æ–°è§„å¾‹(åŸºäºæ–°é¢–æ€§)
            if hasattr(self, 'bpm') and self.bpm:
                # å°è¯•å¤šç§å¯èƒ½çš„è§„å¾‹å­˜å‚¨å±"
                validated_rules = None
                rules_source = None
                
                if hasattr(self.bpm, 'validated_rules') and self.bpm.validated_rules:
                    validated_rules = self.bpm.validated_rules
                    rules_source = 'validated_rules'
                elif hasattr(self.bpm, 'rules') and self.bpm.rules:
                    validated_rules = self.bpm.rules
                    rules_source = 'rules'
                elif hasattr(self.bpm, 'rule_database') and self.bpm.rule_database:
                    validated_rules = self.bpm.rule_database
                    rules_source = 'rule_database'
                
                if validated_rules:
                    # å¤„ç†ä¸åŒçš„æ•°æ®ç»“"
                    if isinstance(validated_rules, dict):
                        recent_rules = list(validated_rules.items())[-1:]  # åªæ£€æŸ¥æœ€æ–°çš„
                    elif isinstance(validated_rules, list):
                        recent_rules = [(len(validated_rules)-1, validated_rules[-1])]  # åªæ£€æŸ¥æœ€æ–°çš„
                    else:
                        recent_rules = []
                    
                    for rule_id, rule_data in recent_rules:
                        # ç¡®å®šè§„å¾‹ç±»å‹
                        rule_type = self._classify_rule_type(rule_data)
                        rule_hash = self.global_knowledge_sync._generate_rule_hash(rule_data, rule_type)
                        
                        # å¦‚æœæ˜¯å…¨æ–°è§„å¾‹,è§¦å‘åŒæ­¥
                        if rule_hash not in self.global_knowledge_sync.synced_rule_hashes:
                            success, msg = self.global_knowledge_sync.sync_new_rule(self, rule_data, rule_type)
                            if success:
                                sync_count += 1
                                if logger:
                                    logger.log(f"ğŸ† {self.name} å‘ç°æ–°é¢–BPMè§„å¾‹å¹¶åŒæ­¥")
                            break  # ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªæ–°è§„å¾‹
            
            # ğŸ¯ è®°å½•åŒæ­¥æ´»åŠ¨ç»Ÿè®¡
            if sync_count > 0:
                # è®°å½•æ–°é¢–å‘ç°
                if hasattr(self, 'increment_novelty_discovery'):
                    for _ in range(sync_count):
                        self.increment_novelty_discovery('experience')
                
                if logger:
                    logger.log(f"ğŸ“Š {self.name} æœ¬è½®å‘ç°å¹¶åŒæ­¥äº† {sync_count} ä¸ªæ–°é¢–çŸ¥è¯†é¡¹ç›®")
            
        except Exception as e:
            if logger:
                logger.log(f"âš ï¸ {self.name} æ–°é¢–æ€§çŸ¥è¯†åŒæ­¥æ£€æŸ¥å¤±ä» {str(e)}")
        
        return sync_count
    
    def _trigger_bmp_blooming_on_new_experience(self, new_experience):
        """å½“å‘ç°æ–°ç»éªŒæ—¶è§¦å‘BPMæ€’æ”¾é˜¶æ®µ"""
        try:
            if hasattr(self, 'bpm') and self.bpm:
                # è·å–å†å²ç»éªŒä½œä¸ºä¸Šä¸‹"""
                historical_experiences = []
                if hasattr(self, 'five_library_system') and self.five_library_system:
                    historical_experiences = self.five_library_system.get_recent_experiences(limit=20)
                
                # ğŸ”§ æ•°æ®æ ¼å¼è½¬æ¢:ç¡®ä¿BPMæ¥æ”¶åˆ°æ­£ç¡®çš„EOCATR_Tupleæ ¼å¼
                processed_experience = new_experience
                processed_historical = []
                
                # è½¬æ¢ä¸»è¦ç»éªŒ(æ”¯æŒå­—ç¬¦ä¸²ã€å­—å…¸ç­‰å¤šç§æ ¼å¼"
                try:
                    processed_experience = self._convert_dict_to_eocar_tuple(new_experience)
                except Exception as conv_e:
                    if logger:
                        logger.log(f"âš ï¸ {self.name} ç»éªŒæ ¼å¼è½¬æ¢å¤±è´¥: {str(conv_e)}, è¾“å…¥ç±»å‹: {type(new_experience)}")
                    return  # è½¬æ¢å¤±è´¥å°±ä¸å¤„ç†
                
                # è½¬æ¢å†å²ç»éªŒ(æ”¯æŒå¤šç§æ ¼å¼)
                for hist_exp in historical_experiences[:10]:  # é™åˆ¶æ•°é‡é¿å…è¿‡è½½
                    try:
                        converted_hist = self._convert_dict_to_eocar_tuple(hist_exp)
                        processed_historical.append(converted_hist)
                    except Exception as hist_e:
                        # è½¬æ¢å¤±è´¥çš„è·³è¿‡,ä½†è®°å½•æ—¥å¿—ç”¨äºè°ƒ"
                        if logger and len(processed_historical) == 0:  # åªä¸ºç¬¬ä¸€ä¸ªå¤±è´¥è®°å½•æ—¥"
                            logger.log(f"âš ï¸ {self.name} å†å²ç»éªŒè½¬æ¢å¤±è´¥: ç±»å‹{type(hist_exp)}")
                        continue
                
                # è°ƒç”¨BPMå¤„ç†æ–°ç»"
                if hasattr(self.bpm, 'process_experience'):
                    # ä½¿ç”¨æ­£ç¡®æ ¼å¼çš„æ•°æ®è°ƒç”¨BPM
                    self.bpm.process_experience(processed_experience, processed_historical)
                    if logger:
                        logger.log(f"ğŸŒ¸ {self.name} BPMæ€’æ”¾é˜¶æ®µå·²æ¿€æ´»,åŸºäºæ–°ç»éªŒè¿›è¡Œè§„å¾‹æŒ–æ˜")
                elif hasattr(self.bpm, 'blooming_phase'):
                    # å¤‡ç”¨è°ƒç”¨æ–¹å¼
                    self.bpm.blooming_phase([processed_experience] + processed_historical)
                    if logger:
                        logger.log(f"ğŸŒ¸ {self.name} BPMæ€’æ”¾é˜¶æ®µå·²æ¿€æ´»(å¤‡ç”¨æ–¹å¼)")
        except Exception as e:
            if logger:
                logger.log(f"âš ï¸ {self.name} BPMæ€’æ”¾é˜¶æ®µè§¦å‘å¤±è´¥: {str(e)}")
    
    def _classify_rule_type(self, rule_data):
        """ç®€å•çš„è§„å¾‹ç±»å‹åˆ†ç±»"""
        rule_str = str(rule_data).lower()
        
        if 'tool' in rule_str and 'target' in rule_str:
            return 'tool_effectiveness_rules'
        elif 'if' in rule_str or 'when' in rule_str:
            return 'causal_rules'
        elif 'behavior' in rule_str or 'action' in rule_str:
            return 'behavioral_rules'
        elif 'environment' in rule_str or 'location' in rule_str:
            return 'environmental_rules'
        else:
            return 'causal_rules'  # é»˜è®¤åˆ†ç±»

    def _determine_decision_stage(self, game):
        """ç¡®å®šå½“å‰åº”è¯¥ä½¿ç”¨çš„å†³ç­–é˜¶æ®µ"""
        # è·å–å½“å‰èµ„æºçŠ¶æ€
        hp = self.hp
        food = self.food
        water = self.water
        
        # æ£€æµ‹å¨èƒè·ç¦»
        min_threat_distance = self._get_min_threat_distance(game)
        
        # é˜¶æ®µä¸€ï¼šæœ¬èƒ½å†³ç­–é˜¶æ®µ
        if (hp <= 20 or food <= 20 or water <= 20) or min_threat_distance <= 3:
            trigger_reasons = []
            trigger_type = None
            
            if hp <= 20:
                trigger_reasons.append(f"è¡€é‡å±é™©({hp})")
                trigger_type = "low_health"
            if food <= 20:
                trigger_reasons.append(f"é£Ÿç‰©ä¸è¶³({food})")
                trigger_type = "low_food" if not trigger_type else trigger_type
            if water <= 20:
                trigger_reasons.append(f"æ°´åˆ†ä¸è¶³({water})")
                trigger_type = "low_water" if not trigger_type else trigger_type
            if min_threat_distance <= 3:
                trigger_reasons.append(f"å¨èƒæ¥è¿‘(è·ç¦»{min_threat_distance})")
                trigger_type = "threat_nearby"
            
            return {
                'stage': 'instinct',
                'reason': 'æœ¬èƒ½å±‚è§¦å‘æ¡ä»¶æ»¡è¶³',
                'trigger_reason': ', '.join(trigger_reasons),
                'trigger_type': trigger_type
            }
        
        # é˜¶æ®µäºŒï¼šDMHAå†³ç­–é˜¶æ®µ
        elif (hp > 20 and hp <= 50) or (food > 20 and food <= 50) or (water > 20 and water <= 50):
            if min_threat_distance > 3:
                return {
                    'stage': 'dmha',
                    'reason': 'èµ„æºä¸­ç­‰ï¼Œæ— ç›´æ¥å¨èƒ',
                    'trigger_reason': f'è¡€é‡:{hp}, é£Ÿç‰©:{food}, æ°´:{water}, æœ€è¿‘å¨èƒè·ç¦»:{min_threat_distance}',
                    'trigger_type': 'moderate_resources'
                }
        
        # é˜¶æ®µä¸‰ï¼šCDLå†³ç­–é˜¶æ®µ
        if hp > 50 and food > 50 and water > 50 and min_threat_distance > 3:
            return {
                'stage': 'cdl',
                'reason': 'èµ„æºå……è¶³ï¼Œç¯å¢ƒå®‰å…¨',
                'trigger_reason': f'è¡€é‡:{hp}, é£Ÿç‰©:{food}, æ°´:{water}, æœ€è¿‘å¨èƒè·ç¦»:{min_threat_distance}',
                'trigger_type': 'abundant_resources'
            }
        
        # é»˜è®¤ä½¿ç”¨DMHAé˜¶æ®µ
        return {
            'stage': 'dmha',
            'reason': 'é»˜è®¤ç›®æ ‡å¯¼å‘å†³ç­–',
            'trigger_reason': f'è¡€é‡:{hp}, é£Ÿç‰©:{food}, æ°´:{water}, æœ€è¿‘å¨èƒè·ç¦»:{min_threat_distance}',
            'trigger_type': 'default'
        }
    
    def _get_min_threat_distance(self, game):
        """è·å–æœ€è¿‘å¨èƒçš„è·ç¦»"""
        min_distance = float('inf')
        
        for animal in game.game_map.animals:
            if animal.alive and animal.type in ["Tiger", "BlackBear"]:
                distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                min_distance = min(min_distance, distance)
        
        return min_distance if min_distance != float('inf') else 999
    
    def _execute_instinct_decision(self, game, trigger_type):
        """æ‰§è¡Œæœ¬èƒ½å±‚å†³ç­– - ç›´æ¥å“åº”ï¼Œä¸ç»è¿‡å¤æ‚æœºåˆ¶"""
        try:
            if trigger_type == "threat_nearby":
                # å¨èƒé€ƒç¦»
                return self._instinct_flee_from_threat(game)
            elif trigger_type == "low_health":
                # å¯»æ‰¾å®‰å…¨åœ°ç‚¹
                return self._instinct_find_safety(game)
            elif trigger_type == "low_food":
                # ç´§æ€¥å¯»æ‰¾é£Ÿç‰©
                return self._instinct_find_food(game)
            elif trigger_type == "low_water":
                # ç´§æ€¥å¯»æ‰¾æ°´æº
                return self._instinct_find_water(game)
            else:
                # é»˜è®¤é€ƒç¦»è¡Œä¸º
                return self._instinct_flee_from_threat(game)
        except Exception as e:
            if logger:
                logger.log(f"{self.name} æœ¬èƒ½å†³ç­–æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _instinct_flee_from_threat(self, game):
        """æœ¬èƒ½é€ƒç¦»å¨èƒ"""
        threats = []
        for animal in game.game_map.animals:
            if animal.alive and animal.type in ["Tiger", "BlackBear"]:
                distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                if distance <= 5:  # æ‰©å¤§æ£€æµ‹èŒƒå›´
                    threats.append(animal)
        
        if threats:
            # è®¡ç®—é€ƒç¦»æ–¹å‘
            escape_direction = self._calculate_escape_direction(threats, game.game_map)
            if escape_direction:
                dx, dy = escape_direction
                if self.move(dx, dy, game.game_map):
                    if logger:
                        logger.log(f"{self.name} æœ¬èƒ½é€ƒç¦»å¨èƒæˆåŠŸ")
                    return True
        
        # å¦‚æœæ— æ³•é€ƒç¦»ï¼Œæ‰§è¡Œéšæœºç§»åŠ¨
        self._execute_random_move()
        return True
    
    def _instinct_find_safety(self, game):
        """æœ¬èƒ½å¯»æ‰¾å®‰å…¨åœ°ç‚¹"""
        # å¯»æ‰¾æœ€è¿‘çš„å®‰å…¨åœ°å½¢
        best_safety_pos = None
        best_safety_score = -1
        
        for dx in range(-3, 4):
            for dy in range(-3, 4):
                new_x, new_y = self.x + dx, self.y + dy
                if game.game_map.is_within_bounds(new_x, new_y):
                    cell_type = game.game_map.grid[new_y][new_x]
                    safety_score = 0
                    
                    if cell_type in ["big_tree", "bush"]:
                        safety_score = 3
                    elif cell_type in ["river", "puddle"]:
                        safety_score = 2
                    elif cell_type == "grass":
                        safety_score = 1
                    
                    if safety_score > best_safety_score:
                        best_safety_score = safety_score
                        best_safety_pos = (new_x, new_y)
        
        if best_safety_pos:
            target_x, target_y = best_safety_pos
            dx = 1 if target_x > self.x else (-1 if target_x < self.x else 0)
            dy = 1 if target_y > self.y else (-1 if target_y < self.y else 0)
            
            if self.move(dx, dy, game.game_map):
                if logger:
                    logger.log(f"{self.name} æœ¬èƒ½å¯»æ‰¾å®‰å…¨åœ°ç‚¹")
                return True
        
        return False
    
    def _instinct_find_food(self, game):
        """æœ¬èƒ½å¯»æ‰¾é£Ÿç‰©"""
        # å¯»æ‰¾æœ€è¿‘çš„é£Ÿç‰©
        nearest_plant = None
        min_distance = float('inf')
        
        for plant in game.game_map.plants:
            if plant.alive and not plant.collected and not plant.toxic:
                distance = abs(plant.x - self.x) + abs(plant.y - self.y)
                if distance < min_distance:
                    min_distance = distance
                    nearest_plant = plant
        
        if nearest_plant:
            # ç›´æ¥æœé£Ÿç‰©ç§»åŠ¨
            dx = 1 if nearest_plant.x > self.x else (-1 if nearest_plant.x < self.x else 0)
            dy = 1 if nearest_plant.y > self.y else (-1 if nearest_plant.y < self.y else 0)
            
            if self.move(dx, dy, game.game_map):
                if logger:
                    logger.log(f"{self.name} æœ¬èƒ½å¯»æ‰¾é£Ÿç‰©")
                
                # å¦‚æœåˆ°è¾¾é£Ÿç‰©ä½ç½®ï¼Œç›´æ¥é‡‡é›†
                if self.x == nearest_plant.x and self.y == nearest_plant.y:
                    self.collect_plant(nearest_plant)
                return True
        
        return False
    
    def _instinct_find_water(self, game):
        """æœ¬èƒ½å¯»æ‰¾æ°´æº"""
        # å¯»æ‰¾æœ€è¿‘çš„æ°´æº
        nearest_water = None
        min_distance = float('inf')
        
        for y in range(game.game_map.height):
            for x in range(game.game_map.width):
                if game.game_map.grid[y][x] in ["river", "puddle"]:
                    distance = abs(x - self.x) + abs(y - self.y)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_water = (x, y)
        
        if nearest_water:
            target_x, target_y = nearest_water
            dx = 1 if target_x > self.x else (-1 if target_x < self.x else 0)
            dy = 1 if target_y > self.y else (-1 if target_y < self.y else 0)
            
            if self.move(dx, dy, game.game_map):
                if logger:
                    logger.log(f"{self.name} æœ¬èƒ½å¯»æ‰¾æ°´æº")
                return True
        
        return False
    
    def _calculate_escape_direction(self, threats, game_map):
        """è®¡ç®—æœ€ä¼˜é€ƒè·‘æ–¹å‘"""
        possible_moves = []
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == 0 and dy == 0:
                    continue
                new_x = self.x + dx
                new_y = self.y + dy
                if game_map.is_within_bounds(new_x, new_y):
                    safety_score = self._evaluate_position_safety(new_x, new_y, threats, game_map)
                    possible_moves.append((dx, dy, safety_score))
        
        if not possible_moves:
            return None
        
        # é€‰æ‹©å®‰å…¨åˆ†æ•°æœ€é«˜çš„ç§»åŠ¨æ–¹å‘
        best_move = max(possible_moves, key=lambda x: x[2])
        return (best_move[0], best_move[1])
    
    def _evaluate_position_safety(self, x, y, threats, game_map):
        """è¯„ä¼°ç‰¹å®šä½ç½®çš„å®‰å…¨ç¨‹åº¦"""
        safety_score = 100
        
        # è€ƒè™‘ä¸æ‰€æœ‰å¨èƒçš„è·ç¦»
        for threat in threats:
            dist = abs(x - threat.x) + abs(y - threat.y)
            if dist == 0:
                return 0  # ä¸å¨èƒé‡å ï¼Œå®Œå…¨ä¸å®‰å…¨
            threat_level = 100 / (dist + 1)  # è·ç¦»è¶Šè¿‘å¨èƒè¶Šå¤§
            safety_score -= threat_level
        
        # è€ƒè™‘åœ°å½¢å› ç´ 
        if game_map.grid[y][x] in ["big_tree", "bush"]:
            safety_score += 20  # æ ‘æœ¨å’ŒçŒæœ¨æä¾›æ©æŠ¤
        elif game_map.grid[y][x] in ["river", "puddle"]:
            safety_score += 10  # æ°´åŸŸæä¾›ä¸€å®šä¿æŠ¤
        
        # è€ƒè™‘æ˜¯å¦é è¿‘åœ°å›¾è¾¹ç¼˜(å¯èƒ½è¢«å›°)
        if x <= 1 or x >= game_map.width - 2 or y <= 1 or y >= game_map.height - 2:
            safety_score -= 30
        
        return max(0, safety_score)  # ç¡®ä¿å®‰å…¨åˆ†æ•°ä¸ä¸ºè´Ÿ

    def _analyze_current_state(self, game):
        """åˆ†æå½“å‰çŠ¶æ€,åˆ¤æ–­èµ„æºå……è¶³æ€§å’Œç´§æ€¥äº‹ä»¶"""
        try:
            # èµ„æºè¯„ä¼°
            health_ratio = self.health / 100.0
            food_ratio = self.food / 100.0  
            water_ratio = self.water / 100.0
            
            # å¨èƒæ£€"""
            threats = self.detect_threats(game.game_map)
            has_immediate_threats = len(threats) > 0
            
            # èµ„æºå……è¶³æ€§åˆ¤ä»(æ‰€æœ‰æŒ‡ä»> 60%)
            resources_sufficient = (health_ratio > 0.6 and 
                                  food_ratio > 0.6 and 
                                  water_ratio > 0.6)
            
            # ç´§æ€¥äº‹ä»¶åˆ¤"
            has_emergency = (health_ratio < 0.3 or 
                           food_ratio < 0.2 or 
                           water_ratio < 0.2 or 
                           has_immediate_threats)
            
            # çŠ¶æ€åˆ†"
            if resources_sufficient and not has_emergency:
                status = "å……è¶³å®‰å…¨"
            elif has_emergency:
                status = "ç´§æ€¥çŠ¶æ€"
            else:
                status = "èµ„æºä¸è¶³"
            
            return {
                'status': status,
                'resources_sufficient': resources_sufficient,
                'has_emergency': has_emergency,
                'health_ratio': health_ratio,
                'food_ratio': food_ratio, 
                'water_ratio': water_ratio,
                'threat_count': len(threats),
                'most_urgent_need': self._identify_most_urgent_need()
            }
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} çŠ¶æ€åˆ†æå¤±ä» {str(e)}")
            return {
                'status': "æœªçŸ¥",
                'resources_sufficient': False,
                'has_emergency': True,
                'health_ratio': 0.5,
                'food_ratio': 0.5,
                'water_ratio': 0.5,
                'threat_count': 0,
                'most_urgent_need': 'survival'
            }

    def _execute_cdl_exploration_cycle(self, game):
        """æ‰§è¡ŒCDLæ¢ç´¢å­¦ä¹ å¾ªç¯"""
        try:
            if not (self.cdl_active and hasattr(self, 'curiosity_driven_learning')):
                return None
            
            # æ„å»ºCDLä¸Šä¸‹"""
            from curiosity_driven_learning import ContextState
            
            # æ”¶é›†ç¯å¢ƒä¿¡æ¯
            nearby_entities = self._collect_nearby_entities(game)
            
            context_state = ContextState(
                symbolized_scene=nearby_entities,
                agent_internal_state={
                    'position': (self.x, self.y),
                    'health': self.health,
                    'food': self.food,
                    'water': self.water,
                    'phase': getattr(self, 'phase', 'exploration'),
                    'developmental_stage': getattr(self, 'developmental_stage', 0.3)
                },
                environmental_factors={
                    'terrain': game.game_map.grid[self.y][self.x],
                    'day': game.current_day,
                    'visited_positions_count': len(getattr(self, 'visited_positions', set()))
                },
                social_context={
                    'nearby_players': [p.name for p in game.players if p != self and abs(p.x - self.x) + abs(p.y - self.y) <= 3]
                },
                timestamp=game.current_day * 24.0
            )
            
            # CDLè¯„ä¼°å’Œå†³"
            cdl_response = self.curiosity_driven_learning.evaluate_novelty_and_curiosity(context_state)
            
            novelty_score = cdl_response.get('novelty_score', 0)
            curiosity_level = cdl_response.get('average_curiosity', 0)
            
            if logger:
                logger.log(f"{self.name} ğŸ§  CDLè¯„ä¼°: æ–°é¢–æ€§{novelty_score:.2f}, å¥½å¥‡å¿ƒ{curiosity_level:.2f}")
            
            # å†³å®šæ˜¯å¦æ‰§è¡ŒCDLæ¢ç´¢ (é™ä½é˜ˆ"
            if cdl_response.get('should_explore', False) or novelty_score > 0.5:
                suggested_action = cdl_response.get('suggested_action', 'explore')
                
                # æ‰§è¡ŒCDLå»ºè®®çš„è¡Œ"
                if suggested_action in ['explore', 'novelty_seeking']:
                    success = self._execute_cdl_exploration_move(game)
                elif suggested_action in ['collect_information', 'uncertainty_reduction']:
                    success = self._execute_cdl_info_gathering(game)
                else:
                    success = self._execute_cdl_exploration_move(game)
                
                if success:
                    # è®°å½•CDLç»éªŒ
                    self._record_cdl_experience(suggested_action, context_state, True)
                    return {'action_taken': suggested_action, 'success': True}
            
            return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} CDLæ¢ç´¢å¾ªç¯å¤±è´¥: {str(e)}")
            return None

    

    def _enhanced_cdl_exploration_with_tools(self, game):
        """å¢å¼ºCDLæ¢ç´¢ - å¢åŠ å·¥å…·ä½¿ç”¨å’Œäº’åŠ¨æ¦‚ç‡"""
        try:
            if not (self.cdl_active and hasattr(self, 'curiosity_driven_learning')):
                return None
            
            # æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
            from curiosity_driven_learning import ContextState
            nearby_entities = self._collect_nearby_entities(game)
            
            # å¥½å¥‡å¿ƒæƒé‡è°ƒèŠ‚ - å¯é€šè¿‡ä¿®æ”¹è¿™äº›å€¼æ¥å¹³è¡¡å†’é™©å’Œæ¢ç´¢
            curiosity_weights = {
                'tool_usage_curiosity': 0.95,      # å¤§å¹…æé«˜å·¥å…·ä½¿ç”¨å¥½å¥‡å¿ƒæƒé‡
                'animal_interaction_curiosity': 0.85,  # å¤§å¹…æé«˜åŠ¨ç‰©äº’åŠ¨å¥½å¥‡å¿ƒæƒé‡  
                'plant_interaction_curiosity': 0.8,   # å¤§å¹…æé«˜æ¤ç‰©äº’åŠ¨å¥½å¥‡å¿ƒæƒé‡
                'exploration_novelty_weight': 0.3,    # é™ä½çº¯æ¢ç´¢æƒé‡ï¼Œé¿å…è¿‡åº¦ç§»åŠ¨
                'repetition_penalty': 0.3             # é‡å¤è¡Œä¸ºæƒ©ç½šæƒé‡
            }
            
            context_state = ContextState(
                symbolized_scene=nearby_entities,
                agent_internal_state={
                    'position': (self.x, self.y),
                    'health': self.health,
                    'food': self.food,
                    'water': self.water,
                    'phase': getattr(self, 'phase', 'exploration'),
                    'curiosity_weights': curiosity_weights  # ä¼ é€’å¥½å¥‡å¿ƒæƒé‡
                },
                environmental_factors={
                    'terrain': game.game_map.grid[self.y][self.x],
                    'day': game.current_day,
                    'visited_positions_count': len(getattr(self, 'visited_positions', set())),
                    'nearby_tools_available': self._check_available_tools(),
                    'nearby_interaction_targets': self._count_interaction_targets(nearby_entities)
                },
                social_context={
                    'nearby_players': [p.name for p in game.players if p != self and abs(p.x - self.x) + abs(p.y - self.y) <= 3]
                },
                timestamp=game.current_day * 24.0
            )
            
            # CDLè¯„ä¼°withå¢å¼ºå¥½å¥‡å¿ƒ
            cdl_response = self.curiosity_driven_learning.evaluate_novelty_and_curiosity(context_state)
            
            novelty_score = cdl_response.get('novelty_score', 0)
            curiosity_level = cdl_response.get('average_curiosity', 0)
            
            # å¢å¼ºå†³ç­–é€»è¾‘
            enhanced_action = self._determine_enhanced_curious_action(
                nearby_entities, curiosity_weights, novelty_score
            )
            
            if enhanced_action:
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ§  å¢å¼ºCDLå†³ç­–: {enhanced_action} "
                                  f"(æ–°é¢–æ€§={novelty_score:.2f}, å¥½å¥‡å¿ƒ={curiosity_level:.2f})")
                
                success = self._execute_enhanced_action(enhanced_action, game)
                # è®°å½•CDLç»éªŒï¼ˆæˆåŠŸæˆ–å¤±è´¥éƒ½è¦è®°å½•ï¼‰
                try:
                    self._record_cdl_experience(enhanced_action, context_state, success)
                except:
                    # å¦‚æœ_record_cdl_experienceä¸å­˜åœ¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                    if hasattr(self, 'five_library_system'):
                        result_type = "success" if success else "failure"
                        self.add_experience_to_direct_library(enhanced_action, result_type, {"source": "enhanced_cdl"})
                
                # æˆåŠŸæˆ–å¤±è´¥éƒ½è¿”å›ç»“æœï¼Œè®©è°ƒç”¨è€…çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆ
                if self.logger:
                    status = "æˆåŠŸ" if success else "å¤±è´¥"
                    self.logger.log(f"{self.name} ğŸ§  å¢å¼ºCDLæ‰§è¡Œ{status}: {enhanced_action}")
                
                return {'action_taken': enhanced_action, 'success': success, 'source': 'enhanced_cdl'}
            else:
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ¤” å¢å¼ºCDLæœªæ‰¾åˆ°åˆé€‚è¡ŒåŠ¨ï¼Œå›é€€åˆ°æ ‡å‡†CDL")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è¡ŒåŠ¨ï¼Œè¿”å›Noneè®©æ—§ç‰ˆCDLæ¥ç®¡
            return None
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å¢å¼ºCDLæ¢ç´¢å¤±è´¥: {str(e)}")
            return None
    
    def _determine_enhanced_curious_action(self, nearby_entities, curiosity_weights, novelty_score):
        """ç¡®å®šå¢å¼ºå¥½å¥‡å¿ƒé©±åŠ¨çš„è¡ŒåŠ¨"""
        import random
        
        # æ£€æŸ¥æœ€è¿‘è¡ŒåŠ¨å†å²ï¼Œé¿å…é‡å¤
        recent_actions = getattr(self, '_recent_cdl_actions', [])
        
        # ä¼˜å…ˆçº§è¡ŒåŠ¨åˆ—è¡¨
        priority_actions = []
        
        # 1. å·¥å…·ä½¿ç”¨è¡ŒåŠ¨ (é«˜å¥½å¥‡å¿ƒæƒé‡)
        if random.random() < curiosity_weights['tool_usage_curiosity']:
            for entity in nearby_entities:
                if entity.get('distance', 999) <= 1:
                    if entity.get('type') in ['Strawberry', 'Mushroom']:
                        if 'collect_plant_with_tool' not in recent_actions[-5:]:
                            priority_actions.append('collect_plant_with_tool')
                    elif entity.get('type') in ['Rabbit', 'Boar']:
                        if 'attack_animal_with_tool' not in recent_actions[-3:]:
                            priority_actions.append('attack_animal_with_tool')
        
        # 2. åŠ¨ç‰©äº’åŠ¨è¡ŒåŠ¨
        if random.random() < curiosity_weights['animal_interaction_curiosity']:
            for entity in nearby_entities:
                if entity.get('distance', 999) <= 2 and entity.get('type') in ['Rabbit', 'Boar']:
                    if 'attack_animal_barehanded' not in recent_actions[-3:]:
                        priority_actions.append('attack_animal_barehanded')
        
        # 3. æ¤ç‰©äº’åŠ¨è¡ŒåŠ¨
        if random.random() < curiosity_weights['plant_interaction_curiosity']:
            for entity in nearby_entities:
                if entity.get('distance', 999) <= 1 and entity.get('type') in ['Strawberry', 'Mushroom']:
                    if 'collect_plant_barehanded' not in recent_actions[-4:]:
                        priority_actions.append('collect_plant_barehanded')
        
        # 4. æ¢ç´¢æ€§ç§»åŠ¨ (é™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦ç§»åŠ¨)
        if random.random() < curiosity_weights['exploration_novelty_weight'] and novelty_score > 0.7:
            if 'explore_move' not in recent_actions[-6:]:
                priority_actions.append('explore_move')
        
        # é€‰æ‹©è¡ŒåŠ¨å¹¶è®°å½•å†å²
        if priority_actions:
            chosen_action = random.choice(priority_actions)
            
            # æ›´æ–°è¡ŒåŠ¨å†å²
            if not hasattr(self, '_recent_cdl_actions'):
                self._recent_cdl_actions = []
            self._recent_cdl_actions.append(chosen_action)
            if len(self._recent_cdl_actions) > 10:
                self._recent_cdl_actions = self._recent_cdl_actions[-10:]
            
            return chosen_action
        
        return None
    
    def _check_available_tools(self):
        """æ£€æŸ¥å¯ç”¨å·¥å…·"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥æ£€æŸ¥ç©å®¶å·¥å…·åº“å­˜
        return ['hand', 'stick', 'stone']  # åŸºç¡€å·¥å…·
    
    def _count_interaction_targets(self, nearby_entities):
        """ç»Ÿè®¡é™„è¿‘å¯äº’åŠ¨ç›®æ ‡"""
        targets = {
            'plants': 0,
            'animals': 0,
            'water_sources': 0
        }
        
        for entity in nearby_entities:
            entity_type = entity.get('type', '')
            if entity_type in ['Strawberry', 'Mushroom']:
                targets['plants'] += 1
            elif entity_type in ['Rabbit', 'Boar', 'Tiger', 'BlackBear']:
                targets['animals'] += 1
            elif entity_type == 'water':
                targets['water_sources'] += 1
        
        return targets
    
    def _execute_enhanced_action(self, action, game):
        """æ‰§è¡Œå¢å¼ºè¡ŒåŠ¨"""
        try:
            if action == 'collect_plant_with_tool':
                return self._execute_tool_plant_collection(game)
            elif action == 'attack_animal_with_tool':
                return self._execute_tool_animal_attack(game)
            elif action == 'collect_plant_barehanded':
                return self._execute_barehanded_plant_collection(game)
            elif action == 'attack_animal_barehanded':
                return self._execute_barehanded_animal_attack(game)
            elif action == 'explore_move':
                return self._execute_cdl_exploration_move(game)
            else:
                return False
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} æ‰§è¡Œå¢å¼ºè¡ŒåŠ¨å¤±è´¥: {str(e)}")
            return False
    
    def _execute_tool_plant_collection(self, game):
        """ä½¿ç”¨å·¥å…·é‡‡é›†æ¤ç‰©"""
        nearby_plants = [p for p in game.game_map.plants 
                        if abs(p.x - self.x) <= 1 and abs(p.y - self.y) <= 1 and not p.collected]
        
        if nearby_plants:
            plant = nearby_plants[0]
            plant_type = plant.__class__.__name__
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨çœŸæ­£çš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ
            best_tool = None
            tool_name = "hand"  # é»˜è®¤å¾’æ‰‹
            
            if hasattr(self, 'get_best_tool_for_target'):
                # å°†æ¤ç‰©ç±»åè½¬æ¢ä¸ºå·¥å…·ç³»ç»Ÿè¯†åˆ«çš„ç±»å‹
                if plant_type in ['Strawberry', 'Mushroom']:
                    target_type = 'ground_plant'
                elif plant_type in ['Potato', 'SweetPotato']:
                    target_type = 'underground_plant'
                elif plant_type in ['Acorn', 'Chestnut']:
                    target_type = 'tree_fruits'
                else:
                    target_type = 'ground_plant'
                
                best_tool = self.get_best_tool_for_target(target_type)
                if best_tool:
                    tool_name = best_tool.name
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ CDLé€‰æ‹©å·¥å…·: {tool_name} é‡‡é›† {plant_type}")
            
            success = self.collect_plant(plant)
            
            if hasattr(self, '_record_tool_usage'):
                # åˆ›å»ºå·¥å…·å¯¹è±¡ç”¨äºè®°å½•
                if best_tool:
                    tool_for_record = best_tool
                else:
                    class SimpleTool:
                        def __init__(self, name):
                            self.name = name
                    tool_for_record = SimpleTool(tool_name)
                
                self._record_tool_usage(tool_for_record, plant_type, success, 5 if success else 0)
            
            if self.logger:
                self.logger.log(f"{self.name} ğŸ”§ CDLå·¥å…·é‡‡é›†: {plant_type} ä½¿ç”¨ {tool_name} {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            return success
        return False
    
    def _execute_tool_animal_attack(self, game):
        """ä½¿ç”¨å·¥å…·æ”»å‡»åŠ¨ç‰©"""
        nearby_animals = [a for a in game.game_map.animals 
                         if abs(a.x - self.x) <= 2 and abs(a.y - self.y) <= 2 and a.alive 
                         and a.__class__.__name__ in ['Rabbit', 'Boar']]
        
        if nearby_animals:
            animal = nearby_animals[0]
            animal_type = animal.__class__.__name__
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿è®°å½•é­é‡
            if not hasattr(self, '_recorded_encounters'):
                self._recorded_encounters = set()
            
            encounter_key = f"{animal.x}_{animal.y}_{animal.__class__.__name__}_{id(animal)}"
            if encounter_key not in self._recorded_encounters:
                self.encounter_animal(animal, game)
                self._recorded_encounters.add(encounter_key)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨çœŸæ­£çš„å·¥å…·é€‰æ‹©ç³»ç»Ÿ
            best_tool = None
            tool_name = "hand"  # é»˜è®¤å¾’æ‰‹
            
            if hasattr(self, 'get_best_tool_for_target'):
                # å°†åŠ¨ç‰©ç±»åè½¬æ¢ä¸ºå·¥å…·ç³»ç»Ÿè¯†åˆ«çš„ç±»å‹
                if animal_type in ['Rabbit', 'Boar']:
                    target_type = 'prey'
                elif animal_type in ['Tiger', 'BlackBear']:
                    target_type = 'predator'
                else:
                    target_type = 'prey'
                
                best_tool = self.get_best_tool_for_target(target_type)
                if best_tool:
                    tool_name = best_tool.name
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ CDLé€‰æ‹©å·¥å…·: {tool_name} æ”»å‡» {animal_type}")
            
            damage = self.attack(animal)
            success = damage > 0
            
            if hasattr(self, '_record_tool_usage'):
                # åˆ›å»ºå·¥å…·å¯¹è±¡ç”¨äºè®°å½•
                if best_tool:
                    tool_for_record = best_tool
                else:
                    class SimpleTool:
                        def __init__(self, name):
                            self.name = name
                    tool_for_record = SimpleTool(tool_name)
                
                self._record_tool_usage(tool_for_record, animal_type, success, damage)
            
            if self.logger:
                self.logger.log(f"{self.name} ğŸ”§ CDLå·¥å…·æ”»å‡»: {animal_type} ä½¿ç”¨ {tool_name} "
                              f"{'æˆåŠŸ' if success else 'å¤±è´¥'} ä¼¤å®³={damage}")
            return success
        return False
    
    def _execute_barehanded_plant_collection(self, game):
        """å¾’æ‰‹é‡‡é›†æ¤ç‰©"""
        nearby_plants = [p for p in game.game_map.plants 
                        if abs(p.x - self.x) <= 1 and abs(p.y - self.y) <= 1 and not p.collected and not p.toxic]
        
        if nearby_plants:
            plant = nearby_plants[0]
            success = self.collect_plant(plant)
            plant_type = plant.__class__.__name__
            if self.logger:
                self.logger.log(f"{self.name} âœ‹ CDLå¾’æ‰‹é‡‡é›†: {plant_type} {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            return success
        return False
    
    def _execute_barehanded_animal_attack(self, game):
        """å¾’æ‰‹æ”»å‡»åŠ¨ç‰©"""
        nearby_animals = [a for a in game.game_map.animals 
                         if abs(a.x - self.x) <= 1 and abs(a.y - self.y) <= 1 and a.alive 
                         and a.__class__.__name__ in ['Rabbit', 'Boar']]
        
        if nearby_animals:
            animal = nearby_animals[0]
            animal_type = animal.__class__.__name__
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿è®°å½•é­é‡
            if not hasattr(self, '_recorded_encounters'):
                self._recorded_encounters = set()
            
            encounter_key = f"{animal.x}_{animal.y}_{animal.__class__.__name__}_{id(animal)}"
            if encounter_key not in self._recorded_encounters:
                self.encounter_animal(animal, game)
                self._recorded_encounters.add(encounter_key)
            
            damage = self.attack(animal)
            success = damage > 0
            if self.logger:
                self.logger.log(f"{self.name} âœ‹ CDLå¾’æ‰‹æ”»å‡»: {animal_type} {'æˆåŠŸ' if success else 'å¤±è´¥'} ä¼¤å®³={damage}")
            return success
        return False

    def _collaborative_goal_determination(self, game, decision_stage, current_state):
        """ğŸ”§ ç¬¬2æ­¥ä¿®å¤ï¼šä¸‰é˜¶æ®µååŒç›®æ ‡ç¡®å®šæœºåˆ¶"""
        try:
            stage = decision_stage['stage']
            
            if stage == 'instinct':
                # æœ¬èƒ½é˜¶æ®µï¼šä¸ç”Ÿå­˜æœ¬èƒ½ååŒ
                return self._instinct_goal_determination(decision_stage, current_state)
            elif stage == 'dmha':
                # DMHAé˜¶æ®µï¼šä¸æ³¨æ„åŠ›æœºåˆ¶ååŒ
                return self._dmha_goal_determination(game, current_state)
            elif stage == 'cdl':
                # CDLé˜¶æ®µï¼šä¸å¥½å¥‡å¿ƒæœºåˆ¶ååŒ
                return self._cdl_goal_determination(game, current_state)
            else:
                # é»˜è®¤ä½¿ç”¨DMHA
                return self._dmha_goal_determination(game, current_state)
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ååŒç›®æ ‡ç¡®å®šå¤±è´¥: {str(e)}")
            return {
                'type': 'survival',
                'urgency': 0.7,
                'context': current_state,
                'source': 'fallback'
            }
    
    def _instinct_goal_determination(self, decision_stage, current_state):
        """æœ¬èƒ½é˜¶æ®µç›®æ ‡ç¡®å®šï¼šä¸ç”Ÿå­˜æœ¬èƒ½ååŒ"""
        trigger_type = decision_stage.get('trigger_type', 'unknown')
        
        # åŸºäºè§¦å‘ç±»å‹ç¡®å®šç´§æ€¥ç›®æ ‡
        if trigger_type == 'threat_nearby':
            return {
                'type': 'threat_avoidance',
                'urgency': 1.0,
                'context': current_state,
                'source': 'instinct',
                'description': f"å¨èƒè§„é¿ (è·ç¦»â‰¤3)"
            }
        elif trigger_type == 'low_health':
            return {
                'type': 'health_recovery',
                'urgency': 0.95,
                'context': current_state,
                'source': 'instinct',
                'description': f"ç´§æ€¥æ²»ç–— (è¡€é‡â‰¤20)"
            }
        elif trigger_type == 'low_water':
            return {
                'type': 'water_acquisition',
                'urgency': 0.9,
                'context': current_state,
                'source': 'instinct',
                'description': f"ç´§æ€¥å¯»æ°´ (æ°´åˆ†â‰¤20)"
            }
        elif trigger_type == 'low_food':
            return {
                'type': 'food_acquisition',
                'urgency': 0.85,
                'context': current_state,
                'source': 'instinct',
                'description': f"ç´§æ€¥è§…é£Ÿ (é£Ÿç‰©â‰¤20)"
            }
        else:
            return {
                'type': 'survival',
                'urgency': 0.8,
                'context': current_state,
                'source': 'instinct',
                'description': "ç»¼åˆç”Ÿå­˜å¨èƒ"
            }
    
    def _dmha_goal_determination(self, game, current_state):
        """DMHAé˜¶æ®µç›®æ ‡ç¡®å®šï¼šä¸æ³¨æ„åŠ›æœºåˆ¶ååŒ"""
        try:
            # æ„å»ºæ³¨æ„åŠ›ä¸Šä¸‹æ–‡
            attention_context = self._build_attention_context(game)
            
            # DMHAå¤„ç†è·å–æ³¨æ„åŠ›ç„¦ç‚¹
            if hasattr(self, 'dmha') and self.dmha:
                attention_output = self.dmha.process_attention(attention_context)
                dominant_focus = attention_output.get('dominant_focus', 'resource')
                attention_score = attention_output.get('attention_score', 0.5)
            else:
                dominant_focus = 'resource'
                attention_score = 0.5
            
            # åŸºäºæ³¨æ„åŠ›ç„¦ç‚¹ç¡®å®šç›®æ ‡
            if dominant_focus == 'resource':
                # èµ„æºç®¡ç†ç›®æ ‡
                if self.water < 35:
                    goal_type = 'water_acquisition'
                    urgency = 0.7
                    description = "èµ„æºç®¡ç†-æ°´æºè·å–"
                elif self.food < 35:
                    goal_type = 'food_acquisition'
                    urgency = 0.65
                    description = "èµ„æºç®¡ç†-é£Ÿç‰©è·å–"
                else:
                    goal_type = 'resource_optimization'
                    urgency = 0.5
                    description = "èµ„æºä¼˜åŒ–é…ç½®"
            elif dominant_focus == 'exploration':
                goal_type = 'environment_exploration'
                urgency = 0.4
                description = "ç¯å¢ƒæ¢ç´¢"
            elif dominant_focus == 'social':
                goal_type = 'social_interaction'
                urgency = 0.3
                description = "ç¤¾äº¤äº’åŠ¨"
            else:
                goal_type = 'resource_acquisition'
                urgency = 0.6
                description = "é»˜è®¤èµ„æºè·å–"
            
            return {
                'type': goal_type,
                'urgency': urgency,
                'context': current_state,
                'source': 'dmha',
                'dmha_focus': dominant_focus,
                'attention_score': attention_score,
                'description': description
            }
            
        except Exception as e:
            return {
                'type': 'resource_acquisition',
                'urgency': 0.6,
                'context': current_state,
                'source': 'dmha_fallback',
                'description': "DMHAå¼‚å¸¸å…œåº•"
            }
    
    def _cdl_goal_determination(self, game, current_state):
        """CDLé˜¶æ®µç›®æ ‡ç¡®å®šï¼šç›´æ¥ç”ŸæˆEOCATRæ¢ç´¢ç›®æ ‡"""
        try:
            # ğŸ¯ ç®€åŒ–CDLï¼šç›´æ¥å¯»æ‰¾æœ€æ–°å¥‡çš„EOCATRç›®æ ‡
            novelty_targets = self._find_novel_eocatr_targets(game)
            
            if novelty_targets:
                # é€‰æ‹©æ–°å¥‡åº¦æœ€é«˜çš„ç›®æ ‡
                best_target = max(novelty_targets, key=lambda x: x['novelty_score'])
                
                eocatr_goal = {
                    'environment': best_target['environment'],
                    'object': best_target['object'],
                    'characteristics': best_target.get('characteristics', ['unknown']),
                    'action': best_target['action'],
                    'tool': best_target.get('tool', None),
                    'expected_result': best_target['expected_result']
                }
                
                description = f"CDLæ¢ç´¢: {best_target['action']} {best_target['object']} (æ–°å¥‡åº¦:{best_target['novelty_score']:.2f})"
                
                cdl_goal = {
                    'type': 'cdl_exploration',  # æ–°çš„ç»Ÿä¸€ç±»å‹
                    'urgency': min(0.8, 0.3 + best_target['novelty_score'] * 0.5),  # åŸºäºæ–°å¥‡åº¦åŠ¨æ€è®¡ç®—ç´§æ€¥åº¦
                    'context': current_state,
                    'source': 'cdl_direct',
                    'novelty_score': best_target['novelty_score'],
                    'description': description,
                    'eocatr_goal': eocatr_goal  # ç›´æ¥åŒ…å«EOCATRç›®æ ‡
                }
                
                # ä¼ é€’ç»™WBMç³»ç»Ÿ
                self._pending_cdl_goal = cdl_goal
                
                if logger:
                    logger.log(f"{self.name} CDLç›´æ¥ç›®æ ‡: {best_target['action']} â†’ {best_target['object']} (æ–°å¥‡åº¦:{best_target['novelty_score']:.2f})")
                
                return cdl_goal
            else:
                # æ²¡æœ‰æ–°å¥‡ç›®æ ‡æ—¶ï¼Œé»˜è®¤éšæœºæ¢ç´¢
                default_eocatr = self._get_default_exploration_eocatr(game)
                
                cdl_goal = {
                    'type': 'cdl_exploration',
                    'urgency': 0.3,
                    'context': current_state,
                    'source': 'cdl_default',
                    'novelty_score': 0.1,
                    'description': "CDLé»˜è®¤æ¢ç´¢",
                    'eocatr_goal': default_eocatr
                }
                
                self._pending_cdl_goal = cdl_goal
                
                if logger:
                    logger.log(f"{self.name} CDLé»˜è®¤æ¢ç´¢: {default_eocatr['action']} â†’ {default_eocatr['object']}")
                
                return cdl_goal
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} CDLç›®æ ‡ç¡®å®šå¤±è´¥: {str(e)}")
            return {
                'type': 'cdl_exploration',
                'urgency': 0.3,
                'context': current_state,
                'source': 'cdl_fallback',
                'description': "CDLå¼‚å¸¸å…œåº•"
            }

    def _find_high_priority_exploration_targets(self, game):
        """ğŸ¯ æ–°å¢ï¼šå¯»æ‰¾é«˜ä¼˜å…ˆçº§æ¢ç´¢ç›®æ ‡ï¼ˆç”Ÿç‰©å¤šæ ·æ€§å’Œå·¥å…·æ•ˆèƒ½æµ‹è¯•ï¼‰"""
        try:
            high_priority_targets = []
            
            # ğŸ¦‹ 1. ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢ - æœ€é«˜ä¼˜å…ˆçº§
            biodiversity_targets = self._find_biodiversity_targets(game)
            high_priority_targets.extend(biodiversity_targets)
            
            # ğŸ”§ 2. å·¥å…·æ•ˆèƒ½æµ‹è¯• - é«˜ä¼˜å…ˆçº§  
            tool_efficiency_targets = self._find_tool_efficiency_targets(game)
            high_priority_targets.extend(tool_efficiency_targets)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            high_priority_targets.sort(key=lambda x: x['priority_score'], reverse=True)
            
            if logger and high_priority_targets:
                logger.log(f"{self.name} ğŸ¯ å‘ç°{len(high_priority_targets)}ä¸ªé«˜ä¼˜å…ˆçº§ç›®æ ‡ï¼Œæœ€é«˜ä¼˜å…ˆçº§: {high_priority_targets[0]['priority_score']:.2f}")
            
            return high_priority_targets[:5]  # è¿”å›å‰5ä¸ªæœ€é«˜ä¼˜å…ˆçº§ç›®æ ‡
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾é«˜ä¼˜å…ˆçº§ç›®æ ‡å¤±è´¥: {str(e)}")
            return []

    def _find_biodiversity_targets(self, game):
        """ğŸ¦‹ å¯»æ‰¾ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢ç›®æ ‡"""
        try:
            biodiversity_targets = []
            
            # æ£€æµ‹è§†é‡ä¸­çš„åŠ¨æ¤ç‰©
            nearby_entities = self._collect_nearby_entities(game, max_distance=3)
            
            # è·å–å·²æ¢ç´¢çš„ç”Ÿç‰©ç§ç±»
            if not hasattr(self, 'explored_species'):
                self.explored_species = set()
            
            for entity in nearby_entities:
                entity_type = entity.get('type', 'unknown')
                distance = entity.get('distance', 999)
                
                # åŠ¨ç‰©æ¢ç´¢ - è¶…é«˜ä¼˜å…ˆçº§
                if entity_type in ['Rabbit', 'Boar', 'Tiger', 'BlackBear'] and distance <= 2:
                    species_key = f"{entity_type}_{entity.get('x', 0)}_{entity.get('y', 0)}"
                    
                    if species_key not in self.explored_species:
                        # æ ¹æ®åŠ¨ç‰©ç±»å‹ç¡®å®šæ¢ç´¢æ–¹å¼å’Œå·¥å…·
                        if entity_type in ['Rabbit', 'Boar']:
                            action = 'hunt_with_tool'
                            tools = ['é•¿çŸ›', 'å¼“ç®­', 'çŸ³å¤´']
                            priority = 0.95  # çŒç‰©æœ€é«˜ä¼˜å…ˆçº§
                        else:  # Tiger, BlackBear
                            action = 'observe_safely'
                            tools = []
                            priority = 0.85  # å±é™©åŠ¨ç‰©è§‚å¯Ÿä¼˜å…ˆçº§
                        
                        biodiversity_targets.append({
                            'type': 'biodiversity_exploration',
                            'environment': f"{game.game_map.grid[entity.get('y', 0)][entity.get('x', 0)]}",
                            'object': entity_type.lower(),
                            'characteristics': ['animal', 'species_' + entity_type.lower()],
                            'action': action,
                            'tool': tools[0] if tools else None,
                            'expected_result': f'learn_species_{entity_type.lower()}',
                            'priority_score': priority,
                            'target_position': (entity.get('x', 0), entity.get('y', 0)),
                            'species_key': species_key
                        })
                
                # æ¤ç‰©æ¢ç´¢ - é«˜ä¼˜å…ˆçº§
                elif entity_type in ['Strawberry', 'Mushroom', 'Tree'] and distance <= 1:
                    species_key = f"{entity_type}_{entity.get('x', 0)}_{entity.get('y', 0)}"
                    
                    if species_key not in self.explored_species:
                        if entity_type in ['Strawberry', 'Mushroom']:
                            action = 'gather_with_tool'
                            tools = ['ç¯®å­', 'é“é”¹']
                            priority = 0.80
                        else:  # Tree
                            action = 'examine_resource'
                            tools = ['é“é”¹', 'æ£å­']
                            priority = 0.75
                        
                        biodiversity_targets.append({
                            'type': 'biodiversity_exploration',
                            'environment': f"{game.game_map.grid[entity.get('y', 0)][entity.get('x', 0)]}",
                            'object': entity_type.lower(),
                            'characteristics': ['plant', 'species_' + entity_type.lower()],
                            'action': action,
                            'tool': tools[0] if tools else None,
                            'expected_result': f'learn_species_{entity_type.lower()}',
                            'priority_score': priority,
                            'target_position': (entity.get('x', 0), entity.get('y', 0)),
                            'species_key': species_key
                        })
            
            return biodiversity_targets
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾ç”Ÿç‰©å¤šæ ·æ€§ç›®æ ‡å¤±è´¥: {str(e)}")
            return []

    def _find_tool_efficiency_targets(self, game):
        """ğŸ”§ å¯»æ‰¾å·¥å…·æ•ˆèƒ½æµ‹è¯•ç›®æ ‡"""
        try:
            tool_efficiency_targets = []
            
            # è·å–AIçš„å·¥å…·è£…å¤‡
            available_tools = getattr(self, 'tools', [])
            if not available_tools:
                return []
            
            # è·å–å·²æµ‹è¯•çš„å·¥å…·ç»„åˆ
            if not hasattr(self, 'tested_tool_combinations'):
                self.tested_tool_combinations = set()
            
            # æ£€æµ‹è§†é‡ä¸­å¯ä»¥æµ‹è¯•å·¥å…·çš„ç›®æ ‡
            nearby_entities = self._collect_nearby_entities(game, max_distance=2)
            
            for tool in available_tools:
                tool_name = getattr(tool, 'name', str(tool))
                
                # æµ‹è¯•å·¥å…·å¯¹ä¸åŒç›®æ ‡çš„æ•ˆèƒ½
                for entity in nearby_entities:
                    entity_type = entity.get('type', 'unknown')
                    combo_key = f"{tool_name}_{entity_type}"
                    
                    if combo_key not in self.tested_tool_combinations:
                        # åŠ¨ç‰©å·¥å…·æµ‹è¯•
                        if entity_type in ['Rabbit', 'Boar', 'Tiger', 'BlackBear']:
                            # æ ¹æ®å·¥å…·ç±»å‹ç¡®å®šæµ‹è¯•æ–¹å¼
                            if tool_name in ['é•¿çŸ›', 'å¼“ç®­']:
                                action = 'test_hunting_tool'
                                priority = 0.90
                            elif tool_name in ['çŸ³å¤´']:
                                action = 'test_ranged_tool'
                                priority = 0.85
                            else:
                                continue  # ä¸é€‚åˆçš„å·¥å…·è·³è¿‡
                            
                            tool_efficiency_targets.append({
                                'type': 'tool_efficiency_testing',
                                'environment': f"{game.game_map.grid[entity.get('y', 0)][entity.get('x', 0)]}",
                                'object': entity_type.lower(),
                                'characteristics': ['target', 'tool_test'],
                                'action': action,
                                'tool': tool_name,
                                'expected_result': f'test_{tool_name}_on_{entity_type.lower()}',
                                'priority_score': priority,
                                'target_position': (entity.get('x', 0), entity.get('y', 0)),
                                'combo_key': combo_key
                            })
                        
                        # æ¤ç‰©å·¥å…·æµ‹è¯•
                        elif entity_type in ['Strawberry', 'Mushroom', 'Tree']:
                            if tool_name in ['ç¯®å­', 'é“é”¹']:
                                action = 'test_gathering_tool'
                                priority = 0.75
                            elif tool_name in ['æ£å­']:
                                action = 'test_utility_tool'
                                priority = 0.70
                            else:
                                continue
                            
                            tool_efficiency_targets.append({
                                'type': 'tool_efficiency_testing',
                                'environment': f"{game.game_map.grid[entity.get('y', 0)][entity.get('x', 0)]}",
                                'object': entity_type.lower(),
                                'characteristics': ['resource', 'tool_test'],
                                'action': action,
                                'tool': tool_name,
                                'expected_result': f'test_{tool_name}_on_{entity_type.lower()}',
                                'priority_score': priority,
                                'target_position': (entity.get('x', 0), entity.get('y', 0)),
                                'combo_key': combo_key
                            })
            
            return tool_efficiency_targets
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾å·¥å…·æ•ˆèƒ½ç›®æ ‡å¤±è´¥: {str(e)}")
            return []

    def _find_novel_eocatr_targets(self, game):
        """ğŸ¯ CDLç®€åŒ–æ ¸å¿ƒï¼šå¯»æ‰¾æ–°å¥‡çš„EOCATRæ¢ç´¢ç›®æ ‡"""
        try:
            novelty_targets = []
            
            # ğŸ” 1. å¯»æ‰¾æœªæ¢ç´¢çš„ä½ç½®
            unexplored_locations = self._find_unexplored_locations(game)
            for location in unexplored_locations:
                novelty_targets.append({
                    'environment': location,
                    'object': 'area',
                    'action': 'move',
                    'expected_result': 'explore_new_area',
                    'novelty_score': 0.8  # æ–°ä½ç½®é«˜æ–°å¥‡åº¦
                })
            
            # ğŸŒ± 2. å¯»æ‰¾æœªäº¤äº’çš„åŠ¨æ¤ç‰©
            novel_creatures = self._find_novel_creatures(game)
            for creature in novel_creatures:
                novelty_targets.append({
                    'environment': 'current_area',
                    'object': creature['name'],
                    'characteristics': creature.get('characteristics', ['unknown']),
                    'action': 'interact',
                    'expected_result': 'learn_about_creature',
                    'novelty_score': 0.7  # æ–°ç”Ÿç‰©ä¸­ç­‰æ–°å¥‡åº¦
                })
            
            # ğŸ”§ 3. å¯»æ‰¾æœªä½¿ç”¨çš„å·¥å…·
            novel_tools = self._find_novel_tools(game)
            for tool in novel_tools:
                novelty_targets.append({
                    'environment': 'current_area',
                    'object': tool['target_object'],
                    'action': 'use',
                    'tool': tool['name'],
                    'expected_result': tool['expected_result'],
                    'novelty_score': 0.6  # æ–°å·¥å…·ä¸­ç­‰æ–°å¥‡åº¦
                })
            
            # ğŸ¯ 4. å¯»æ‰¾æœªå°è¯•çš„è¡Œä¸ºç»„åˆ
            novel_actions = self._find_novel_actions(game)
            for action_combo in novel_actions:
                novelty_targets.append({
                    'environment': action_combo['environment'],
                    'object': action_combo['object'],
                    'action': action_combo['action'],
                    'tool': action_combo.get('tool', None),
                    'expected_result': action_combo['expected_result'],
                    'novelty_score': 0.5  # æ–°è¡Œä¸ºç»„åˆä½æ–°å¥‡åº¦
                })
            
            # æŒ‰æ–°å¥‡åº¦æ’åº
            novelty_targets.sort(key=lambda x: x['novelty_score'], reverse=True)
            
            if logger and novelty_targets:
                logger.log(f"{self.name} å‘ç°{len(novelty_targets)}ä¸ªæ–°å¥‡ç›®æ ‡ï¼Œæœ€é«˜æ–°å¥‡åº¦: {novelty_targets[0]['novelty_score']:.2f}")
            
            return novelty_targets[:10]  # è¿”å›å‰10ä¸ªæœ€æ–°å¥‡çš„ç›®æ ‡
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾æ–°å¥‡ç›®æ ‡å¤±è´¥: {str(e)}")
            return []

    def _get_default_exploration_eocatr(self, game):
        """è·å–é»˜è®¤çš„æ¢ç´¢EOCATRç›®æ ‡"""
        try:
            # ç®€å•çš„é»˜è®¤æ¢ç´¢è¡Œä¸º
            default_actions = [
                {
                    'environment': 'current_area',
                    'object': 'surroundings',
                    'action': 'observe',
                    'expected_result': 'gather_information'
                },
                {
                    'environment': 'nearby_area',
                    'object': 'area',
                    'action': 'move',
                    'expected_result': 'explore_vicinity'
                },
                {
                    'environment': 'current_area',
                    'object': 'ground',
                    'action': 'search',
                    'expected_result': 'find_resources'
                }
            ]
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªé»˜è®¤è¡Œä¸º
            import random
            return random.choice(default_actions)
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è·å–é»˜è®¤æ¢ç´¢ç›®æ ‡å¤±è´¥: {str(e)}")
            return {
                'environment': 'current_area',
                'object': 'surroundings',
                'action': 'observe',
                'expected_result': 'basic_exploration'
            }

    def _find_unexplored_locations(self, game):
        """å¯»æ‰¾æœªæ¢ç´¢çš„ä½ç½®"""
        try:
            if not hasattr(self, 'visited_positions'):
                self.visited_positions = set()
            
            unexplored = []
            current_x, current_y = self.x, self.y
            
            # æ£€æŸ¥å‘¨å›´8ä¸ªæ–¹å‘çš„ä½ç½®
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx == 0 and dy == 0:  # è·³è¿‡å½“å‰ä½ç½®
                        continue
                    
                    new_x, new_y = current_x + dx, current_y + dy
                    
                    # æ£€æŸ¥è¾¹ç•Œ
                    if (0 <= new_x < len(game.game_map.grid[0]) and 
                        0 <= new_y < len(game.game_map.grid)):
                        
                        pos = (new_x, new_y)
                        if pos not in self.visited_positions:
                            terrain = game.game_map.grid[new_y][new_x]
                            unexplored.append(f"{terrain}_at_{new_x}_{new_y}")
            
            return unexplored[:3]  # è¿”å›æœ€å¤š3ä¸ªæœªæ¢ç´¢ä½ç½®
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾æœªæ¢ç´¢ä½ç½®å¤±è´¥: {str(e)}")
            return []

    def _find_novel_creatures(self, game):
        """å¯»æ‰¾æœªäº¤äº’çš„åŠ¨æ¤ç‰©"""
        try:
            if not hasattr(self, 'interacted_creatures'):
                self.interacted_creatures = set()
            
            novel_creatures = []
            nearby_entities = self._collect_nearby_entities(game)
            
            for entity in nearby_entities:
                creature_id = f"{entity['type']}_{entity.get('x', 0)}_{entity.get('y', 0)}"
                
                if creature_id not in self.interacted_creatures:
                    if entity['type'] in ['Rabbit', 'Boar', 'Strawberry', 'Mushroom', 'Tree']:
                        novel_creatures.append({
                            'name': entity['type'].lower(),
                            'characteristics': self._get_creature_characteristics(entity['type']),
                            'id': creature_id
                        })
            
            return novel_creatures[:3]  # è¿”å›æœ€å¤š3ä¸ªæ–°ç”Ÿç‰©
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾æ–°ç”Ÿç‰©å¤±è´¥: {str(e)}")
            return []

    def _find_novel_tools(self, game):
        """å¯»æ‰¾æœªä½¿ç”¨çš„å·¥å…·"""
        try:
            if not hasattr(self, 'used_tools'):
                self.used_tools = set()
            
            novel_tools = []
            available_tools = ['stone', 'stick', 'berry', 'water']  # ç®€åŒ–çš„å·¥å…·åˆ—è¡¨
            
            for tool in available_tools:
                if tool not in self.used_tools:
                    target_object, expected_result = self._get_tool_usage(tool)
                    if target_object:
                        novel_tools.append({
                            'name': tool,
                            'target_object': target_object,
                            'expected_result': expected_result
                        })
            
            return novel_tools[:2]  # è¿”å›æœ€å¤š2ä¸ªæ–°å·¥å…·
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾æ–°å·¥å…·å¤±è´¥: {str(e)}")
            return []

    def _find_novel_actions(self, game):
        """å¯»æ‰¾æœªå°è¯•çš„è¡Œä¸ºç»„åˆ"""
        try:
            if not hasattr(self, 'tried_actions'):
                self.tried_actions = set()
            
            novel_actions = []
            basic_actions = ['observe', 'search', 'move', 'gather']
            objects = ['ground', 'trees', 'water', 'rocks']
            
            for action in basic_actions:
                for obj in objects:
                    action_combo = f"{action}_{obj}"
                    if action_combo not in self.tried_actions:
                        novel_actions.append({
                            'environment': 'current_area',
                            'object': obj,
                            'action': action,
                            'expected_result': f"{action}_result_from_{obj}"
                        })
            
            return novel_actions[:3]  # è¿”å›æœ€å¤š3ä¸ªæ–°è¡Œä¸ºç»„åˆ
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å¯»æ‰¾æ–°è¡Œä¸ºå¤±è´¥: {str(e)}")
            return []

    def _get_creature_characteristics(self, creature_type):
        """è·å–ç”Ÿç‰©ç‰¹å¾"""
        characteristics_map = {
            'Rabbit': ['small', 'fast', 'edible'],
            'Boar': ['large', 'dangerous', 'edible'],
            'Strawberry': ['plant', 'edible', 'sweet'],
            'Mushroom': ['plant', 'edible', 'nutritious'],
            'Tree': ['large', 'resource', 'shelter']
        }
        return characteristics_map.get(creature_type, ['unknown'])

    def _get_tool_usage(self, tool):
        """è·å–å·¥å…·ç”¨é€”"""
        usage_map = {
            'stone': ('rabbit', 'hunting_success'),
            'stick': ('ground', 'digging_result'),
            'berry': ('self', 'nutrition_gain'),
            'water': ('self', 'hydration_gain')
        }
        return usage_map.get(tool, (None, None))

    def _record_attempted_action(self, eocatr_goal):
        """è®°å½•å°è¯•çš„è¡Œä¸ºï¼Œç”¨äºæ–°å¥‡åº¦è·Ÿè¸ª"""
        try:
            # åˆå§‹åŒ–è·Ÿè¸ªé›†åˆ
            if not hasattr(self, 'visited_positions'):
                self.visited_positions = set()
            if not hasattr(self, 'interacted_creatures'):
                self.interacted_creatures = set()
            if not hasattr(self, 'used_tools'):
                self.used_tools = set()
            if not hasattr(self, 'tried_actions'):
                self.tried_actions = set()
            if not hasattr(self, 'explored_species'):
                self.explored_species = set()
            if not hasattr(self, 'tested_tool_combinations'):
                self.tested_tool_combinations = set()
            
            action = eocatr_goal.get('action', '')
            obj = eocatr_goal.get('object', '')
            tool = eocatr_goal.get('tool', None)
            
            # è®°å½•ä½ç½®æ¢ç´¢
            if action == 'move':
                self.visited_positions.add((self.x, self.y))
            
            # è®°å½•ç”Ÿç‰©äº¤äº’
            if action == 'interact' and obj:
                creature_id = f"{obj}_{self.x}_{self.y}"
                self.interacted_creatures.add(creature_id)
            
            # ğŸ¦‹ æ–°å¢ï¼šè®°å½•ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢
            if hasattr(eocatr_goal, 'species_key'):
                self.explored_species.add(eocatr_goal['species_key'])
            
            # ğŸ”§ æ–°å¢ï¼šè®°å½•å·¥å…·æ•ˆèƒ½æµ‹è¯•
            if hasattr(eocatr_goal, 'combo_key'):
                self.tested_tool_combinations.add(eocatr_goal['combo_key'])
            
            # è®°å½•å·¥å…·ä½¿ç”¨
            if tool:
                self.used_tools.add(tool)
            
            # è®°å½•è¡Œä¸ºç»„åˆ
            if action and obj:
                action_combo = f"{action}_{obj}"
                self.tried_actions.add(action_combo)
                
            if logger:
                logger.log(f"{self.name} ğŸ·ï¸ è®°å½•å°è¯•: {action} {obj} {f'with {tool}' if tool else ''}")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®°å½•è¡Œä¸ºå¤±è´¥: {str(e)}")

    def _convert_abstract_goal_to_eocatr(self, abstract_goal, game):
        """ç›®æ ‡è½¬æ¢å™¨ï¼šå°†CDLæŠ½è±¡ç›®æ ‡è½¬æ¢ä¸ºWBMå¯ç†è§£çš„EOCATRæ ¼å¼"""
        try:
            goal_type = abstract_goal.get('type', 'survival')
            current_terrain = game.game_map.grid[self.y][self.x]
            nearby_entities = self._collect_nearby_entities(game)
            
            # æ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯
            context = {
                'food_level': self.food,
                'water_level': self.water,
                'health_level': self.health,
                'terrain': current_terrain,
                'nearby_entities': nearby_entities,
                'position': (self.x, self.y)
            }
            
            # æ ¹æ®ä¸åŒæŠ½è±¡ç›®æ ‡ç±»å‹è¿›è¡Œå…·è±¡åŒ–è½¬æ¢
            if goal_type == 'skill_development':
                return self._convert_skill_development_goal(context)
            elif goal_type == 'knowledge_acquisition':
                return self._convert_knowledge_acquisition_goal(context)
            elif goal_type == 'environment_exploration':
                return self._convert_exploration_goal(context)
            else:
                return self._convert_survival_goal(context)
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ç›®æ ‡è½¬æ¢å¤±è´¥: {str(e)}")
            return {
                'environment': 'unknown',
                'object': 'resource',
                'characteristics': ['needed'],
                'action': 'search',
                'tool': None,
                'expected_result': 'survival'
            }
    
    def _convert_skill_development_goal(self, context):
        """å°†skill_developmentè½¬æ¢ä¸ºå…·ä½“çš„EOCATRæŠ€èƒ½ç›®æ ‡"""
        if context['food_level'] < 60:
            # é£Ÿç‰©ä¸è¶³ â†’ å‘å±•è§…é£ŸæŠ€èƒ½
            nearby_prey = [e for e in context['nearby_entities'] 
                          if e.get('type') in ['Rabbit', 'Boar'] and e.get('distance', 999) <= 2]
            nearby_plants = [e for e in context['nearby_entities'] 
                           if e.get('type') in ['Strawberry', 'Mushroom'] and e.get('distance', 999) <= 1]
            
            if nearby_prey:
                target = nearby_prey[0]
                return {
                    'environment': context['terrain'],
                    'object': target['type'].lower(),
                    'characteristics': ['prey', 'edible'],
                    'action': 'hunt',
                    'tool': 'available_weapon',
                    'expected_result': f"food_gain_from_{target['type']}"
                }
            elif nearby_plants:
                target = nearby_plants[0]
                return {
                    'environment': context['terrain'],
                    'object': target['type'].lower(),
                    'characteristics': ['plant', 'edible'],
                    'action': 'gather',
                    'tool': None,
                    'expected_result': f"food_gain_from_{target['type']}"
                }
        
        # é»˜è®¤ï¼šå‘å±•ç§»åŠ¨æ¢ç´¢æŠ€èƒ½
        return {
            'environment': context['terrain'],
            'object': 'unexplored_area',
            'characteristics': ['unknown', 'potential'],
            'action': 'move',
            'tool': None,
            'expected_result': 'area_exploration'
        }
    
    def _convert_knowledge_acquisition_goal(self, context):
        """å°†knowledge_acquisitionè½¬æ¢ä¸ºå…·ä½“çš„EOCATRå­¦ä¹ ç›®æ ‡"""
        nearby_entities = context['nearby_entities']
        learning_targets = [e for e in nearby_entities if e.get('distance', 999) <= 2]
        
        if learning_targets:
            target = learning_targets[0]
            return {
                'environment': context['terrain'],
                'object': target['type'].lower(),
                'characteristics': ['observable', 'learnable'],
                'action': 'observe',
                'tool': None,
                'expected_result': f"knowledge_about_{target['type']}"
            }
        else:
            return {
                'environment': context['terrain'],
                'object': 'environment',
                'characteristics': ['current', 'observable'],
                'action': 'analyze',
                'tool': None,
                'expected_result': 'environmental_knowledge'
            }
    
    def _convert_exploration_goal(self, context):
        """å°†environment_explorationè½¬æ¢ä¸ºå…·ä½“çš„EOCATRæ¢ç´¢ç›®æ ‡"""
        return {
            'environment': 'adjacent_area',
            'object': 'unexplored_terrain',
            'characteristics': ['unknown', 'adjacent'],
            'action': 'move',
            'tool': None,
            'expected_result': 'territory_expansion'
        }
    
    def _convert_survival_goal(self, context):
        """å°†åŸºç¡€ç”Ÿå­˜ç›®æ ‡è½¬æ¢ä¸ºEOCATRæ ¼å¼"""
        if context['health_level'] < 50:
            return {
                'environment': context['terrain'],
                'object': 'safe_location',
                'characteristics': ['safe', 'protective'],
                'action': 'seek',
                'tool': None,
                'expected_result': 'health_recovery'
            }
        elif context['food_level'] < context['water_level']:
            return {
                'environment': context['terrain'],
                'object': 'food_source',
                'characteristics': ['edible', 'nutritious'],
                'action': 'seek',
                'tool': None,
                'expected_result': 'hunger_relief'
            }
        else:
            return {
                'environment': context['terrain'],
                'object': 'water_source',
                'characteristics': ['drinkable', 'clean'],
                'action': 'seek',
                'tool': None,
                'expected_result': 'thirst_relief'
            }

    def _calculate_environment_novelty(self, game):
        """è®¡ç®—ç¯å¢ƒæ–°å¥‡åº¦"""
        try:
            # ç®€åŒ–çš„æ–°å¥‡åº¦è®¡ç®—
            current_pos = (self.x, self.y)
            if not hasattr(self, 'visited_positions'):
                self.visited_positions = set()
            
            # æ£€æŸ¥å‘¨å›´åŒºåŸŸçš„æ¢ç´¢ç¨‹åº¦
            explored_count = 0
            total_count = 0
            
            for dx in range(-2, 3):
                for dy in range(-2, 3):
                    check_pos = (self.x + dx, self.y + dy)
                    total_count += 1
                    if check_pos in self.visited_positions:
                        explored_count += 1
            
            # æ–°å¥‡åº¦ = 1 - æ¢ç´¢æ¯”ä¾‹
            novelty = 1.0 - (explored_count / total_count) if total_count > 0 else 1.0
            
            # è®°å½•å½“å‰ä½ç½®
            self.visited_positions.add(current_pos)
            
            return novelty
            
        except Exception:
            return 0.5

    def _dmha_calculate_primary_goal(self, game, current_state):
        """DMHAè®¡ç®—ä¸»è¦ç›®æ ‡"""
        try:
            # æ„å»ºæ³¨æ„åŠ›ä¸Šä¸‹æ–‡
            attention_context = self._build_attention_context(game)
            
            # DMHAå¤„ç†
            if hasattr(self, 'dmha') and self.dmha:
                attention_output = self.dmha.process_attention(attention_context)
                dominant_focus = attention_output.get('dominant_focus', 'resource')
            else:
                dominant_focus = 'resource'  # é»˜è®¤å…³æ³¨èµ„æº
            
            # æ ¹æ®å½“å‰çŠ¶æ€ç¡®å®šå…·ä½“ç›®"""
            if current_state['has_emergency']:
                if current_state['health_ratio'] < 0.3:
                    goal_type = 'health_recovery'
                    urgency = 0.9
                elif current_state['threat_count'] > 0:
                    goal_type = 'threat_avoidance'
                    urgency = 1.0
                elif current_state['water_ratio'] < 0.2:
                    goal_type = 'water_acquisition'
                    urgency = 0.8
                else:
                    goal_type = 'food_acquisition'
                    urgency = 0.7
            else:
                # éç´§æ€¥æƒ…å†µä¸‹æ ¹æ®DMHAç„¦ç‚¹ç¡®å®šç›®æ ‡
                if dominant_focus == 'social':
                    goal_type = 'social_interaction'
                    urgency = 0.4
                elif dominant_focus == 'exploration':
                    goal_type = 'environment_exploration'
                    urgency = 0.3
                else:
                    goal_type = current_state['most_urgent_need']
                    urgency = 0.5
            
            return {
                'type': goal_type,
                'urgency': urgency,
                'context': current_state,
                'dmha_focus': dominant_focus
            }
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} DMHAç›®æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            return {
                'type': 'survival',
                'urgency': 0.7,
                'context': current_state,
                'dmha_focus': 'resource'
            }

    def _decision_library_matching(self, target_goal, game):
        """å†³ç­–åº“åŒ¹é…- å¯»æ‰¾ç°æˆçš„å†³ç­–"""
        try:
            # ğŸ¯ é¦–å…ˆå°è¯•ä»å¯æ‰§è¡Œè§„å¾‹åº“ä¸­æŸ¥æ‰¾
            situation_context = {
                'goal_type': target_goal['type'],
                'food_level': 'low' if self.food < 50 else 'normal',
                'health_level': 'low' if self.health < 50 else 'normal',
                'water_level': 'low' if self.water < 50 else 'normal'
            }
            
            # è·å–é™„è¿‘çš„å®ä½“ä¿¡æ¯æ¥å¢å¼ºä¸Šä¸‹æ–‡
            nearby_entities = self._collect_nearby_entities(game)
            for entity in nearby_entities:
                if entity['distance'] <= 1:  # ç´§é‚»çš„å®ä½“
                    entity_type = entity['type']
                    if entity_type in ['Strawberry', 'Mushroom']:
                        situation_context['plant_type'] = 'ground_plant'
                        situation_context['tool_available'] = None  # ç®€åŒ–ï¼Œåç»­å¯ä»¥æ£€æŸ¥å®é™…å·¥å…·
                    elif entity_type in ['Tiger', 'BlackBear']:
                        situation_context['animal_type'] = 'predator'
                        situation_context['target_species'] = entity_type
                    elif entity_type in ['Rabbit', 'Boar']:
                        situation_context['animal_type'] = 'prey'
                        situation_context['target_species'] = entity_type
            
            # æŸ¥æ‰¾é€‚ç”¨çš„è§„å¾‹
            applicable_rule = self._find_applicable_rule_for_situation(situation_context)
            if applicable_rule:
                predictions = applicable_rule.get('predictions', {})
                action = predictions.get('action', 'explore')
                confidence = applicable_rule.get('confidence', 0.5)
                
                logger.log(f"{self.name} ğŸ¯ æ‰¾åˆ°é€‚ç”¨è§„å¾‹: {action} (ç½®ä¿¡åº¦: {confidence:.2f})")
                return {
                    'success': True,
                    'action': action,
                    'confidence': confidence,
                    'rule_id': applicable_rule.get('rule_id'),
                    'source': 'actionable_rules'
                }
            
            # ğŸ”§ ç»§ç»­åŸæœ‰çš„äº”åº“ç³»ç»Ÿé€»è¾‘
            if not (hasattr(self, 'five_library_system') and self.five_library_system):
                return None
            
            # æ„å»ºåŒ¹é…ä¸Šä¸‹"""
            match_context = {
                'goal_type': target_goal['type'],
                'urgency': target_goal['urgency'],
                'hp': self.health,
                'food': self.food,
                'water': self.water,
                'position': (self.x, self.y),
                'day': getattr(game, 'current_day', 1)
            }
            
            # ä»äº”åº“ç³»ç»ŸæŸ¥æ‰¾åŒ¹é…å†³"
            decision_result = self.five_library_system.generate_decision_from_context(
                context=match_context,
                source='decision_library_matching'
            )
            
            if decision_result.get('success') and decision_result.get('decision'):
                decision = decision_result['decision']
                confidence = decision_result.get('confidence', 0)
                
                # è®¾ç½®åŒ¹é…é˜ˆ"
                if confidence > 0.6:  # åŒ¹é…åº¦è¶³å¤Ÿé«˜
                    return {
                        'success': True,
                        'action': decision.action,
                        'confidence': confidence,
                        'decision_id': decision_result.get('decision_id'),
                        'source': 'decision_library'
                    }
            
            return {'success': False, 'reason': 'æ— åŒ¹é…å†³ç­–æˆ–åŒ¹é…åº¦ä¸è¶³'}
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} å†³ç­–åº“åŒ¹é…å¤±ä» {str(e)}")
            return {'success': False, 'reason': f'åŒ¹é…å¼‚å¸¸: {str(e)}'}

    def _wbm_rule_based_decision(self, target_goal, game, logger=None):
        """ğŸ”§ ç¬¬3æ­¥ä¿®å¤ï¼šWBMä¸“æ³¨å†³ç­–æ–¹æ¡ˆåˆ¶å®šæœºåˆ¶
        
        WBMçš„æ ¸å¿ƒèŒè´£ï¼š
        1. ä»ç›®æ ‡å‡ºå‘ï¼Œä»è§„å¾‹åº“ä¸­é€‰æ‹©åˆé€‚çš„è§„å¾‹
        2. ç»„åˆè§„å¾‹å½¢æˆå†³ç­–é“¾
        3. å®Œæˆå†³ç­–é“¾è¯„ä¼°ï¼ˆBPUè¯„ä¼°ï¼‰
        4. ç¡®å®šæœ€ä¼˜å†³ç­–é“¾æ–¹æ¡ˆ
        """
        try:
            if logger:
                logger.log(f"{self.name} ğŸŒ‰ WBMå†³ç­–åˆ¶å®šå¼€å§‹ - ç›®æ ‡: {target_goal.get('type', 'unknown')} (ç´§æ€¥åº¦: {target_goal.get('urgency', 0):.2f})")
            
            # === ç¬¬1æ­¥ï¼šè§„å¾‹æ£€ç´¢ ===
            available_rules = self._wbm_retrieve_rules(target_goal, game, logger)
            
            if not available_rules:
                if logger:
                    logger.log(f"{self.name} âŒ WBMæ— å¯ç”¨è§„å¾‹ï¼Œè·³è¿‡å†³ç­–åˆ¶å®š")
                return None
            
            # === ç¬¬2æ­¥ï¼šè§„å¾‹æ¥å¤´æœºåˆ¶ ===
            rule_connections = self._wbm_rule_connecting(available_rules, target_goal, logger)
            
            # === ç¬¬3æ­¥ï¼šè§„å¾‹é“¾æ„å»º ===
            decision_chains = self._wbm_chain_building(rule_connections, target_goal, game, logger)
            
            if not decision_chains:
                if logger:
                    logger.log(f"{self.name} âŒ WBMæ— æ³•æ„å»ºæœ‰æ•ˆå†³ç­–é“¾")
                return None
            
            # === ç¬¬4æ­¥ï¼šBPUæ•ˆç”¨è¯„ä¼° ===
            evaluated_chains = self._wbm_bpu_evaluation(decision_chains, target_goal, game, logger)
            
            # === ç¬¬5æ­¥ï¼šæœ€ä¼˜æ–¹æ¡ˆé€‰æ‹© ===
            optimal_solution = self._wbm_select_optimal_solution(evaluated_chains, target_goal, logger)
            
            if optimal_solution:
                if logger:
                    logger.log(f"{self.name} âœ… WBMå†³ç­–åˆ¶å®šå®Œæˆ: {optimal_solution['action']} (æ•ˆç”¨: {optimal_solution['utility']:.2f})")
                return optimal_solution
            else:
                if logger:
                    logger.log(f"{self.name} âŒ WBMæ— æœ‰æ•ˆå†³ç­–æ–¹æ¡ˆ")
                return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBMå†³ç­–åˆ¶å®šå¼‚å¸¸: {str(e)}")
            return None
    
    def _wbm_retrieve_rules(self, target_goal, game, logger=None):
        """WBMè§„å¾‹æ£€ç´¢ï¼šä»è§„å¾‹åº“è·å–ä¸ç›®æ ‡ç›¸å…³çš„è§„å¾‹ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒEOCATRè½¬æ¢ï¼‰"""
        available_rules = []
        
        try:
            # === å¢å¼ºç‰ˆè§„å¾‹æ£€ç´¢ï¼šç›´æ¥ä½¿ç”¨EOCATRè½¬æ¢å™¨ ===
            try:
                # å¯¼å…¥EOCATRè½¬æ¢å™¨
                from wooden_bridge_model import EOCATR_CONVERTER
                
                goal_description = target_goal.get('type', 'unknown')
                urgency = target_goal.get('urgency', 0.5)
                
                # è·å–EOCATRè§„å¾‹
                eocatr_rules = EOCATR_CONVERTER.get_eocatr_rules_from_five_libraries()
                
                if logger:
                    logger.log(f"{self.name} ğŸ”§ EOCATRè·å–: åŸå§‹è§„å¾‹{len(eocatr_rules)}æ¡")
                
                # è½¬æ¢ä¸ºWBMæ ¼å¼
                wbm_rules = EOCATR_CONVERTER.convert_eocatr_rules_to_wbm(eocatr_rules)
                
                # æ ¹æ®ç›®æ ‡å’Œç´§æ€¥åº¦è¿‡æ»¤ç›¸å…³è§„å¾‹
                filtered_rules = []
                for rule in wbm_rules:
                    # ç®€åŒ–è¿‡æ»¤ï¼šæš‚æ—¶å…è®¸æ‰€æœ‰è§„å¾‹é€šè¿‡ï¼Œé¿å…å…¼å®¹æ€§è®¡ç®—é—®é¢˜
                    filtered_rules.append(rule)
                
                available_rules.extend(filtered_rules)
                
                if logger:
                    logger.log(f"{self.name} âœ… EOCATRè½¬æ¢: WBMè§„å¾‹{len(wbm_rules)}æ¡, è¿‡æ»¤å{len(filtered_rules)}æ¡")
                        
            except Exception as enhanced_error:
                if logger:
                    logger.log(f"{self.name} âš ï¸ EOCATRå¢å¼ºæ£€ç´¢å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•: {str(enhanced_error)}")
            
            # === ä¼ ç»Ÿè§„å¾‹æ£€ç´¢ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰ ===
            # 1. ä»ç›´æ¥è§„å¾‹åº“è·å–è§„å¾‹
            direct_rules = self._get_rules_from_direct_library(target_goal)
            available_rules.extend(direct_rules)
            
            # 2. ä»æ€»è§„å¾‹åº“è·å–è§„å¾‹  
            total_rules = self._get_rules_from_total_library(target_goal)
            available_rules.extend(total_rules)
            
            # 3. è¡¥å……åŸºç¡€ç”Ÿå­˜è§„å¾‹
            basic_rules = self._get_basic_survival_rules_for_wbm()
            available_rules.extend(basic_rules)
            
            if logger:
                logger.log(f"{self.name} ğŸ“š WBMè§„å¾‹æ£€ç´¢: ç›´æ¥è§„å¾‹{len(direct_rules)}æ¡, æ€»è§„å¾‹{len(total_rules)}æ¡, åŸºç¡€è§„å¾‹{len(basic_rules)}æ¡")
                    
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBMè§„å¾‹æ£€ç´¢å¤±è´¥: {str(e)}")
            # å…œåº•ï¼šä½¿ç”¨åŸºç¡€è§„å¾‹
            basic_rules = self._get_basic_survival_rules_for_wbm()
            available_rules.extend(basic_rules)
        
        return available_rules
    
    def _wbm_rule_connecting(self, available_rules, target_goal, logger=None):
        """WBMè§„å¾‹æ¥å¤´æœºåˆ¶ï¼šåˆ†æè§„å¾‹é—´çš„å…¼å®¹æ€§å’Œè¿æ¥æ€§"""
        connections = []
        
        try:
            # ç®€åŒ–ç‰ˆè§„å¾‹æ¥å¤´ï¼šåŸºäºç›®æ ‡ç±»å‹å’Œæ¡ä»¶é¢„æµ‹çš„å…¼å®¹æ€§
            goal_type = target_goal.get('type', 'unknown')
            
            for rule in available_rules:
                # è®¡ç®—è§„å¾‹ä¸ç›®æ ‡çš„åŒ¹é…åº¦
                compatibility_score = self._calculate_rule_goal_compatibility(rule, goal_type)
                
                if compatibility_score > 0.3:  # å…¼å®¹æ€§é˜ˆå€¼
                    connections.append({
                        'rule': rule,
                        'compatibility_score': compatibility_score,
                        'goal_type': goal_type
                    })
            
            # æŒ‰å…¼å®¹æ€§æ’åº
            connections.sort(key=lambda x: x['compatibility_score'], reverse=True)
            
            if logger and connections:
                logger.log(f"{self.name} ğŸ”— WBMè§„å¾‹æ¥å¤´: å‘ç°{len(connections)}ä¸ªå…¼å®¹è§„å¾‹")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBMè§„å¾‹æ¥å¤´å¤±è´¥: {str(e)}")
        
        return connections
    
    def _wbm_chain_building(self, rule_connections, target_goal, game, logger=None):
        """WBMè§„å¾‹é“¾æ„å»ºï¼šåŸºäºè´ªå¿ƒç­–ç•¥æ„å»ºå‰å‘å†³ç­–é“¾"""
        decision_chains = []
        
        try:
            # åŸºäºè´ªå¿ƒç­–ç•¥æ„å»ºå†³ç­–é“¾
            for i, connection in enumerate(rule_connections[:5]):  # é™åˆ¶è€ƒè™‘å‰5ä¸ªæœ€å…¼å®¹çš„è§„å¾‹
                rule = connection['rule']
                
                # ç”ŸæˆåŸºäºæ­¤è§„å¾‹çš„å†³ç­–é“¾
                chain = self._build_single_rule_chain(rule, target_goal, game)
                
                if chain:
                    decision_chains.append(chain)
            
            if logger and decision_chains:
                logger.log(f"{self.name} â›“ï¸ WBMé“¾æ„å»º: ç”Ÿæˆ{len(decision_chains)}æ¡å†³ç­–é“¾")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBMé“¾æ„å»ºå¤±è´¥: {str(e)}")
        
        return decision_chains
    
    def _wbm_bpu_evaluation(self, decision_chains, target_goal, game, logger=None):
        """WBM BPUè¯„ä¼°ï¼šå››ç»´æ•ˆç”¨ç©ºé—´è¯„ä¼°(æˆåŠŸ-æˆæœ¬-æ—¶é—´-é£é™©)"""
        evaluated_chains = []
        
        try:
            for chain in decision_chains:
                # è®¡ç®—BPUå››ç»´æ•ˆç”¨
                success_utility = self._calculate_success_utility(chain, target_goal)
                cost_penalty = self._calculate_cost_penalty(chain, game)
                time_penalty = self._calculate_time_penalty(chain)
                risk_penalty = self._calculate_risk_penalty(chain, game)
                
                # BPUå…¬å¼ï¼šBPU = æˆåŠŸæ•ˆç”¨ - Î»c*æˆæœ¬ - Î»t*æ—¶é—´ - Î»r*é£é™©
                # ä½¿ç”¨åŠ¨æ€æƒé‡
                lambda_c = 0.1  # æˆæœ¬æƒé‡
                lambda_t = 0.05  # æ—¶é—´æƒé‡  
                lambda_r = 0.15  # é£é™©æƒé‡
                
                bpu_utility = success_utility - lambda_c * cost_penalty - lambda_t * time_penalty - lambda_r * risk_penalty
                
                evaluated_chains.append({
                    'chain': chain,
                    'bpu_utility': bpu_utility,
                    'success_utility': success_utility,
                    'cost_penalty': cost_penalty,
                    'time_penalty': time_penalty,
                    'risk_penalty': risk_penalty
                })
            
            # æŒ‰BPUæ•ˆç”¨æ’åº
            evaluated_chains.sort(key=lambda x: x['bpu_utility'], reverse=True)
            
            if logger and evaluated_chains:
                best = evaluated_chains[0]
                logger.log(f"{self.name} ğŸ“Š WBM BPUè¯„ä¼°: æœ€ä½³é“¾æ•ˆç”¨{best['bpu_utility']:.2f} (æˆåŠŸ:{best['success_utility']:.2f}, æˆæœ¬:{best['cost_penalty']:.2f})")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBM BPUè¯„ä¼°å¤±è´¥: {str(e)}")
        
        return evaluated_chains
    
    def _wbm_select_optimal_solution(self, evaluated_chains, target_goal, logger=None):
        """WBMæœ€ä¼˜æ–¹æ¡ˆé€‰æ‹©ï¼šé€‰æ‹©BPUæ•ˆç”¨æœ€é«˜çš„å†³ç­–æ–¹æ¡ˆ"""
        if not evaluated_chains:
            return None
        
        try:
            best_chain = evaluated_chains[0]  # BPUæ•ˆç”¨æœ€é«˜çš„é“¾
            
            # æå–ç¬¬ä¸€ä¸ªå¯æ‰§è¡Œè¡ŒåŠ¨
            chain_data = best_chain['chain']
            action = chain_data.get('action', 'explore')
            
            return {
                'action': action,
                'source': 'wbm_optimal',
                'confidence': min(0.9, best_chain['bpu_utility']),
                'utility': best_chain['bpu_utility'],
                'chain_info': {
                    'success_utility': best_chain['success_utility'],
                    'cost_penalty': best_chain['cost_penalty'],
                    'time_penalty': best_chain['time_penalty'],
                    'risk_penalty': best_chain['risk_penalty']
                }
            }
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ WBMæ–¹æ¡ˆé€‰æ‹©å¤±è´¥: {str(e)}")
            return None

    def _calculate_rule_goal_compatibility(self, rule, goal_type):
        """è®¡ç®—è§„å¾‹ä¸ç›®æ ‡çš„å…¼å®¹æ€§åˆ†æ•°ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒCDLç›®æ ‡ï¼‰"""
        try:
            compatibility = 0.0
            
            # ğŸ”§ ä¿®å¤ï¼šCDLæ¢ç´¢ç›®æ ‡ç‰¹æ®Šå¤„ç†
            if goal_type == 'cdl_exploration':
                # CDLæ¢ç´¢ç›®æ ‡ä¸å¤§å¤šæ•°è§„å¾‹éƒ½æœ‰åŸºç¡€å…¼å®¹æ€§
                compatibility += 0.6  # åŸºç¡€å…¼å®¹æ€§
                
                # æ£€æŸ¥è§„å¾‹æ˜¯å¦ä¸æ¢ç´¢ç›¸å…³
                rule_conditions = getattr(rule, 'conditions', {})
                rule_predictions = getattr(rule, 'predictions', {})
                rule_text = str(rule_conditions) + str(rule_predictions)
                
                exploration_keywords = ['move', 'explore', 'search', 'discover', 'investigate', 'area', 'location']
                for keyword in exploration_keywords:
                    if keyword in rule_text.lower():
                        compatibility += 0.2
                        break
                        
                # è§„å¾‹ç½®ä¿¡åº¦å½±å“
                rule_confidence = getattr(rule, 'confidence', 0.5)
                compatibility = compatibility * (0.7 + 0.3 * rule_confidence)
                
                return min(1.0, compatibility)
            
            # åŸæœ‰çš„å…¶ä»–ç›®æ ‡ç±»å‹å¤„ç†
            rule_conditions = getattr(rule, 'conditions', {})
            rule_predictions = getattr(rule, 'predictions', {})
            
            # ç›®æ ‡ç±»å‹åŒ¹é…æ£€æŸ¥
            if goal_type in str(rule_conditions).lower() or goal_type in str(rule_predictions).lower():
                compatibility += 0.5
            
            # æ‰©å±•çš„å…³é”®è¯åŒ¹é…
            goal_keywords = {
                'threat_avoidance': ['threat', 'danger', 'escape', 'flee', 'avoid', 'safe', 'hide'],
                'food_acquisition': ['food', 'eat', 'collect', 'hunt', 'gather', 'plant', 'berry'],
                'water_acquisition': ['water', 'drink', 'river', 'puddle', 'thirst', 'hydrate'],
                'environment_exploration': ['explore', 'move', 'discover', 'search', 'area', 'territory'],
                'health_recovery': ['health', 'heal', 'safe', 'rest', 'recover', 'shelter'],
                'resource_acquisition': ['resource', 'collect', 'gather', 'find', 'search'],
                'survival': ['survive', 'live', 'safety', 'protection', 'basic']
            }
            
            keywords = goal_keywords.get(goal_type, [])
            rule_text = str(rule_conditions) + str(rule_predictions)
            
            # å¢å¼ºå…³é”®è¯åŒ¹é…
            matched_keywords = 0
            for keyword in keywords:
                if keyword in rule_text.lower():
                    matched_keywords += 1
            
            if matched_keywords > 0:
                compatibility += min(0.4, matched_keywords * 0.15)  # å¤šå…³é”®è¯åŒ¹é…ç»™æ›´é«˜åˆ†æ•°
            
            # é€šç”¨å…¼å®¹æ€§ï¼šä»»ä½•è§„å¾‹éƒ½æœ‰åŸºç¡€å¯ç”¨æ€§
            if compatibility == 0:
                compatibility = 0.3  # æé«˜é»˜è®¤å…¼å®¹æ€§
            
            # è§„å¾‹ç½®ä¿¡åº¦å½±å“
            rule_confidence = getattr(rule, 'confidence', 0.5)
            compatibility = compatibility * (0.5 + 0.5 * rule_confidence)
            
            return min(1.0, compatibility)
            
        except Exception:
            return 0.4  # æé«˜é»˜è®¤å…¼å®¹æ€§ï¼Œç¡®ä¿æœ‰è§„å¾‹å¯ç”¨
    
    def _build_single_rule_chain(self, rule, target_goal, game):
        """åŸºäºå•ä¸ªè§„å¾‹æ„å»ºå†³ç­–é“¾"""
        try:
            # ä»è§„å¾‹ä¸­æå–è¡ŒåŠ¨
            action = self._extract_action_from_rule(rule, target_goal)
            
            if action and self._is_action_executable(action, game):
                return {
                    'rule': rule,
                    'action': action,
                    'goal_type': target_goal.get('type', 'unknown'),
                    'confidence': getattr(rule, 'confidence', 0.5)
                }
            return None
            
        except Exception:
            return None
    
    def _calculate_success_utility(self, chain, target_goal):
        """è®¡ç®—æˆåŠŸæ•ˆç”¨"""
        try:
            base_utility = target_goal.get('urgency', 0.5)
            rule_confidence = chain.get('confidence', 0.5)
            return base_utility * rule_confidence
        except Exception:
            return 0.3
    
    def _calculate_cost_penalty(self, chain, game):
        """è®¡ç®—æˆæœ¬æƒ©ç½š"""
        try:
            # ç®€åŒ–çš„æˆæœ¬è®¡ç®—ï¼šåŸºäºè¡ŒåŠ¨ç±»å‹
            action = chain.get('action', 'explore')
            
            if 'attack' in action:
                return 0.3  # æ”»å‡»è¡Œä¸ºæˆæœ¬é«˜
            elif 'collect' in action:
                return 0.1  # é‡‡é›†è¡Œä¸ºæˆæœ¬ä½
            else:
                return 0.2  # é»˜è®¤æˆæœ¬
                
        except Exception:
            return 0.2
    
    def _calculate_time_penalty(self, chain):
        """è®¡ç®—æ—¶é—´æƒ©ç½š"""
        try:
            # ç®€åŒ–çš„æ—¶é—´è®¡ç®—
            return 0.1  # å¤§å¤šæ•°è¡ŒåŠ¨æ—¶é—´æˆæœ¬ç›¸è¿‘
        except Exception:
            return 0.1
    
    def _calculate_risk_penalty(self, chain, game):
        """è®¡ç®—é£é™©æƒ©ç½š"""
        try:
            # ç®€åŒ–çš„é£é™©è®¡ç®—ï¼šåŸºäºç¯å¢ƒå¨èƒ
            threats = self.detect_threats(game.game_map)
            risk_factor = min(0.5, len(threats) * 0.1)
            
            action = chain.get('action', 'explore')
            if 'attack' in action:
                risk_factor += 0.2  # æ”»å‡»è¡Œä¸ºé£é™©é«˜
            
            return risk_factor
            
        except Exception:
            return 0.1

    def _long_chain_execution_management(self, game, target_goal, logger=None):
        """ğŸ”§ ç¬¬4æ­¥ä¿®å¤ï¼šé•¿é“¾æœºåˆ¶æ‰§è¡Œç®¡ç†
        
        é•¿é“¾æœºåˆ¶çš„æ ¸å¿ƒèŒè´£ï¼š
        1. åœ¨æ¯ä¸ªå›åˆå¼€å§‹ï¼Œåˆ¤æ–­ä¸Šä¸€ä¸ªå†³ç­–é“¾æ˜¯å¦æ‰§è¡Œå®Œæ¯•
        2. å¦‚æœå·²ç»“æŸï¼Œå¼€å¯æ–°çš„å†³ç­–é“¾
        3. å¦‚æœæœªç»“æŸï¼Œç»§ç»­æ‰§è¡Œå¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®æ”¹
        """
        try:
            # === æ­¥éª¤1ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„é•¿é“¾è®¡åˆ’ ===
            if hasattr(self, 'current_multi_day_plan') and self.current_multi_day_plan:
                if logger:
                    logger.log(f"{self.name} ğŸ—“ï¸ å‘ç°æ­£åœ¨æ‰§è¡Œçš„é•¿é“¾è®¡åˆ’ï¼Œè¿›è¡ŒçŠ¶æ€æ£€æŸ¥")
                
                # ç»§ç»­æ‰§è¡Œç°æœ‰è®¡åˆ’
                continue_result = self._continue_existing_long_chain(game, logger)
                if continue_result:
                    return continue_result
                else:
                    # ç°æœ‰è®¡åˆ’æ‰§è¡Œå®Œæ¯•æˆ–å¤±è´¥ï¼Œæ¸…é™¤
                    self._clear_current_plan("æ‰§è¡Œå®Œæ¯•æˆ–å¤±è´¥", logger)
            
            # === æ­¥éª¤2ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦å¯åŠ¨æ–°çš„é•¿é“¾è®¡åˆ’ ===
            if self._should_start_new_long_chain(target_goal, game, logger):
                if logger:
                    logger.log(f"{self.name} ğŸ—“ï¸ å¼€å¯æ–°çš„é•¿é“¾å†³ç­–è®¡åˆ’")
                
                new_plan_result = self._start_new_long_chain(target_goal, game, logger)
                if new_plan_result:
                    return new_plan_result
            
            # === æ­¥éª¤3ï¼šä¸éœ€è¦é•¿é“¾è§„åˆ’ ===
            if logger:
                logger.log(f"{self.name} ğŸ—“ï¸ å½“å‰æƒ…å†µä¸éœ€è¦é•¿é“¾è§„åˆ’ï¼Œäº¤ç”±WBMå•æ­¥å†³ç­–")
            
            return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ é•¿é“¾æ‰§è¡Œç®¡ç†å¼‚å¸¸: {str(e)}")
            return None
    
    def _continue_existing_long_chain(self, game, logger=None):
        """ç»§ç»­æ‰§è¡Œç°æœ‰é•¿é“¾è®¡åˆ’"""
        try:
            plan = self.current_multi_day_plan
            current_day = getattr(self, 'plan_current_day', 0) + 1
            
            if logger:
                logger.log(f"{self.name} ğŸ“… æ£€æŸ¥é•¿é“¾è®¡åˆ’ç¬¬{current_day}å¤© (æ€»è®¡{plan.total_days}å¤©)")
            
            # 1. ç¯å¢ƒå˜åŒ–æ£€æµ‹
            current_state = self._get_current_wbm_state(game)
            environment_changed = self._detect_plan_environment_change(current_state)
            
            if environment_changed:
                if logger:
                    logger.log(f"{self.name} âš ï¸ æ£€æµ‹åˆ°ç¯å¢ƒå˜åŒ–: {environment_changed}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­å½“å‰è®¡åˆ’
                if self._should_interrupt_plan(environment_changed, plan):
                    if logger:
                        logger.log(f"{self.name} ğŸ›‘ ç¯å¢ƒå˜åŒ–å¯¼è‡´è®¡åˆ’ä¸­æ–­ï¼Œé‡æ–°è§„åˆ’")
                    self._clear_current_plan("ç¯å¢ƒå˜åŒ–ä¸­æ–­", logger)
                    return None
            
            # 2. æ‰§è¡Œä»Šå¤©çš„è¡ŒåŠ¨
            today_action = plan.get_action_for_day(current_day)
            if today_action:
                self.plan_current_day = current_day
                
                if logger:
                    logger.log(f"{self.name} ğŸ¯ é•¿é“¾ç¬¬{current_day}å¤©æ‰§è¡Œ: {today_action.action}")
                    logger.log(f"{self.name}    æ¨ç†: {today_action.reasoning}")
                
                # è®°å½•æ‰§è¡ŒçŠ¶æ€
                self._update_daily_execution_log(current_day, today_action, current_state)
                
                # 3. æ£€æŸ¥æ˜¯å¦å®Œæˆæ•´ä¸ªè®¡åˆ’
                if current_day >= plan.total_days:
                    if logger:
                        logger.log(f"{self.name} ğŸ‰ é•¿é“¾è®¡åˆ’æ‰§è¡Œå®Œæˆ!")
                    self._complete_long_chain_plan(True, "æ­£å¸¸å®Œæˆ", logger)
                
                return {
                    'action': today_action.action,
                    'source': 'long_chain_continue',
                    'status': f'ç¬¬{current_day}å¤©',
                    'confidence': today_action.confidence,
                    'plan_goal': plan.goal.description if hasattr(plan.goal, 'description') else str(plan.goal)
                }
            
            # 4. æ²¡æœ‰æ‰¾åˆ°ä»Šå¤©çš„è¡ŒåŠ¨ï¼Œè®¡åˆ’å¼‚å¸¸
            if logger:
                logger.log(f"{self.name} âŒ é•¿é“¾è®¡åˆ’ç¬¬{current_day}å¤©æ— è¡ŒåŠ¨ï¼Œè®¡åˆ’å¼‚å¸¸ç»“æŸ")
            
            self._complete_long_chain_plan(False, "è®¡åˆ’å¼‚å¸¸", logger)
            return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ ç»§ç»­é•¿é“¾è®¡åˆ’å¼‚å¸¸: {str(e)}")
            self._clear_current_plan("æ‰§è¡Œå¼‚å¸¸", logger)
            return None
    
    def _should_start_new_long_chain(self, target_goal, game, logger=None):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯åŠ¨æ–°çš„é•¿é“¾è®¡åˆ’"""
        try:
            goal_type = target_goal.get('type', 'unknown')
            urgency = target_goal.get('urgency', 0.5)
            
            # 1. ä½ç´§æ€¥åº¦ç›®æ ‡é€‚åˆé•¿é“¾è§„åˆ’
            if urgency <= 0.6:
                if logger:
                    logger.log(f"{self.name} ğŸ¯ ç›®æ ‡ç´§æ€¥åº¦ä½({urgency:.2f})ï¼Œé€‚åˆé•¿é“¾è§„åˆ’")
                return True
            
            # 2. ç‰¹å®šç›®æ ‡ç±»å‹éœ€è¦é•¿é“¾è§„åˆ’ - ğŸ¯ æ›´æ–°ï¼šæ–°å¢ç”Ÿç‰©å¤šæ ·æ€§å’Œå·¥å…·æ•ˆèƒ½æµ‹è¯•
            long_chain_goals = [
                'biodiversity_exploration',      # æ–°å¢ï¼šç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢ - æœ€é«˜ä¼˜å…ˆçº§
                'tool_efficiency_testing',      # æ–°å¢ï¼šå·¥å…·æ•ˆèƒ½æµ‹è¯• - é«˜ä¼˜å…ˆçº§
                'cdl_exploration',               # ä¿ç•™ï¼šCDLåœ°å›¾æ¢ç´¢
                'environment_exploration',       # åºŸå¼ƒä½†ä¿ç•™å…¼å®¹æ€§
                'resource_optimization',         # åºŸå¼ƒä½†ä¿ç•™å…¼å®¹æ€§
                'skill_development',             # åºŸå¼ƒä½†ä¿ç•™å…¼å®¹æ€§
                'knowledge_acquisition'          # åºŸå¼ƒä½†ä¿ç•™å…¼å®¹æ€§
            ]
            
            if goal_type in long_chain_goals:
                if logger:
                    logger.log(f"{self.name} ğŸ¯ ç›®æ ‡ç±»å‹({goal_type})éœ€è¦é•¿é“¾è§„åˆ’")
                return True
            
            # 3. èµ„æºå……è¶³æ—¶å¯ä»¥è¿›è¡Œé•¿é“¾è§„åˆ’
            if self.health > 60 and self.food > 50 and self.water > 50:
                threats = self.detect_threats(game.game_map) if hasattr(self, 'detect_threats') else []
                if len(threats) == 0:
                    if logger:
                        logger.log(f"{self.name} ğŸ¯ èµ„æºå……è¶³ä¸”ç¯å¢ƒå®‰å…¨ï¼Œé€‚åˆé•¿é“¾è§„åˆ’")
                    return True
            
            if logger:
                logger.log(f"{self.name} ğŸ¯ å½“å‰æ¡ä»¶ä¸é€‚åˆé•¿é“¾è§„åˆ’")
            return False
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ é•¿é“¾å¯åŠ¨åˆ¤æ–­å¼‚å¸¸: {str(e)}")
            return False
    
    def _start_new_long_chain(self, target_goal, game, logger=None):
        """å¯åŠ¨æ–°çš„é•¿é“¾å†³ç­–è®¡åˆ’"""
        try:
            if logger:
                logger.log(f"{self.name} ğŸš€ å¯åŠ¨æ–°é•¿é“¾è®¡åˆ’ - ç›®æ ‡: {target_goal.get('type', 'unknown')}")
            
            # ä½¿ç”¨WBMè¿›è¡Œé•¿é“¾å†³ç­–åˆ¶å®š
            wbm_result = self._wbm_rule_based_decision(target_goal, game, logger)
            
            # æ£€æŸ¥WBMæ˜¯å¦ç”Ÿæˆäº†é•¿é“¾è®¡åˆ’
            if wbm_result and wbm_result.get('source') == 'wbm_optimal':
                # å°†WBMçš„å•æ­¥å†³ç­–è½¬æ¢ä¸ºé•¿é“¾è®¡åˆ’çš„èµ·å§‹
                first_action = wbm_result['action']
                
                # åˆå§‹åŒ–é•¿é“¾è®¡åˆ’çŠ¶æ€
                self._initialize_long_chain_state(target_goal, first_action)
                
                if logger:
                    logger.log(f"{self.name} âœ… æ–°é•¿é“¾è®¡åˆ’å¯åŠ¨: é¦–ä¸ªè¡ŒåŠ¨ {first_action}")
                
                return {
                    'action': first_action,
                    'source': 'long_chain_start',
                    'status': 'æ–°è®¡åˆ’ç¬¬1æ­¥',
                    'confidence': wbm_result.get('confidence', 0.5),
                    'plan_goal': target_goal.get('description', target_goal.get('type', 'unknown'))
                }
            
            if logger:
                logger.log(f"{self.name} âŒ WBMæœªèƒ½ç”Ÿæˆé•¿é“¾è®¡åˆ’")
            return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âŒ å¯åŠ¨é•¿é“¾è®¡åˆ’å¼‚å¸¸: {str(e)}")
            return None
    
    def _detect_plan_environment_change(self, current_state):
        """æ£€æµ‹å½±å“è®¡åˆ’çš„ç¯å¢ƒå˜åŒ–"""
        try:
            # æ£€æŸ¥å¥åº·çŠ¶å†µ
            health = current_state.get('health', 100)
            if health < 30:
                return "å¥åº·çŠ¶å†µå±æ€¥"
            
            # æ£€æŸ¥èµ„æºçŠ¶å†µ  
            food = current_state.get('food', 100)
            water = current_state.get('water', 100)
            if food < 20 or water < 20:
                return "èµ„æºä¸¥é‡ä¸è¶³"
            
            # æ£€æŸ¥å¨èƒæƒ…å†µï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
            # è¿™é‡Œå¯ä»¥åŠ å…¥æ›´è¯¦ç»†çš„å¨èƒæ£€æµ‹é€»è¾‘
            
            return None  # æ— é‡å¤§ç¯å¢ƒå˜åŒ–
            
        except Exception:
            return None
    
    def _should_interrupt_plan(self, environment_change, plan):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸­æ–­å½“å‰è®¡åˆ’"""
        # å¥åº·å±æ€¥æˆ–èµ„æºä¸¥é‡ä¸è¶³æ—¶ä¸­æ–­è®¡åˆ’
        critical_changes = ["å¥åº·çŠ¶å†µå±æ€¥", "èµ„æºä¸¥é‡ä¸è¶³", "ç›´æ¥å¨èƒ"]
        return environment_change in critical_changes
    
    def _update_daily_execution_log(self, day, action, state):
        """æ›´æ–°æ¯æ—¥æ‰§è¡Œæ—¥å¿—"""
        try:
            if not hasattr(self, 'daily_execution_log'):
                self.daily_execution_log = []
            
            # ç¡®ä¿æ—¥å¿—åˆ—è¡¨è¶³å¤Ÿé•¿
            while len(self.daily_execution_log) < day:
                self.daily_execution_log.append({})
            
            execution_record = {
                'day': day,
                'action': action.action,
                'reasoning': action.reasoning,
                'confidence': action.confidence,
                'start_state': state.copy(),
                'timestamp': time.time()
            }
            
            if len(self.daily_execution_log) == day:
                self.daily_execution_log.append(execution_record)
            else:
                self.daily_execution_log[day - 1] = execution_record
                
        except Exception:
            pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
    
    def _initialize_long_chain_state(self, target_goal, first_action):
        """åˆå§‹åŒ–é•¿é“¾è®¡åˆ’çŠ¶æ€"""
        try:
            # åˆ›å»ºç®€åŒ–çš„é•¿é“¾è®¡åˆ’å¯¹è±¡
            class SimpleLongChainPlan:
                def __init__(self, goal, total_days, first_action):
                    self.goal = goal
                    self.total_days = total_days
                    self.actions = [first_action]
                    self.start_time = time.time()
                
                def get_action_for_day(self, day):
                    # ç®€åŒ–ç‰ˆï¼šä¸ºæ¯å¤©ç”Ÿæˆåˆç†çš„è¡ŒåŠ¨
                    if day == 1:
                        return SimpleAction(self.actions[0], f"ç¬¬{day}å¤©: {self.actions[0]}", 0.7)
                    elif day <= self.total_days:
                        # åŸºäºç›®æ ‡ç±»å‹ç”Ÿæˆåç»­è¡ŒåŠ¨
                        goal_type = self.goal.get('type', 'explore')
                        if goal_type == 'environment_exploration':
                            action = f'explore_move'
                        elif goal_type == 'resource_optimization':
                            action = f'resource_check'
                        else:
                            action = f'continue_goal'
                        
                        return SimpleAction(action, f"ç¬¬{day}å¤©: ç»§ç»­{goal_type}", 0.6)
                    return None
            
            class SimpleAction:
                def __init__(self, action, reasoning, confidence):
                    self.action = action
                    self.reasoning = reasoning
                    self.confidence = confidence
            
            self.current_multi_day_plan = SimpleLongChainPlan(target_goal, 3, first_action)
            
            self.plan_current_day = 0
            self.daily_execution_log = []
            
            # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
            if not hasattr(self, 'plan_completion_stats'):
                self.plan_completion_stats = {
                    'total_started': 0,
                    'total_completed': 0,
                    'total_interrupted': 0
                }
            
            self.plan_completion_stats['total_started'] += 1
            
        except Exception:
            pass
    
    def _complete_long_chain_plan(self, success, reason, logger=None):
        """å®Œæˆé•¿é“¾è®¡åˆ’"""
        try:
            if logger:
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                logger.log(f"{self.name} ğŸ“Š é•¿é“¾è®¡åˆ’{status}å®Œæˆ: {reason}")
            
            # æ›´æ–°ç»Ÿè®¡
            if hasattr(self, 'plan_completion_stats'):
                if success:
                    self.plan_completion_stats['total_completed'] += 1
                else:
                    self.plan_completion_stats['total_interrupted'] += 1
            
            # æ¸…é™¤å½“å‰è®¡åˆ’
            self._clear_current_plan(reason, logger)
            
        except Exception:
            pass
    
    def _clear_current_plan(self, reason, logger=None):
        """æ¸…é™¤å½“å‰è®¡åˆ’"""
        try:
            self.current_multi_day_plan = None
            self.plan_current_day = 0
            
            if logger:
                logger.log(f"{self.name} ğŸ—‘ï¸ é•¿é“¾è®¡åˆ’å·²æ¸…é™¤: {reason}")
                
        except Exception:
            pass

    
    def _calculate_decision_weights(self, available_actions, current_context):
        """è®¡ç®—å†³ç­–æƒé‡ - å¢åŠ å·¥å…·ä½¿ç”¨ä¼˜å…ˆçº§"""
        weights = {}
        
        for action in available_actions:
            base_weight = 1.0
            
            # å·¥å…·ä½¿ç”¨è¡Œä¸ºè·å¾—æ›´é«˜æƒé‡
            if 'tool' in action or 'collect' in action or 'attack' in action:
                base_weight *= 2.5  # å·¥å…·ä½¿ç”¨ä¼˜å…ˆçº§æå‡150%
            
            # WBMè§„å¾‹å†³ç­–è·å¾—é¢å¤–æƒé‡
            if current_context.get('decision_source') == 'WBMè§„å¾‹å†³ç­–':
                base_weight *= 1.8
            
            # åŸºäºèµ„æºçŠ¶æ€è°ƒæ•´æƒé‡
            if self.food < 70 and ('collect' in action or 'attack' in action):
                base_weight *= 2.0  # ä½é£Ÿç‰©æ—¶ä¼˜å…ˆè§…é£Ÿè¡Œä¸º
            
            if self.water < 70 and 'drink' in action:
                base_weight *= 2.0  # ä½æ°´åˆ†æ—¶ä¼˜å…ˆé¥®æ°´
            
            # é¿å…é‡å¤è¡Œä¸º
            recent_actions = getattr(self, '_recent_actions', [])
            if len(recent_actions) >= 3 and all(a == action for a in recent_actions[-3:]):
                base_weight *= 0.3  # è¿ç»­ç›¸åŒè¡Œä¸ºæƒé‡é™ä½
            
            weights[action] = base_weight
        
        return weights


    def _emrs_evaluate_decision(self, action, goal, pre_state, post_state, execution_result):
        """EMRSæœºåˆ¶è¯„ä»·å†³ç­–è´¨é‡"""
        try:
            # è®¡ç®—çŠ¶æ€å˜"""
            health_change = post_state['health'] - pre_state['health']
            food_change = post_state['food'] - pre_state['food']
            water_change = post_state['water'] - pre_state['water']
            
            # åŸºç¡€è¯„åˆ†
            base_score = 0.5
            
            # æ ¹æ®ç›®æ ‡ç±»å‹è°ƒæ•´è¯„åˆ†
            if goal['type'] == 'health_recovery':
                base_score += max(0, health_change / 20.0)  # å¥åº·æå‡å¥–åŠ±
            elif goal['type'] == 'food_acquisition':
                base_score += max(0, food_change / 15.0)   # é£Ÿç‰©è·å–å¥–åŠ±
            elif goal['type'] == 'water_acquisition':
                base_score += max(0, water_change / 15.0)  # æ°´åˆ†è·å–å¥–åŠ±
            elif goal['type'] == 'threat_avoidance':
                # å¨èƒè§„é¿:å¦‚æœæˆåŠŸé€ƒè„±(å¥åº·æœªå‡ä»åˆ™å¥–åŠ±
                if health_change >= 0:
                    base_score += 0.3
            
            # æ‰§è¡ŒæˆåŠŸæ€§å¥–åŠ±
            if execution_result.get('success', False):
                base_score += 0.2
            
            # ç´§æ€¥åº¦åŒ¹é…å¥–åŠ±
            urgency_bonus = goal['urgency'] * 0.1
            base_score += urgency_bonus
            
            # é™åˆ¶è¯„åˆ†èŒƒå›´
            quality_score = max(0.0, min(1.0, base_score))
            
            return {
                'quality_score': quality_score,
                'health_change': health_change,
                'food_change': food_change,
                'water_change': water_change,
                'goal_achievement': quality_score > 0.6
            }
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} EMRSè¯„ä»·å¤±è´¥: {str(e)}")
            return {
                'quality_score': 0.5,
                'health_change': 0,
                'food_change': 0,
                'water_change': 0,
                'goal_achievement': False
            }

    def _identify_most_urgent_need(self):
        """è¯†åˆ«æœ€ç´§æ€¥çš„éœ€æ±‚"""
        try:
            health_need = max(0, 70 - self.health)
            food_need = max(0, 50 - self.food) 
            water_need = max(0, 50 - self.water)
            
            if health_need > food_need and health_need > water_need:
                return 'health_recovery'
            elif water_need > food_need:
                return 'water_acquisition'
            elif food_need > 0:
                return 'food_acquisition'
            else:
                return 'exploration'
        except:
            return 'survival'

    def _collect_nearby_entities(self, game, max_distance=3):
        """æ”¶é›†é™„è¿‘çš„å®ä½“ä¿¡æ¯"""
        try:
            nearby_entities = []
            
            # æ”¶é›†é™„è¿‘åŠ¨ç‰©
            for animal in game.game_map.animals:
                distance = abs(animal.x - self.x) + abs(animal.y - self.y)
                if distance <= max_distance:
                    nearby_entities.append({
                        'type': animal.type,
                        'x': animal.x,
                        'y': animal.y,
                        'position': (animal.x, animal.y),
                        'distance': distance
                    })
            
            # æ”¶é›†é™„è¿‘æ¤ç‰©
            for plant in game.game_map.plants:
                distance = abs(plant.x - self.x) + abs(plant.y - self.y)
                if distance <= max_distance:
                    nearby_entities.append({
                        'type': plant.__class__.__name__,
                        'x': plant.x,
                        'y': plant.y,
                        'position': (plant.x, plant.y),
                        'distance': distance
                    })
            
            return nearby_entities
        except:
            return []

    def _capture_current_state(self):
        """æ•è·å½“å‰çŠ¶æ€å¿«ç…§"""
        return {
            'health': self.health,
            'food': self.food,
            'water': self.water,
            'position': (self.x, self.y)
        }

    def _execute_planned_action(self, action, game):
        """æ‰§è¡Œè®¡åˆ’çš„è¡ŒåŠ¨"""
        try:
            # æ‰§è¡Œè¡ŒåŠ¨
            if hasattr(self, '_execute_action'):
                self._execute_action(action)
            
            # è¿”å›æ‰§è¡Œç»“æœ
            result = {'success': True, 'action': action}
            return result
        except Exception as e:
            return {'success': False, 'error': str(e), 'action': action}

    def _record_cdl_experience(self, action, context_state, success):
        """è®°å½•CDLç»éªŒ"""
        try:
            cdl_result = {
                'success': success,
                'action_type': action,
                'decision_source': 'cdl_exploration',
                'context': context_state
            }
            self.add_eocar_experience(action, cdl_result, source="cdl_exploration")
        except Exception as e:
            if logger:
                logger.log(f"{self.name} CDLç»éªŒè®°å½•å¤±è´¥: {str(e)}")

    # ============================================================================
    # WBMæœ¨æ¡¥æ¨¡å‹è¾…åŠ©æ–¹æ³• (æ–°å¢)
    # ============================================================================
    
    def _get_basic_survival_rules_for_wbm(self):
        """ä¸ºWBMè·å–åŸºç¡€ç”Ÿå­˜è§„å¾‹"""
        try:
            from wooden_bridge_model import Rule
            basic_rules = []
            
            # å¥åº·æ¢å¤è§„å¾‹
            if self.health < 50:
                health_rule = Rule(
                    rule_id="basic_health_recovery",
                    rule_type="action",
                    conditions={'health_level': 'low', 'environment': 'any'},
                    predictions={'action': 'collect_healing_plant', 'expected_result': 'health_increase'},
                    confidence=0.6
                )
                basic_rules.append(health_rule)
            
            # é£Ÿç‰©è·å–è§„å¾‹
            if self.food < 40:
                food_rule = Rule(
                    rule_id="basic_food_acquisition",
                    rule_type="action", 
                    conditions={'resource_status': 'depleted', 'environment': 'any'},
                    predictions={'action': 'collect_food_plant', 'expected_result': 'food_increase'},
                    confidence=0.7
                )
                basic_rules.append(food_rule)
            
            # å¨èƒè§„é¿è§„å¾‹ - ğŸ”§ ä¿®å¤ï¼šç§»é™¤æœªå®šä¹‰çš„contextå˜é‡
            threat_rule = Rule(
                rule_id="environmental_threat_assessment_and_response",
                rule_type="cognitive_action",
                conditions={
                    'threats_nearby': True,
                    'environment_type': 'unknown',  # ä¿®å¤ï¼šä½¿ç”¨å›ºå®šå€¼
                    'threat_level': 1  # ä¿®å¤ï¼šä½¿ç”¨å›ºå®šå€¼
                },
                predictions={
                    'assessment_action': 'analyze_threat_characteristics',
                    'primary_response': 'implement_context_appropriate_avoidance',
                    'expected_result': 'threat_neutralization_or_avoidance',
                    'secondary_actions': ['secure_escape_route', 'monitor_threat_movement']
                },
                confidence=0.8
            )
            basic_rules.append(threat_rule)
            
            # æ¢ç´¢è§„å¾‹
            explore_rule = Rule(
                rule_id="basic_exploration",
                rule_type="action",
                conditions={'resource_status': 'adequate', 'threats_nearby': False},
                predictions={'action': 'explore_new_area', 'expected_result': 'knowledge_gain'},
                confidence=0.5
            )
            basic_rules.append(explore_rule)
            
            return basic_rules
            
        except Exception as e:
            if hasattr(self, 'logger') and self.logger:
                self.logger.log(f"{self.name} åŸºç¡€è§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []
    
    def _convert_target_goal_to_wbm_goal(self, target_goal):
        """å°†ç›®æ ‡è½¬æ¢ä¸ºWBM Goalå¯¹è±¡"""
        try:
            from wooden_bridge_model import Goal, GoalType
            
            # æ ¹æ®ç›®æ ‡ç±»å‹è½¬æ¢
            goal_type = GoalType.EXPLORATION  # é»˜è®¤
            if target_goal.get('type') == 'health_recovery':
                goal_type = GoalType.SURVIVAL
            elif target_goal.get('type') in ['food_acquisition', 'water_acquisition']:
                goal_type = GoalType.RESOURCE_ACQUISITION
            elif target_goal.get('type') == 'threat_avoidance':
                goal_type = GoalType.THREAT_AVOIDANCE
            elif target_goal.get('type') == 'exploration':
                goal_type = GoalType.EXPLORATION
                
            wbm_goal = Goal(
                goal_type=goal_type,
                description=target_goal.get('description', 'Unknown goal'),
                priority=target_goal.get('priority', 0.5),
                urgency=target_goal.get('urgency', 0.5),
                context=target_goal.get('context', {})
            )
            
            return wbm_goal
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} ç›®æ ‡è½¬æ¢å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤æ¢ç´¢ç›®æ ‡
            from wooden_bridge_model import Goal, GoalType
            return Goal(
                goal_type=GoalType.EXPLORATION,
                description="é»˜è®¤æ¢ç´¢",
                priority=0.5,
                urgency=0.3
            )
    
    def _get_current_wbm_state(self, game):
        """è·å–å½“å‰WBMçŠ¶æ€"""
        try:
            threats = self.detect_threats(game.game_map)
            nearby_resources = self._get_nearby_resources(game)
            
            state = {
                'health': self.health,
                'food': self.food,
                'water': self.water,
                'position': (self.x, self.y),
                'environment': self._get_current_environment_type(game),
                'threats_nearby': len(threats) > 0,
                'threat_count': len(threats),
                'resources_nearby': len(nearby_resources) > 0,
                'resource_count': len(nearby_resources),
                'status': 'critical' if self.health < 30 else 'low' if self.health < 60 else 'good'
            }
            
            return state
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} WBMçŠ¶æ€è·å–å¤±è´¥: {str(e)}")
            return {
                'health': self.health,
                'position': (self.x, self.y),
                'status': 'unknown'
            }
    
    def _extract_wbm_target_state(self, target_goal, game):
        """æå–WBMç›®æ ‡çŠ¶æ€"""
        try:
            goal_type = target_goal.get('type', 'exploration')
            
            if goal_type == 'health_recovery':
                return {
                    'health': min(100, self.health + 30),
                    'status': 'healthy',
                    'safety': 'secured'
                }
            elif goal_type == 'food_acquisition':
                return {
                    'food': min(100, self.food + 40),
                    'resource_status': 'adequate',
                    'hunger': 'satisfied'
                }
            elif goal_type == 'water_acquisition':
                return {
                    'water': min(100, self.water + 40),
                    'resource_status': 'adequate',
                    'thirst': 'quenched'
                }
            elif goal_type == 'threat_avoidance':
                return {
                    'threats_nearby': False,
                    'safety': 'secured',
                    'status': 'safe'
                }
            else:  # exploration
                return {
                    'knowledge': 'expanded',
                    'area': 'explored',
                    'discovery': 'made'
                }
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} WBMç›®æ ‡çŠ¶æ€æå–å¤±è´¥: {str(e)}")
            return {'goal_achieved': True}
    
    def _extract_action_from_rule(self, rule, target_goal):
        """ä»è§„å¾‹ä¸­æå–è¡ŒåŠ¨å»ºè®®ï¼ˆä¿®å¤ç‰ˆï¼šç¡®ä¿è¡ŒåŠ¨å¯æ‰§è¡Œï¼‰"""
        try:
            # ä»è§„å¾‹çš„predictionsä¸­æå–è¡ŒåŠ¨
            if hasattr(rule, 'predictions') and rule.predictions:
                if 'action' in rule.predictions:
                    raw_action = rule.predictions['action']
                    # è½¬æ¢ä¸ºå¯æ‰§è¡Œæ ¼å¼
                    executable_action = self._convert_to_executable_action(raw_action, target_goal)
                    if executable_action:
                        return executable_action
                elif 'move' in rule.predictions:
                    return self._convert_move_to_executable_action(rule.predictions['move'])
                elif 'behavior' in rule.predictions:
                    return self._convert_behavior_to_executable_action(rule.predictions['behavior'])
            
            # ğŸ”§ ä¿®å¤ï¼šé’ˆå¯¹CDLç›®æ ‡ç±»å‹çš„ä¸“é—¨å¤„ç†
            goal_type = target_goal.get('type', 'exploration')
            if goal_type == 'cdl_exploration':
                # CDLæ¢ç´¢ç›®æ ‡ç›´æ¥æ˜ å°„åˆ°å¯æ‰§è¡Œè¡ŒåŠ¨
                return self._get_cdl_exploration_action(target_goal)
            
            # ğŸ”§ ä¿®å¤ï¼šå¢åŠ åŸºäºè§„å¾‹ç±»å‹çš„å¤šæ ·åŒ–åŠ¨ä½œç”Ÿæˆ
            if hasattr(rule, 'rule_type'):
                rule_type = rule.rule_type
                
                # åŸºäºè§„å¾‹ç±»å‹ç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œ
                executable_action = self._generate_executable_actions_from_rule_type(rule_type, goal_type, rule)
                if executable_action:
                    return executable_action
            
            # æ ¹æ®ç›®æ ‡ç±»å‹æ¨æ–­è¡ŒåŠ¨ï¼ˆç¡®ä¿å¯æ‰§è¡Œï¼‰
            if goal_type == 'health_recovery':
                return 'collect_plant'  # ç®€åŒ–ä¸ºå¯æ‰§è¡Œè¡ŒåŠ¨
            elif goal_type == 'food_acquisition':
                return 'collect_plant'  # é£Ÿç‰©é‡‡é›†
            elif goal_type == 'water_acquisition':
                return 'drink_water'    # æ°´æºè¡¥å……
            elif goal_type == 'threat_avoidance':
                return 'escape'         # å¨èƒé€ƒé¿
            else:
                return 'move_up'        # é»˜è®¤ç§»åŠ¨è¡ŒåŠ¨
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è§„å¾‹è¡ŒåŠ¨æå–å¤±è´¥: {str(e)}")
            return 'move_up'  # å®‰å…¨çš„é»˜è®¤è¡ŒåŠ¨

    def _convert_to_executable_action(self, raw_action, target_goal):
        """å°†åŸå§‹è¡ŒåŠ¨è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„æ ‡å‡†æ ¼å¼"""
        try:
            # è¡ŒåŠ¨æ˜ å°„è¡¨ï¼šåŸå§‹è¡ŒåŠ¨ -> å¯æ‰§è¡Œè¡ŒåŠ¨
            action_mapping = {
                # ç§»åŠ¨ç±»
                'explore': 'move_up',
                'explore_random_direction': 'move_up', 
                'move': 'move_up',
                'explore_new_area': 'move_right',
                'investigate_object': 'move_down',
                'map_territory': 'move_left',
                
                # é‡‡é›†ç±»
                'collect': 'collect_plant',
                'gather': 'collect_plant',
                'collect_plant': 'collect_plant',
                'collect_food': 'collect_plant',
                'collect_healing_plant': 'collect_plant',
                'gather_food': 'collect_plant',
                'hunt_animal': 'attack_animal',
                
                # æ°´æºç±»
                'drink': 'drink_water',
                'drink_water': 'drink_water',
                'find_water': 'drink_water',
                
                # æ”»å‡»ç±»
                'attack': 'attack_animal',
                'hunt': 'attack_animal',
                'attack_animal': 'attack_animal',
                
                # é€ƒè·‘ç±»
                'flee': 'escape',
                'escape': 'escape',
                'run_away': 'escape',
                'avoid_danger': 'escape'
            }
            
            # ç›´æ¥æ˜ å°„
            if raw_action in action_mapping:
                return action_mapping[raw_action]
            
            # æ¨¡ç³ŠåŒ¹é…
            raw_lower = raw_action.lower()
            for key, value in action_mapping.items():
                if key in raw_lower:
                    return value
            
            # å…³é”®è¯åŒ¹é…
            if any(word in raw_lower for word in ['move', 'go', 'walk', 'explore']):
                return 'move_up'
            elif any(word in raw_lower for word in ['collect', 'gather', 'pick']):
                return 'collect_plant'
            elif any(word in raw_lower for word in ['drink', 'water']):
                return 'drink_water'
            elif any(word in raw_lower for word in ['attack', 'hunt', 'kill']):
                return 'attack_animal'
            elif any(word in raw_lower for word in ['flee', 'escape', 'run']):
                return 'escape'
            
            return None
            
        except Exception:
            return None

    def _get_cdl_exploration_action(self, target_goal):
        """è·å–CDLæ¢ç´¢ç›®æ ‡çš„å¯æ‰§è¡Œè¡ŒåŠ¨"""
        try:
            # ä»CDLç›®æ ‡çš„ä¸Šä¸‹æ–‡ä¸­æå–EOCATRä¿¡æ¯
            context = target_goal.get('context', {})
            eocatr_action = context.get('eocatr_action', 'move')
            eocatr_object = context.get('eocatr_object', 'area')
            
            # åŸºäºEOCATRè¡ŒåŠ¨ç±»å‹é€‰æ‹©å¯æ‰§è¡Œè¡ŒåŠ¨
            if eocatr_action == 'move':
                # éšæœºé€‰æ‹©ç§»åŠ¨æ–¹å‘
                import random
                return random.choice(['move_up', 'move_down', 'move_left', 'move_right'])
            elif eocatr_action == 'interact':
                if 'animal' in eocatr_object or 'rabbit' in eocatr_object:
                    return 'attack_animal'
                else:
                    return 'collect_plant'
            elif eocatr_action == 'use':
                return 'attack_animal'  # ä½¿ç”¨å·¥å…·é€šå¸¸æ„å‘³ç€æ”»å‡»
            elif eocatr_action == 'observe':
                return 'move_up'  # è§‚å¯Ÿé€šè¿‡ç§»åŠ¨å®ç°
            elif eocatr_action == 'search':
                return 'collect_plant'  # æœç´¢é€šè¿‡é‡‡é›†å®ç°
            else:
                return 'move_up'  # é»˜è®¤ç§»åŠ¨
                
        except Exception:
            return 'move_up'

    def _generate_executable_actions_from_rule_type(self, rule_type, goal_type, rule):
        """åŸºäºè§„å¾‹ç±»å‹ç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œ"""
        try:
            import random
            
            # è§„å¾‹ç±»å‹ä¸å¯æ‰§è¡ŒåŠ¨ä½œçš„æ˜ å°„
            rule_action_mapping = {
                'survival': ['collect_plant', 'drink_water', 'move_up'],
                'exploration': ['move_up', 'move_down', 'move_left', 'move_right'],
                'resource_gathering': ['collect_plant', 'attack_animal', 'drink_water'],
                'threat_response': ['escape', 'move_up', 'move_down'],
                'social': ['move_up', 'move_right'],  # ç®€åŒ–ä¸ºç§»åŠ¨
                'environmental': ['collect_plant', 'drink_water'],
                'BMP_validated': ['collect_plant', 'move_up'],
                'BMP_candidate': ['move_left', 'move_right']
            }
            
            # è·å–åŸºç¡€åŠ¨ä½œåˆ—è¡¨
            base_actions = rule_action_mapping.get(str(rule_type), rule_action_mapping.get('survival', ['move_up']))
            
            # æ ¹æ®ç›®æ ‡ç±»å‹è¿‡æ»¤åŠ¨ä½œ
            if goal_type == 'cdl_exploration':
                # CDLæ¢ç´¢åå‘ç§»åŠ¨
                movement_actions = ['move_up', 'move_down', 'move_left', 'move_right']
                filtered_actions = [action for action in base_actions if action in movement_actions]
                if filtered_actions:
                    return random.choice(filtered_actions)
            
            return random.choice(base_actions) if base_actions else 'move_up'
            
        except Exception:
            return 'move_up'

    def _convert_move_to_executable_action(self, move_action):
        """è½¬æ¢ç§»åŠ¨è¡ŒåŠ¨ä¸ºå¯æ‰§è¡Œæ ¼å¼"""
        try:
            move_mapping = {
                'up': 'move_up',
                'down': 'move_down', 
                'left': 'move_left',
                'right': 'move_right',
                'north': 'move_up',
                'south': 'move_down',
                'west': 'move_left',
                'east': 'move_right'
            }
            
            move_str = str(move_action).lower()
            for key, value in move_mapping.items():
                if key in move_str:
                    return value
            
            return 'move_up'  # é»˜è®¤å‘ä¸Šç§»åŠ¨
            
        except Exception:
            return 'move_up'

    def _convert_behavior_to_executable_action(self, behavior_action):
        """è½¬æ¢è¡Œä¸ºæè¿°ä¸ºå¯æ‰§è¡Œæ ¼å¼"""
        try:
            behavior_str = str(behavior_action).lower()
            
            if any(word in behavior_str for word in ['collect', 'gather', 'pick']):
                return 'collect_plant'
            elif any(word in behavior_str for word in ['attack', 'hunt', 'fight']):
                return 'attack_animal'
            elif any(word in behavior_str for word in ['drink', 'water']):
                return 'drink_water'
            elif any(word in behavior_str for word in ['escape', 'flee', 'run']):
                return 'escape'
            elif any(word in behavior_str for word in ['move', 'go', 'walk']):
                return 'move_up'
            else:
                return 'move_up'  # é»˜è®¤ç§»åŠ¨
                
        except Exception:
            return 'move_up'
    
    def _generate_diverse_actions_from_rule_type(self, rule_type, goal_type, rule):
        """åŸºäºè§„å¾‹ç±»å‹å’Œç›®æ ‡ç±»å‹ç”Ÿæˆå¤šæ ·åŒ–åŠ¨ä½œ"""
        try:
            import random
            
            # è§„å¾‹ç±»å‹ä¸åŠ¨ä½œçš„æ˜ å°„
            rule_action_mapping = {
                'survival': ['explore', 'collect_plant', 'find_shelter', 'search_water'],
                'exploration': ['explore_new_area', 'investigate_object', 'search_resources', 'map_territory'],
                'resource_gathering': ['collect_plant', 'hunt_animal', 'gather_materials', 'search_water'],
                'threat_response': ['flee_from_danger', 'hide_from_predator', 'find_safe_spot', 'climb_tree'],
                'social': ['share_information', 'seek_help', 'form_alliance', 'follow_leader'],
                'environmental': ['adapt_to_weather', 'find_shelter', 'conserve_energy', 'migrate'],
                'BMP_validated': ['apply_learned_pattern', 'use_successful_strategy', 'repeat_effective_action'],
                'BMP_candidate': ['test_new_approach', 'experiment_with_variation', 'try_alternative_method']
            }
            
            # ç›®æ ‡ç±»å‹ä¿®é¥°ç¬¦
            goal_modifiers = {
                'threat_avoidance': ['quick_', 'safe_', 'evasive_', 'defensive_'],
                'exploration': ['curious_', 'systematic_', 'bold_', 'careful_'],
                'food_acquisition': ['efficient_', 'targeted_', 'opportunistic_'],
                'water_acquisition': ['urgent_', 'systematic_', 'cautious_'],
                'health_recovery': ['gentle_', 'restorative_', 'healing_']
            }
            
            # è·å–åŸºç¡€åŠ¨ä½œåˆ—è¡¨
            base_actions = rule_action_mapping.get(rule_type, rule_action_mapping.get('survival', []))
            if not base_actions:
                return None
            
            # é€‰æ‹©ä¸€ä¸ªåŸºç¡€åŠ¨ä½œ
            base_action = random.choice(base_actions)
            
            # æ·»åŠ ç›®æ ‡ä¿®é¥°ç¬¦
            modifiers = goal_modifiers.get(goal_type, [''])
            if modifiers and modifiers[0]:  # å¦‚æœæœ‰éç©ºä¿®é¥°ç¬¦
                modifier = random.choice(modifiers)
                enhanced_action = f"{modifier}{base_action}"
            else:
                enhanced_action = base_action
            
            return enhanced_action
            
        except Exception as e:
            return None
    
    def _generate_threat_avoidance_action(self, target_goal, rule):
        """ç”Ÿæˆå¤šæ ·åŒ–çš„å¨èƒè§„é¿åŠ¨ä½œ"""
        try:
            import random
            
            # å¨èƒè§„é¿çš„å¤šæ ·åŒ–åŠ¨ä½œ
            threat_actions = [
                'move_away_from_danger',
                'find_safe_hiding_spot', 
                'climb_to_safety',
                'retreat_to_known_area',
                'use_environment_for_cover',
                'create_distraction_and_escape',
                'seek_group_protection',
                'take_defensive_position',
                'use_tools_for_protection',
                'flee_to_water_source',
                'hide_behind_large_object',
                'move_in_zigzag_pattern'
            ]
            
            # åŸºäºä¸Šä¸‹æ–‡é€‰æ‹©æ›´åˆé€‚çš„åŠ¨ä½œ
            context = target_goal.get('context', {})
            threat_count = context.get('threat_count', 1)
            
            if threat_count > 1:
                # å¤šå¨èƒæƒ…å†µï¼Œä¼˜å…ˆé€‰æ‹©éšè—å’Œé˜²å¾¡
                preferred_actions = [
                    'find_safe_hiding_spot',
                    'take_defensive_position', 
                    'seek_group_protection',
                    'use_environment_for_cover'
                ]
                return random.choice(preferred_actions)
            else:
                # å•å¨èƒæƒ…å†µï¼Œå¯ä»¥é€‰æ‹©æ›´å¤šæ ·åŒ–çš„ç­–ç•¥
                return random.choice(threat_actions)
                
        except Exception as e:
            # ğŸ”§ é‡æ„ï¼šæ™ºèƒ½å›é€€åŠ¨ä½œç”Ÿæˆ
            if hasattr(goal, 'goal_type'):
                if goal.goal_type.value == 'threat_avoidance':
                    return 'assess_and_respond_to_immediate_threats'
                elif goal.goal_type.value == 'resource_acquisition':
                    return 'search_and_evaluate_available_resources'
                elif goal.goal_type.value == 'exploration':
                    return 'conduct_systematic_area_survey'
                else:
                    return 'observe_environment_and_plan_response'
            else:
                return 'analyze_situation_and_determine_optimal_action'

    def _extract_action_from_rule_chain(self, rule_chain, target_goal):
        """ä»è§„å¾‹é“¾ä¸­æå–ç¬¬ä¸€ä¸ªå¯æ‰§è¡ŒåŠ¨ä½œ"""
        try:
            if not rule_chain:
                return None
            
            # ä»ç¬¬ä¸€ä¸ªè§„å¾‹å¼€å§‹æå–åŠ¨ä½œ
            first_rule = rule_chain[0]
            return self._extract_action_from_rule(first_rule, target_goal)
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"è§„å¾‹é“¾åŠ¨ä½œæå–å¤±è´¥: {str(e)}")
            return None

    def _convert_bmp_rule_to_wbm_rule(self, bmp_rule, context):
        """å°†BMPè§„å¾‹è½¬æ¢ä¸ºWBMè§„å¾‹æ ¼å¼"""
        try:
            from wooden_bridge_model import Rule
            
            # å¦‚æœå·²ç»æ˜¯WBM Ruleæ ¼å¼ï¼Œç›´æ¥è¿”å›
            if hasattr(bmp_rule, '__class__') and bmp_rule.__class__.__name__ == 'Rule':
                return bmp_rule
            
            # ä»BMPè§„å¾‹ä¸­æå–ä¿¡æ¯
            rule_id = getattr(bmp_rule, 'rule_id', f"converted_{id(bmp_rule)}")
            rule_type = getattr(bmp_rule, 'rule_type', 'survival')
            conditions = getattr(bmp_rule, 'conditions', {})
            predictions = getattr(bmp_rule, 'predictions', {})
            confidence = getattr(bmp_rule, 'confidence', 0.5)
            
            # åˆ›å»ºWBM Ruleå¯¹è±¡
            wbm_rule = Rule(
                rule_id=rule_id,
                rule_type=rule_type,
                conditions=conditions,
                predictions=predictions,
                confidence=confidence
            )
            
            return wbm_rule
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"BMPè§„å¾‹è½¬æ¢å¤±è´¥: {str(e)}")
            return None

    def _is_basic_rule_applicable(self, rule, current_context, target_goal):
        """æ£€æŸ¥åŸºç¡€è§„å¾‹æ˜¯å¦é€‚ç”¨äºå½“å‰æƒ…å†µ"""
        try:
            if not rule or not hasattr(rule, 'conditions'):
                return False
            
            conditions = rule.conditions
            if isinstance(conditions, dict):
                # æ£€æŸ¥ç¯å¢ƒåŒ¹é…
                if 'environment' in conditions and 'environment' in current_context:
                    if conditions['environment'] != current_context['environment']:
                        return False
                
                # æ£€æŸ¥å¥åº·çŠ¶æ€åŒ¹é…
                if 'health_level' in conditions and 'health_level' in current_context:
                    if conditions['health_level'] != current_context['health_level']:
                        return False
                
                # æ£€æŸ¥ç›®æ ‡ç›¸å…³æ€§
                if hasattr(rule, 'target_goals'):
                    if target_goal not in rule.target_goals:
                        return False
            
            return True
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"åŸºç¡€è§„å¾‹é€‚ç”¨æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    def _extract_action_from_basic_rule(self, rule, target_goal):
        """ä»åŸºç¡€è§„å¾‹ä¸­æå–åŠ¨ä½œ"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨é€šç”¨çš„åŠ¨ä½œæå–æ–¹æ³•
            action = self._extract_action_from_rule(rule, target_goal)
            if action and action != 'explore_random_direction':
                return action
            
            # å¦‚æœè§„å¾‹æœ‰ç‰¹å®šçš„åŠ¨ä½œæ˜ å°„
            if hasattr(rule, 'action_mapping') and target_goal in rule.action_mapping:
                return rule.action_mapping[target_goal]
            
            # é»˜è®¤åŠ¨ä½œæ˜ å°„
            default_actions = {
                'food_acquisition': 'collect_plant',
                'water_acquisition': 'explore',
                'threat_avoidance': 'explore',
                'health_recovery': 'collect_plant',
                'survival': 'explore'
            }
            
            return default_actions.get(target_goal, 'explore')
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"åŸºç¡€è§„å¾‹åŠ¨ä½œæå–å¤±è´¥: {str(e)}")
            return 'explore'
    
    # ============================================================================
    # EOCATRç³»ç»ŸçŠ¶æ€æŸ¥è¯¢æ–¹æ³• (æ–°å¢)
    # ============================================================================
    
    def get_eocatr_system_status(self) -> dict:
        """
        è·å–EOCATRç³»ç»Ÿå®Œæ•´çŠ¶æ€æŠ¥å‘Š
        
        Returns:
            åŒ…å«ç³»ç»ŸçŠ¶æ€çš„è¯¦ç»†å­—å…¸
        """
        status_report = {
            'system_initialized': self.eocatr_initialized,
            'generation_timestamp': time.time(),
            'components_status': {},
            'generation_statistics': {},
            'matrix_coverage': {},
            'system_health': 'unknown'
        }
        
        try:
            # 1. ç»„ä»¶çŠ¶æ€æ£€æŸ¥
            status_report['components_status'] = {
                'five_library_system': {
                    'active': self.five_library_system_active,
                    'initialized': self.five_library_system is not None
                },
                'bmp_system': {
                    'active': hasattr(self, 'bmp') and self.bmp is not None,
                    'initialized': hasattr(self, 'bmp')
                },
                'eocatr_generation': {
                    'active': self.eocatr_initialized,
                    'stats_available': hasattr(self, 'eocatr_generation_stats')
                }
            }
            
            # 2. ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            if hasattr(self, 'eocatr_generation_stats'):
                status_report['generation_statistics'] = dict(self.eocatr_generation_stats)
            
            # 3. BMPç³»ç»Ÿè§„å¾‹ç»Ÿè®¡
            if hasattr(self, 'bmp') and self.bmp is not None:
                try:
                    bmp_stats = self.bmp.get_eocatr_generation_statistics()
                    status_report['bmp_statistics'] = bmp_stats
                except:
                    status_report['bmp_statistics'] = {'error': 'BMPç»Ÿè®¡æŸ¥è¯¢å¤±è´¥'}
            
            # 4. äº”åº“ç³»ç»ŸçŸ©é˜µç»Ÿè®¡
            if self.five_library_system_active and self.five_library_system:
                try:
                    matrix_stats = self.five_library_system.get_eocatr_matrix_statistics()
                    status_report['matrix_coverage'] = matrix_stats
                    
                    # å®Œæ•´æ€§éªŒè¯
                    if hasattr(self, 'bmp') and self.bmp is not None:
                        bmp_stats = status_report.get('bmp_statistics', {})
                        completeness = self.five_library_system.validate_eocatr_matrix_completeness(bmp_stats)
                        status_report['completeness_validation'] = completeness
                except:
                    status_report['matrix_coverage'] = {'error': 'äº”åº“ç³»ç»Ÿç»Ÿè®¡æŸ¥è¯¢å¤±è´¥'}
            
            # 5. ç³»ç»Ÿå¥åº·çŠ¶æ€è¯„ä¼°
            health_score = 0
            max_score = 4
            
            if status_report['components_status']['five_library_system']['active']:
                health_score += 1
            if status_report['components_status']['bmp_system']['active']:
                health_score += 1
            if status_report['components_status']['eocatr_generation']['active']:
                health_score += 1
            if status_report['generation_statistics'].get('total_generated', 0) > 0:
                health_score += 1
            
            health_percentage = (health_score / max_score) * 100
            
            if health_percentage >= 100:
                status_report['system_health'] = 'excellent'
            elif health_percentage >= 75:
                status_report['system_health'] = 'good'
            elif health_percentage >= 50:
                status_report['system_health'] = 'fair'
            elif health_percentage >= 25:
                status_report['system_health'] = 'poor'
            else:
                status_report['system_health'] = 'critical'
            
            status_report['health_score'] = f"{health_score}/{max_score} ({health_percentage:.1f}%)"
            
        except Exception as e:
            status_report['error'] = str(e)
            status_report['system_health'] = 'error'
        
        return status_report
    
    def get_eocatr_rule_coverage_report(self) -> dict:
        """
        è·å–EOCATRè§„å¾‹è¦†ç›–ç‡è¯¦ç»†æŠ¥å‘Š
        
        Returns:
            åŒ…å«è§„å¾‹è¦†ç›–æƒ…å†µçš„è¯¦ç»†å­—å…¸
        """
        coverage_report = {
            'report_timestamp': time.time(),
            'theoretical_total': 0,
            'generated_total': 0,
            'coverage_percentage': 0.0,
            'rule_type_breakdown': {},
            'matrix_dimension_coverage': {},
            'quality_assessment': {}
        }
        
        try:
            # è·å–ç†è®ºè§„å¾‹æ€»æ•°
            if self.five_library_system_active and self.five_library_system:
                matrix_stats = self.five_library_system.get_eocatr_matrix_statistics()
                coverage_report['theoretical_total'] = matrix_stats.get('total_theoretical_rules', 0)
                coverage_report['matrix_dimension_coverage'] = matrix_stats.get('matrix_dimensions', {})
            
            # è·å–å·²ç”Ÿæˆè§„å¾‹æ•°é‡
            if hasattr(self, 'eocatr_generation_stats'):
                coverage_report['generated_total'] = self.eocatr_generation_stats.get('total_generated', 0)
            
            # è®¡ç®—è¦†ç›–ç‡
            if coverage_report['theoretical_total'] > 0:
                coverage_report['coverage_percentage'] = (
                    coverage_report['generated_total'] / coverage_report['theoretical_total']
                ) * 100
            
            # BMPè§„å¾‹ç±»å‹åˆ†æ
            if hasattr(self, 'bmp') and self.bmp is not None:
                try:
                    bmp_stats = self.bmp.get_eocatr_generation_statistics()
                    if 'systematic_eocatr_rules' in bmp_stats:
                        coverage_report['rule_type_breakdown'] = bmp_stats['systematic_eocatr_rules']
                except:
                    coverage_report['rule_type_breakdown'] = {'error': 'BMPè§„å¾‹åˆ†æå¤±è´¥'}
            
            # è´¨é‡è¯„ä¼°
            coverage_percentage = coverage_report['coverage_percentage']
            if coverage_percentage >= 90:
                coverage_report['quality_assessment'] = {
                    'level': 'excellent',
                    'description': 'è¦†ç›–ç‡ä¼˜ç§€,ç³»ç»Ÿæ€§è§„å¾‹ç”Ÿæˆå®Œæ•´'
                }
            elif coverage_percentage >= 70:
                coverage_report['quality_assessment'] = {
                    'level': 'good',
                    'description': 'è¦†ç›–ç‡è‰¯å¥½,åŸºæœ¬æ»¡è¶³å†³ç­–éœ€æ±‚'
                }
            elif coverage_percentage >= 50:
                coverage_report['quality_assessment'] = {
                    'level': 'fair',
                    'description': 'è¦†ç›–ç‡ä¸­ç­‰,å¯èƒ½å½±å“å†³ç­–è´¨é‡'
                }
            elif coverage_percentage >= 25:
                coverage_report['quality_assessment'] = {
                    'level': 'poor',
                    'description': 'è¦†ç›–ç‡åä½,éœ€è¦æ”¹è¿›è§„å¾‹ç”Ÿæˆ'
                }
            else:
                coverage_report['quality_assessment'] = {
                    'level': 'critical',
                    'description': 'è¦†ç›–ç‡æä½,ç³»ç»Ÿå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ'
                }
            
        except Exception as e:
            coverage_report['error'] = str(e)
            coverage_report['quality_assessment'] = {
                'level': 'error',
                'description': f'æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}'
            }
        
        return coverage_report
    
    def print_eocatr_status_summary(self):
        """
        æ‰“å°EOCATRç³»ç»ŸçŠ¶æ€æ‘˜è¦(ç”¨äºè°ƒè¯•å’Œç›‘æ§)
        """
        if not logger:
            return
        
        try:
            status = self.get_eocatr_system_status()
            coverage = self.get_eocatr_rule_coverage_report()
            
            logger.log(f"\n=== {self.name} EOCATRç³»ç»ŸçŠ¶æ€æ‘˜è¦ ===")
            logger.log(f"ç³»ç»Ÿåˆå§‹åŒ–: {'âœ…' if status['system_initialized'] else 'âŒ'}")
            logger.log(f"ç³»ç»Ÿå¥åº·åº¦: {status['health_score']} ({status['system_health']})")
            
            logger.log(f"\nç»„ä»¶çŠ¶æ€:")
            components = status['components_status']
            logger.log(f"  äº”åº“ç³»ç»Ÿ: {'âœ…' if components['five_library_system']['active'] else 'âŒ'}")
            logger.log(f"  BMPç³»ç»Ÿ: {'âœ…' if components['bmp_system']['active'] else 'âŒ'}")
            logger.log(f"  EOCATRç”Ÿæˆ: {'âœ…' if components['eocatr_generation']['active'] else 'âŒ'}")
            
            logger.log(f"\nè§„å¾‹è¦†ç›–æƒ…å†µ:")
            logger.log(f"  ç†è®ºæ€»æ•°: {coverage['theoretical_total']:,}")
            logger.log(f"  å·²ç”Ÿæˆæ•°: {coverage['generated_total']:,}")
            logger.log(f"  è¦†ç›–ç‡: {coverage['coverage_percentage']:.2f}%")
            logger.log(f"  è´¨é‡è¯„ä¼°: {coverage['quality_assessment']['level']} - {coverage['quality_assessment']['description']}")
            
            if 'generation_statistics' in status and status['generation_statistics']:
                stats = status['generation_statistics']
                logger.log(f"\nç”Ÿæˆç»Ÿè®¡:")
                logger.log(f"  é…ç½®ID: {stats.get('matrix_config_id', 'N/A')}")
                logger.log(f"  ç”Ÿæˆæ—¶é—´: {stats.get('generation_time', 0):.3f}ç§’")
                logger.log(f"  ä¸Šæ¬¡ç”Ÿæˆ: {time.strftime('%H:%M:%S', time.localtime(stats.get('last_generation_timestamp', 0)))}")
            
        except Exception as e:
            logger.log(f"âŒ {self.name} EOCATRçŠ¶æ€æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")

    def _build_eocatr_matrix_config(self, game, goal) -> Dict:
        """æ„å»ºEOCATRçŸ©é˜µé…ç½®"""
        try:
            # æ”¶é›†å½“å‰ç¯å¢ƒä¿¡æ¯
            environments = [self._get_current_environment_type(game)]
            
            # æ”¶é›†å¯è§çš„å¯¹è±¡
            objects = []
            nearby_resources = self._get_nearby_resources(game)
            for resource in nearby_resources:
                objects.append(resource.get('type', 'unknown'))
            
            # æ”¶é›†å¨èƒå¯¹è±¡
            threats = self.detect_threats(game.game_map)
            for threat in threats:
                objects.append(threat.get('type', 'unknown'))
            
            # åŸºäºç›®æ ‡ç±»å‹ç¡®å®šç‰¹å¾
            attributes = []
            if hasattr(goal, 'goal_type'):
                if goal.goal_type.value == 'survival':
                    attributes.extend(['è¡€é‡ä½', 'å±é™©', 'ç´§æ€¥'])
                elif goal.goal_type.value == 'resource_acquisition':
                    attributes.extend(['è·ç¦»è¿‘', 'è¥å…»ä¸°å¯Œ', 'å¯é£Ÿç”¨'])
                elif goal.goal_type.value == 'exploration':
                    attributes.extend(['æœªæ¢ç´¢', 'æ–°é¢–', 'å®‰å…¨'])
                elif goal.goal_type.value == 'threat_avoidance':
                    attributes.extend(['å±é™©', 'è·ç¦»è¿‘', 'å¨èƒé«˜'])
            
            # åŸºäºå½“å‰çŠ¶æ€æ·»åŠ ç‰¹å¾
            if self.health < 30:
                attributes.append('è¡€é‡ä½')
            if self.food < 30:
                attributes.append('è¥å…»ç¼ºä¹')
            if self.water < 30:
                attributes.append('ç¼ºæ°´')
            
            # å®šä¹‰å¯èƒ½çš„è¡ŒåŠ¨
            actions = ['ç§»åŠ¨', 'é‡‡é›†', 'æ”»å‡»', 'é€ƒé¿', 'è§‚å¯Ÿ', 'æ¢ç´¢']
            
            # å®šä¹‰å¯èƒ½çš„å·¥å…·
            tools = ['æ— å·¥å…·', 'çŸ³å¤´', 'æœ¨æ£', 'é™·é˜±']
            
            # å®šä¹‰å¯èƒ½çš„ç»“æœ
            results = ['æˆåŠŸ', 'å¤±è´¥', 'è·å¾—é£Ÿç‰©', 'å—åˆ°ä¼¤å®³', 'æˆåŠŸé€ƒè„±', 'å‘ç°ä¿¡æ¯']
            
            return {
                'environments': environments,
                'objects': list(set(objects)) if objects else ['æœªçŸ¥å¯¹è±¡'],
                'attributes': list(set(attributes)) if attributes else ['æœªçŸ¥ç‰¹å¾'],
                'actions': actions,
                'tools': tools,
                'results': results
            }
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} æ„å»ºEOCATRé…ç½®å¤±è´¥: {str(e)}")
            return {
                'environments': ['å¼€é˜”åœ°'],
                'objects': ['è‰è“', 'è˜‘è‡'],
                'attributes': ['è·ç¦»è¿‘', 'å®‰å…¨'],
                'actions': ['ç§»åŠ¨', 'é‡‡é›†'],
                'tools': ['æ— å·¥å…·'],
                'results': ['æˆåŠŸ', 'å¤±è´¥']
            }

    def _convert_bmp_rule_to_action(self, rule, goal, game) -> str:
        """å°†BMPè§„å¾‹è½¬æ¢ä¸ºWBMå¯æ‰§è¡Œçš„è¡ŒåŠ¨"""
        try:
            # ä»è§„å¾‹çš„é¢„æµ‹ä¸­æå–è¡ŒåŠ¨å»ºè®®
            if hasattr(rule, 'predictions') and rule.predictions:
                # æŸ¥æ‰¾è¡ŒåŠ¨ç›¸å…³çš„é¢„æµ‹
                for key, value in rule.predictions.items():
                    if 'action' in key.lower() or 'move' in key.lower():
                        return str(value)
            
            # ä»è§„å¾‹çš„æ¡ä»¶ä¸­æ¨æ–­è¡ŒåŠ¨
            if hasattr(rule, 'conditions') and rule.conditions:
                for key, value in rule.conditions.items():
                    if key == 'action':
                        return str(value)
            
            # ä»è§„å¾‹çš„æ¨¡å¼ä¸­æå–è¡ŒåŠ¨
            if hasattr(rule, 'pattern') and rule.pattern:
                pattern_lower = rule.pattern.lower()
                if 'é‡‡é›†' in pattern_lower or 'collect' in pattern_lower:
                    return 'gather'
                elif 'æ”»å‡»' in pattern_lower or 'attack' in pattern_lower:
                    return 'attack'
                elif 'é€ƒé¿' in pattern_lower or 'flee' in pattern_lower:
                    return 'flee'
                elif 'ç§»åŠ¨' in pattern_lower or 'move' in pattern_lower:
                    return random.choice(['up', 'down', 'left', 'right'])
                elif 'æ¢ç´¢' in pattern_lower or 'explore' in pattern_lower:
                    return random.choice(['up', 'down', 'left', 'right'])
                elif 'è§‚å¯Ÿ' in pattern_lower or 'observe' in pattern_lower:
                    return 'wait'
            
            # åŸºäºç›®æ ‡ç±»å‹æ¨æ–­è¡ŒåŠ¨
            if hasattr(goal, 'goal_type'):
                if goal.goal_type.value == 'resource_acquisition':
                    # å¦‚æœæœ‰é™„è¿‘çš„èµ„æºï¼Œæœèµ„æºç§»åŠ¨
                    nearby_resources = self._get_nearby_resources(game)
                    if nearby_resources:
                        return 'gather'
                    else:
                        return random.choice(['up', 'down', 'left', 'right'])
                elif goal.goal_type.value == 'threat_avoidance':
                    return 'flee'
                elif goal.goal_type.value == 'exploration':
                    return random.choice(['up', 'down', 'left', 'right'])
            
            # é»˜è®¤è¿”å›æ¢ç´¢è¡ŒåŠ¨
            return random.choice(['up', 'down', 'left', 'right'])
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} BMPè§„å¾‹è½¬æ¢è¡ŒåŠ¨å¤±è´¥: {str(e)}")
            return random.choice(['up', 'down', 'left', 'right'])


#
# æ¸¸æˆä¸»æ§åˆ¶ç±»
#
    def add_eocatr_experience_to_unified_system(self, action, result, context=None):
        """æ·»åŠ EOCATRæ ¼å¼ç»éªŒåˆ°ç»Ÿä¸€ç³»ç»Ÿ"""
        try:
            from eocatr_unified_format import create_unified_eocatr
            
            # æ„å»ºEOCATRç»éªŒ
            eocatr_experience = create_unified_eocatr(
                environment=context.get('environment') if context else self._get_current_environment_detailed(),
                object_name=context.get('object') if context else self._get_current_object_detailed(),
                action=action,
                tool=context.get('tool', 'no_tool') if context else 'no_tool',
                result=result,
                characteristics=context.get('characteristics') if context else self._get_current_characteristics_detailed(),
                player_id=self.name,
                success='success' in result.lower() if isinstance(result, str) else True,
                reward=context.get('reward', 1.0) if context else 1.0
            )
            
            # æ·»åŠ åˆ°BMPç”Ÿæˆå™¨
            if hasattr(self, 'unified_decision_system') and self.unified_decision_system:
                rules = self.unified_decision_system.add_experiences_to_bmp([eocatr_experience])
                
                if self.logger and rules:
                    self.logger.log(f"{self.name} EOCATRç»éªŒç”Ÿæˆäº† {len(rules)} ä¸ªæ–°è§„å¾‹")
            
            # åŒæ—¶æ·»åŠ åˆ°äº”åº“ç³»ç»Ÿ
            if hasattr(self, 'five_library_system') and self.five_library_system:
                self.five_library_system.add_experience_to_direct_library(
                    action=action,
                    result=result,
                    context=context or {}
                )
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} EOCATRç»éªŒå¤„ç†å¤±è´¥: {str(e)}")

    def _record_tool_usage(self, tool, target_type, success, damage_or_gain=0):
        """è®°å½•å·¥å…·ä½¿ç”¨æƒ…å†µå¹¶æ›´æ–°å­¦ä¹ ç»éªŒ - æ”¯æŒçœŸå®å­¦ä¹ æœºåˆ¶"""
        # ğŸ§  æ›´æ–°å·¥å…·å­¦ä¹ æ•°æ®ï¼ˆæ ¸å¿ƒå­¦ä¹ æœºåˆ¶ï¼‰
        self._update_tool_learning_data(tool, target_type, success, damage_or_gain)
        
        # ä¿æŒåŸæœ‰ç»Ÿè®¡åŠŸèƒ½
        if not hasattr(self, 'tool_usage_stats'):
            self.tool_usage_stats = {}
        
        tool_name = tool.name if hasattr(tool, 'name') else str(tool)
        
        if tool_name not in self.tool_usage_stats:
            self.tool_usage_stats[tool_name] = {
                'total_uses': 0,
                'successful_uses': 0,
                'target_types': {},
                'total_gain': 0
            }
        
        stats = self.tool_usage_stats[tool_name]
        stats['total_uses'] += 1
        
        if success:
            stats['successful_uses'] += 1
            stats['total_gain'] += damage_or_gain
        
        if target_type not in stats['target_types']:
            stats['target_types'][target_type] = {'uses': 0, 'successes': 0}
        
        stats['target_types'][target_type]['uses'] += 1
        if success:
            stats['target_types'][target_type]['successes'] += 1
        
        # ç»Ÿä¸€æ—¥å¿—æ ¼å¼
        success_rate = (stats['successful_uses'] / stats['total_uses']) * 100
        if hasattr(self, 'logger') and self.logger:
            self.logger.log(f"ğŸ“š è®°å½•{tool_name}{'æ”»å‡»' if 'animal' in target_type else 'é‡‡é›†'}: {target_type} {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # å†™å…¥å·¥å…·ä½¿ç”¨è°ƒè¯•æ–‡ä»¶
        debug_file = f"logs/ilai_{self.name}/tool_usage_debug.txt"
        import os
        os.makedirs(os.path.dirname(debug_file), exist_ok=True)
        
        with open(debug_file, "a", encoding="utf-8") as f:
            f.write(f"ğŸ”§ {self.name} å·¥å…·ä½¿ç”¨: {tool_name} å¯¹ {target_type} "
                   f"æˆåŠŸ={success} æ”¶ç›Š/ä¼¤å®³={damage_or_gain} "
                   f"æ€»æˆåŠŸç‡={success_rate:.1f}%\n")
    
    def _update_tool_learning_data(self, tool, target_type, success, damage_or_gain):
        """æ›´æ–°å·¥å…·å­¦ä¹ æ•°æ® - æ ¸å¿ƒå­¦ä¹ æœºåˆ¶"""
        try:
            tool_name = getattr(tool, 'name', tool.__class__.__name__)
            
            # åˆ›å»ºç»éªŒé”®
            experience_key = (tool_name, target_type)
            
            # åˆå§‹åŒ–æˆ–æ›´æ–°å·¥å…·æ•ˆæœæ•°æ®
            if experience_key not in self.tool_effectiveness:
                self.tool_effectiveness[experience_key] = {
                    'successes': 0,
                    'attempts': 0,
                    'total_damage_or_gain': 0,
                    'effectiveness': 0.5  # åˆå§‹å‡è®¾50%æˆåŠŸç‡
                }
            
            # æ›´æ–°ç»Ÿè®¡æ•°æ®
            data = self.tool_effectiveness[experience_key]
            data['attempts'] += 1
            if success:
                data['successes'] += 1
            data['total_damage_or_gain'] += damage_or_gain
            
            # é‡æ–°è®¡ç®—æ•ˆæœç‡
            data['effectiveness'] = data['successes'] / data['attempts']
            
            # æ›´æ–°å®éªŒè®¡æ•°
            if tool_name not in self.tool_experiment_counts:
                self.tool_experiment_counts[tool_name] = 0
            self.tool_experiment_counts[tool_name] += 1
            
            # ğŸ“ å­¦ä¹ æ—¥å¿—
            if self.logger and data['attempts'] % 5 == 0:  # æ¯5æ¬¡å°è¯•è®°å½•ä¸€æ¬¡å­¦ä¹ è¿›åº¦
                effectiveness_percent = data['effectiveness'] * 100
                self.logger.log(f"ğŸ“ {self.name} å­¦ä¹ è¿›åº¦: {tool_name}å¯¹{target_type}æ•ˆæœç‡{effectiveness_percent:.1f}% ({data['successes']}/{data['attempts']})")
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"âš ï¸ {self.name} å·¥å…·å­¦ä¹ æ•°æ®æ›´æ–°å¤±è´¥: {str(e)}")
    
    def _execute_next_plan_step(self, game):
        """æ‰§è¡Œå¤šæ­¥è®¡åˆ’çš„ä¸‹ä¸€ä¸ªæ­¥éª¤"""
        try:
            if self.current_plan is None or 'steps' not in self.current_plan:
                return {'status': 'failed', 'reason': 'æ— æ•ˆçš„è®¡åˆ’ç»“æ„'}
            
            steps = self.current_plan['steps']
            if self.current_plan_step >= len(steps):
                return {'status': 'completed', 'reason': 'æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ'}
            
            current_step = steps[self.current_plan_step]
            action = current_step.get('action', '')
            
            if logger:
                logger.log(f"{self.name} ğŸ¯ æ‰§è¡Œè®¡åˆ’æ­¥éª¤ {self.current_plan_step + 1}: {action}")
            
            # æ‰§è¡Œå½“å‰æ­¥éª¤çš„è¡ŒåŠ¨
            execution_result = self._execute_planned_action(action, game)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            step_result = {
                'step_index': self.current_plan_step,
                'action': action,
                'success': execution_result.get('success', False),
                'result': execution_result,
                'timestamp': time.time()
            }
            self.plan_execution_history.append(step_result)
            
            # æ£€æŸ¥æ­¥éª¤æ˜¯å¦æˆåŠŸ
            if execution_result.get('success', False):
                self.current_plan_step += 1
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆäº†æ‰€æœ‰æ­¥éª¤
                if self.current_plan_step >= len(steps):
                    return {'status': 'completed', 'reason': 'è®¡åˆ’æ‰§è¡ŒæˆåŠŸ'}
                else:
                    return {'status': 'continue', 'reason': 'æ­¥éª¤æˆåŠŸï¼Œç»§ç»­ä¸‹ä¸€æ­¥'}
            else:
                # æ­¥éª¤å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥é‡è¯•
                self.plan_failure_count += 1
                if self.plan_failure_count >= 3:  # æœ€å¤šé‡è¯•3æ¬¡
                    return {'status': 'failed', 'reason': f'æ­¥éª¤æ‰§è¡Œå¤±è´¥æ¬¡æ•°è¿‡å¤š: {action}'}
                else:
                    return {'status': 'continue', 'reason': f'æ­¥éª¤å¤±è´¥ä½†å¯é‡è¯•: {action}'}
                    
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®¡åˆ’æ­¥éª¤æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return {'status': 'failed', 'reason': f'æ‰§è¡Œå¼‚å¸¸: {str(e)}'}
    
    def _is_plan_still_valid(self, game):
        """æ£€æŸ¥å½“å‰è®¡åˆ’æ˜¯å¦ä»ç„¶æœ‰æ•ˆ"""
        try:
            if self.current_plan is None:
                return False
            
            # æ£€æŸ¥è®¡åˆ’çš„å‰ææ¡ä»¶æ˜¯å¦ä»ç„¶æ»¡è¶³
            plan_goal = self.current_plan.get('goal', {})
            goal_type = plan_goal.get('type', '')
            
            # æ ¹æ®ç›®æ ‡ç±»å‹æ£€æŸ¥æœ‰æ•ˆæ€§
            if goal_type == 'find_food':
                # å¦‚æœé£Ÿç‰©å·²ç»å……è¶³ï¼Œè®¡åˆ’å¯èƒ½ä¸å†å¿…è¦
                if self.food > 70:
                    return False
            elif goal_type == 'find_water':
                # å¦‚æœæ°´åˆ†å·²ç»å……è¶³ï¼Œè®¡åˆ’å¯èƒ½ä¸å†å¿…è¦
                if self.water > 70:
                    return False
            elif goal_type == 'avoid_danger':
                # æ£€æŸ¥å¨èƒæ˜¯å¦ä»ç„¶å­˜åœ¨
                min_threat_distance = self._get_min_threat_distance(game)
                if min_threat_distance > 10:  # å¨èƒå·²ç»è¿œç¦»
                    return False
            
            # æ£€æŸ¥è®¡åˆ’æ˜¯å¦å·²ç»è¿‡æ—¶ï¼ˆè¶…è¿‡5ä¸ªå›åˆï¼‰
            plan_age = time.time() - self.current_plan.get('created_time', 0)
            if plan_age > 300:  # 5åˆ†é’Ÿï¼ˆå‡è®¾æ¯å›åˆ1åˆ†é’Ÿï¼‰
                return False
            
            return True
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®¡åˆ’æœ‰æ•ˆæ€§æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return False
    
    def _reset_plan_state(self):
        """é‡ç½®è®¡åˆ’çŠ¶æ€"""
        try:
            if self.current_plan is not None and logger:
                logger.log(f"{self.name} ğŸ”„ é‡ç½®å¤šæ­¥è®¡åˆ’çŠ¶æ€")
            
            self.current_plan = None
            self.current_plan_step = 0
            self.plan_failure_count = 0
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if len(self.plan_execution_history) > 0:
                total_plans = self.multi_step_stats['plans_created']
                completed_plans = self.multi_step_stats['plans_completed']
                self.multi_step_stats['plan_success_rate'] = completed_plans / total_plans if total_plans > 0 else 0.0
                
                # è®¡ç®—å¹³å‡è®¡åˆ’é•¿åº¦
                if self.plan_execution_history:
                    total_steps = sum(len(plan.get('steps', [])) for plan in [self.current_plan] if plan)
                    self.multi_step_stats['average_plan_length'] = total_steps / total_plans if total_plans > 0 else 0.0
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è®¡åˆ’çŠ¶æ€é‡ç½®å¼‚å¸¸: {str(e)}")
    
    def _generate_multi_step_plan(self, goal, game):
        """åŸºäºBPUç®—æ³•ç”Ÿæˆå¤šæ­¥è§„åˆ’æ¥å®ç°ç›®æ ‡"""
        try:
            if logger:
                logger.log(f"{self.name} ğŸŒ‰ BPUå¼€å§‹é€ æ¡¥: ç›®æ ‡ {goal}")
            
            # ç¬¬1æ­¥: å®šä¹‰èµ·ç‚¹å’Œç»ˆç‚¹
            current_state = self._get_current_state_for_planning(game)
            goal_condition = self._extract_goal_condition(goal)
            
            if logger:
                logger.log(f"{self.name} ğŸ¯ èµ·ç‚¹çŠ¶æ€: {current_state}")
                logger.log(f"{self.name} ğŸ ç›®æ ‡æ¡ä»¶: {goal_condition}")
            
            # ç¬¬2æ­¥: æ”¶é›†æ‰€æœ‰å¯ç”¨çš„"å»ºæ"ï¼ˆè§„å¾‹ï¼‰
            available_rules = self._collect_relevant_rules(goal, current_state)
            
            if not available_rules:
                if logger:
                    logger.log(f"{self.name} âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è§„å¾‹ï¼Œå›é€€åˆ°ç®€å•è®¡åˆ’")
                return self._generate_fallback_plan(goal, game)
            
            if logger:
                logger.log(f"{self.name} ğŸ§± æ”¶é›†åˆ° {len(available_rules)} æ¡ç›¸å…³è§„å¾‹")
            
            # ç¬¬3æ­¥: åŸºäºè§„å¾‹çš„å›¾æœç´¢ç®—æ³•ï¼ˆBPUé€ æ¡¥æ ¸å¿ƒï¼‰
            candidate_plans = self._bpu_bridge_search(current_state, goal_condition, available_rules)
            
            if not candidate_plans:
                if logger:
                    logger.log(f"{self.name} âŒ BPUæœç´¢æœªæ‰¾åˆ°æœ‰æ•ˆè·¯å¾„ï¼Œå›é€€åˆ°ç®€å•è®¡åˆ’")
                return self._generate_fallback_plan(goal, game)
            
            # ç¬¬4æ­¥: ä½¿ç”¨BPUå…¬å¼è¯„ä¼°æ‰€æœ‰å€™é€‰è®¡åˆ’
            best_plan = self._evaluate_plans_with_bpu(candidate_plans, goal)
            
            if best_plan:
                if logger:
                    logger.log(f"{self.name} ğŸ† BPUé€‰æ‹©æœ€ä¼˜è®¡åˆ’: {len(best_plan['steps'])}æ­¥, æ•ˆç”¨åˆ†: {best_plan.get('bpu_score', 0):.2f}")
                return best_plan
            
            return None
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} âš ï¸ BPUå¤šæ­¥è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
                import traceback
                logger.log(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return self._generate_fallback_plan(goal, game)
    
    def _generate_water_seeking_plan(self, game):
        """ç”Ÿæˆå¯»æ‰¾æ°´æºçš„å¤šæ­¥è®¡åˆ’"""
        steps = []
        
        # æ­¥éª¤1: æ¢ç´¢é™„è¿‘å¯»æ‰¾æ°´æº
        steps.append({'action': 'move_up', 'description': 'å‘åŒ—æ¢ç´¢å¯»æ‰¾æ°´æº'})
        steps.append({'action': 'move_right', 'description': 'å‘ä¸œç»§ç»­æœç´¢'})
        steps.append({'action': 'move_down', 'description': 'å‘å—æœç´¢æ°´æº'})
        
        # å¦‚æœåœ¨æ²³æµæˆ–æ± å¡˜é™„è¿‘ï¼Œæ·»åŠ é¥®æ°´æ­¥éª¤
        current_cell = game.game_map.grid[self.y][self.x] if hasattr(game, 'game_map') else 'unknown'
        if current_cell in ['river', 'puddle']:
            steps.append({'action': 'drink_water', 'description': 'åœ¨æ°´æºå¤„é¥®æ°´'})
        
        return steps
    
    def _generate_food_seeking_plan(self, game):
        """ç”Ÿæˆå¯»æ‰¾é£Ÿç‰©çš„å¤šæ­¥è®¡åˆ’"""
        steps = []
        
        # æ­¥éª¤1: ç³»ç»Ÿæ€§æœç´¢é£Ÿç‰©
        steps.append({'action': 'move_left', 'description': 'å‘è¥¿æœç´¢é£Ÿç‰©'})
        steps.append({'action': 'collect_plant', 'description': 'æ”¶é›†å‘ç°çš„æ¤ç‰©'})
        steps.append({'action': 'move_up', 'description': 'ç»§ç»­å‘åŒ—æœç´¢'})
        steps.append({'action': 'collect_plant', 'description': 'æ”¶é›†æ›´å¤šé£Ÿç‰©'})
        
        return steps
    
    def _generate_threat_avoidance_plan(self, game):
        """ç”Ÿæˆå¨èƒè§„é¿çš„å¤šæ­¥è®¡åˆ’"""
        steps = []
        
        # æ£€æµ‹å¨èƒä½ç½®å¹¶åˆ¶å®šé€ƒè·‘è·¯çº¿
        threats = self.detect_threats(game.game_map) if hasattr(self, 'detect_threats') else []
        
        if threats:
            # æ­¥éª¤1: å¿«é€Ÿè¿œç¦»å¨èƒ
            steps.append({'action': 'move_left', 'description': 'å¿«é€Ÿå‘è¥¿é€ƒç¦»å¨èƒ'})
            steps.append({'action': 'move_left', 'description': 'ç»§ç»­è¿œç¦»å¨èƒåŒºåŸŸ'})
            steps.append({'action': 'move_up', 'description': 'å‘å®‰å…¨åŒºåŸŸç§»åŠ¨'})
            # æ­¥éª¤2: å¯»æ‰¾å®‰å…¨ä½ç½®
            steps.append({'action': 'move_up', 'description': 'å¯»æ‰¾æ›´å®‰å…¨çš„ä½ç½®'})
        
        return steps
    
    def _generate_exploration_plan(self, game):
        """ç”Ÿæˆæ¢ç´¢çš„å¤šæ­¥è®¡åˆ’"""
        steps = []
        
        # ç³»ç»Ÿæ€§æ¢ç´¢å‘¨å›´åŒºåŸŸ
        steps.append({'action': 'move_up', 'description': 'å‘åŒ—æ¢ç´¢æœªçŸ¥åŒºåŸŸ'})
        steps.append({'action': 'move_right', 'description': 'å‘ä¸œç»§ç»­æ¢ç´¢'})
        steps.append({'action': 'move_down', 'description': 'å‘å—æ¢ç´¢æ–°åŒºåŸŸ'})
        steps.append({'action': 'move_left', 'description': 'å‘è¥¿å®ŒæˆåŒºåŸŸæ¢ç´¢'})
        
        return steps
    
    def _generate_general_survival_plan(self, game):
        """ç”Ÿæˆé€šç”¨ç”Ÿå­˜è®¡åˆ’"""
        steps = []
        
        # æ ¹æ®å½“å‰çŠ¶æ€åˆ¶å®šè®¡åˆ’
        if self.water < 50:
            steps.extend(self._generate_water_seeking_plan(game))
        
        if self.food < 50:
            steps.extend(self._generate_food_seeking_plan(game))
        
        # å¦‚æœæ²¡æœ‰ç´§æ€¥éœ€æ±‚ï¼Œè¿›è¡Œæ¢ç´¢
        if not steps:
            steps.extend(self._generate_exploration_plan(game))
        
        return steps
    
    def _get_current_state_for_planning(self, game):
        """è·å–å½“å‰çŠ¶æ€ç”¨äºè§„åˆ’"""
        return {
            'position': (self.x, self.y),
            'health': self.health,
            'food': self.food,
            'water': self.water,
            'current_cell': game.game_map.grid[self.y][self.x] if hasattr(game, 'game_map') else 'unknown',
            'tools': [tool.name for tool in getattr(self, 'tools', [])],
            'nearby_threats': len(self.detect_threats(game.game_map)) if hasattr(self, 'detect_threats') else 0
        }
    
    def _extract_goal_condition(self, goal):
        """ä»ç›®æ ‡ä¸­æå–å®Œæˆæ¡ä»¶"""
        goal_str = str(goal).lower()
        
        if 'water' in goal_str:
            return {'type': 'water', 'condition': 'water > 90'}
        elif 'food' in goal_str:
            return {'type': 'food', 'condition': 'food > 90'}
        elif 'threat' in goal_str or 'danger' in goal_str:
            return {'type': 'safety', 'condition': 'nearby_threats == 0'}
        elif 'exploration' in goal_str:
            return {'type': 'exploration', 'condition': 'new_area_discovered'}
        else:
            return {'type': 'general', 'condition': 'health > 80 and food > 50 and water > 50'}
    
    def _collect_relevant_rules(self, goal, current_state):
        """æ”¶é›†ä¸ç›®æ ‡ç›¸å…³çš„æ‰€æœ‰è§„å¾‹"""
        relevant_rules = []
        
        try:
            # ä»ç›´æ¥è§„å¾‹åº“æ”¶é›†è§„å¾‹
            if hasattr(self, 'five_library_system') and self.five_library_system:
                direct_rules = self._get_rules_from_direct_library(goal)
                relevant_rules.extend(direct_rules)
            
            # ä»æ€»è§„å¾‹åº“æ”¶é›†è§„å¾‹
            total_rules = self._get_rules_from_total_library(goal)
            relevant_rules.extend(total_rules)
            
            # ä»BPMç”Ÿæˆæ–°è§„å¾‹
            bmp_rules = self._get_rules_from_bmp(goal, current_state)
            relevant_rules.extend(bmp_rules)
            
            # æ·»åŠ åŸºç¡€ç”Ÿå­˜è§„å¾‹
            basic_rules = self._get_basic_survival_rules_for_bpu(goal)
            relevant_rules.extend(basic_rules)
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è§„å¾‹æ”¶é›†å¼‚å¸¸: {str(e)}")
        
        return relevant_rules
    
    def _get_rules_from_direct_library(self, goal):
        """ä»ç›´æ¥è§„å¾‹åº“è·å–ç›¸å…³è§„å¾‹"""
        from wooden_bridge_model import Rule
        rules = []
        try:
            # å®é™…æŸ¥è¯¢direct_rules.dbæ•°æ®åº“
            import sqlite3
            import os
            
            db_path = "five_libraries/direct_rules.db"
            if os.path.exists(db_path):
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # æŸ¥è¯¢éªŒè¯è¿‡çš„è§„å¾‹ - ä¿®å¤å­—æ®µå
                cursor.execute("SELECT * FROM direct_rules WHERE validation_status='validated' LIMIT 20")
                db_rules = cursor.fetchall()
                
                # è·å–åˆ—å
                column_names = [description[0] for description in cursor.description]
                
                for row in db_rules:
                    rule_data = dict(zip(column_names, row))
                    try:
                        # è½¬æ¢ä¸ºWBM Ruleå¯¹è±¡ - ä¿®å¤å­—æ®µå
                        import json
                        try:
                            conditions = json.loads(rule_data.get('conditions', '{}'))
                        except:
                            conditions = {}
                        try:
                            predictions = json.loads(rule_data.get('predictions', '{}'))
                        except:
                            predictions = {}
                            
                        wbm_rule = Rule(
                            rule_id=rule_data.get('rule_id', f"direct_rule_{rule_data.get('id', 'unknown')}"),
                            rule_type=rule_data.get('rule_type', 'action'),
                            conditions=conditions,
                            predictions=predictions,
                            confidence=float(rule_data.get('confidence', 0.5))
                        )
                        rules.append(wbm_rule)
                    except Exception as e:
                        if self.logger:
                            self.logger.log(f"{self.name} è½¬æ¢ç›´æ¥è§„å¾‹å¤±è´¥: {str(e)}")
                
                conn.close()
                
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ“‹ ä»ç›´æ¥è§„å¾‹åº“è·å– {len(rules)} æ¡è§„å¾‹")
            else:
                # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè§„å¾‹
                goal_str = str(goal).lower()
                if 'water' in goal_str:
                    rules.extend([
                        Rule(
                            rule_id='direct_water_1',
                            rule_type='action',
                            conditions={'current_cell': 'open_field'},
                            predictions={'water_discovery_chance': 0.7},
                            confidence=0.85
                        ),
                        Rule(
                            rule_id='direct_water_2',
                            rule_type='action', 
                            conditions={'current_cell': 'river'},
                            predictions={'water_gain': 40},
                            confidence=0.95
                        )
                    ])
                elif 'food' in goal_str:
                    rules.extend([
                        Rule(
                            rule_id='direct_food_1',
                            rule_type='action',
                            conditions={'current_cell': 'open_field'},
                            predictions={'food_discovery_chance': 0.6},
                            confidence=0.80
                        ),
                        Rule(
                            rule_id='direct_food_2',
                            rule_type='action',
                            conditions={'nearby_plant': True},
                            predictions={'food_gain': 8},
                            confidence=0.90
                        )
                    ])
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç›´æ¥è§„å¾‹åº“æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        return rules
    
    def _get_rules_from_total_library(self, goal):
        """ä»æ€»è§„å¾‹åº“è·å–ç›¸å…³è§„å¾‹"""
        from wooden_bridge_model import Rule
        rules = []
        try:
            # å®é™…æŸ¥è¯¢rule_knowledge.dbæ•°æ®åº“
            import sqlite3
            import os
            
            db_path = "five_libraries/rule_knowledge.db"
            if os.path.exists(db_path):
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # æŸ¥è¯¢éªŒè¯è¿‡çš„è§„å¾‹
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = cursor.fetchall()
                
                for table in tables:
                    table_name = table[0]
                    try:
                        cursor.execute(f"SELECT * FROM {table_name} LIMIT 10")
                        db_rules = cursor.fetchall()
                        
                        column_names = [description[0] for description in cursor.description]
                        
                        for row in db_rules:
                            rule_data = dict(zip(column_names, row))
                            try:
                                # è½¬æ¢ä¸ºWBM Ruleå¯¹è±¡
                                wbm_rule = Rule(
                                    rule_id=rule_data.get('rule_id', f"total_rule_{table_name}_{rule_data.get('id', 'unknown')}"),
                                    rule_type=rule_data.get('rule_type', 'knowledge'),
                                    conditions=eval(rule_data.get('conditions', '{}')) if rule_data.get('conditions') else {},
                                    predictions=eval(rule_data.get('predictions', '{}')) if rule_data.get('predictions') else {},
                                    confidence=float(rule_data.get('confidence', 0.6))
                                )
                                rules.append(wbm_rule)
                            except Exception as e:
                                if self.logger:
                                    self.logger.log(f"{self.name} è½¬æ¢æ€»è§„å¾‹å¤±è´¥: {str(e)}")
                    except Exception as e:
                        continue
                
                conn.close()
                
                if self.logger and rules:
                    self.logger.log(f"{self.name} ğŸ“š ä»æ€»è§„å¾‹åº“è·å– {len(rules)} æ¡è§„å¾‹")
            else:
                # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè§„å¾‹
                goal_str = str(goal).lower()
                if 'water' in goal_str:
                    rules.append(Rule(
                        rule_id='total_water_1',
                        rule_type='knowledge',
                        conditions={'position': 'any'},
                        predictions={'water_discovery_strategy': 'find_high_ground'},
                        confidence=0.75
                    ))
                elif 'exploration' in goal_str:
                    rules.append(Rule(
                        rule_id='total_explore_1',
                        rule_type='knowledge',
                        conditions={'position': 'any'},
                        predictions={'exploration_efficiency': 0.3},
                        confidence=0.90
                    ))
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} æ€»è§„å¾‹åº“æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        return rules
    
    def _get_rules_from_bmp(self, goal, current_state):
        """ä»BPMç”Ÿæˆç›¸å…³è§„å¾‹"""
        rules = []
        try:
            if hasattr(self, 'bpm') and self.bpm:
                # è·å–BPMçš„éªŒè¯è§„å¾‹
                bmp_validated_rules = self.bpm.get_all_validated_rules()
                
                for bmp_rule in bmp_validated_rules:
                    # ä½¿ç”¨æ–°çš„to_wbm_formatæ–¹æ³•è½¬æ¢æ ¼å¼
                    if hasattr(bmp_rule, 'to_wbm_format'):
                        try:
                            wbm_rule = bmp_rule.to_wbm_format()
                            # æ£€æŸ¥è§„å¾‹æ˜¯å¦ä¸ç›®æ ‡ç›¸å…³
                            if self._is_bmp_rule_relevant_to_goal(wbm_rule, goal):
                                rules.append(wbm_rule)
                                if logger:
                                    logger.log(f"{self.name} ğŸ”„ BMPè§„å¾‹è½¬æ¢æˆåŠŸ: {wbm_rule['id']}")
                        except Exception as e:
                            if logger:
                                logger.log(f"{self.name} BMPè§„å¾‹è½¬æ¢å¤±è´¥: {str(e)}")
                    else:
                        # å›é€€åˆ°æ‰‹åŠ¨è½¬æ¢
                        wbm_rule = self._manual_convert_bmp_rule(bmp_rule, goal)
                        if wbm_rule:
                            rules.append(wbm_rule)
                
                if logger and rules:
                    logger.log(f"{self.name} ğŸ“‹ ä»BMPè·å–åˆ° {len(rules)} æ¡ç›¸å…³è§„å¾‹")
                    
        except Exception as e:
            if logger:
                logger.log(f"{self.name} BPMè§„å¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        return rules
    
    def _is_bmp_rule_relevant_to_goal(self, wbm_rule, goal):
        """æ£€æŸ¥BMPè§„å¾‹æ˜¯å¦ä¸ç›®æ ‡ç›¸å…³"""
        try:
            goal_str = str(goal).lower()
            rule_action = wbm_rule.get('action', '').lower()
            rule_result = str(wbm_rule.get('result', {})).lower()
            
            # åŸºäºç›®æ ‡ç±»å‹çš„ç›¸å…³æ€§æ£€æŸ¥
            if 'water' in goal_str:
                return any(keyword in rule_action or keyword in rule_result 
                          for keyword in ['water', 'drink', 'hydrat', 'river', 'stream'])
            elif 'food' in goal_str:
                return any(keyword in rule_action or keyword in rule_result 
                          for keyword in ['food', 'eat', 'plant', 'forage', 'collect', 'hunt'])
            elif 'explore' in goal_str:
                return any(keyword in rule_action or keyword in rule_result 
                          for keyword in ['move', 'explore', 'search', 'discover', 'wander'])
            elif 'safe' in goal_str or 'threat' in goal_str:
                return any(keyword in rule_action or keyword in rule_result 
                          for keyword in ['flee', 'escape', 'avoid', 'safe', 'hide', 'retreat'])
            else:
                # é»˜è®¤è®¤ä¸ºæ‰€æœ‰è§„å¾‹éƒ½å¯èƒ½ç›¸å…³
                return True
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} è§„å¾‹ç›¸å…³æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            return True  # å‡ºé”™æ—¶ä¿å®ˆåœ°è®¤ä¸ºç›¸å…³
    
    def _manual_convert_bmp_rule(self, bmp_rule, goal):
        """æ‰‹åŠ¨è½¬æ¢BMPè§„å¾‹ä¸ºWBMæ ¼å¼ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        try:
            # å°è¯•ä»BMPè§„å¾‹ä¸­æå–åŸºæœ¬ä¿¡æ¯
            rule_id = getattr(bmp_rule, 'rule_id', f'bmp_rule_{id(bmp_rule)}')
            pattern = getattr(bmp_rule, 'pattern', '')
            confidence = getattr(bmp_rule, 'confidence', 0.5)
            
            # ç®€å•çš„åŠ¨ä½œæå–
            action = 'unknown_action'
            if hasattr(bmp_rule, 'conditions'):
                conditions = bmp_rule.conditions
                if isinstance(conditions, dict) and 'action' in conditions:
                    action = conditions['action']
            
            # ä»patternä¸­æå–åŠ¨ä½œï¼ˆå¦‚æœå¯èƒ½ï¼‰
            if action == 'unknown_action' and pattern:
                # ç®€å•çš„æ¨¡å¼åŒ¹é…
                common_actions = ['move', 'drink', 'eat', 'collect', 'search', 'explore', 'flee', 'attack']
                for act in common_actions:
                    if act in pattern.lower():
                        action = act
                        break
            
            # æ„å»ºWBMæ ¼å¼
            wbm_rule = {
                'id': rule_id,
                'condition': getattr(bmp_rule, 'conditions', {}),
                'action': action,
                'result': getattr(bmp_rule, 'predictions', {}),
                'confidence': confidence,
                'source': 'bmp_manual_conversion',
                'original_pattern': pattern
            }
            
            return wbm_rule
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} æ‰‹åŠ¨è½¬æ¢BMPè§„å¾‹å¤±è´¥: {str(e)}")
            return None

    def _get_basic_survival_rules_for_bpu(self, goal):
        """è·å–åŸºç¡€ç”Ÿå­˜è§„å¾‹ç”¨äºBPU"""
        rules = []
        
        # åŸºç¡€ç§»åŠ¨è§„å¾‹
        rules.append({
            'id': 'basic_move_north',
            'condition': {'position': 'any'},
            'action': 'move_up',
            'result': {'position_change': (0, -1)},
            'confidence': 0.95,
            'source': 'basic_knowledge'
        })
        
        rules.append({
            'id': 'basic_move_south',
            'condition': {'position': 'any'},
            'action': 'move_down', 
            'result': {'position_change': (0, 1)},
            'confidence': 0.95,
            'source': 'basic_knowledge'
        })
        
        rules.append({
            'id': 'basic_move_east',
            'condition': {'position': 'any'},
            'action': 'move_right',
            'result': {'position_change': (1, 0)},
            'confidence': 0.95,
            'source': 'basic_knowledge'
        })
        
        rules.append({
            'id': 'basic_move_west',
            'condition': {'position': 'any'},
            'action': 'move_left',
            'result': {'position_change': (-1, 0)},
            'confidence': 0.95,
            'source': 'basic_knowledge'
        })
        
        # åŸºç¡€èµ„æºè·å–è§„å¾‹
        goal_str = str(goal).lower()
        if 'water' in goal_str:
            rules.extend([
                {
                    'id': 'basic_drink_water',
                    'condition': {'current_cell': 'river'},
                    'action': 'drink_water',
                    'result': {'water_gain': 50},
                    'confidence': 0.98,
                    'source': 'basic_knowledge'
                },
                {
                    'id': 'basic_find_water',
                    'condition': {'position': 'any'},
                    'action': 'search_for_water',
                    'result': {'water_gain': 30},
                    'confidence': 0.70,
                    'source': 'basic_knowledge'
                },
                {
                    'id': 'basic_emergency_water',
                    'condition': {'water_low': True},
                    'action': 'emergency_hydration',
                    'result': {'water_gain': 65},
                    'confidence': 0.85,
                    'source': 'basic_knowledge'
                }
            ])
            
        elif 'food' in goal_str:
            rules.extend([
                {
                    'id': 'basic_collect_plant',
                    'condition': {'nearby_plant': True},
                    'action': 'collect_plant',
                    'result': {'food_gain': 7},
                    'confidence': 0.85,
                    'source': 'basic_knowledge'
                },
                {
                    'id': 'basic_forage',
                    'condition': {'position': 'any'},
                    'action': 'forage_for_food',
                    'result': {'food_gain': 20},
                    'confidence': 0.75,
                    'source': 'basic_knowledge'
                },
                {
                    'id': 'basic_emergency_food',
                    'condition': {'food_low': True},
                    'action': 'emergency_foraging',
                    'result': {'food_gain': 45},
                    'confidence': 0.80,
                    'source': 'basic_knowledge'
                }
            ])
        
        return rules
    
    def _bpu_bridge_search(self, start_state, goal_condition, available_rules):
        """BPUé€ æ¡¥æ ¸å¿ƒç®—æ³•ï¼šåŸºäºè§„å¾‹çš„å›¾æœç´¢"""
        candidate_plans = []
        
        try:
            # åˆå§‹åŒ–æœç´¢é˜Ÿåˆ—ï¼ˆå¼€æ”¾åˆ—è¡¨ï¼‰
            open_list = [{'state': start_state, 'path': [], 'cost': 0}]
            closed_set = set()
            max_iterations = 50  # é˜²æ­¢æ— é™å¾ªç¯
            max_plan_length = 6   # æœ€å¤§è®¡åˆ’é•¿åº¦
            max_plans = 5        # æœ€å¤§å€™é€‰è®¡åˆ’æ•°
            
            iteration = 0
            while open_list and len(candidate_plans) < max_plans and iteration < max_iterations:
                iteration += 1
                
                # é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„åŠæˆå“æ¡¥ï¼ˆå¯å‘å¼ï¼šæˆæœ¬æœ€ä½ï¼‰
                current = min(open_list, key=lambda x: x['cost'])
                open_list.remove(current)
                
                current_state = current['state']
                current_path = current['path']
                current_cost = current['cost']
                
                # é¿å…é‡å¤çŠ¶æ€
                state_key = self._state_to_key(current_state)
                if state_key in closed_set:
                    continue
                closed_set.add(state_key)
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                if self._check_goal_achieved(current_state, goal_condition):
                    if len(current_path) > 0:  # ç¡®ä¿æœ‰å®é™…æ­¥éª¤
                        candidate_plans.append({
                            'steps': current_path,
                            'final_state': current_state,
                            'total_cost': current_cost,
                            'goal': goal_condition
                        })
                    continue
                
                # å¦‚æœè·¯å¾„å¤ªé•¿ï¼Œè·³è¿‡
                if len(current_path) >= max_plan_length:
                    continue
                
                # å¯»æ‰¾é€‚ç”¨çš„è§„å¾‹ï¼ˆä¸‹ä¸€å—"æ¡¥æ¿"ï¼‰
                applicable_rules = self._find_applicable_rules(current_state, available_rules)
                
                for rule in applicable_rules:
                     # é¢„æµ‹æ‰§è¡Œè§„å¾‹åçš„æ–°çŠ¶æ€
                     new_state = self._predict_state_after_rule(current_state, rule)
                     # åœ¨æ–°çŠ¶æ€ä¸­æ·»åŠ å½“å‰è·¯å¾„ä¿¡æ¯ç”¨äºç›®æ ‡æ£€æŸ¥
                     new_state['_current_path'] = current_path
                     
                     new_step = {
                         'action': rule['action'],
                         'rule_id': rule['id'],
                         'confidence': rule['confidence'],
                         'description': f"æ‰§è¡Œè§„å¾‹ {rule['id']}: {rule['action']}"
                     }
                     new_path = current_path + [new_step]
                     new_cost = current_cost + (1.0 / rule['confidence'])  # ç½®ä¿¡åº¦è¶Šä½æˆæœ¬è¶Šé«˜
                     
                     # æ·»åŠ åˆ°å¼€æ”¾åˆ—è¡¨
                     open_list.append({
                         'state': new_state,
                         'path': new_path,
                         'cost': new_cost
                     })
            
            if logger and candidate_plans:
                logger.log(f"{self.name} ğŸ” BPUæœç´¢å®Œæˆ: æ‰¾åˆ° {len(candidate_plans)} ä¸ªå€™é€‰è®¡åˆ’")
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} BPUæœç´¢å¼‚å¸¸: {str(e)}")
        
        return candidate_plans
    
    def _state_to_key(self, state):
        """å°†çŠ¶æ€è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„é”®"""
        try:
            position = state.get('position', (0, 0))
            health = state.get('health', 100)
            food = state.get('food', 100)
            water = state.get('water', 100)
            return f"{position[0]}_{position[1]}_{health//10}_{food//10}_{water//10}"
        except:
            return str(hash(str(state)))
    
    def _check_goal_achieved(self, state, goal_condition):
        """æ£€æŸ¥ç›®æ ‡æ˜¯å¦è¾¾æˆ"""
        try:
            goal_type = goal_condition.get('type', 'general')
            
            if goal_type == 'water':
                # å¦‚æœæ°´é‡å·²ç»å¾ˆé«˜ï¼Œè€ƒè™‘æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥è¡ŒåŠ¨
                current_water = state.get('water', 0)
                if current_water >= 95:  # å·²ç»éå¸¸å……è¶³
                    return True
                elif current_water > 90:  # å……è¶³ä½†å¯ä»¥æ›´å¥½
                    return len(state.get('_current_path', [])) >= 2  # è‡³å°‘2æ­¥åå†æ£€æŸ¥
                else:
                    return False
            elif goal_type == 'food':
                current_food = state.get('food', 0)
                if current_food >= 95:
                    return True
                elif current_food > 90:
                    return len(state.get('_current_path', [])) >= 2
                else:
                    return False
            elif goal_type == 'safety':
                return state.get('nearby_threats', 1) == 0
            elif goal_type == 'exploration':
                return state.get('new_area_discovered', False) or state.get('exploration_progress', 0) >= 1.0
            else:
                return (state.get('health', 0) > 80 and 
                       state.get('food', 0) > 50 and 
                       state.get('water', 0) > 50)
        except:
            return False
    
    def _find_applicable_rules(self, current_state, available_rules):
        """æ‰¾åˆ°åœ¨å½“å‰çŠ¶æ€ä¸‹é€‚ç”¨çš„è§„å¾‹"""
        applicable = []
        
        for rule in available_rules:
            if self._rule_condition_matches(current_state, rule['condition']):
                applicable.append(rule)
        
        return applicable
    
    def _rule_condition_matches(self, state, condition):
        """æ£€æŸ¥è§„å¾‹çš„æ¡ä»¶æ˜¯å¦ä¸å½“å‰çŠ¶æ€åŒ¹é…"""
        try:
            # ç®€åŒ–çš„æ¡ä»¶åŒ¹é…é€»è¾‘
            if condition.get('position') == 'any':
                return True
            
            if 'current_cell' in condition:
                required_cell = condition['current_cell']
                actual_cell = state.get('current_cell', 'unknown')
                # å¯¹äºopen_fieldï¼ŒåŒ¹é…å¤šç§åœ°å½¢
                if required_cell == 'open_field':
                    return actual_cell in ['plain', 'grass', 'open_field']
                return actual_cell == required_cell
            
            if 'nearby_plant' in condition:
                # ç®€åŒ–ï¼šå‡è®¾å¤§éƒ¨åˆ†ä½ç½®éƒ½å¯èƒ½æœ‰æ¤ç‰©
                return True
            
            # æ£€æŸ¥èµ„æºæ¡ä»¶
            if 'water_low' in condition:
                return state.get('water', 100) < 50
            
            if 'food_low' in condition:
                return state.get('food', 100) < 50
            
            # æ£€æŸ¥ä½ç½®æ¡ä»¶
            if 'position' in condition and condition['position'] != 'any':
                pos = condition['position']
                if isinstance(pos, tuple):
                    return state.get('position', (0, 0)) == pos
            
            return True  # é»˜è®¤åŒ¹é…
            
        except:
            return False
    
    def _predict_state_after_rule(self, current_state, rule):
        """é¢„æµ‹æ‰§è¡Œè§„å¾‹åçš„çŠ¶æ€"""
        new_state = current_state.copy()
        
        try:
            result = rule.get('result', {})
            
            # å¤„ç†ä½ç½®å˜åŒ–
            if 'position_change' in result:
                pos_change = result['position_change']
                if isinstance(pos_change, tuple):
                    old_pos = new_state.get('position', (0, 0))
                    new_state['position'] = (old_pos[0] + pos_change[0], old_pos[1] + pos_change[1])
            
            # å¤„ç†èµ„æºå˜åŒ–
            if 'water_gain' in result:
                new_state['water'] = min(100, new_state.get('water', 0) + result['water_gain'])
            
            if 'food_gain' in result:
                new_state['food'] = min(100, new_state.get('food', 0) + result['food_gain'])
            
            # å¤„ç†å…¶ä»–çŠ¶æ€å˜åŒ–
            if 'new_area_discovered' in result:
                new_state['new_area_discovered'] = result['new_area_discovered']
                
        except Exception as e:
            if logger:
                logger.log(f"{self.name} çŠ¶æ€é¢„æµ‹å¼‚å¸¸: {str(e)}")
        
        return new_state
    
    def _evaluate_plans_with_bpu(self, candidate_plans, goal):
        """ä½¿ç”¨BPUå…¬å¼è¯„ä¼°å€™é€‰è®¡åˆ’"""
        if not candidate_plans:
            return None
        
        best_plan = None
        best_score = -1
        
        alpha = 0.1  # æˆæœ¬æ•æ„Ÿåº¦ç³»æ•°
        
        for plan in candidate_plans:
            try:
                # è®¡ç®—ç½®ä¿¡åº¦ä¹˜ç§¯ âˆConf(R_i)
                confidence_product = 1.0
                for step in plan['steps']:
                    confidence_product *= step.get('confidence', 0.5)
                
                # è®¡ç®—æ€»æˆæœ¬ Cost(P)
                total_cost = len(plan['steps'])  # æ­¥éª¤æ•°ä½œä¸ºåŸºç¡€æˆæœ¬
                
                # BPUå…¬å¼: BPU(P) = âˆConf(R_i) / (1 + Î±Â·Cost(P))
                bpu_score = confidence_product / (1 + alpha * total_cost)
                
                plan['bpu_score'] = bpu_score
                plan['confidence_product'] = confidence_product
                plan['total_cost'] = total_cost
                
                if bpu_score > best_score:
                    best_score = bpu_score
                    best_plan = plan
                    
                if logger:
                    logger.log(f"{self.name} ğŸ“Š è®¡åˆ’è¯„ä¼°: {len(plan['steps'])}æ­¥, ç½®ä¿¡åº¦ç§¯: {confidence_product:.3f}, æˆæœ¬: {total_cost}, BPUåˆ†: {bpu_score:.3f}")
                    
            except Exception as e:
                if logger:
                    logger.log(f"{self.name} è®¡åˆ’è¯„ä¼°å¼‚å¸¸: {str(e)}")
        
        if best_plan:
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            return {
                'goal': goal,
                'steps': best_plan['steps'],
                'created_time': time.time(),
                'estimated_duration': len(best_plan['steps']),
                'plan_type': 'bpu_optimized',
                'bpu_score': best_plan['bpu_score'],
                'confidence_product': best_plan['confidence_product'],
                'total_cost': best_plan['total_cost']
            }
        
        return None
    
    def _generate_fallback_plan(self, goal, game):
        """ç”Ÿæˆå›é€€è®¡åˆ’ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        goal_str = str(goal).lower()
        
        if 'water' in goal_str:
            return self._generate_simple_water_plan()
        elif 'food' in goal_str:
            return self._generate_simple_food_plan()
        else:
            return self._generate_simple_exploration_plan()
    
    def _generate_simple_water_plan(self):
        """ç”Ÿæˆç®€å•çš„å¯»æ°´è®¡åˆ’"""
        return {
            'goal': 'water',
            'steps': [
                {'action': 'move_up', 'description': 'å‘åŒ—å¯»æ‰¾æ°´æº', 'confidence': 0.7},
                {'action': 'move_right', 'description': 'å‘ä¸œç»§ç»­æœç´¢', 'confidence': 0.7}
            ],
            'created_time': time.time(),
            'estimated_duration': 2,
            'plan_type': 'fallback_water'
        }
    
    def _generate_simple_food_plan(self):
        """ç”Ÿæˆç®€å•çš„å¯»é£Ÿè®¡åˆ’"""
        return {
            'goal': 'food',
            'steps': [
                {'action': 'move_left', 'description': 'å‘è¥¿å¯»æ‰¾é£Ÿç‰©', 'confidence': 0.7},
                {'action': 'collect_plant', 'description': 'æ”¶é›†æ¤ç‰©', 'confidence': 0.8}
            ],
            'created_time': time.time(),
            'estimated_duration': 2,
            'plan_type': 'fallback_food'
        }
    
    def _generate_simple_exploration_plan(self):
        """ç”Ÿæˆç®€å•çš„æ¢ç´¢è®¡åˆ’"""
        return {
            'goal': 'exploration',
            'steps': [
                {'action': 'move_up', 'description': 'å‘åŒ—æ¢ç´¢', 'confidence': 0.8},
                {'action': 'move_right', 'description': 'å‘ä¸œæ¢ç´¢', 'confidence': 0.8}
            ],
            'created_time': time.time(),
            'estimated_duration': 2,
            'plan_type': 'fallback_exploration'
        }
    
    # === WBMé•¿é“¾å†³ç­–åŠŸèƒ½ ===
    
    def _should_use_long_chain_planning(self, target_goal, game):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨é•¿é“¾å†³ç­–è§„åˆ’"""
        # å¤æ‚ç›®æ ‡éœ€è¦é•¿é“¾è§„åˆ’
        complex_goals = ['exploration', 'resource_acquisition', 'threat_avoidance', 'social_interaction']
        if target_goal in complex_goals:
            return True
        
        # èµ„æºç´§å¼ æ—¶éœ€è¦é•¿æœŸè§„åˆ’
        if self.health < 50 or self.food < 40 or self.water < 40:
            return True
        
        # æœ‰å¤šä¸ªå¨èƒæ—¶éœ€è¦æˆ˜ç•¥è§„åˆ’
        threats = self.detect_threats(game.game_map)
        if len(threats) >= 2:
            return True
        
        return False
    
    def _generate_wbm_long_chain_plan(self, wbm_goal, available_rules, game, logger):
        """ç”ŸæˆWBMé•¿é“¾å†³ç­–è®¡åˆ’"""
        try:
            if not hasattr(self, 'wooden_bridge_model') or not self.wooden_bridge_model:
                return None
            
            current_state = self._get_current_wbm_state(game)
            max_days = self._determine_plan_length(wbm_goal, current_state)
            
            if logger:
                logger.log(f"{self.name} ğŸ¯ å¼€å§‹ç”ŸæˆWBMé•¿é“¾å†³ç­–è®¡åˆ’: ç›®æ ‡={wbm_goal.description}, é¢„è®¡å¤©æ•°={max_days}")
            
            # ä½¿ç”¨WBMçš„é•¿é“¾å†³ç­–åŠŸèƒ½
            multi_day_plan = self.wooden_bridge_model.generate_multi_day_plan(
                goal=wbm_goal,
                available_rules=available_rules,
                current_state=current_state,
                max_days=max_days
            )
            
            return multi_day_plan
            
        except Exception as e:
            if logger:
                logger.log(f"{self.name} WBMé•¿é“¾è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    def _determine_plan_length(self, goal, current_state):
        """æ ¹æ®ç›®æ ‡å’ŒçŠ¶æ€ç¡®å®šè®¡åˆ’é•¿åº¦"""
        # æ ¹æ®ç›®æ ‡ç±»å‹ç¡®å®šåŸºç¡€å¤©æ•°
        base_days = {
            'exploration': 4,
            'resource_acquisition': 3,
            'threat_avoidance': 2,
            'social_interaction': 3,
            'survival': 5
        }.get(goal.goal_type.value if hasattr(goal, 'goal_type') else 'survival', 3)
        
        # æ ¹æ®ç´§æ€¥åº¦è°ƒæ•´
        if hasattr(goal, 'urgency'):
            if goal.urgency > 0.8:
                base_days = max(1, base_days - 1)  # ç´§æ€¥æƒ…å†µç¼©çŸ­è®¡åˆ’
            elif goal.urgency < 0.3:
                base_days = min(7, base_days + 2)  # éç´§æ€¥æƒ…å†µå¯ä»¥å»¶é•¿è®¡åˆ’
        
        # æ ¹æ®èµ„æºçŠ¶å†µè°ƒæ•´
        health = current_state.get('health', 100)
        if health < 30:
            base_days = min(2, base_days)  # å¥åº·å±æ€¥æ—¶ç¼©çŸ­è®¡åˆ’
        
        return base_days
    
    def _log_wbm_long_chain_decision(self, multi_day_plan, logger):
        """è®°å½•WBMé•¿é“¾å†³ç­–åˆ°æ­£å¼æ—¥å¿—"""
        if not logger or not multi_day_plan:
            return
        
        import time
        logger.log("=" * 80)
        logger.log(f"ğŸ—“ï¸ {self.name} ILAIé•¿é“¾å†³ç­–è®¡åˆ’ç”Ÿæˆ | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.log("=" * 80)
        logger.log(f"ğŸ“‹ è®¡åˆ’ID: {multi_day_plan.plan_id}")
        logger.log(f"ğŸ¯ ç›®æ ‡: {multi_day_plan.goal.description}")
        logger.log(f"ğŸ“Š ç›®æ ‡ç±»å‹: {multi_day_plan.goal.goal_type.value}")
        logger.log(f"âš¡ ç´§æ€¥åº¦: {multi_day_plan.goal.urgency:.2f} | ä¼˜å…ˆçº§: {multi_day_plan.goal.priority:.2f}")
        logger.log(f"ğŸ“… è®¡åˆ’å¤©æ•°: {multi_day_plan.total_days}å¤©")
        logger.log(f"ğŸŒ‰ æ¡¥æ¢ç­–ç•¥: {multi_day_plan.bridge_plan.reasoning_strategy.value}")
        logger.log(f"ğŸ² é¢„æœŸæˆåŠŸç‡: {multi_day_plan.bridge_plan.expected_success_rate:.2f}")
        logger.log("")
        
        logger.log("ğŸ“… è¯¦ç»†æ¯æ—¥è¡ŒåŠ¨è®¡åˆ’:")
        for daily_action in multi_day_plan.daily_actions:
            logger.log(f"  ç¬¬{daily_action.day}å¤©:")
            logger.log(f"    ğŸ® åŠ¨ä½œ: {daily_action.action}")
            logger.log(f"    ğŸ§  æ¨ç†: {daily_action.reasoning}")
            logger.log(f"    ğŸ“Š é¢„æœŸå˜åŒ–: {daily_action.expected_state_change}")
            logger.log(f"    ğŸ¯ ç½®ä¿¡åº¦: {daily_action.confidence:.2f}")
            if daily_action.risk_assessment:
                logger.log(f"    âš ï¸ é£é™©: {', '.join(daily_action.risk_assessment)}")
            if daily_action.fallback_actions:
                logger.log(f"    ğŸ”„ å¤‡é€‰: {', '.join(daily_action.fallback_actions)}")
            logger.log("")
        
        if multi_day_plan.bridge_plan.rules_used:
            logger.log("ğŸ§± ä½¿ç”¨çš„è§„å¾‹:")
            for rule in multi_day_plan.bridge_plan.rules_used:
                logger.log(f"  - {rule.rule_id}: {rule.confidence:.2f}ç½®ä¿¡åº¦")
        
        logger.log("=" * 80)
        logger.log(f"ğŸ’¡ {self.name} ILAIæ™ºèƒ½ä½“ç°: é•¿é“¾å†³ç­–è§„åˆ’ - èƒ½å¤Ÿé¢„è§æœªæ¥å‡ å¤©çš„è¡ŒåŠ¨éœ€æ±‚")
        logger.log("ğŸ”— è§„å¾‹é“¾æ¨ç†: å°†å¤šä¸ªç®€å•è§„å¾‹è¿æ¥æˆå¤æ‚çš„å¤šæ­¥ç­–ç•¥")
        logger.log("âš–ï¸ é£é™©è¯„ä¼°: æ¯æ­¥è¡ŒåŠ¨éƒ½è€ƒè™‘äº†å¯èƒ½çš„é£é™©å’Œå¤‡é€‰æ–¹æ¡ˆ")
        logger.log("=" * 80)
    
    def _continue_multi_day_plan(self, game, logger):
        """ç»§ç»­æ‰§è¡Œå¤šæ—¥è®¡åˆ’ - å¢å¼ºç‰ˆè®°å¿†åŠŸèƒ½"""
        if not hasattr(self, 'current_multi_day_plan') or not self.current_multi_day_plan:
            return None
        
        plan = self.current_multi_day_plan
        previous_day = getattr(self, 'plan_current_day', 0)
        current_day = previous_day + 1
        
        if logger:
            logger.log(f"{self.name} ğŸ—“ï¸ æ£€æŸ¥å¤šæ—¥è®¡åˆ’æ‰§è¡ŒçŠ¶æ€: ç¬¬{current_day}å¤© (æ€»è®¡{plan.total_days}å¤©)")
        
        # 1. æ£€æŸ¥ä¸Šä¸€å¤©çš„æ‰§è¡Œç»“æœ
        if previous_day > 0 and len(self.daily_execution_log) >= previous_day:
            last_execution = self.daily_execution_log[previous_day - 1]
            if logger:
                success_status = "æˆåŠŸ" if last_execution.get('success', False) else "å¤±è´¥"
                logger.log(f"{self.name}    ç¬¬{previous_day}å¤©æ‰§è¡Œ{success_status}: {last_execution.get('action', 'unknown')}")
        
        # 2. è·å–å½“å‰ç¯å¢ƒçŠ¶æ€å¹¶ä¸åˆ¶å®šè®¡åˆ’æ—¶æ¯”è¾ƒ
        current_state = self._get_current_wbm_state(game)
        environment_changed = self._detect_environment_change(current_state)
        
        if environment_changed and logger:
            logger.log(f"{self.name} âš ï¸ æ£€æµ‹åˆ°ç¯å¢ƒå˜åŒ–: {environment_changed['changes']}")
        
        # 3. æ£€æŸ¥è®¡åˆ’æ˜¯å¦éœ€è¦è°ƒæ•´
        adjustment_result = self.wooden_bridge_model.check_and_adjust_multi_day_plan(
            plan, current_state
        )
        
        if adjustment_result.needs_adjustment:
            if logger:
                logger.log(f"{self.name} ğŸ”„ å¤šæ—¥è®¡åˆ’éœ€è¦è°ƒæ•´: {adjustment_result.adjustment_reason}")
            
            # è®°å½•è°ƒæ•´å†å²
            self.plan_adjustment_history.append({
                'day': current_day,
                'reason': adjustment_result.adjustment_reason,
                'old_plan_id': plan.plan_id if hasattr(plan, 'plan_id') else 'unknown',
                'timestamp': time.time()
            })
            self.plan_completion_stats['total_adjusted'] += 1
            
            if adjustment_result.new_plan:
                self.current_multi_day_plan = adjustment_result.new_plan
                plan = adjustment_result.new_plan
                current_day = 1  # é‡æ–°å¼€å§‹æ–°è®¡åˆ’
                if logger:
                    logger.log(f"{self.name} ğŸ”„ å·²åˆ‡æ¢åˆ°æ–°è®¡åˆ’: {plan.goal.description}")
        
        # 4. æ‰§è¡Œä»Šå¤©çš„è¡ŒåŠ¨
        today_action = plan.get_action_for_day(current_day)
        if today_action:
            if logger:
                logger.log(f"{self.name} ğŸ—“ï¸ WBMé•¿é“¾å†³ç­–ç¬¬{current_day}å¤©æ‰§è¡Œ: {today_action.action}")
                logger.log(f"{self.name}    æ¨ç†: {today_action.reasoning}")
                logger.log(f"{self.name}    ç½®ä¿¡åº¦: {today_action.confidence:.2f}")
                if hasattr(today_action, 'expected_changes'):
                    logger.log(f"{self.name}    é¢„æœŸå˜åŒ–: {today_action.expected_changes}")
                
            self.plan_current_day = current_day
            
            # 5. è®°å½•ä»Šæ—¥è®¡åˆ’æ‰§è¡Œå¼€å§‹
            execution_record = {
                'day': current_day,
                'action': today_action.action,
                'reasoning': today_action.reasoning,
                'confidence': today_action.confidence,
                'start_time': time.time(),
                'planned': True,
                'success': None,  # å°†åœ¨æ‰§è¡Œåæ›´æ–°
                'environment_state': current_state.copy()
            }
            
            # ç¡®ä¿æ—¥å¿—åˆ—è¡¨è¶³å¤Ÿé•¿
            while len(self.daily_execution_log) < current_day:
                self.daily_execution_log.append({})
            
            if len(self.daily_execution_log) == current_day:
                self.daily_execution_log.append(execution_record)
            else:
                self.daily_execution_log[current_day - 1] = execution_record
            
            # 6. æ£€æŸ¥æ˜¯å¦æ˜¯æœ€åä¸€å¤©
            if current_day >= plan.total_days:
                if logger:
                    logger.log(f"{self.name} ğŸ‰ å¤šæ—¥è®¡åˆ’å³å°†å®Œæˆ: {plan.goal.description}")
                # æ³¨æ„ï¼šè¿™é‡Œä¸ç«‹å³æ¸…é™¤è®¡åˆ’ï¼Œç­‰æ‰§è¡Œå®Œæˆåå†æ¸…é™¤
            
            return {
                'action': today_action.action,
                'source': 'wbm_long_chain_continue',
                'confidence': today_action.confidence,
                'day': current_day,
                'plan_goal': plan.goal.description if hasattr(plan.goal, 'description') else str(plan.goal)
            }
        
        # 7. è®¡åˆ’æ‰§è¡Œå®Œæ¯•æˆ–å‡ºé”™
        if logger:
            logger.log(f"{self.name} âŒ å¤šæ—¥è®¡åˆ’æ‰§è¡Œå¼‚å¸¸ç»“æŸ")
        
        self._complete_multi_day_plan(success=False, reason="execution_error", logger=logger)
        return None

    def _detect_environment_change(self, current_state):
        """æ£€æµ‹ç¯å¢ƒå˜åŒ–"""
        if not hasattr(self, 'plan_initial_state') or not self.plan_initial_state:
            return None
            
        initial_state = self.plan_initial_state
        changes = []
        
        # æ£€æŸ¥å¨èƒå˜åŒ–
        if current_state.get('threats', []) != initial_state.get('threats', []):
            changes.append("å¨èƒæƒ…å†µå˜åŒ–")
        
        # æ£€æŸ¥å¥åº·çŠ¶æ€å˜åŒ–
        current_health = current_state.get('health', 100)
        initial_health = initial_state.get('health', 100)
        if abs(current_health - initial_health) > 20:
            changes.append(f"å¥åº·çŠ¶æ€æ˜¾è‘—å˜åŒ– ({initial_health}->{current_health})")
        
        # æ£€æŸ¥èµ„æºçŠ¶æ€å˜åŒ–
        current_food = current_state.get('food', 0)
        initial_food = initial_state.get('food', 0)
        if abs(current_food - initial_food) > 5:
            changes.append(f"é£Ÿç‰©çŠ¶æ€å˜åŒ– ({initial_food}->{current_food})")
            
        current_water = current_state.get('water', 0)
        initial_water = initial_state.get('water', 0)
        if abs(current_water - initial_water) > 5:
            changes.append(f"æ°´åˆ†çŠ¶æ€å˜åŒ– ({initial_water}->{current_water})")
        
        # æ£€æŸ¥ä½ç½®å˜åŒ–ï¼ˆå¦‚æœè®¡åˆ’åŒ…å«ä½ç½®è¦æ±‚ï¼‰
        current_pos = (current_state.get('x', 0), current_state.get('y', 0))
        initial_pos = (initial_state.get('x', 0), initial_state.get('y', 0))
        if current_pos != initial_pos:
            distance = abs(current_pos[0] - initial_pos[0]) + abs(current_pos[1] - initial_pos[1])
            if distance > 3:
                changes.append(f"ä½ç½®å¤§å¹…å˜åŒ– {initial_pos}->{current_pos}")
        
        if changes:
            return {
                'changed': True,
                'changes': changes,
                'severity': 'high' if len(changes) > 2 else 'medium'
            }
        
        return None
    
    def _complete_multi_day_plan(self, success=True, reason="completed", logger=None):
        """å®Œæˆå¤šæ—¥è®¡åˆ’å¹¶æ›´æ–°ç»Ÿè®¡"""
        if hasattr(self, 'current_multi_day_plan') and self.current_multi_day_plan:
            plan = self.current_multi_day_plan
            
            if success:
                self.plan_completion_stats['total_completed'] += 1
                if logger:
                    logger.log(f"{self.name} âœ… å¤šæ—¥è®¡åˆ’æˆåŠŸå®Œæˆ: {plan.goal.description if hasattr(plan.goal, 'description') else str(plan.goal)}")
            else:
                self.plan_completion_stats['total_interrupted'] += 1
                self.plan_failure_reasons.append({
                    'plan_goal': plan.goal.description if hasattr(plan.goal, 'description') else str(plan.goal),
                    'reason': reason,
                    'day_reached': getattr(self, 'plan_current_day', 0),
                    'total_days': plan.total_days,
                    'timestamp': time.time()
                })
                
                if logger:
                    logger.log(f"{self.name} âŒ å¤šæ—¥è®¡åˆ’ä¸­æ–­: {reason}")
        
        # æ¸…é™¤å½“å‰è®¡åˆ’çŠ¶æ€
        self.current_multi_day_plan = None
        self.plan_current_day = 0
        self.plan_initial_state = None
    
    def _update_daily_execution_result(self, execution_result, logger=None):
        """æ›´æ–°å½“å‰å¤©çš„æ‰§è¡Œç»“æœ"""
        if (hasattr(self, 'plan_current_day') and self.plan_current_day > 0 and 
            len(self.daily_execution_log) >= self.plan_current_day):
            
            current_record = self.daily_execution_log[self.plan_current_day - 1]
            current_record.update({
                'success': execution_result.get('success', False),
                'end_time': time.time(),
                'execution_time': time.time() - current_record.get('start_time', time.time()),
                'actual_result': execution_result.get('result', 'unknown'),
                'rewards_gained': execution_result.get('rewards', {}),
                'obstacles_encountered': execution_result.get('obstacles', [])
            })
            
            if logger:
                success_text = "æˆåŠŸ" if current_record['success'] else "å¤±è´¥"
                logger.log(f"{self.name} ğŸ“‹ ç¬¬{self.plan_current_day}å¤©æ‰§è¡Œç»“æœ: {success_text}")
                
            # å¦‚æœæ˜¯æœ€åä¸€å¤©ä¸”æˆåŠŸå®Œæˆï¼Œæ ‡è®°æ•´ä¸ªè®¡åˆ’ä¸ºå®Œæˆ
            if (self.plan_current_day >= self.current_multi_day_plan.total_days and 
                current_record['success']):
                self._complete_multi_day_plan(success=True, reason="all_days_completed", logger=logger)
    
    def get_long_chain_memory_status(self):
        """è·å–é•¿é“¾å†³ç­–è®°å¿†çŠ¶æ€"""
        return {
            'has_active_plan': self.current_multi_day_plan is not None,
            'current_day': getattr(self, 'plan_current_day', 0),
            'total_days': self.current_multi_day_plan.total_days if self.current_multi_day_plan else 0,
            'plan_goal': (self.current_multi_day_plan.goal.description 
                         if self.current_multi_day_plan and hasattr(self.current_multi_day_plan.goal, 'description') 
                         else None),
            'execution_log_days': len(self.daily_execution_log),
            'adjustments_made': len(self.plan_adjustment_history),
            'completion_stats': self.plan_completion_stats.copy()
        }


class GlobalKnowledgeSync:
    """å…¨å±€çŸ¥è¯†åŒæ­¥ä»- è´Ÿè´£åè°ƒæ‰€æœ‰ç©å®¶çš„çŸ¥è¯†åŒæ­¥"""
    
    def __init__(self, players=None):
        self.players = players or []
        self.unified_db_dir = "global_five_libraries"  # ä½¿ç”¨ç›®å½•è€Œéæ–‡ä»¶
        self.sync_interval = 100  # è°ƒæ•´ä¸ºæ¯100è½®åŒæ­¥ä¸€æ¬¡ (æ€§èƒ½ä¼˜åŒ–)
        self.last_sync_turn = 0
        self.sync_stats = {
            'total_syncs': 0,
            'experiences_synced': 0,
            'rules_synced': 0,
            'failed_syncs': 0
        }
        
        # æ·»åŠ å»é‡æœºåˆ¶
        self.synced_experience_hashes = set()
        self.synced_rule_hashes = set()
        
        # åˆå§‹åŒ–ç»Ÿä¸€çŸ¥è¯†æ•°æ®åº“
        try:
            from five_library_system import FiveLibrarySystem
            import os
            
            # æ¸…ç†æ—§çš„å†²çªæ–‡ä»¶(å¦‚æœå­˜åœ¨)
            old_file_path = "five_library_system.db"
            if os.path.exists(old_file_path) and os.path.isfile(old_file_path):
                # å¤‡ä»½æ—§æ–‡ä»¶
                backup_name = f"{old_file_path}.backup_{int(time.time())}"
                os.rename(old_file_path, backup_name)
                if logger:
                    logger.log(f"ğŸ”„ å·²å¤‡ä»½æ—§æ•°æ®åº“æ–‡ä»¶ä¸º: {backup_name}")
            
            # ä½¿ç”¨æ­£ç¡®çš„ç›®å½•è·¯å¾„åˆå§‹åŒ–äº”åº“ç³»ç»Ÿ
            self.unified_system = FiveLibrarySystem(self.unified_db_dir)
            if logger:
                logger.log(f"ğŸŒ å…¨å±€çŸ¥è¯†åŒæ­¥å™¨å·²å¯åŠ¨,ä½¿ç”¨ç›®å½• {self.unified_db_dir}")
                
        except Exception as e:
            if logger:
                logger.log(f"å…¨å±€çŸ¥è¯†åŒæ­¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                import traceback
                logger.log(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.unified_system = None
    
    def register_player(self, player):
        """æ³¨å†Œç©å®¶åˆ°å…¨å±€çŸ¥è¯†åŒæ­¥ç½‘ç»œ"""
        if player not in self.players:
            self.players.append(player)
            # ç»™ç©å®¶è®¾ç½®å…¨å±€åŒæ­¥å™¨å¼•ç”¨
            player.global_knowledge_sync = self
            if logger:
                logger.log(f"ğŸŒ {player.name} å·²æ³¨å†Œåˆ°å…¨å±€çŸ¥è¯†åŒæ­¥ç½‘ç»œ")
    
    def sync_new_experience(self, discoverer, experience):
        """åŒæ­¥æ–°å‘ç°çš„ç»éªŒå¹¶ç»™äºˆå£°èª‰å¥–åŠ±"""
        try:
            # ç”Ÿæˆç»éªŒå“ˆå¸Œç”¨äºå»é‡
            exp_hash = self._generate_experience_hash(experience)
            
            # æ£€æŸ¥æ˜¯å¦å·²åŒæ­¥
            if exp_hash in self.synced_experience_hashes:
                return False, "ç»éªŒå·²å­˜åœ¨"
            
            # æ·»åŠ åˆ°å·²åŒæ­¥é›†åˆ
            self.synced_experience_hashes.add(exp_hash)
            
            # åˆ†å‘ç»™å…¶ä»–ILAI/RILAIç©å®¶
            shared_count = 0
            for player in self.players:
                if (player.name != discoverer.name and 
                    player.player_type in ['ILAI', 'RILAI'] and 
                    player.is_alive()):
                    try:
                        # æ·»åŠ åˆ°ç©å®¶çš„é—´æ¥ç»éªŒåº“
                        if hasattr(player, 'five_library_system') and player.five_library_system:
                            # ä½¿ç”¨äº”åº“ç³»ç»Ÿæ·»åŠ ç»éªŒ
                            try:
                                # è½¬æ¢ç»éªŒæ ¼å¼ä¸ºEOCATRExperience
                                from five_library_system import EOCATRExperience
                                import time
                                
                                # ğŸ”§ å¼ºåŒ–æ•°æ®æ ¼å¼æ£€æŸ¥å’Œè½¬æ¢
                                if isinstance(experience, dict):
                                    eocar_exp = EOCATRExperience(
                                        environment=experience.get('environment', 'unknown'),
                                        object=experience.get('object', 'unknown'),
                                        characteristics=experience.get('characteristics', 'unknown'),
                                        action=experience.get('action', 'unknown'),
                                        tools=experience.get('tools', 'none'),
                                        result=experience.get('result', 'unknown'),
                                        player_id=player.name,
                                        timestamp=experience.get('timestamp', time.time()),
                                        metadata={'sender': discoverer.name, 'credibility': 0.8, 'source': 'indirect'}
                                    )
                                elif isinstance(experience, str):
                                    # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„ç»éªŒ
                                    eocar_exp = EOCATRExperience(
                                        environment='unknown',
                                        object='unknown',
                                        characteristics='unknown',
                                        action=experience,
                                        tools='none',
                                        result='unknown',
                                        player_id=player.name,
                                        timestamp=time.time(),
                                        metadata={'sender': discoverer.name, 'credibility': 0.5, 'source': 'indirect', 'original_format': 'string'}
                                    )
                                elif hasattr(experience, 'to_dict'):
                                    # å¦‚æœæœ‰to_dictæ–¹æ³•,å…ˆè½¬æ¢ä¸ºå­—å…¸
                                    exp_dict = experience.to_dict()
                                    eocar_exp = EOCATRExperience(
                                        environment=exp_dict.get('environment', 'unknown'),
                                        object=exp_dict.get('object', 'unknown'),
                                        characteristics=exp_dict.get('characteristics', 'unknown'),
                                        action=exp_dict.get('action', 'unknown'),
                                        tools=exp_dict.get('tools', 'none'),
                                        result=exp_dict.get('result', 'unknown'),
                                        player_id=player.name,
                                        timestamp=exp_dict.get('timestamp', time.time()),
                                        metadata={'sender': discoverer.name, 'credibility': 0.8, 'source': 'indirect'}
                                    )
                                else:
                                    # å¦‚æœå·²ç»æ˜¯EOCATRExperienceå¯¹è±¡æˆ–å…¶ä»–æ ¼å¼,ä½¿ç”¨getattr
                                    eocar_exp = EOCATRExperience(
                                        environment=getattr(experience, 'environment', 'unknown'),
                                        object=getattr(experience, 'object', 'unknown'),
                                        characteristics=getattr(experience, 'characteristics', 'unknown'),
                                        action=getattr(experience, 'action', str(experience)),
                                        tools=getattr(experience, 'tools', 'none'),
                                        result=getattr(experience, 'result', 'unknown'),
                                        player_id=player.name,
                                        timestamp=getattr(experience, 'timestamp', time.time()),
                                        metadata={'sender': discoverer.name, 'credibility': 0.8, 'source': 'indirect'}
                                    )
                                
                                result = player.five_library_system.add_experience_to_direct_library(eocar_exp)
                                if result.get('success'):
                                    shared_count += 1
                            except Exception as format_error:
                                if logger:
                                    logger.log(f"âš ï¸ å‘{player.name}åˆ†å‘ç»éªŒæ ¼å¼è½¬æ¢å¤±è´¥: {str(format_error)}")
                    except Exception as e:
                        if logger:
                            logger.log(f"âš ï¸ å‘{player.name}åˆ†å‘ç»éªŒå¤±è´¥: {str(e)}")
            
            # ç»™å‘ç°è€…å¥–åŠ±ï¼ˆå·²ç§»é™¤å£°èª‰ç³»ç»Ÿï¼‰
            # æ–°ç»éªŒå‘ç°è€…å°†è·å¾—å…¶ä»–å½¢å¼çš„å¥–åŠ±
            
            # ğŸ”§ ä¿®å¤ï¼šè®°å½•å‘ç°è€…çš„ä¿¡æ¯åˆ†äº«ç»Ÿè®¡
            if hasattr(discoverer, '_record_info_sharing'):
                discoverer._record_info_sharing(shared_count)
            elif hasattr(discoverer, 'shared_info_count'):
                discoverer.shared_info_count += 1
            
            # æ›´æ–°ç»Ÿè®¡
            self.sync_stats['experiences_synced'] += 1
            
            if shared_count > 0 and logger:
                logger.log(f"ğŸŒ {discoverer.name} åˆ†äº«ç»éªŒç»™{shared_count}ä¸ªç”¨æˆ·")
            
            return True, f"ç»éªŒå·²åˆ†äº«ç»™{shared_count}ä¸ªç”¨æˆ·"
            
        except Exception as e:
            if logger:
                logger.log(f"ä»ç»éªŒåŒæ­¥å¤±è´¥: {str(e)}")
            return False, f"åŒæ­¥å¤±è´¥: {str(e)}"
    
    def sync_new_rule(self, discoverer, rule, rule_type):
        """åŒæ­¥æ–°å‘ç°çš„è§„å¾‹å¹¶ç»™äºˆå£°èª‰å¥–åŠ±"""
        try:
            # ç”Ÿæˆè§„å¾‹å“ˆå¸Œç”¨äºå»é‡
            rule_hash = self._generate_rule_hash(rule, rule_type)
            
            # æ£€æŸ¥æ˜¯å¦å·²åŒæ­¥
            if rule_hash in self.synced_rule_hashes:
                return False, "è§„å¾‹å·²å­˜åœ¨"
            
            # æ·»åŠ åˆ°å·²åŒæ­¥é›†åˆ
            self.synced_rule_hashes.add(rule_hash)
            
            # åˆ†å‘ç»™å…¶ä»–ILAI/RILAIç©å®¶
            shared_count = 0
            for player in self.players:
                if (player.name != discoverer.name and 
                    player.player_type in ['ILAI', 'RILAI'] and 
                    player.is_alive()):
                    try:
                        # æ·»åŠ åˆ°ç©å®¶çš„é—´æ¥è§„å¾‹åº“
                        if hasattr(player, 'five_library_system') and player.five_library_system:
                            # ä½¿ç”¨äº”åº“ç³»ç»Ÿæ·»åŠ è§„å¾‹
                            try:
                                # è½¬æ¢è§„å¾‹æ ¼å¼ä¸ºåˆ—è¡¨
                                import time
                                if isinstance(rule, dict):
                                    rule_dict = rule.copy()
                                    rule_dict.update({
                                        'rule_type': rule_type,
                                        'source': 'indirect',
                                        'sender': discoverer.name,
                                        'credibility': 0.9,
                                        'player_id': player.name,
                                        'created_time': time.time()
                                    })
                                    rules_list = [rule_dict]
                                else:
                                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼,è½¬æ¢ä¸ºå­—å…¸
                                    rule_dict = {
                                        'conditions': {'condition': str(rule)},
                                        'predictions': {'expected_outcome': 'unknown'},
                                        'rule_type': rule_type,
                                        'confidence': 0.9,
                                        'support_count': 1,
                                        'contradiction_count': 0,
                                        'validation_count': 0,
                                        'creator_id': discoverer.name,
                                        'created_time': time.time()
                                    }
                                    rules_list = [rule_dict]
                                
                                result = player.five_library_system.add_rules_to_direct_library(rules_list)
                                if result.get('success'):
                                    shared_count += 1
                            except Exception as format_error:
                                if logger:
                                    logger.log(f"âš ï¸ å‘{player.name}åˆ†å‘è§„å¾‹æ ¼å¼è½¬æ¢å¤±è´¥: {str(format_error)}")
                    except Exception as e:
                        if logger:
                            logger.log(f"âš ï¸ å‘{player.name}åˆ†å‘è§„å¾‹å¤±è´¥: {str(e)}")
            
            # ç»™å‘ç°è€…å¥–åŠ±ï¼ˆå·²ç§»é™¤å£°èª‰ç³»ç»Ÿï¼‰
            # æ–°è§„å¾‹å‘ç°è€…å°†è·å¾—å…¶ä»–å½¢å¼çš„å¥–åŠ±
            
            # ğŸ”§ ä¿®å¤ï¼šè®°å½•å‘ç°è€…çš„ä¿¡æ¯åˆ†äº«ç»Ÿè®¡
            if hasattr(discoverer, '_record_info_sharing'):
                discoverer._record_info_sharing(shared_count)
            elif hasattr(discoverer, 'shared_info_count'):
                discoverer.shared_info_count += 1
            
            # æ›´æ–°ç»Ÿè®¡
            self.sync_stats['rules_synced'] += 1
            
            if shared_count > 0 and logger:
                logger.log(f"ğŸ† {discoverer.name} åˆ†äº«è§„å¾‹[{rule_type}]ç»™{shared_count}ä¸ªç”¨æˆ·")
            
            return True, f"è§„å¾‹å·²åˆ†äº«ç»™{shared_count}ä¸ªç”¨æˆ·"
            
        except Exception as e:
            if logger:
                logger.log(f"ä»è§„å¾‹åŒæ­¥å¤±è´¥: {str(e)}")
            return False, f"åŒæ­¥å¤±è´¥: {str(e)}"
    
    def _generate_experience_hash(self, experience):
        """ç”Ÿæˆç»éªŒå“ˆå¸Œç”¨äºå»é‡,æ”¯æŒå¤šç§æ•°æ®æ ¼å¼"""
        import hashlib
        
        # ğŸ”§ å¼ºåŒ–æ•°æ®æ ¼å¼å¤„ç†
        try:
            if hasattr(experience, 'to_dict'):
                exp_dict = experience.to_dict()
            elif isinstance(experience, dict):
                exp_dict = experience
            elif isinstance(experience, str):
                # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„ç»éªŒæ•°æ®
                exp_dict = {'raw': experience, 'action': experience, 'environment': 'unknown'}
            elif hasattr(experience, '__dict__'):
                # å¤„ç†å¯¹è±¡æ ¼å¼
                exp_dict = experience.__dict__
            else:
                exp_dict = {'raw': str(experience)}
            
            # å®‰å…¨çš„å­—æ®µæå–,é¿å…strå¯¹è±¡è°ƒç”¨get()é”™è¯¯
            if isinstance(exp_dict, dict):
                key_fields = [
                    str(exp_dict.get('action', '')),
                    str(exp_dict.get('environment', '')),
                    str(exp_dict.get('object', '')),
                    str(exp_dict.get('tool', '')),
                    str(exp_dict.get('result', ''))
                ]
            else:
                # å¦‚æœä»ç„¶ä¸æ˜¯å­—å…¸,ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²è¡¨ç¤º
                key_fields = [str(exp_dict)]
            
            return hashlib.md5('|'.join(key_fields).encode()).hexdigest()
            
        except Exception as e:
            # æœ€åçš„é˜²é”™æªæ–½
            if logger:
                logger.log(f"âš ï¸ ç»éªŒå“ˆå¸Œç”Ÿæˆå¤±è´¥,ä½¿ç”¨é»˜è®¤å“ˆä» {str(e)}, ç±»å‹: {type(experience)}")
            return hashlib.md5(str(experience).encode()).hexdigest()
    
    def _generate_rule_hash(self, rule, rule_type):
        """ç”Ÿæˆè§„å¾‹å“ˆå¸Œç”¨äºå»é‡,æ”¯æŒå¤šç§æ•°æ®æ ¼å¼"""
        import hashlib
        
        # ğŸ”§ å¼ºåŒ–æ•°æ®æ ¼å¼å¤„ç†
        try:
            if hasattr(rule, 'to_dict'):
                rule_dict = rule.to_dict()
            elif isinstance(rule, dict):
                rule_dict = rule
            elif isinstance(rule, str):
                # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„è§„å¾‹æ•°æ®
                rule_dict = {'raw': rule, 'conditions': rule, 'predictions': 'unknown'}
            elif hasattr(rule, '__dict__'):
                # å¤„ç†å¯¹è±¡æ ¼å¼
                rule_dict = rule.__dict__
            else:
                rule_dict = {'raw': str(rule)}
            
            # å®‰å…¨çš„å­—æ®µæå–,é¿å…strå¯¹è±¡è°ƒç”¨get()é”™è¯¯
            if isinstance(rule_dict, dict):
                key_fields = [
                    rule_type,
                    str(rule_dict.get('conditions', rule_dict.get('condition', ''))),
                    str(rule_dict.get('predictions', rule_dict.get('expected_outcome', '')))
                ]
            else:
                # å¦‚æœä»ç„¶ä¸æ˜¯å­—å…¸,ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²è¡¨ç¤º
                key_fields = [rule_type, str(rule_dict)]
            
            return hashlib.md5('|'.join(key_fields).encode()).hexdigest()
            
        except Exception as e:
            # æœ€åçš„é˜²é”™æªæ–½
            if logger:
                logger.log(f"âš ï¸ è§„å¾‹å“ˆå¸Œç”Ÿæˆå¤±è´¥,ä½¿ç”¨é»˜è®¤å“ˆä» {str(e)}, ç±»å‹: {type(rule)}")
            return hashlib.md5(f"{rule_type}|{str(rule)}".encode()).hexdigest()
    
    def auto_sync_to_unified_db(self, current_turn):
        """è‡ªåŠ¨åŒæ­¥åˆ°ç»Ÿä¸€æ•°æ®åº“"""
        if not self.unified_system or not self.players:
            return
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŒ"""
        if current_turn - self.last_sync_turn >= self.sync_interval:
            try:
                synced_count = 0
                for player in self.players:
                    if hasattr(player, 'five_library_system') and player.five_library_system:
                        # åŒæ­¥ä¸ªäººç»éªŒåˆ°æ€»åº“
                        sync_result = player.five_library_system.sync_all_direct_rules_to_total()
                        synced_count += sync_result.get('rules_synced', 0)
                
                self.sync_stats['total_syncs'] += 1
                self.last_sync_turn = current_turn
                
                if logger and synced_count > 0:
                    logger.log(f"ğŸ”„ å…¨å±€çŸ¥è¯†åŒæ­¥å®Œæˆ: åŒæ­¥{synced_count}æ¡è§„å¾‹")
                    
            except Exception as e:
                self.sync_stats['failed_syncs'] += 1
                if logger:
                    logger.log(f"å…¨å±€çŸ¥è¯†åŒæ­¥å¤±è´¥: {e}")
    

    def get_sync_statistics(self):
        """è·å–åŒæ­¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.sync_stats.copy()
        stats['registered_players'] = len(self.players)
        stats['unique_experiences'] = len(self.synced_experience_hashes)
        stats['unique_rules'] = len(self.synced_rule_hashes)
        return stats


class Game:
    def __init__(self, settings, canvas, ui_update_callback):
        self.settings = settings
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„è®¾ç½®éƒ½å­˜åœ¨
        default_settings = {
            'group_hunt_frequency': 5,  # é»˜è®¤5å¤©ä¸€æ¬¡ç¾¤ä½“ç‹©çŒ
            'respawn_frequency': 20,    # é»˜è®¤20å¤©èµ„æºé‡ç”Ÿ
            'enable_translation': True,  # é»˜è®¤å¯ç”¨ç¿»è¯‘ç³»ç»Ÿ
        }
        
        for key, value in default_settings.items():
            if key not in self.settings:
                self.settings[key] = value
        
        self.canvas = canvas
        self.ui_update_callback = ui_update_callback
        self.current_day = 0
        self.game_over = False
        self.game_map = GameMap(
            settings["map_width"], settings["map_height"], settings["map_type"], settings["seed"]
        )
        logger.log_seed(settings["seed"])
        logger.log_predator_count(self.game_map.get_predator_count())
        self.players = []
        
        # åˆå§‹åŒ–å…¨å±€çŸ¥è¯†åŒæ­¥å™¨(åœ¨åˆå§‹åŒ–ç©å®¶ä¹‹å‰)
        self.global_knowledge_sync = GlobalKnowledgeSync()
        
        # === ğŸŒ è‡ªåŠ¨å¯åŠ¨ç¿»è¯‘ç³»ç»Ÿ ===
        self.translation_monitor = None
        if self.settings.get('enable_translation', True):
            try:
                from auto_translation_integration import auto_start_translation_on_game_start
                self.translation_monitor = auto_start_translation_on_game_start()
                if self.translation_monitor:
                    logger.log("ğŸŒ æ—¥å¿—ç¿»è¯‘ç³»ç»Ÿå·²è‡ªåŠ¨å¯åŠ¨")
            except Exception as e:
                logger.log(f"âš ï¸ ç¿»è¯‘ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {str(e)}")
        
        self.initialize_players()

    def initialize_players(self):
        # å†…ç½® 10 ä¸ªDQN ç©å®¶
        for i in range(10):
            name = f"DQN{i+1}"
            self.players.append(DQNPlayer(name, self.game_map))
        # å†…ç½® 10 ä¸ªPPO ç©å®¶
        for i in range(10):
            name = f"PPO{i+1}"
            self.players.append(PPOPlayer(name, self.game_map))
        # å†…ç½® 10 ä¸ªILAI ç©å®¶
        for i in range(10):
            name = f"ILAI{i+1}"
            self.players.append(ILAIPlayer(name, self.game_map))
        # å†…ç½® 10 ä¸ªRILAI ç©å®¶(ä½¿ç”¨ILAIPlayerä½†å¯ç”¨å¼ºåŒ–å­¦ä¹ )
        for i in range(10):
            name = f"RILAI{i+1}"
            player = ILAIPlayer(name, self.game_map)
            player.player_type = "RILAI"  # ä¿®æ”¹ç©å®¶ç±»å‹æ ‡è¯†
            player.use_reinforcement_learning = True  # å¯ç”¨å¼ºåŒ–å­¦ä¹ 
            self.players.append(player)
        
        # æ³¨å†ŒILAIå’ŒRILAIç©å®¶åˆ°å…¨å±€çŸ¥è¯†åŒæ­¥ç½‘ç»œ
        for player in self.players:
            if player.player_type in ['ILAI', 'RILAI']:
                self.global_knowledge_sync.register_player(player)
        
        # å¯ç”¨æ€§èƒ½è¿½è¸ª
        try:
            from game_performance_integration import enable_game_performance_tracking
            enable_game_performance_tracking(self.players)
        except ImportError:
            logger.log("âš ï¸ æ€§èƒ½è¿½è¸ªæ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ€§èƒ½ç»Ÿè®¡é›†æˆ")
        except Exception as e:
            logger.log(f"âš ï¸ æ€§èƒ½è¿½è¸ªå¯ç”¨å¤±è´¥: {str(e)}")

    def run_turn(self):
        if self.game_over:
            return
        logger.log(f"ç¬¬{self.current_day + 1} å›åˆå¼€å§‹")
        
        # åŠ¨ç‰©è¡ŒåŠ¨(åŒ…æ‹¬æ•é£Ÿè€…çš„è¿½å‡»)
        for animal in self.game_map.animals:
            if animal.alive:
                animal.move(self.game_map, self.players)
        
        # ç©å®¶è¡ŒåŠ¨
        for player in self.players:
            if player.is_alive():
                player.take_turn(self)
                player.survival_days = self.current_day + 1
        
        # === æ–°å¢ï¼šä¿å­˜AIæ¨¡å‹ä»¥å®ç°é•¿æœŸè®°å¿† ===
        # æ¯5å›åˆä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼Œå‡å°‘IOå¼€é”€ï¼ŒåŒæ—¶åœ¨æ¸¸æˆç»“æŸæ—¶ç¡®ä¿ä¿å­˜
        if (self.current_day + 1) % 5 == 0 or self.current_day + 1 >= self.settings["game_duration"]:
            for player in self.players:
                if player.is_alive() and hasattr(player, 'save_model'):
                    try:
                        player.save_model()
                        logger.log(f"ğŸ’¾ {player.name} æ¨¡å‹å·²ä¿å­˜ (ç¬¬{self.current_day + 1}å¤©)")
                    except Exception as e:
                        logger.log(f"âš ï¸ ä¿å­˜{player.name}çš„æ¨¡å‹å¤±è´¥: {str(e)}")
        
        # è§¦å‘çŸ¥è¯†åŒæ­¥æ£€æŸ¥(æ¯å›åˆæ£€æŸ¥ILAI/RILAIç©å®¶)
        for player in self.players:
            if player.player_type in ['ILAI', 'RILAI'] and player.is_alive():
                if hasattr(player, '_trigger_knowledge_sync'):
                    try:
                        sync_count = player._trigger_knowledge_sync()
                        if sync_count > 0:
                            self.global_knowledge_sync.sync_stats['total_syncs'] += sync_count
                    except Exception as e:
                        logger.log(f"âš ï¸ {player.name} çŸ¥è¯†åŒæ­¥å¤±è´¥: {str(e)}")
        
        # å…¨å±€çŸ¥è¯†åŒæ­¥(å®šæœŸåŒæ­¥)
        self.global_knowledge_sync.auto_sync_to_unified_db(self.current_day)
                
        # ç¾¤ä½“ç‹©çŒäº‹ä»¶(æ¯éš”è®¾å®šå¤©æ•°è§¦å‘ä¸€æ¬¡)
        if (self.current_day + 1) % self.settings["group_hunt_frequency"] == 0:
            self.group_hunt()
            
        self.respawn_resources()
        self.current_day += 1
        self.ui_update_callback()
        
        if self.current_day >= self.settings["game_duration"] or all(
            not p.is_alive() for p in self.players
        ):
            self.end_game()
        else:
            if self.canvas:
                self.canvas.after(500, self.run_turn)  # ä¸‹ä¸€å›åˆå»¶æ—¶ 500ms (æ€§èƒ½ä¼˜åŒ–)

    def group_hunt(self):
        # æ¨¡æ‹Ÿç¾¤ä½“ç‹©çŒ:è‹¥æœ‰ç©å®¶åœ¨çŒ›å…½(Tiger å’ŒBlackBear)é™„è¿‘5 æ ¼,åˆ™å…±åŒæ”»å‡»è·å–å¥–åŠ±
        for animal in self.game_map.animals:
            if animal.alive and animal.type in ["Tiger", "BlackBear"]:
                participants = []
                for player in self.players:
                    if player.is_alive() and abs(player.x - animal.x) <= 5 and abs(player.y - animal.y) <= 5:
                        participants.append(player)
                if participants:
                    total_damage = sum(p.damage_dealt for p in participants)
                    if total_damage == 0:
                        total_damage = 1
                    # è‹¥ç´¯è®¡ä¼¤å®³è¶³å¤Ÿå‡»æ€çŒ›å…½,åˆ™åˆ†é…é£Ÿç‰©å¥–åŠ±
                    if animal.hp <= sum(p.damage_dealt for p in participants):
                        animal.alive = False
                        reward = animal.food
                        for p in participants:
                            contribution = p.damage_dealt / total_damage
                            gained_food = min(100 - p.food, round(reward * contribution))  # ç¡®ä¿ä¸è¶…è¿‡100ä¸Šé™
                            p.food += gained_food
                            logger.log(
                                f"{p.name} participated in group hunt and gained {gained_food} food"
                            )

    def respawn_resources(self):
        # æ¯å›åˆæ£€æŸ¥èµ„æº(æ¤ç‰©)æ˜¯å¦å¯é‡ç”Ÿ(10å¤©å†…éšæœºåˆ·æ–°æœºåˆ¶,ç®€å•æ¨¡æ‹Ÿ)
        for plant in self.game_map.plants:
            if plant.collected and random.random() < 0.01:
                plant.collected = False
                logger.log("A plant has respawned.")

    def end_game(self):
        self.game_over = True
        logger.log("æ¸¸æˆç»“æŸ")
        
        # === æ¸¸æˆç»“æŸæ—¶æœ€ç»ˆä¿å­˜æ‰€æœ‰AIæ¨¡å‹ ===
        logger.log("ğŸ¯ æ­£åœ¨æ‰§è¡Œæœ€ç»ˆæ¨¡å‹ä¿å­˜...")
        for player in self.players:
            if hasattr(player, 'save_model'):
                try:
                    player.save_model()
                    logger.log(f"âœ… {player.name} æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜")
                except Exception as e:
                    logger.log(f"âŒ ä¿å­˜{player.name}æœ€ç»ˆæ¨¡å‹å¤±è´¥: {str(e)}")
        
        rankings = self.calculate_rankings()
        
        # æ›´æ–°è¡¨å¤´ï¼Œåœ¨æœ€åæ·»åŠ ç®—åŠ›æ¶ˆè€—å’Œååº”æ—¶é—´
        header = (
            "|æ’å|ç©å®¶|ç”Ÿå­˜å¤©æ•°|è¡€é‡|é£Ÿç‰©|æ°´|æ¢ç´¢ç‡|å‘ç°æ¤ç‰©|é‡‡é›†æ¤ç‰©|é­é‡åŠ¨ç‰©|å‡»æ€åŠ¨ç‰©|å‘ç°å¤§æ ‘|æ¢ç´¢å±±æ´|æ–°é¢–å‘ç°|ç®—åŠ›æ¶ˆè€—|ååº”æ—¶é—´|"
        )
        logger.log(header)
        
        for rank, player in enumerate(rankings, 1):
            # è·å–æ€§èƒ½ç»Ÿè®¡æ•°æ®
            computation_cost = "N/A"
            response_time = "N/A"
            
            # æ£€æŸ¥ç©å®¶æ˜¯å¦æœ‰æ€§èƒ½è¿½è¸ªå™¨
            if hasattr(player, 'performance_tracker') and player.performance_tracker:
                try:
                    stats = player.performance_tracker.get_performance_summary()
                    # è®¡ç®—ç®—åŠ›æ¶ˆè€—ï¼ˆç´¯è®¡CPUä½¿ç”¨æ—¶é—´ï¼Œå•ä½ï¼šç§’ï¼‰
                    computation_cost = f"{stats.get('total_execution_time', 0):.2f}s"
                    # è®¡ç®—å¹³å‡ååº”æ—¶é—´ï¼ˆå•ä½ï¼šæ¯«ç§’ï¼‰
                    avg_response = stats.get('average_execution_time', 0)
                    response_time = f"{avg_response*1000:.0f}ms"
                except Exception as e:
                    # å¦‚æœè·å–æ€§èƒ½æ•°æ®å¤±è´¥ï¼Œä¿æŒé»˜è®¤å€¼
                    if hasattr(player, 'logger') and player.logger:
                        player.logger.log(f"è·å–{player.name}æ€§èƒ½æ•°æ®å¤±è´¥: {str(e)}")
            
            line = (
                f"|{rank}|{player.name}|{player.survival_days}|"
                f"{player.hp}|{player.food}|{player.water}|{player.exploration_rate}|"
                f"{player.found_plants}|{player.collected_plants}|{player.encountered_animals}|"
                f"{player.killed_animals}|{player.found_big_tree}|{player.explored_cave}|"
                f"{player.novelty_discoveries}|{computation_cost}|{response_time}|"
            )
            logger.log(line)
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        try:
            from game_performance_integration import generate_game_performance_report
            generate_game_performance_report()
        except ImportError:
            pass
        except Exception as e:
            logger.log(f"âš ï¸ æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # === ğŸ”¥ å…³é”®ä¿®å¤ï¼šå…ˆå†™å…¥æ—¥å¿—æ–‡ä»¶ ===
        logger.write_log_file()
        
        # === ğŸŒ æ—¥å¿—å†™å…¥åï¼Œç»™ç¿»è¯‘ç³»ç»Ÿæ—¶é—´å¤„ç†æ–°æ—¥å¿— ===
        if self.translation_monitor:
            try:
                print("ğŸŒ æ—¥å¿—æ–‡ä»¶å·²ç”Ÿæˆï¼Œç­‰å¾…ç¿»è¯‘ç³»ç»Ÿå¤„ç†...")
                
                # ç­‰å¾…3ç§’é’Ÿè®©ç¿»è¯‘ç³»ç»Ÿå¤„ç†æ–°ç”Ÿæˆçš„æ—¥å¿—
                import time
                time.sleep(3)
                
                # å¼ºåˆ¶æ£€æŸ¥å¹¶ç¿»è¯‘æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
                try:
                    from game_integrated_translation_system import force_translate_all_logs
                    force_translate_all_logs()
                    print("ğŸŒ å·²å¼ºåˆ¶ç¿»è¯‘æ‰€æœ‰æ—¥å¿—æ–‡ä»¶")
                except Exception as force_e:
                    print(f"âš ï¸ å¼ºåˆ¶ç¿»è¯‘å¤±è´¥: {str(force_e)}")
                
                # ç°åœ¨æ‰åœæ­¢ç¿»è¯‘ç³»ç»Ÿ
                from auto_translation_integration import auto_stop_translation_on_game_end
                auto_stop_translation_on_game_end()
                print("ğŸŒ æ—¥å¿—ç¿»è¯‘ç³»ç»Ÿå·²è‡ªåŠ¨åœæ­¢")
                
            except Exception as e:
                print(f"âš ï¸ ç¿»è¯‘ç³»ç»Ÿåœæ­¢å¤±è´¥: {str(e)}")

    def calculate_rankings(self):
        # æ’åä¾æ®:ä¼˜å…ˆæ¯”è¾ƒç”Ÿå­˜å¤©æ•°ã€è¡€é‡ã€é£Ÿç‰©ã€æ°´,è‹¥ç›¸åŒä»¥å§“åå­—å…¸æ’åº
        alive_players = [p for p in self.players if p.survival_days > 0]
        return sorted(
            alive_players,
            key=lambda p: (
                -p.survival_days,
                -p.hp,
                -p.food,
                -p.water,
                p.name,
            ),
        )


#
# UI éƒ¨åˆ† - ä½¿ç”¨ tkinter åˆ›å»ºä¸€ä¸ªå·¦ä¾§æ§åˆ¶é¢æ¿å’Œå³ä¾§çš„åœ°å›¾å¯è§†åŒ–åŒºåŸŸ
#
    def _execute_high_priority_exploration(self, game):
        """ğŸ¯ æ–°å¢ï¼šæ‰§è¡Œé«˜ä¼˜å…ˆçº§æ¢ç´¢ç›®æ ‡ï¼ˆç”Ÿç‰©å¤šæ ·æ€§å’Œå·¥å…·æ•ˆèƒ½æµ‹è¯•ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…æ‰§è¡Œçš„é«˜ä¼˜å…ˆçº§CDLç›®æ ‡
            if hasattr(self, '_pending_cdl_goal') and self._pending_cdl_goal:
                cdl_goal = self._pending_cdl_goal
                goal_type = cdl_goal.get('type', '')
                
                # æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢
                if goal_type == 'biodiversity_exploration':
                    return self._execute_biodiversity_exploration(cdl_goal, game)
                
                # æ‰§è¡Œå·¥å…·æ•ˆèƒ½æµ‹è¯•
                elif goal_type == 'tool_efficiency_testing':
                    return self._execute_tool_efficiency_testing(cdl_goal, game)
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} é«˜ä¼˜å…ˆçº§æ¢ç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def _execute_biodiversity_exploration(self, cdl_goal, game):
        """ğŸ¦‹ æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢"""
        try:
            eocatr_goal = cdl_goal.get('eocatr_goal', {})
            action = eocatr_goal.get('action', '')
            target_object = eocatr_goal.get('object', '')
            target_pos = cdl_goal.get('target_position', None)
            species_key = cdl_goal.get('species_key', None)
            
            if not target_pos:
                return False
            
            # ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            if (self.x, self.y) != target_pos:
                # è®¡ç®—ç§»åŠ¨æ–¹å‘
                dx = 1 if target_pos[0] > self.x else -1 if target_pos[0] < self.x else 0
                dy = 1 if target_pos[1] > self.y else -1 if target_pos[1] < self.y else 0
                
                # å°è¯•ç§»åŠ¨
                new_x, new_y = self.x + dx, self.y + dy
                if self._is_valid_position(new_x, new_y, game):
                    self.x, self.y = new_x, new_y
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢:ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®({new_x},{new_y})")
                    return True
            
            # åˆ°è¾¾ç›®æ ‡ä½ç½®ï¼Œæ‰§è¡Œå…·ä½“æ¢ç´¢è¡Œä¸º
            success = False
            if action == 'hunt_with_tool':
                success = self._execute_biodiversity_hunting(target_object, eocatr_goal.get('tool'), game)
            elif action == 'gather_with_tool':
                success = self._execute_biodiversity_gathering(target_object, eocatr_goal.get('tool'), game)
            elif action == 'observe_safely':
                success = self._execute_biodiversity_observation(target_object, game)
            elif action == 'examine_resource':
                success = self._execute_biodiversity_examination(target_object, game)
            
            # è®°å½•æ¢ç´¢çš„ç‰©ç§
            if success and species_key:
                if not hasattr(self, 'explored_species'):
                    self.explored_species = set()
                self.explored_species.add(species_key)
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ¦‹ å·²è®°å½•æ¢ç´¢ç‰©ç§: {species_key}")
            
            return success
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    def _execute_tool_efficiency_testing(self, cdl_goal, game):
        """ğŸ”§ æ‰§è¡Œå·¥å…·æ•ˆèƒ½æµ‹è¯•"""
        try:
            eocatr_goal = cdl_goal.get('eocatr_goal', {})
            action = eocatr_goal.get('action', '')
            target_object = eocatr_goal.get('object', '')
            tool_name = eocatr_goal.get('tool', '')
            target_pos = cdl_goal.get('target_position', None)
            combo_key = cdl_goal.get('combo_key', None)
            
            if not target_pos or not tool_name:
                return False
            
            # ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            if (self.x, self.y) != target_pos:
                # è®¡ç®—ç§»åŠ¨æ–¹å‘
                dx = 1 if target_pos[0] > self.x else -1 if target_pos[0] < self.x else 0
                dy = 1 if target_pos[1] > self.y else -1 if target_pos[1] < self.y else 0
                
                # å°è¯•ç§»åŠ¨
                new_x, new_y = self.x + dx, self.y + dy
                if self._is_valid_position(new_x, new_y, game):
                    self.x, self.y = new_x, new_y
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ å·¥å…·æ•ˆèƒ½æµ‹è¯•:ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®({new_x},{new_y})")
                    return True
            
            # åˆ°è¾¾ç›®æ ‡ä½ç½®ï¼Œæ‰§è¡Œå·¥å…·æµ‹è¯•
            success = False
            if action == 'test_hunting_tool':
                success = self._test_hunting_tool_efficiency(target_object, tool_name, game)
            elif action == 'test_ranged_tool':
                success = self._test_ranged_tool_efficiency(target_object, tool_name, game)
            elif action == 'test_gathering_tool':
                success = self._test_gathering_tool_efficiency(target_object, tool_name, game)
            elif action == 'test_utility_tool':
                success = self._test_utility_tool_efficiency(target_object, tool_name, game)
            
            # è®°å½•æµ‹è¯•çš„å·¥å…·ç»„åˆ
            if success and combo_key:
                if not hasattr(self, 'tested_tool_combinations'):
                    self.tested_tool_combinations = set()
                self.tested_tool_combinations.add(combo_key)
                if self.logger:
                    self.logger.log(f"{self.name} ğŸ”§ å·²è®°å½•å·¥å…·æµ‹è¯•: {combo_key}")
            
            return success
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} å·¥å…·æ•ˆèƒ½æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

    # ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§æ¢ç´¢çš„å…·ä½“æ‰§è¡Œå‡½æ•°
    def _execute_biodiversity_hunting(self, target_object, tool_name, game):
        """æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§ç‹©çŒ"""
        try:
            # å¯»æ‰¾ç›®æ ‡åŠ¨ç‰©
            for animal in game.game_map.animals:
                if (animal.type.lower() == target_object and 
                    animal.alive and 
                    abs(animal.x - self.x) + abs(animal.y - self.y) <= 1):
                    
                    old_food = self.food
                    damage = self.attack(animal)
                    
                    success = damage > 0 or not animal.alive
                    if self.logger:
                        status = "æˆåŠŸ" if success else "å¤±è´¥"
                        self.logger.log(f"{self.name} ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§ç‹©çŒ: ä½¿ç”¨{tool_name}æ”»å‡»{target_object} {status}")
                    
                    return success
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç”Ÿç‰©å¤šæ ·æ€§ç‹©çŒå¤±è´¥: {str(e)}")
            return False

    def _execute_biodiversity_gathering(self, target_object, tool_name, game):
        """æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§é‡‡é›†"""
        try:
            # å¯»æ‰¾ç›®æ ‡æ¤ç‰©
            for plant in game.game_map.plants:
                if (plant.__class__.__name__.lower() == target_object and 
                    not plant.collected and 
                    abs(plant.x - self.x) + abs(plant.y - self.y) <= 1):
                    
                    old_food = self.food
                    self.collect_plant(plant)
                    
                    success = self.food > old_food
                    if self.logger:
                        status = "æˆåŠŸ" if success else "å¤±è´¥"
                        self.logger.log(f"{self.name} ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§é‡‡é›†: ä½¿ç”¨{tool_name}é‡‡é›†{target_object} {status}")
                    
                    return success
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç”Ÿç‰©å¤šæ ·æ€§é‡‡é›†å¤±è´¥: {str(e)}")
            return False

    def _execute_biodiversity_observation(self, target_object, game):
        """æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§è§‚å¯Ÿï¼ˆå®‰å…¨è§‚å¯ŸçŒ›å…½ï¼‰"""
        try:
            # å¯»æ‰¾ç›®æ ‡åŠ¨ç‰©è¿›è¡Œè§‚å¯Ÿ
            for animal in game.game_map.animals:
                if (animal.type.lower() == target_object and 
                    animal.alive and 
                    abs(animal.x - self.x) + abs(animal.y - self.y) <= 2):
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§è§‚å¯Ÿ: å®‰å…¨è§‚å¯Ÿ{target_object}çš„è¡Œä¸ºç‰¹å¾")
                    
                    # è§‚å¯ŸæˆåŠŸï¼Œè·å¾—çŸ¥è¯†ä½†ä¸è¿›è¡Œæ”»å‡»
                    return True
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç”Ÿç‰©å¤šæ ·æ€§è§‚å¯Ÿå¤±è´¥: {str(e)}")
            return False

    def _execute_biodiversity_examination(self, target_object, game):
        """æ‰§è¡Œç”Ÿç‰©å¤šæ ·æ€§æ£€æŸ¥ï¼ˆæ£€æŸ¥æ ‘æœ¨ç­‰èµ„æºï¼‰"""
        try:
            # å¯»æ‰¾ç›®æ ‡èµ„æºè¿›è¡Œæ£€æŸ¥
            for plant in game.game_map.plants:
                if (plant.__class__.__name__.lower() == target_object and 
                    abs(plant.x - self.x) + abs(plant.y - self.y) <= 1):
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ¦‹ ç”Ÿç‰©å¤šæ ·æ€§æ£€æŸ¥: æ£€æŸ¥{target_object}çš„èµ„æºç‰¹æ€§")
                    
                    # æ£€æŸ¥æˆåŠŸï¼Œè·å¾—å…³äºèµ„æºçš„ä¿¡æ¯
                    return True
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç”Ÿç‰©å¤šæ ·æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    # ğŸ”§ å·¥å…·æ•ˆèƒ½æµ‹è¯•çš„å…·ä½“æ‰§è¡Œå‡½æ•°
    def _test_hunting_tool_efficiency(self, target_object, tool_name, game):
        """æµ‹è¯•ç‹©çŒå·¥å…·æ•ˆèƒ½"""
        try:
            # å¯»æ‰¾ç›®æ ‡åŠ¨ç‰©è¿›è¡Œå·¥å…·æµ‹è¯•
            for animal in game.game_map.animals:
                if (animal.type.lower() == target_object and 
                    animal.alive and 
                    abs(animal.x - self.x) + abs(animal.y - self.y) <= 1):
                    
                    old_health = animal.health if hasattr(animal, 'health') else 100
                    damage = self.attack(animal)
                    
                    # è®°å½•å·¥å…·æ•ˆèƒ½
                    efficiency = damage / 100.0  # ç®€åŒ–çš„æ•ˆèƒ½è®¡ç®—
                    success = damage > 0
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ ç‹©çŒå·¥å…·æµ‹è¯•: {tool_name}å¯¹{target_object}é€ æˆ{damage}ä¼¤å®³ï¼Œæ•ˆèƒ½{efficiency:.2f}")
                    
                    return success
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} ç‹©çŒå·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def _test_ranged_tool_efficiency(self, target_object, tool_name, game):
        """æµ‹è¯•è¿œç¨‹å·¥å…·æ•ˆèƒ½"""
        try:
            # å¯»æ‰¾ç›®æ ‡åŠ¨ç‰©è¿›è¡Œè¿œç¨‹å·¥å…·æµ‹è¯•
            for animal in game.game_map.animals:
                if (animal.type.lower() == target_object and 
                    animal.alive and 
                    abs(animal.x - self.x) + abs(animal.y - self.y) <= 2):  # è¿œç¨‹å·¥å…·å¯ä»¥æ›´è¿œè·ç¦»
                    
                    damage = self.attack(animal)
                    efficiency = damage / 80.0  # è¿œç¨‹å·¥å…·çš„æ•ˆèƒ½åŸºå‡†ä¸åŒ
                    success = damage > 0
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ è¿œç¨‹å·¥å…·æµ‹è¯•: {tool_name}å¯¹{target_object}é€ æˆ{damage}ä¼¤å®³ï¼Œæ•ˆèƒ½{efficiency:.2f}")
                    
                    return success
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} è¿œç¨‹å·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def _test_gathering_tool_efficiency(self, target_object, tool_name, game):
        """æµ‹è¯•é‡‡é›†å·¥å…·æ•ˆèƒ½"""
        try:
            # å¯»æ‰¾ç›®æ ‡æ¤ç‰©è¿›è¡Œé‡‡é›†å·¥å…·æµ‹è¯•
            for plant in game.game_map.plants:
                if (plant.__class__.__name__.lower() == target_object and 
                    not plant.collected and 
                    abs(plant.x - self.x) + abs(plant.y - self.y) <= 1):
                    
                    old_food = self.food
                    self.collect_plant(plant)
                    food_gain = self.food - old_food
                    
                    efficiency = food_gain / 20.0  # é‡‡é›†å·¥å…·çš„æ•ˆèƒ½åŸºå‡†
                    success = food_gain > 0
                    
                    if self.logger:
                        self.logger.log(f"{self.name} ğŸ”§ é‡‡é›†å·¥å…·æµ‹è¯•: {tool_name}é‡‡é›†{target_object}è·å¾—{food_gain}é£Ÿç‰©ï¼Œæ•ˆèƒ½{efficiency:.2f}")
                    
                    return success
            
            return False
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} é‡‡é›†å·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def _test_utility_tool_efficiency(self, target_object, tool_name, game):
        """æµ‹è¯•é€šç”¨å·¥å…·æ•ˆèƒ½"""
        try:
            # å¯¹ç›®æ ‡è¿›è¡Œé€šç”¨å·¥å…·æµ‹è¯•
            if self.logger:
                self.logger.log(f"{self.name} ğŸ”§ é€šç”¨å·¥å…·æµ‹è¯•: ä½¿ç”¨{tool_name}å¯¹{target_object}è¿›è¡Œå¤šåŠŸèƒ½æµ‹è¯•")
            
            # ç®€åŒ–çš„é€šç”¨å·¥å…·æµ‹è¯•ï¼Œæ€»æ˜¯è¿”å›æˆåŠŸ
            return True
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"{self.name} é€šç”¨å·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def _is_valid_position(self, x, y, game):
        """æ£€æŸ¥ä½ç½®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            return (0 <= x < len(game.game_map.grid[0]) and 
                    0 <= y < len(game.game_map.grid))
        except:
            return False


class GameUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Survival Game Control Panel")
        self.create_control_panel()
        self.create_canvas()
        self.game = None

    def create_control_panel(self):
        self.control_frame = tk.Frame(self.root)
        self.control_frame.pack(side=tk.LEFT, fill=tk.Y)
        # Start button
        self.start_button = tk.Button(
            self.control_frame, text="Start Game", command=self.start_game
        )
        self.start_button.pack(pady=5)

        # Map controls
        tk.Label(self.control_frame, text="Map Controls").pack()
        self.map_width_var = tk.IntVar(value=settings["map_width"])
        self.map_height_var = tk.IntVar(value=settings["map_height"])
        map_size_frame = tk.Frame(self.control_frame)
        map_size_frame.pack(pady=2)
        tk.Label(map_size_frame, text="Width").grid(row=0, column=0)
        tk.Button(
            map_size_frame,
            text="-",
            command=lambda: self.adjust("map_width", -5),
        ).grid(row=0, column=1)
        tk.Label(map_size_frame, textvariable=self.map_width_var).grid(row=0, column=2)
        tk.Button(
            map_size_frame,
            text="+",
            command=lambda: self.adjust("map_width", 5),
        ).grid(row=0, column=3)
        tk.Label(map_size_frame, text="Height").grid(row=1, column=0)
        tk.Button(
            map_size_frame,
            text="-",
            command=lambda: self.adjust("map_height", -5),
        ).grid(row=1, column=1)
        tk.Label(map_size_frame, textvariable=self.map_height_var).grid(row=1, column=2)
        tk.Button(
            map_size_frame,
            text="+",
            command=lambda: self.adjust("map_height", 5),
        ).grid(row=1, column=3)

        # Map type selection
        tk.Label(self.control_frame, text="Map Type").pack()
        self.map_type_var = tk.StringVar(value=settings["map_type"])
        map_types = ["Grassland", "Desert", "Forest", "Mountain"]
        self.map_type_menu = tk.OptionMenu(
            self.control_frame, self.map_type_var, *map_types
        )
        self.map_type_menu.pack(pady=2)

        # Map seed input
        tk.Label(self.control_frame, text="Map Seed").pack()
        self.seed_var = tk.IntVar(value=settings["seed"])
        self.seed_entry = tk.Entry(self.control_frame, textvariable=self.seed_var)
        self.seed_entry.pack(pady=2)

        # Resource controls
        tk.Label(self.control_frame, text="Resource Controls").pack()
        self.resource_abundance_var = tk.IntVar(value=settings["resource_abundance"])
        resource_frame = tk.Frame(self.control_frame)
        resource_frame.pack(pady=2)
        tk.Label(resource_frame, text="Abundance(%):").grid(row=0, column=0)
        tk.Button(
            resource_frame,
            text="-",
            command=lambda: self.adjust("resource_abundance", -5),
        ).grid(row=0, column=1)
        tk.Label(resource_frame, textvariable=self.resource_abundance_var).grid(
            row=0, column=2
        )
        tk.Button(
            resource_frame,
            text="+",
            command=lambda: self.adjust("resource_abundance", 5),
        ).grid(row=0, column=3)
        self.resource_regen_var = tk.IntVar(value=settings["resource_regen"])
        tk.Label(resource_frame, text="Regen Cycle(days):").grid(row=1, column=0)
        tk.Button(
            resource_frame,
            text="-",
            command=lambda: self.adjust("resource_regen", -1),
        ).grid(row=1, column=1)
        tk.Label(resource_frame, textvariable=self.resource_regen_var).grid(
            row=1, column=2
        )
        tk.Button(
            resource_frame,
            text="+",
            command=lambda: self.adjust("resource_regen", 1),
        ).grid(row=1, column=3)

        # Duration controls
        tk.Label(self.control_frame, text="Duration Control(days)").pack()
        self.game_duration_var = tk.IntVar(value=settings["game_duration"])
        duration_frame = tk.Frame(self.control_frame)
        duration_frame.pack(pady=2)
        tk.Button(
            duration_frame,
            text="-",
            command=lambda: self.adjust("game_duration", -5),
        ).grid(row=0, column=0)
        tk.Label(duration_frame, textvariable=self.game_duration_var).grid(row=0, column=1)
        tk.Button(
            duration_frame,
            text="+",
            command=lambda: self.adjust("game_duration", 5),
        ).grid(row=0, column=2)

        # Group hunt frequency
        tk.Label(self.control_frame, text="Group Hunt Frequency(%)").pack()
        self.group_hunt_var = tk.IntVar(value=settings["group_hunt_frequency"])
        hunt_frame = tk.Frame(self.control_frame)
        hunt_frame.pack(pady=2)
        tk.Button(
            hunt_frame,
            text="-",
            command=lambda: self.adjust("group_hunt_frequency", -1),
        ).grid(row=0, column=0)
        tk.Label(hunt_frame, textvariable=self.group_hunt_var).grid(row=0, column=1)
        tk.Button(
            hunt_frame,
            text="+",
            command=lambda: self.adjust("group_hunt_frequency", 1),
        ).grid(row=0, column=2)

        # Reasoning attention
        tk.Label(self.control_frame, text="Reasoning Attention(%)").pack()
        self.reasoning_attention_var = tk.IntVar(value=settings["reasoning_attention"])
        reasoning_frame = tk.Frame(self.control_frame)
        reasoning_frame.pack(pady=2)
        tk.Button(
            reasoning_frame,
            text="-",
            command=lambda: self.adjust("reasoning_attention", -5),
        ).grid(row=0, column=0)
        tk.Label(reasoning_frame, textvariable=self.reasoning_attention_var).grid(
            row=0, column=1
        )
        tk.Button(
            reasoning_frame,
            text="+",
            command=lambda: self.adjust("reasoning_attention", 5),
        ).grid(row=0, column=2)

        # Honesty settings (0 means never send messages)
        tk.Label(self.control_frame, text="Honesty(0=never send msg)").pack()
        self.honesty_true_var = tk.IntVar(value=settings["honesty_true"])
        self.honesty_false_var = tk.IntVar(value=settings["honesty_false"])
        self.honesty_none_var = tk.IntVar(value=settings["honesty_none"])
        honesty_frame = tk.Frame(self.control_frame)
        honesty_frame.pack(pady=2)
        tk.Label(honesty_frame, text="True").grid(row=0, column=0)
        tk.Button(
            honesty_frame,
            text="-",
            command=lambda: self.adjust("honesty_true", -5),
        ).grid(row=0, column=1)
        tk.Label(honesty_frame, textvariable=self.honesty_true_var).grid(
            row=0, column=2
        )
        tk.Button(
            honesty_frame,
            text="+",
            command=lambda: self.adjust("honesty_true", 5),
        ).grid(row=0, column=3)
        tk.Label(honesty_frame, text="False").grid(row=1, column=0)
        tk.Button(
            honesty_frame,
            text="-",
            command=lambda: self.adjust("honesty_false", -5),
        ).grid(row=1, column=1)
        tk.Label(honesty_frame, textvariable=self.honesty_false_var).grid(
            row=1, column=2
        )
        tk.Button(
            honesty_frame,
            text="+",
            command=lambda: self.adjust("honesty_false", 5),
        ).grid(row=1, column=3)
        tk.Label(honesty_frame, text="None:").grid(row=2, column=0)
        tk.Button(
            honesty_frame,
            text="-",
            command=lambda: self.adjust("honesty_none", -5),
        ).grid(row=2, column=1)
        tk.Label(honesty_frame, textvariable=self.honesty_none_var).grid(
            row=2, column=2
        )
        tk.Button(
            honesty_frame,
            text="+",
            command=lambda: self.adjust("honesty_none", 5),
        ).grid(row=2, column=3)

        # Infant Learning mechanism control buttons
        tk.Label(self.control_frame, text="Infant Learning Mechanism Control").pack(pady=5)
        self.ilai_vars = {}
        mechanism_list = [
            ("Hierarchical Cognitive Framework", "enable_hierarchical_cognition"),
            ("Developmental Cognitive Framework", "enable_developmental_cognition"),
            ("Dynamic Multi-Head Attention", "enable_dynamic_multihead_attention"),
            ("Social Decision Mechanism", "enable_social_decision"),
            ("Diverse Reward Mechanism", "enable_diverse_rewards"),
            ("Long Short-Term Memory", "enable_lstm"),
            ("Curiosity-Driven Mechanism", "enable_curiosity"),
            ("Deep Logical Alignment", "enable_deep_logical_alignment"),
            ("Reinforcement Learning", "enable_reinforcement_learning"),
        ]
        for text, key in mechanism_list:
            var = tk.BooleanVar(value=settings[key])
            chk = tk.Checkbutton(self.control_frame, text=text, variable=var)
            chk.pack(anchor="w")
            self.ilai_vars[key] = var

        # === ğŸŒ ç¿»è¯‘ç³»ç»Ÿæ§åˆ¶ ===
        tk.Label(self.control_frame, text="Translation System Control").pack(pady=5)
        self.translation_var = tk.BooleanVar(value=settings.get("enable_translation", True))
        translation_chk = tk.Checkbutton(
            self.control_frame, 
            text="ğŸŒ Auto English Translation", 
            variable=self.translation_var,
            font=("Arial", 10, "bold")
        )
        translation_chk.pack(anchor="w")
        
        # æ·»åŠ ç¿»è¯‘ç³»ç»Ÿè¯´æ˜
        translation_info = tk.Label(
            self.control_frame, 
            text="Automatically translate Chinese logs to English",
            font=("Arial", 8),
            fg="gray"
        )
        translation_info.pack(anchor="w", padx=20)

        # Animal/Plant abundance buttons
        tk.Label(self.control_frame, text="Animal/Plant Abundance Control").pack(pady=5)
        abundance_frame = tk.Frame(self.control_frame)
        abundance_frame.pack(pady=2)
        tk.Label(abundance_frame, text="Predator:").grid(row=0, column=0)
        self.animal_predator_var = tk.IntVar(
            value=settings["animal_abundance_predator"]
        )
        tk.Button(
            abundance_frame,
            text="-",
            command=lambda: self.adjust("animal_abundance_predator", -5),
        ).grid(row=0, column=1)
        tk.Label(abundance_frame, textvariable=self.animal_predator_var).grid(
            row=0, column=2
        )
        tk.Button(
            abundance_frame,
            text="+",
            command=lambda: self.adjust("animal_abundance_predator", 5),
        ).grid(row=0, column=3)
        tk.Label(abundance_frame, text="Prey:").grid(row=1, column=0)
        self.animal_prey_var = tk.IntVar(value=settings["animal_abundance_prey"])
        tk.Button(
            abundance_frame,
            text="-",
            command=lambda: self.adjust("animal_abundance_prey", -5),
        ).grid(row=1, column=1)
        tk.Label(abundance_frame, textvariable=self.animal_prey_var).grid(
            row=1, column=2
        )
        tk.Button(
            abundance_frame,
            text="+",
            command=lambda: self.adjust("animal_abundance_prey", 5),
        ).grid(row=1, column=3)
        tk.Label(abundance_frame, text="Edible Plant:").grid(row=2, column=0)
        self.plant_edible_var = tk.IntVar(value=settings["plant_abundance_edible"])
        tk.Button(
            abundance_frame,
            text="-",
            command=lambda: self.adjust("plant_abundance_edible", -5),
        ).grid(row=2, column=1)
        tk.Label(abundance_frame, textvariable=self.plant_edible_var).grid(
            row=2, column=2
        )
        tk.Button(
            abundance_frame,
            text="+",
            command=lambda: self.adjust("plant_abundance_edible", 5),
        ).grid(row=2, column=3)
        tk.Label(abundance_frame, text="Toxic Plant:").grid(row=3, column=0)
        self.plant_toxic_var = tk.IntVar(value=settings["plant_abundance_toxic"])
        tk.Button(
            abundance_frame,
            text="-",
            command=lambda: self.adjust("plant_abundance_toxic", -5),
        ).grid(row=3, column=1)
        tk.Label(abundance_frame, textvariable=self.plant_toxic_var).grid(
            row=3, column=2
        )
        tk.Button(
            abundance_frame,
            text="+",
            command=lambda: self.adjust("plant_abundance_toxic", 5),
        ).grid(row=3, column=3)

    def adjust(self, key, delta):
        if key in ["map_width", "map_height"]:
            settings[key] = max(10, settings[key] + delta)
            if key == "map_width":
                self.map_width_var.set(settings[key])
            else:
                self.map_height_var.set(settings[key])
        elif key == "resource_abundance":
            settings[key] = max(1, settings[key] + delta)
            self.resource_abundance_var.set(settings[key])
        elif key == "resource_regen":
            settings[key] = max(1, settings[key] + delta)
            self.resource_regen_var.set(settings[key])
        elif key == "game_duration":
            settings[key] = max(1, settings[key] + delta)
            self.game_duration_var.set(settings[key])
        elif key == "group_hunt_frequency":
            settings[key] = max(1, settings[key] + delta)
            self.group_hunt_var.set(settings[key])
        elif key == "reasoning_attention":
            settings[key] = max(0, settings[key] + delta)
            self.reasoning_attention_var.set(settings[key])
        elif key in ["honesty_true", "honesty_false", "honesty_none"]:
            settings[key] = max(0, settings[key] + delta)
            if key == "honesty_true":
                self.honesty_true_var.set(settings[key])
            elif key == "honesty_false":
                self.honesty_false_var.set(settings[key])
            else:
                self.honesty_none_var.set(settings[key])
        elif key in [
            "animal_abundance_predator",
            "animal_abundance_prey",
            "plant_abundance_edible",
            "plant_abundance_toxic",
        ]:
            settings[key] = max(1, settings[key] + delta)
            if key == "animal_abundance_predator":
                self.animal_predator_var.set(settings[key])
            elif key == "animal_abundance_prey":
                self.animal_prey_var.set(settings[key])
            elif key == "plant_abundance_edible":
                self.plant_edible_var.set(settings[key])
            else:
                self.plant_toxic_var.set(settings[key])

    def create_canvas(self):
        # Create a frame to contain day label and canvas
        self.canvas_frame = tk.Frame(self.root)
        self.canvas_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)
        
        # Create day label
        self.day_label = tk.Label(self.canvas_frame, text="Game Days: 0", font=("Arial", 14, "bold"))
        self.day_label.pack(pady=5)
        
        # Create larger canvas
        self.canvas = tk.Canvas(self.canvas_frame, width=1000, height=1000, bg="white")
        self.canvas.pack()

    def update_canvas(self):
        # å°†åœ°å›¾ç½‘æ ¼ã€åŠ¨ç‰©ã€æ¤ç‰©å’Œç©å®¶æ˜¾ç¤ºåˆ°ç”»å¸ƒä¸Š
        self.canvas.delete("all")
        
        if not self.game:
            return
            
        # Update day label
        self.day_label.config(text=f"Game Days: {self.game.current_day}")

        # Calculate scale
        scale = min(1000 / self.game.game_map.width, 1000 / self.game.game_map.height)
        # Draw terrain background
        for i in range(self.game.game_map.height):
            for j in range(self.game.game_map.width):
                cell = self.game.game_map.grid[i][j]
                color = "white"
                if cell == "plain":
                    color = "#e0e0e0"
                elif cell == "big_tree":
                    color = "green"
                elif cell == "bush":
                    color = "darkgreen"
                elif cell == "rock":
                    color = "gray"
                elif cell == "cave":
                    color = "brown"
                elif cell == "river":
                    color = "blue"
                elif cell == "puddle":
                    color = "lightblue"
                self.canvas.create_rectangle(
                    j * scale, i * scale, (j + 1) * scale, (i + 1) * scale, fill=color, outline=""
                )
        # Draw animals: predators in red, prey in orange
        for animal in self.game.game_map.animals:
            if animal.alive:
                x = animal.x * scale
                y = animal.y * scale
                if animal.type in ["Tiger", "BlackBear"]:
                    fill_color = "red"
                else:
                    fill_color = "orange"
                self.canvas.create_oval(x, y, x + scale, y + scale, fill=fill_color)
        # Draw plants
        for plant in self.game.game_map.plants:
            if not plant.collected:
                x = plant.x * scale
                y = plant.y * scale
                fill_color = "pink" if not getattr(plant, "toxic", False) else "purple"
                self.canvas.create_rectangle(x, y, x + scale, y + scale, fill=fill_color)
        # Draw players: DQN in blue, PPO in cyan, ILAI in magenta
        for player in self.game.players:
            if player.is_alive():
                x = player.x * scale
                y = player.y * scale
                if player.player_type == "DQN":
                    fill_color = "blue"
                elif player.player_type == "PPO":
                    fill_color = "cyan"
                elif player.player_type == "ILAI":
                    fill_color = "magenta"
                elif player.player_type == "RL":
                    fill_color = "yellow"
                # Draw player icon
                self.canvas.create_oval(x, y, x + scale, y + scale, fill=fill_color)
                # Display name above player icon
                self.canvas.create_text(x + scale/2, y - 5, text=player.name, 
                                     anchor="s", font=("Arial", max(int(scale/3), 8)), fill="black")

    def start_game(self):
        # Read parameters from UI and update global settings
        settings["map_width"] = self.map_width_var.get()
        settings["map_height"] = self.map_height_var.get()
        settings["map_type"] = self.map_type_var.get()
        settings["seed"] = self.seed_var.get()
        settings["resource_abundance"] = self.resource_abundance_var.get()
        settings["resource_regen"] = self.resource_regen_var.get()
        settings["game_duration"] = self.game_duration_var.get()
        settings["group_hunt_frequency"] = self.group_hunt_var.get()
        settings["reasoning_attention"] = self.reasoning_attention_var.get()
        settings["honesty_true"] = self.honesty_true_var.get()
        settings["honesty_false"] = self.honesty_false_var.get()
        settings["honesty_none"] = self.honesty_none_var.get()
        # === ğŸŒ è¯»å–ç¿»è¯‘ç³»ç»Ÿè®¾ç½® ===
        settings["enable_translation"] = self.translation_var.get()
        for key, var in self.ilai_vars.items():
            settings[key] = var.get()
        # Create game instance
        self.game = Game(settings, self.canvas, self.update_canvas)
        self.start_button.config(state=tk.DISABLED)
        self.game.run_turn()


if __name__ == "__main__":
    root = tk.Tk()
    app = GameUI(root)
    root.mainloop()
