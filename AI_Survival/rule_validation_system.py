"""
è§„å¾‹éªŒè¯ç³»ç»Ÿï¼ˆRule Validation Systemï¼‰

å®ç°BPMä¸­çš„è§„å¾‹éªŒè¯æœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»åŠ¨éªŒè¯ç­–ç•¥ - è¯†åˆ«å’Œé€‰æ‹©éœ€è¦éªŒè¯çš„è§„å¾‹
2. ç½®ä¿¡åº¦æ›´æ–°ç®—æ³• - åŸºäºéªŒè¯ç»“æœåŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦
3. å†’é™©éªŒè¯æœºåˆ¶ - åœ¨å®‰å…¨èŒƒå›´å†…è¿›è¡Œæ¢ç´¢æ€§éªŒè¯
4. éªŒè¯ç»“æœå¤„ç† - åˆ†ç±»å¤„ç†éªŒè¯æˆåŠŸ/å¤±è´¥/éƒ¨åˆ†æˆåŠŸçš„æƒ…å†µ

åŸºäºç”¨æˆ·æå‡ºçš„"é€‚å½“å†’é™©éªŒè¯"ç†å¿µï¼Œå¦‚é€šè¿‡é­é‡å¤§é»‘ç†Šå¾—å‡ºçš„è§„å¾‹éœ€è¦åœ¨é‡åˆ°é‡çŒªæ—¶éªŒè¯ã€‚

ä½œè€…ï¼šAIç”Ÿå­˜æ¸¸æˆé¡¹ç›®ç»„
ç‰ˆæœ¬ï¼š1.0.0
"""

import time
import math
import random
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple, Set
from enum import Enum
from collections import defaultdict, deque
from eocar_combination_generator import CandidateRule, CombinationType
from scene_symbolization_mechanism import (
    EOCATR_Tuple, SymbolicEnvironment, SymbolicObjectCategory, 
    SymbolicAction, SymbolicCharacteristics, SymbolicResult, SymbolicTool
)


class ValidationStrategy(Enum):
    """éªŒè¯ç­–ç•¥æšä¸¾"""
    PASSIVE = "passive"              # è¢«åŠ¨éªŒè¯ï¼šç­‰å¾…è‡ªç„¶æƒ…å†µéªŒè¯
    ACTIVE_SAFE = "active_safe"      # ä¸»åŠ¨å®‰å…¨éªŒè¯ï¼šåœ¨å®‰å…¨æƒ…å†µä¸‹éªŒè¯
    ACTIVE_RISKY = "active_risky"    # ä¸»åŠ¨å†’é™©éªŒè¯ï¼šé€‚åº¦å†’é™©éªŒè¯
    OPPORTUNISTIC = "opportunistic"  # æœºä¼šéªŒè¯ï¼šé‡åˆ°ç›¸ä¼¼æƒ…å†µæ—¶éªŒè¯
    SYSTEMATIC = "systematic"        # ç³»ç»ŸéªŒè¯ï¼šæœ‰è®¡åˆ’åœ°éªŒè¯å…³é”®è§„å¾‹


class ValidationResult(Enum):
    """éªŒè¯ç»“æœæšä¸¾"""
    SUCCESS = "success"              # éªŒè¯æˆåŠŸï¼šé¢„æœŸç»“æœä¸å®é™…ç»“æœä¸€è‡´
    FAILURE = "failure"              # éªŒè¯å¤±è´¥ï¼šé¢„æœŸç»“æœä¸å®é™…ç»“æœå®Œå…¨ä¸ç¬¦
    PARTIAL = "partial"              # éƒ¨åˆ†éªŒè¯ï¼šç»“æœéƒ¨åˆ†ç¬¦åˆé¢„æœŸ
    INCONCLUSIVE = "inconclusive"    # ç»“æœä¸æ˜ç¡®ï¼šæ— æ³•ç¡®å®šéªŒè¯ç»“æœ
    ERROR = "error"                  # éªŒè¯é”™è¯¯ï¼šéªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜


class RiskLevel(Enum):
    """é£é™©ç­‰çº§æšä¸¾"""
    SAFE = "safe"                    # å®‰å…¨ï¼šé¢„æœŸæ— è´Ÿé¢åæœ
    LOW = "low"                      # ä½é£é™©ï¼šå¯èƒ½æœ‰è½»å¾®è´Ÿé¢åæœ
    MEDIUM = "medium"                # ä¸­ç­‰é£é™©ï¼šå¯èƒ½æœ‰ä¸­ç­‰è´Ÿé¢åæœ
    HIGH = "high"                    # é«˜é£é™©ï¼šå¯èƒ½æœ‰ä¸¥é‡è´Ÿé¢åæœ
    CRITICAL = "critical"            # æé«˜é£é™©ï¼šå¯èƒ½å±åŠç”Ÿå­˜


@dataclass
class ValidationAttempt:
    """éªŒè¯å°è¯•è®°å½•"""
    attempt_id: str                   # å°è¯•ID
    rule_id: str                      # è¢«éªŒè¯è§„å¾‹ID
    timestamp: float                  # éªŒè¯æ—¶é—´
    strategy: ValidationStrategy      # ä½¿ç”¨çš„éªŒè¯ç­–ç•¥
    risk_level: RiskLevel            # é£é™©ç­‰çº§
    
    # éªŒè¯ä¸Šä¸‹æ–‡
    context_eocar: EOCATR_Tuple       # éªŒè¯æ—¶çš„EOCATRæƒ…å†µ
    expected_result: Dict[str, Any]   # é¢„æœŸç»“æœ
    actual_result: Dict[str, Any]     # å®é™…ç»“æœ
    
    # éªŒè¯ç»“æœ
    validation_result: ValidationResult  # éªŒè¯ç»“æœ
    confidence_before: float         # éªŒè¯å‰ç½®ä¿¡åº¦
    confidence_after: float          # éªŒè¯åç½®ä¿¡åº¦
    confidence_change: float         # ç½®ä¿¡åº¦å˜åŒ–
    
    # éªŒè¯è´¨é‡
    reliability_score: float = 0.0   # éªŒè¯å¯é æ€§å¾—åˆ†
    relevance_score: float = 0.0     # éªŒè¯ç›¸å…³æ€§å¾—åˆ†
    impact_score: float = 0.0        # éªŒè¯å½±å“å¾—åˆ†
    
    def calculate_validation_quality(self) -> float:
        """è®¡ç®—éªŒè¯è´¨é‡ç»¼åˆå¾—åˆ†"""
        return (self.reliability_score * 0.4 + 
                self.relevance_score * 0.4 + 
                self.impact_score * 0.2)


@dataclass
class ValidationPlan:
    """éªŒè¯è®¡åˆ’"""
    plan_id: str                     # è®¡åˆ’ID
    target_rules: List[str]          # ç›®æ ‡è§„å¾‹IDåˆ—è¡¨
    strategy: ValidationStrategy     # éªŒè¯ç­–ç•¥
    priority: float = 0.5            # ä¼˜å…ˆçº§ (0.0-1.0)
    
    # è®¡åˆ’å‚æ•°
    max_risk_level: RiskLevel = RiskLevel.MEDIUM  # æœ€å¤§å¯æ¥å—é£é™©
    expected_attempts: int = 1       # é¢„æœŸéªŒè¯æ¬¡æ•°
    timeout_hours: float = 24.0      # è®¡åˆ’è¶…æ—¶æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    
    # è®¡åˆ’çŠ¶æ€
    created_time: float = field(default_factory=time.time)
    status: str = "pending"          # pending/active/completed/cancelled
    progress: float = 0.0            # è¿›åº¦ (0.0-1.0)
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥è®¡åˆ’æ˜¯å¦å·²è¿‡æœŸ"""
        return (time.time() - self.created_time) / 3600 > self.timeout_hours


class ConfidenceUpdater:
    """ç½®ä¿¡åº¦æ›´æ–°å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or self._default_config()
        
        # è´å¶æ–¯æ›´æ–°å‚æ•°
        self.prior_alpha = self.config.get('prior_alpha', 1.0)  # å…ˆéªŒæˆåŠŸæ¬¡æ•°
        self.prior_beta = self.config.get('prior_beta', 1.0)    # å…ˆéªŒå¤±è´¥æ¬¡æ•°
        
        # å­¦ä¹ ç‡å‚æ•°
        self.base_learning_rate = self.config.get('base_learning_rate', 0.1)
        self.success_multiplier = self.config.get('success_multiplier', 1.2)
        self.failure_multiplier = self.config.get('failure_multiplier', 1.5)
        
        # ç½®ä¿¡åº¦è¾¹ç•Œ
        self.min_confidence = self.config.get('min_confidence', 0.01)
        self.max_confidence = self.config.get('max_confidence', 0.99)
    
    def _default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            'prior_alpha': 1.0,
            'prior_beta': 1.0,
            'base_learning_rate': 0.1,
            'success_multiplier': 1.2,
            'failure_multiplier': 1.5,
            'min_confidence': 0.01,
            'max_confidence': 0.99,
            'decay_factor': 0.95,  # æ—¶é—´è¡°å‡å› å­
            'relevance_weight': 0.3,  # ç›¸å…³æ€§æƒé‡
            'reliability_weight': 0.4,  # å¯é æ€§æƒé‡
        }
    
    def update_confidence(self, rule: CandidateRule, attempt: ValidationAttempt) -> float:
        """åŸºäºéªŒè¯å°è¯•æ›´æ–°è§„å¾‹ç½®ä¿¡åº¦"""
        
        # è®¡ç®—åŸºç¡€æ›´æ–°é‡
        base_update = self._calculate_base_update(attempt)
        
        # åº”ç”¨è´¨é‡è°ƒæ•´
        quality_factor = self._calculate_quality_factor(attempt)
        
        # åº”ç”¨ç›¸å…³æ€§è°ƒæ•´
        relevance_factor = self._calculate_relevance_factor(rule, attempt)
        
        # åº”ç”¨æ—¶é—´è¡°å‡
        time_factor = self._calculate_time_factor(rule, attempt)
        
        # è®¡ç®—æœ€ç»ˆæ›´æ–°é‡
        final_update = base_update * quality_factor * relevance_factor * time_factor
        
        # æ›´æ–°ç½®ä¿¡åº¦
        new_confidence = rule.confidence + final_update
        
        # åº”ç”¨è¾¹ç•Œçº¦æŸ
        new_confidence = max(self.min_confidence, min(self.max_confidence, new_confidence))
        
        return new_confidence
    
    def _calculate_base_update(self, attempt: ValidationAttempt) -> float:
        """è®¡ç®—åŸºç¡€ç½®ä¿¡åº¦æ›´æ–°é‡"""
        if attempt.validation_result == ValidationResult.SUCCESS:
            return self.base_learning_rate * self.success_multiplier
        elif attempt.validation_result == ValidationResult.FAILURE:
            return -self.base_learning_rate * self.failure_multiplier
        elif attempt.validation_result == ValidationResult.PARTIAL:
            # éƒ¨åˆ†éªŒè¯çš„æ›´æ–°é‡å–å†³äºéƒ¨åˆ†æˆåŠŸçš„ç¨‹åº¦
            partial_success_rate = self._estimate_partial_success_rate(attempt)
            return self.base_learning_rate * (2 * partial_success_rate - 1)
        else:  # INCONCLUSIVE æˆ– ERROR
            return 0.0
    
    def _estimate_partial_success_rate(self, attempt: ValidationAttempt) -> float:
        """ä¼°è®¡éƒ¨åˆ†éªŒè¯çš„æˆåŠŸç‡"""
        expected = attempt.expected_result
        actual = attempt.actual_result
        
        # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
        matches = 0
        total = 0
        
        for key in expected:
            if key in actual:
                total += 1
                if expected[key] == actual[key]:
                    matches += 1
                elif isinstance(expected[key], (int, float)) and isinstance(actual[key], (int, float)):
                    # æ•°å€¼ç±»å‹æŒ‰ç›¸ä¼¼åº¦è®¡ç®—
                    diff = abs(expected[key] - actual[key])
                    max_val = max(abs(expected[key]), abs(actual[key]), 1)
                    similarity = 1 - min(diff / max_val, 1)
                    matches += similarity
        
        return matches / total if total > 0 else 0.5
    
    def _calculate_quality_factor(self, attempt: ValidationAttempt) -> float:
        """è®¡ç®—éªŒè¯è´¨é‡å› å­"""
        quality_score = attempt.calculate_validation_quality()
        # å°†è´¨é‡å¾—åˆ†è½¬æ¢ä¸ºä¹˜æ•°å› å­ (0.5 - 1.5)
        return 0.5 + quality_score
    
    def _calculate_relevance_factor(self, rule: CandidateRule, attempt: ValidationAttempt) -> float:
        """è®¡ç®—éªŒè¯ç›¸å…³æ€§å› å­"""
        # æ£€æŸ¥éªŒè¯ä¸Šä¸‹æ–‡ä¸è§„å¾‹æ¡ä»¶çš„åŒ¹é…ç¨‹åº¦
        relevance = self._calculate_context_relevance(rule, attempt.context_eocar)
        
        # å°†ç›¸å…³æ€§è½¬æ¢ä¸ºä¹˜æ•°å› å­ (0.3 - 1.2)
        return 0.3 + 0.9 * relevance
    
    def _calculate_context_relevance(self, rule: CandidateRule, context: EOCATR_Tuple) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        try:
            relevance_scores = []
            
            # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°å¤„ç†æ¡ä»¶å…ƒç´ ï¼Œé¿å…SymbolicElementå“ˆå¸Œé—®é¢˜
            condition_elements = getattr(rule, 'condition_elements', [])
            
            if not condition_elements:
                return 0.5  # é»˜è®¤ç›¸å…³æ€§
            
            # æ£€æŸ¥æ¯ä¸ªæ¡ä»¶å…ƒç´ 
            for condition in condition_elements:
                # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°è½¬æ¢æ¡ä»¶ä¸ºå­—ç¬¦ä¸²
                condition_str = ""
                if hasattr(condition, 'content'):
                    condition_str = str(condition.content)
                elif isinstance(condition, str):
                    condition_str = condition
                else:
                    condition_str = str(condition)
                
                if "ç¯å¢ƒ=" in condition_str:
                    env_name = condition_str.split("=")[1]
                    if hasattr(context.environment, 'value'):
                        context_env = context.environment.value
                    else:
                        context_env = str(context.environment)
                    
                    if env_name == context_env:
                        relevance_scores.append(1.0)
                    else:
                        relevance_scores.append(0.3)
                        
                elif "å¯¹è±¡=" in condition_str:
                    obj_name = condition_str.split("=")[1]
                    if hasattr(context.object_category, 'value'):
                        context_obj = context.object_category.value
                    else:
                        context_obj = str(context.object_category)
                        
                    if obj_name == context_obj:
                        relevance_scores.append(1.0)
                    else:
                        relevance_scores.append(0.3)
                        
                elif "åŠ¨ä½œ=" in condition_str:
                    action_name = condition_str.split("=")[1]
                    if hasattr(context.action, 'value'):
                        context_action = context.action.value
                    else:
                        context_action = str(context.action)
                        
                    if action_name == context_action:
                        relevance_scores.append(1.0)
                    else:
                        relevance_scores.append(0.3)
                else:
                    # å±æ€§ç±»æ¡ä»¶ï¼Œç»™ä¸­ç­‰ç›¸å…³æ€§
                    relevance_scores.append(0.6)
            
            return sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0.5
            
        except Exception as e:
            # å¦‚æœå‡ºç°ä»»ä½•é”™è¯¯ï¼Œè¿”å›é»˜è®¤ç›¸å…³æ€§
            if hasattr(self, 'logger') and self.logger:
                self.logger.log(f"è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§å¤±è´¥: {str(e)}")
            return 0.5
    
    def _calculate_time_factor(self, rule: CandidateRule, attempt: ValidationAttempt) -> float:
        """è®¡ç®—æ—¶é—´è¡°å‡å› å­"""
        time_since_creation = attempt.timestamp - rule.generation_time
        hours_since_creation = time_since_creation / 3600
        
        # æ—¶é—´è¡°å‡ï¼šè§„å¾‹è¶Šæ–°ï¼ŒéªŒè¯çš„å½±å“è¶Šå¤§
        decay = self.config['decay_factor'] ** (hours_since_creation / 24)  # æ¯24å°æ—¶è¡°å‡
        
        return max(0.5, decay)  # æœ€å°ä¿æŒ50%çš„å½±å“


class RiskAssessor:
    """é£é™©è¯„ä¼°å™¨"""
    
    def __init__(self, logger=None):
        self.logger = logger
        
        # é£é™©è¯„ä¼°è§„åˆ™
        self.risk_rules = {
            # ç¯å¢ƒé£é™©
            SymbolicEnvironment.DANGEROUS_ZONE: RiskLevel.HIGH,
            SymbolicEnvironment.FOREST: RiskLevel.MEDIUM,
            SymbolicEnvironment.OPEN_FIELD: RiskLevel.LOW,
            SymbolicEnvironment.SAFE_ZONE: RiskLevel.SAFE,
            SymbolicEnvironment.WATER_AREA: RiskLevel.LOW,
            
            # å¯¹è±¡é£é™©
            SymbolicObjectCategory.DANGEROUS_ANIMAL: RiskLevel.HIGH,
            SymbolicObjectCategory.HARMLESS_ANIMAL: RiskLevel.LOW,
            SymbolicObjectCategory.POISONOUS_PLANT: RiskLevel.MEDIUM,
            SymbolicObjectCategory.EDIBLE_PLANT: RiskLevel.SAFE,
            SymbolicObjectCategory.WATER_SOURCE: RiskLevel.SAFE,
            
            # åŠ¨ä½œé£é™©
            SymbolicAction.ATTACK: RiskLevel.HIGH,
            SymbolicAction.AVOID: RiskLevel.SAFE,
            SymbolicAction.EXPLORE: RiskLevel.MEDIUM,
            SymbolicAction.EAT: RiskLevel.MEDIUM,
            SymbolicAction.GATHER: RiskLevel.LOW,
            SymbolicAction.DRINK: RiskLevel.SAFE,
        }
    
    def assess_validation_risk(self, rule: CandidateRule, context: EOCATR_Tuple, 
                              player_state: Optional[Dict[str, Any]] = None) -> RiskLevel:
        """è¯„ä¼°éªŒè¯ç‰¹å®šè§„å¾‹çš„é£é™©ç­‰çº§ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        
        risk_factors = []
        
        # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°è®¿é—®æšä¸¾å€¼ï¼Œé¿å…SymbolicElementå“ˆå¸Œé—®é¢˜
        try:
            # ç¯å¢ƒé£é™©
            env_key = context.environment if hasattr(context.environment, 'value') else None
            env_risk = self.risk_rules.get(env_key, RiskLevel.MEDIUM)
            risk_factors.append(env_risk.value)
            
            # å¯¹è±¡é£é™©
            obj_key = context.object_category if hasattr(context.object_category, 'value') else None
            obj_risk = self.risk_rules.get(obj_key, RiskLevel.MEDIUM)
            risk_factors.append(obj_risk.value)
            
            # åŠ¨ä½œé£é™©
            action_key = context.action if hasattr(context.action, 'value') else None
            action_risk = self.risk_rules.get(action_key, RiskLevel.MEDIUM)
            risk_factors.append(action_risk.value)
        except Exception as e:
            # å¦‚æœå‡ºç°å“ˆå¸Œé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é£é™©ç­‰çº§
            if self.logger:
                self.logger.log(f"é£é™©è¯„ä¼°è®¿é—®æšä¸¾å¤±è´¥: {str(e)}")
            risk_factors.extend([RiskLevel.MEDIUM.value] * 3)
        
        # ç‰¹å¾é£é™©
        char_risk = self._assess_characteristics_risk(context.characteristics)
        risk_factors.append(char_risk.value)
        
        # ç©å®¶çŠ¶æ€é£é™©
        if player_state:
            state_risk = self._assess_player_state_risk(player_state)
            risk_factors.append(state_risk.value)
        
        # è§„å¾‹ç‰¹å®šé£é™©
        rule_risk = self._assess_rule_specific_risk(rule)
        risk_factors.append(rule_risk.value)
        
        # è®¡ç®—ç»¼åˆé£é™©ç­‰çº§
        risk_mapping = {"safe": 0, "low": 1, "medium": 2, "high": 3, "critical": 4}
        reverse_mapping = {0: RiskLevel.SAFE, 1: RiskLevel.LOW, 2: RiskLevel.MEDIUM, 
                          3: RiskLevel.HIGH, 4: RiskLevel.CRITICAL}
        
        avg_risk = sum(risk_mapping[rf] for rf in risk_factors) / len(risk_factors)
        final_risk_level = reverse_mapping[round(avg_risk)]
        
        if self.logger:
            self.logger.log(f"éªŒè¯é£é™©è¯„ä¼°: {rule.rule_id} -> {final_risk_level.value}")
        
        return final_risk_level
    
    def _assess_characteristics_risk(self, characteristics: SymbolicCharacteristics) -> RiskLevel:
        """è¯„ä¼°ç‰¹å¾ç›¸å…³é£é™©"""
        if characteristics.dangerous:
            return RiskLevel.HIGH
        elif characteristics.poisonous:
            return RiskLevel.MEDIUM
        elif characteristics.distance and characteristics.distance < 1.0:
            return RiskLevel.MEDIUM  # è¿‘è·ç¦»æ¥è§¦é£é™©
        else:
            return RiskLevel.LOW
    
    def _assess_player_state_risk(self, player_state: Dict[str, Any]) -> RiskLevel:
        """è¯„ä¼°ç©å®¶çŠ¶æ€ç›¸å…³é£é™©"""
        health = player_state.get('health', 100)
        food = player_state.get('food', 100)
        water = player_state.get('water', 100)
        
        # ç”Ÿå‘½å€¼ä½æ—¶é£é™©é«˜
        if health < 30:
            return RiskLevel.CRITICAL
        elif health < 50:
            return RiskLevel.HIGH
        elif health < 70:
            return RiskLevel.MEDIUM
        
        # é¥¥é¥¿æˆ–å£æ¸´æ—¶é£é™©å¢åŠ 
        if food < 20 or water < 20:
            return RiskLevel.HIGH
        elif food < 40 or water < 40:
            return RiskLevel.MEDIUM
        
        return RiskLevel.LOW
    
    def _assess_rule_specific_risk(self, rule: CandidateRule) -> RiskLevel:
        """è¯„ä¼°è§„å¾‹ç‰¹å®šé£é™©"""
        # è§„å¾‹ç½®ä¿¡åº¦ä½æ—¶é£é™©é«˜
        if rule.confidence < 0.3:
            return RiskLevel.HIGH
        elif rule.confidence < 0.5:
            return RiskLevel.MEDIUM
        
        # é¢„æœŸè´Ÿé¢ç»“æœçš„è§„å¾‹éªŒè¯é£é™©é«˜
        expected_result = rule.expected_result
        if (expected_result.get('hp_change', 0) < 0 or 
            expected_result.get('success', True) == False):
            return RiskLevel.HIGH
        
        return RiskLevel.LOW


class ValidationPlanner:
    """éªŒè¯è®¡åˆ’å™¨"""
    
    def __init__(self, confidence_updater: ConfidenceUpdater, 
                 risk_assessor: RiskAssessor, logger=None):
        self.confidence_updater = confidence_updater
        self.risk_assessor = risk_assessor
        self.logger = logger
        
        # éªŒè¯è®¡åˆ’å­˜å‚¨
        self.active_plans: Dict[str, ValidationPlan] = {}
        self.completed_plans: List[ValidationPlan] = []
        self.validation_history: List[ValidationAttempt] = []
        
        # è®¡åˆ’ç”Ÿæˆå‚æ•°
        self.max_active_plans = 5
        self.plan_counter = 0
    
    def create_validation_plan(self, rules: List[CandidateRule], 
                              strategy: ValidationStrategy = ValidationStrategy.OPPORTUNISTIC,
                              max_risk: RiskLevel = RiskLevel.MEDIUM) -> Optional[ValidationPlan]:
        """åˆ›å»ºéªŒè¯è®¡åˆ’"""
        
        if len(self.active_plans) >= self.max_active_plans:
            if self.logger:
                self.logger.log("éªŒè¯è®¡åˆ’å·²æ»¡ï¼Œæ— æ³•åˆ›å»ºæ–°è®¡åˆ’")
            return None
        
        # é€‰æ‹©éœ€è¦éªŒè¯çš„è§„å¾‹
        target_rules = self._select_validation_targets(rules, max_risk)
        
        if not target_rules:
            return None
        
        self.plan_counter += 1
        plan = ValidationPlan(
            plan_id=f"plan_{self.plan_counter}_{strategy.value}",
            target_rules=[rule.rule_id for rule in target_rules],
            strategy=strategy,
            priority=self._calculate_plan_priority(target_rules),
            max_risk_level=max_risk
        )
        
        self.active_plans[plan.plan_id] = plan
        
        if self.logger:
            self.logger.log(f"åˆ›å»ºéªŒè¯è®¡åˆ’: {plan.plan_id}, ç›®æ ‡è§„å¾‹æ•°: {len(target_rules)}")
        
        return plan
    
    def _select_validation_targets(self, rules: List[CandidateRule], 
                                  max_risk: RiskLevel) -> List[CandidateRule]:
        """é€‰æ‹©éœ€è¦éªŒè¯çš„è§„å¾‹"""
        candidates = []
        
        for rule in rules:
            # ä¼˜å…ˆé€‰æ‹©ä¸­ç­‰ç½®ä¿¡åº¦çš„è§„å¾‹ï¼ˆæœ€éœ€è¦éªŒè¯ï¼‰
            if 0.3 <= rule.confidence <= 0.7:
                candidates.append((rule, self._calculate_validation_priority(rule)))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        candidates.sort(key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©å‰å‡ ä¸ªè§„å¾‹
        max_targets = 3
        selected = [rule for rule, _ in candidates[:max_targets]]
        
        return selected
    
    def _calculate_validation_priority(self, rule: CandidateRule) -> float:
        """è®¡ç®—è§„å¾‹éªŒè¯ä¼˜å…ˆçº§"""
        priority = 0.0
        
        # ç½®ä¿¡åº¦å› å­ï¼šä¸­ç­‰ç½®ä¿¡åº¦ä¼˜å…ˆçº§æœ€é«˜
        conf_factor = 1 - abs(rule.confidence - 0.5) * 2
        priority += conf_factor * 0.4
        
        # ä½¿ç”¨é¢‘ç‡å› å­ï¼šæ¿€æ´»æ¬¡æ•°å¤šçš„è§„å¾‹ä¼˜å…ˆçº§é«˜
        usage_factor = min(rule.activation_count / 10, 1.0)
        priority += usage_factor * 0.3
        
        # æ–°é²œåº¦å› å­ï¼šè¾ƒæ–°çš„è§„å¾‹ä¼˜å…ˆçº§é«˜
        age_hours = (time.time() - rule.generation_time) / 3600
        freshness_factor = max(0, 1 - age_hours / 48)  # 48å°æ—¶å†…è®¤ä¸ºæ–°é²œ
        priority += freshness_factor * 0.2
        
        # è´¨é‡å› å­ï¼šé«˜è´¨é‡è§„å¾‹ä¼˜å…ˆçº§é«˜
        quality_factor = rule.calculate_quality_score()
        priority += quality_factor * 0.1
        
        return priority
    
    def _calculate_plan_priority(self, rules: List[CandidateRule]) -> float:
        """è®¡ç®—è®¡åˆ’ä¼˜å…ˆçº§"""
        if not rules:
            return 0.0
        
        avg_priority = sum(self._calculate_validation_priority(rule) for rule in rules) / len(rules)
        return avg_priority
    
    def suggest_validation_action(self, current_context: EOCATR_Tuple, 
                                 available_rules: List[CandidateRule],
                                 player_state: Optional[Dict[str, Any]] = None) -> Optional[Tuple[CandidateRule, ValidationStrategy]]:
        """å»ºè®®å½“å‰æƒ…å†µä¸‹çš„éªŒè¯è¡ŒåŠ¨"""
        
        # å¯»æ‰¾ä¸å½“å‰ä¸Šä¸‹æ–‡ç›¸å…³çš„è§„å¾‹
        relevant_rules = self._find_relevant_rules(current_context, available_rules)
        
        if not relevant_rules:
            return None
        
        # è¯„ä¼°æ¯ä¸ªè§„å¾‹çš„éªŒè¯ä»·å€¼å’Œé£é™©
        best_rule = None
        best_strategy = None
        best_score = 0
        
        for rule in relevant_rules:
            # è¯„ä¼°é£é™©
            risk_level = self.risk_assessor.assess_validation_risk(rule, current_context, player_state)
            
            # è®¡ç®—éªŒè¯ä»·å€¼
            validation_value = self._calculate_validation_value(rule, risk_level)
            
            if validation_value > best_score:
                best_score = validation_value
                best_rule = rule
                best_strategy = self._select_validation_strategy(rule, risk_level)
        
        if best_rule and best_score > 0.3:  # é˜ˆå€¼
            return (best_rule, best_strategy)
        
        return None
    
    def _find_relevant_rules(self, context: EOCATR_Tuple, 
                           rules: List[CandidateRule]) -> List[CandidateRule]:
        """æ‰¾åˆ°ä¸å½“å‰ä¸Šä¸‹æ–‡ç›¸å…³çš„è§„å¾‹"""
        relevant = []
        
        for rule in rules:
            relevance = self.confidence_updater._calculate_context_relevance(rule, context)
            if relevance > 0.5:  # ç›¸å…³æ€§é˜ˆå€¼
                relevant.append(rule)
        
        return relevant
    
    def _calculate_validation_value(self, rule: CandidateRule, risk_level: RiskLevel) -> float:
        """è®¡ç®—éªŒè¯ä»·å€¼"""
        value = 0.0
        
        # ä¸ç¡®å®šæ€§ä»·å€¼ï¼šç½®ä¿¡åº¦è¶Šä¸ç¡®å®šï¼ŒéªŒè¯ä»·å€¼è¶Šé«˜
        uncertainty = 1 - abs(rule.confidence - 0.5) * 2
        value += uncertainty * 0.4
        
        # é‡è¦æ€§ä»·å€¼ï¼šè´¨é‡å¾—åˆ†é«˜çš„è§„å¾‹éªŒè¯ä»·å€¼é«˜
        importance = rule.calculate_quality_score()
        value += importance * 0.3
        
        # é£é™©æƒ©ç½šï¼šé£é™©è¶Šé«˜ï¼Œä»·å€¼è¶Šä½
        risk_penalty = {"safe": 0, "low": 0.1, "medium": 0.3, "high": 0.6, "critical": 0.9}
        value -= risk_penalty.get(risk_level.value, 0.5)
        
        # éªŒè¯å†å²ï¼šå·²éªŒè¯æ¬¡æ•°å¤šçš„è§„å¾‹ä»·å€¼é™ä½
        validation_count = rule.validation_attempts
        history_penalty = min(validation_count / 5, 0.5)
        value -= history_penalty * 0.2
        
        return max(0, value)
    
    def _select_validation_strategy(self, rule: CandidateRule, risk_level: RiskLevel) -> ValidationStrategy:
        """é€‰æ‹©éªŒè¯ç­–ç•¥"""
        if risk_level == RiskLevel.SAFE:
            return ValidationStrategy.ACTIVE_SAFE
        elif risk_level == RiskLevel.LOW:
            return ValidationStrategy.ACTIVE_SAFE
        elif risk_level == RiskLevel.MEDIUM:
            return ValidationStrategy.OPPORTUNISTIC
        elif risk_level == RiskLevel.HIGH:
            return ValidationStrategy.PASSIVE
        else:  # CRITICAL
            return ValidationStrategy.PASSIVE


class RuleValidationSystem:
    """è§„å¾‹éªŒè¯ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, logger=None, config: Optional[Dict[str, Any]] = None):
        self.logger = logger
        self.config = config or {}
        
        # ç»„ä»¶åˆå§‹åŒ–
        self.confidence_updater = ConfidenceUpdater(config)
        self.risk_assessor = RiskAssessor(logger)
        self.validation_planner = ValidationPlanner(
            self.confidence_updater, self.risk_assessor, logger
        )
        
        # éªŒè¯å†å²
        self.validation_attempts: List[ValidationAttempt] = []
        self.attempt_counter = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_validations': 0,
            'successful_validations': 0,
            'failed_validations': 0,
            'error_validations': 0,  # ğŸ”§ æ–°å¢ï¼šé”™è¯¯éªŒè¯ç»Ÿè®¡
            'risky_validations': 0,
            'avg_confidence_change': 0.0
        }
        
        if self.logger:
            self.logger.log("è§„å¾‹éªŒè¯ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    def validate_rule(self, rule: CandidateRule, context: EOCATR_Tuple, 
                     actual_result: Dict[str, Any], 
                     strategy: ValidationStrategy = ValidationStrategy.OPPORTUNISTIC) -> ValidationAttempt:
        """éªŒè¯è§„å¾‹ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ç‰ˆï¼‰"""
        
        attempt_id = f"attempt_{int(time.time())}_{rule.rule_id}"
        
        try:
            # ğŸ”§ å¢å¼ºï¼šå®‰å…¨åœ°è¯„ä¼°é£é™©ï¼Œé¿å…å±æ€§è®¿é—®é”™è¯¯
            try:
                risk_level = self.risk_assessor.assess_validation_risk(rule, context)
            except Exception as risk_error:
                if self.logger:
                    self.logger.log(f"é£é™©è¯„ä¼°å¤±è´¥: {str(risk_error)}, ä½¿ç”¨é»˜è®¤é£é™©ç­‰çº§")
                risk_level = RiskLevel.MEDIUM  # é»˜è®¤é£é™©ç­‰çº§
            
            # ğŸ”§ å¢å¼ºï¼šå®‰å…¨åœ°è·å–é¢„æœŸç»“æœï¼Œå¤„ç†ä¸åŒçš„ç»“æœæ ¼å¼
            expected_result = {}
            try:
                if hasattr(rule, 'expected_result') and rule.expected_result:
                    if isinstance(rule.expected_result, dict):
                        expected_result = rule.expected_result.copy()
                    else:
                        # å¦‚æœexpected_resultä¸æ˜¯å­—å…¸ï¼Œå°è¯•è½¬æ¢
                        expected_result = {'success': True, 'hp_change': 0, 'reward': 0.1}
                        if self.logger:
                            self.logger.log(f"è§„å¾‹ {rule.rule_id} çš„é¢„æœŸç»“æœæ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                else:
                    expected_result = {'success': True, 'hp_change': 0, 'reward': 0.1}
            except Exception as result_error:
                if self.logger:
                    self.logger.log(f"è·å–é¢„æœŸç»“æœå¤±è´¥: {str(result_error)}, ä½¿ç”¨é»˜è®¤å€¼")
                expected_result = {'success': True, 'hp_change': 0, 'reward': 0.1}
            
            # ğŸ”§ å¢å¼ºï¼šå®‰å…¨åœ°åˆ†æéªŒè¯ç»“æœ
            try:
                validation_result = self._analyze_validation_result(expected_result, actual_result)
            except Exception as analysis_error:
                if self.logger:
                    self.logger.log(f"éªŒè¯ç»“æœåˆ†æå¤±è´¥: {str(analysis_error)}, æ ‡è®°ä¸ºé”™è¯¯")
                validation_result = ValidationResult.ERROR
            
            # åˆ›å»ºéªŒè¯å°è¯•è®°å½•
            attempt = ValidationAttempt(
                attempt_id=attempt_id,
                rule_id=rule.rule_id,
                timestamp=time.time(),
                strategy=strategy,
                risk_level=risk_level,
                context_eocar=context,
                expected_result=expected_result,
                actual_result=actual_result,
                validation_result=validation_result,
                confidence_before=rule.confidence,
                confidence_after=rule.confidence,  # å°†åœ¨ä¸‹é¢æ›´æ–°
                confidence_change=0.0  # å°†åœ¨ä¸‹é¢æ›´æ–°
            )
            
            # ğŸ”§ å¢å¼ºï¼šå®‰å…¨åœ°æ›´æ–°ç½®ä¿¡åº¦
            try:
                new_confidence = self.confidence_updater.update_confidence(rule, attempt)
                attempt.confidence_after = new_confidence
                attempt.confidence_change = new_confidence - rule.confidence
                rule.confidence = new_confidence
            except Exception as confidence_error:
                if self.logger:
                    self.logger.log(f"ç½®ä¿¡åº¦æ›´æ–°å¤±è´¥: {str(confidence_error)}, ä¿æŒåŸç½®ä¿¡åº¦")
                attempt.confidence_after = rule.confidence
                attempt.confidence_change = 0.0
            
            # ğŸ”§ å¢å¼ºï¼šå®‰å…¨åœ°è®¡ç®—éªŒè¯è´¨é‡åˆ†æ•°
            try:
                attempt.reliability_score = self._calculate_reliability_score(attempt)
                attempt.relevance_score = self.confidence_updater._calculate_relevance_factor(rule, attempt)
                attempt.impact_score = self._calculate_impact_score(attempt)
            except Exception as score_error:
                if self.logger:
                    self.logger.log(f"è´¨é‡åˆ†æ•°è®¡ç®—å¤±è´¥: {str(score_error)}, ä½¿ç”¨é»˜è®¤åˆ†æ•°")
                attempt.reliability_score = 0.5
                attempt.relevance_score = 0.5
                attempt.impact_score = 0.5
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_stats(attempt)
            
            if self.logger:
                self.logger.log(f"è§„å¾‹éªŒè¯å®Œæˆ: {rule.rule_id} -> {validation_result.value} "
                              f"(ç½®ä¿¡åº¦: {rule.confidence:.3f})")
            
            return attempt
            
        except Exception as e:
            # ğŸ”§ å¢å¼ºï¼šå…¨å±€é”™è¯¯å¤„ç†ï¼Œç¡®ä¿ç³»ç»Ÿä¸ä¼šå´©æºƒ
            if self.logger:
                self.logger.log(f"è§„å¾‹éªŒè¯ç³»ç»Ÿå¤„ç†å¤±è´¥: {str(e)}")
            
            # åˆ›å»ºé”™è¯¯éªŒè¯å°è¯•è®°å½•
            error_attempt = ValidationAttempt(
                attempt_id=attempt_id,
                rule_id=rule.rule_id,
                timestamp=time.time(),
                strategy=strategy,
                risk_level=RiskLevel.CRITICAL,  # é”™è¯¯æƒ…å†µæ ‡è®°ä¸ºå…³é”®é£é™©
                context_eocar=context,
                expected_result={'success': False, 'hp_change': 0, 'reward': 0},
                actual_result=actual_result,
                validation_result=ValidationResult.ERROR,
                confidence_before=rule.confidence,
                confidence_after=rule.confidence,
                confidence_change=0.0,
                reliability_score=0.0,
                relevance_score=0.0,
                impact_score=0.0
            )
            
            return error_attempt
    
    def _analyze_validation_result(self, expected: Dict[str, Any], 
                                  actual: Dict[str, Any]) -> ValidationResult:
        """åˆ†æéªŒè¯ç»“æœ"""
        if not expected or not actual:
            return ValidationResult.INCONCLUSIVE
        
        matches = 0
        total = 0
        
        for key in expected:
            if key in actual:
                total += 1
                if expected[key] == actual[key]:
                    matches += 1
                elif isinstance(expected[key], bool) and isinstance(actual[key], bool):
                    # å¸ƒå°”å€¼å¿…é¡»å®Œå…¨åŒ¹é…
                    pass
                elif isinstance(expected[key], (int, float)) and isinstance(actual[key], (int, float)):
                    # æ•°å€¼ç±»å‹å…è®¸ä¸€å®šè¯¯å·®
                    error_rate = abs(expected[key] - actual[key]) / max(abs(expected[key]), 1)
                    if error_rate < 0.2:  # 20%è¯¯å·®å†…è®¤ä¸ºåŒ¹é…
                        matches += 1
        
        if total == 0:
            return ValidationResult.INCONCLUSIVE
        
        match_rate = matches / total
        
        if match_rate >= 0.9:
            return ValidationResult.SUCCESS
        elif match_rate >= 0.6:
            return ValidationResult.PARTIAL
        elif match_rate >= 0.1:
            return ValidationResult.FAILURE
        else:
            return ValidationResult.FAILURE
    
    def _calculate_reliability_score(self, attempt: ValidationAttempt) -> float:
        """è®¡ç®—éªŒè¯å¯é æ€§å¾—åˆ†"""
        score = 0.5  # åŸºç¡€å¾—åˆ†
        
        # é£é™©ç­‰çº§å½±å“å¯é æ€§
        risk_bonus = {"safe": 0.3, "low": 0.2, "medium": 0.0, "high": -0.2, "critical": -0.4}
        score += risk_bonus.get(attempt.risk_level.value, 0)
        
        # ä¸Šä¸‹æ–‡å®Œæ•´æ€§
        context = attempt.context_eocar
        if context.confidence > 0.8:
            score += 0.2
        
        # éªŒè¯ç­–ç•¥å½±å“
        strategy_bonus = {
            ValidationStrategy.SYSTEMATIC: 0.3,
            ValidationStrategy.ACTIVE_SAFE: 0.2,
            ValidationStrategy.OPPORTUNISTIC: 0.1,
            ValidationStrategy.ACTIVE_RISKY: -0.1,
            ValidationStrategy.PASSIVE: 0.0
        }
        score += strategy_bonus.get(attempt.strategy, 0)
        
        return max(0.0, min(1.0, score))
    
    def _calculate_impact_score(self, attempt: ValidationAttempt) -> float:
        """è®¡ç®—éªŒè¯å½±å“å¾—åˆ†"""
        score = 0.0
        
        # ç½®ä¿¡åº¦å˜åŒ–å¹…åº¦
        confidence_change = abs(attempt.confidence_change)
        score += min(confidence_change * 2, 0.5)
        
        # éªŒè¯ç»“æœçš„æ˜ç¡®æ€§
        if attempt.validation_result in [ValidationResult.SUCCESS, ValidationResult.FAILURE]:
            score += 0.3
        elif attempt.validation_result == ValidationResult.PARTIAL:
            score += 0.1
        
        # é£é™©æ‰¿æ‹…çš„å‹‡æ°”å¥–åŠ±
        if (attempt.risk_level in [RiskLevel.MEDIUM, RiskLevel.HIGH] and 
            attempt.validation_result == ValidationResult.SUCCESS):
            score += 0.2
        
        return max(0.0, min(1.0, score))
    
    def _update_stats(self, attempt: ValidationAttempt):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            # æ›´æ–°åŸºç¡€ç»Ÿè®¡
            self.stats['total_validations'] += 1
            
            if attempt.validation_result == ValidationResult.SUCCESS:
                self.stats['successful_validations'] += 1
            elif attempt.validation_result == ValidationResult.FAILURE:
                self.stats['failed_validations'] += 1
            elif attempt.validation_result == ValidationResult.ERROR:
                self.stats['error_validations'] += 1
            
            # ğŸ”§ æ–°å¢ï¼šå¤±è´¥æ¢å¤æœºåˆ¶ç»Ÿè®¡
            if attempt.validation_result in [ValidationResult.FAILURE, ValidationResult.ERROR]:
                self._handle_validation_failure(attempt)
            
            # è®°å½•éªŒè¯å†å²
            self.validation_attempts.append(attempt)
            
            # é™åˆ¶å†å²è®°å½•å¤§å°ï¼Œé¿å…å†…å­˜æ³„æ¼
            if len(self.validation_attempts) > 1000:
                self.validation_attempts = self.validation_attempts[-500:]  # ä¿ç•™æœ€è¿‘500æ¡
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å¤±è´¥: {str(e)}")
    
    def _handle_validation_failure(self, attempt: ValidationAttempt):
        """å¤„ç†éªŒè¯å¤±è´¥çš„å›é€€æœºåˆ¶"""
        try:
            # ğŸ”§ å›é€€æœºåˆ¶1ï¼šé™ä½è§„å¾‹ç½®ä¿¡åº¦
            if hasattr(self, '_failed_rules'):
                if attempt.rule_id not in self._failed_rules:
                    self._failed_rules[attempt.rule_id] = 0
                self._failed_rules[attempt.rule_id] += 1
            else:
                self._failed_rules = {attempt.rule_id: 1}
            
            # ğŸ”§ å›é€€æœºåˆ¶2ï¼šæ ‡è®°é«˜é£é™©è§„å¾‹
            failure_count = self._failed_rules.get(attempt.rule_id, 0)
            if failure_count >= 3:  # è¿ç»­å¤±è´¥3æ¬¡
                if hasattr(self, '_high_risk_rules'):
                    self._high_risk_rules.add(attempt.rule_id)
                else:
                    self._high_risk_rules = {attempt.rule_id}
                
                if self.logger:
                    self.logger.log(f"è§„å¾‹ {attempt.rule_id} è¢«æ ‡è®°ä¸ºé«˜é£é™©ï¼ˆå¤±è´¥æ¬¡æ•°: {failure_count}ï¼‰")
            
            # ğŸ”§ å›é€€æœºåˆ¶3ï¼šè°ƒæ•´éªŒè¯ç­–ç•¥
            if failure_count >= 2:
                if hasattr(self, '_strategy_adjustments'):
                    self._strategy_adjustments[attempt.rule_id] = ValidationStrategy.PASSIVE
                else:
                    self._strategy_adjustments = {attempt.rule_id: ValidationStrategy.PASSIVE}
                
                if self.logger:
                    self.logger.log(f"è§„å¾‹ {attempt.rule_id} éªŒè¯ç­–ç•¥è°ƒæ•´ä¸ºè¢«åŠ¨éªŒè¯")
                    
        except Exception as e:
            if self.logger:
                self.logger.log(f"éªŒè¯å¤±è´¥å¤„ç†å‡ºé”™: {str(e)}")
    
    def get_recommended_strategy(self, rule_id: str) -> ValidationStrategy:
        """è·å–æ¨èçš„éªŒè¯ç­–ç•¥ï¼ˆè€ƒè™‘å†å²å¤±è´¥ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­–ç•¥è°ƒæ•´
            if hasattr(self, '_strategy_adjustments') and rule_id in self._strategy_adjustments:
                return self._strategy_adjustments[rule_id]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜é£é™©è§„å¾‹
            if hasattr(self, '_high_risk_rules') and rule_id in self._high_risk_rules:
                return ValidationStrategy.PASSIVE
            
            # æ£€æŸ¥å¤±è´¥æ¬¡æ•°
            if hasattr(self, '_failed_rules'):
                failure_count = self._failed_rules.get(rule_id, 0)
                if failure_count >= 2:
                    return ValidationStrategy.OPPORTUNISTIC
                elif failure_count >= 1:
                    return ValidationStrategy.ACTIVE_SAFE
            
            # é»˜è®¤ç­–ç•¥
            return ValidationStrategy.OPPORTUNISTIC
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"è·å–æ¨èç­–ç•¥å¤±è´¥: {str(e)}")
            return ValidationStrategy.PASSIVE  # å‡ºé”™æ—¶ä½¿ç”¨æœ€å®‰å…¨çš„ç­–ç•¥
    
    def reset_rule_status(self, rule_id: str):
        """é‡ç½®è§„å¾‹çŠ¶æ€ï¼ˆæ¸…é™¤å¤±è´¥è®°å½•ï¼‰"""
        try:
            if hasattr(self, '_failed_rules') and rule_id in self._failed_rules:
                del self._failed_rules[rule_id]
            
            if hasattr(self, '_high_risk_rules') and rule_id in self._high_risk_rules:
                self._high_risk_rules.remove(rule_id)
            
            if hasattr(self, '_strategy_adjustments') and rule_id in self._strategy_adjustments:
                del self._strategy_adjustments[rule_id]
            
            if self.logger:
                self.logger.log(f"è§„å¾‹ {rule_id} çŠ¶æ€å·²é‡ç½®")
                
        except Exception as e:
            if self.logger:
                self.logger.log(f"é‡ç½®è§„å¾‹çŠ¶æ€å¤±è´¥: {str(e)}")
    
    def get_system_health(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        try:
            total = self.stats['total_validations']
            if total == 0:
                return {"status": "æœªå¼€å§‹", "health_score": 0.0}
            
            success_rate = self.stats['successful_validations'] / total
            error_rate = self.stats['error_validations'] / total
            
            # è®¡ç®—å¥åº·åˆ†æ•°
            health_score = success_rate * 0.7 + (1 - error_rate) * 0.3
            
            # ç¡®å®šçŠ¶æ€
            if health_score >= 0.8:
                status = "ä¼˜ç§€"
            elif health_score >= 0.6:
                status = "è‰¯å¥½"
            elif health_score >= 0.4:
                status = "ä¸€èˆ¬"
            else:
                status = "éœ€è¦å…³æ³¨"
            
            return {
                "status": status,
                "health_score": health_score,
                "success_rate": success_rate,
                "error_rate": error_rate,
                "total_validations": total,
                "high_risk_rules": len(getattr(self, '_high_risk_rules', set())),
                "failed_rules": len(getattr(self, '_failed_rules', {}))
            }
            
        except Exception as e:
            if self.logger:
                self.logger.log(f"è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€å¤±è´¥: {str(e)}")
            return {"status": "é”™è¯¯", "health_score": 0.0, "error": str(e)}
    
    def get_validation_suggestions(self, current_context: EOCATR_Tuple,
                                  available_rules: List[CandidateRule],
                                  player_state: Optional[Dict[str, Any]] = None) -> List[Tuple[CandidateRule, ValidationStrategy]]:
        """è·å–éªŒè¯å»ºè®®"""
        suggestions = []
        
        # è·å–ä¸»è¦å»ºè®®
        main_suggestion = self.validation_planner.suggest_validation_action(
            current_context, available_rules, player_state
        )
        
        if main_suggestion:
            suggestions.append(main_suggestion)
        
        # æ·»åŠ å¤‡é€‰å»ºè®®
        for rule in available_rules[:3]:  # åªè€ƒè™‘å‰3ä¸ªè§„å¾‹
            if main_suggestion and rule.rule_id == main_suggestion[0].rule_id:
                continue
                
            relevance = self.confidence_updater._calculate_context_relevance(rule, current_context)
            if relevance > 0.3:
                risk_level = self.risk_assessor.assess_validation_risk(rule, current_context, player_state)
                strategy = self.validation_planner._select_validation_strategy(rule, risk_level)
                suggestions.append((rule, strategy))
        
        return suggestions[:3]  # æœ€å¤šè¿”å›3ä¸ªå»ºè®®
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–éªŒè¯ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        
        # è®¡ç®—æˆåŠŸç‡
        if stats['total_validations'] > 0:
            stats['success_rate'] = stats['successful_validations'] / stats['total_validations']
            stats['failure_rate'] = stats['failed_validations'] / stats['total_validations']
            stats['risk_taking_rate'] = stats['risky_validations'] / stats['total_validations']
        else:
            stats['success_rate'] = 0.0
            stats['failure_rate'] = 0.0
            stats['risk_taking_rate'] = 0.0
        
        stats['active_plans'] = len(self.validation_planner.active_plans)
        stats['total_attempts'] = len(self.validation_attempts)
        
        return stats 