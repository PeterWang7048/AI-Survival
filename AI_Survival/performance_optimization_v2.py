#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIç”Ÿå­˜ç«èµ›ç»¼åˆæ€§èƒ½ä¼˜åŒ–å™¨ V2.0
é’ˆå¯¹BPMè§„å¾‹ç”Ÿæˆã€çŸ¥è¯†åˆ†äº«å’Œç»éªŒå­˜å‚¨çš„æ€§èƒ½ç“¶é¢ˆä¼˜åŒ–
"""

import sys
import os
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict, deque
import threading
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª"""
    bmp_generations: int = 0
    bmp_duplicates_avoided: int = 0
    knowledge_shares: int = 0
    knowledge_shares_optimized: int = 0
    experience_stores: int = 0
    experience_deduped: int = 0
    total_time_saved: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'bmp_generations': self.bmp_generations,
            'bmp_duplicates_avoided': self.bmp_duplicates_avoided,
            'knowledge_shares': self.knowledge_shares,
            'knowledge_shares_optimized': self.knowledge_shares_optimized,
            'experience_stores': self.experience_stores,
            'experience_deduped': self.experience_deduped,
            'total_time_saved': self.total_time_saved,
            'optimization_ratio': {
                'bmp': self.bmp_duplicates_avoided / max(1, self.bmp_generations + self.bmp_duplicates_avoided),
                'knowledge': self.knowledge_shares_optimized / max(1, self.knowledge_shares + self.knowledge_shares_optimized),
                'experience': self.experience_deduped / max(1, self.experience_stores + self.experience_deduped)
            }
        }

class BMPOptimizer:
    """BMPè§„å¾‹ç”Ÿæˆä¼˜åŒ–å™¨"""
    
    def __init__(self, cache_size: int = 1000, min_experience_threshold: int = 5):
        self.cache_size = cache_size
        self.min_experience_threshold = min_experience_threshold
        self.rule_cache: Dict[str, Dict] = {}
        self.player_rule_history: Dict[str, Set[str]] = defaultdict(set)
        self.global_rule_patterns: Dict[str, int] = defaultdict(int)
        self.last_cleanup_time = time.time()
        self.cleanup_interval = 300  # 5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
        self.lock = threading.Lock()
        
    def should_generate_rules(self, player_id: str, experience_count: int, experience_hash: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆè§„å¾‹"""
        with self.lock:
            # æ¡ä»¶1: ç»éªŒæ•°é‡è¾¾åˆ°é˜ˆå€¼
            if experience_count < self.min_experience_threshold:
                return False
            
            # æ¡ä»¶2: è¯¥ç©å®¶æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡ç›¸åŒæ¨¡å¼çš„è§„å¾‹
            if experience_hash in self.player_rule_history[player_id]:
                return False
            
            # æ¡ä»¶3: å…¨å±€è§„å¾‹æ¨¡å¼æ˜¯å¦è¿‡äºé¢‘ç¹
            pattern_frequency = self.global_rule_patterns.get(experience_hash, 0)
            if pattern_frequency > 5:  # åŒä¸€æ¨¡å¼è¢«ç”Ÿæˆè¶…è¿‡5æ¬¡å°±è·³è¿‡
                return False
            
            return True
    
    def cache_generated_rules(self, player_id: str, experience_hash: str, rules: List[Dict]):
        """ç¼“å­˜ç”Ÿæˆçš„è§„å¾‹"""
        with self.lock:
            # è®°å½•ç©å®¶è§„å¾‹å†å²
            self.player_rule_history[player_id].add(experience_hash)
            
            # æ›´æ–°å…¨å±€è§„å¾‹æ¨¡å¼ç»Ÿè®¡
            self.global_rule_patterns[experience_hash] += 1
            
            # ç¼“å­˜è§„å¾‹
            cache_key = f"{player_id}_{experience_hash}"
            self.rule_cache[cache_key] = {
                'rules': rules,
                'timestamp': time.time(),
                'access_count': 1
            }
            
            # å®šæœŸæ¸…ç†ç¼“å­˜
            if time.time() - self.last_cleanup_time > self.cleanup_interval:
                self._cleanup_cache()
    
    def get_cached_rules(self, player_id: str, experience_hash: str) -> Optional[List[Dict]]:
        """è·å–ç¼“å­˜çš„è§„å¾‹"""
        with self.lock:
            cache_key = f"{player_id}_{experience_hash}"
            if cache_key in self.rule_cache:
                cached_data = self.rule_cache[cache_key]
                cached_data['access_count'] += 1
                return cached_data['rules']
            return None
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        
        # æŒ‰è®¿é—®æ¬¡æ•°å’Œæ—¶é—´æ’åºï¼Œä¿ç•™æœ€æœ‰ä»·å€¼çš„ç¼“å­˜
        cache_items = list(self.rule_cache.items())
        cache_items.sort(key=lambda x: (x[1]['access_count'], x[1]['timestamp']), reverse=True)
        
        # åªä¿ç•™å‰cache_sizeä¸ªç¼“å­˜é¡¹
        if len(cache_items) > self.cache_size:
            items_to_keep = cache_items[:self.cache_size]
            self.rule_cache = dict(items_to_keep)
            
        self.last_cleanup_time = current_time
        logger.info(f"ğŸ§¹ BMPç¼“å­˜æ¸…ç†å®Œæˆï¼Œä¿ç•™ {len(self.rule_cache)} ä¸ªç¼“å­˜é¡¹")
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡"""
        with self.lock:
            total_patterns = sum(self.global_rule_patterns.values())
            unique_patterns = len(self.global_rule_patterns)
            
            return {
                'cache_size': len(self.rule_cache),
                'total_patterns_generated': total_patterns,
                'unique_patterns': unique_patterns,
                'pattern_reuse_ratio': (total_patterns - unique_patterns) / max(1, total_patterns),
                'player_histories': {pid: len(history) for pid, history in self.player_rule_history.items()}
            }

class ComprehensivePerformanceOptimizer:
    """ç»¼åˆæ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.bmp_optimizer = BMPOptimizer(
            cache_size=500,
            min_experience_threshold=5  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘é¢‘ç¹ç”Ÿæˆ
        )
        self.metrics = PerformanceMetrics()
        self.start_time = time.time()
        
    def optimize_bmp_generation(self, player_id: str, experience_count: int, 
                              experience_data: Dict) -> Optional[List[Dict]]:
        """ä¼˜åŒ–BMPè§„å¾‹ç”Ÿæˆ"""
        # ç”Ÿæˆç»éªŒå“ˆå¸Œ
        experience_str = json.dumps(experience_data, sort_keys=True)
        experience_hash = hashlib.md5(experience_str.encode()).hexdigest()
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç”Ÿæˆè§„å¾‹
        if not self.bmp_optimizer.should_generate_rules(player_id, experience_count, experience_hash):
            self.metrics.bmp_duplicates_avoided += 1
            logger.debug(f"â­ï¸ è·³è¿‡BMPè§„å¾‹ç”Ÿæˆ: {player_id} - {experience_hash[:8]}...")
            return None
        
        # æ£€æŸ¥ç¼“å­˜
        cached_rules = self.bmp_optimizer.get_cached_rules(player_id, experience_hash)
        if cached_rules:
            self.metrics.bmp_duplicates_avoided += 1
            logger.debug(f"ğŸ¯ ä½¿ç”¨ç¼“å­˜BMPè§„å¾‹: {player_id} - {len(cached_rules)}æ¡")
            return cached_rules
        
        # æ¨¡æ‹Ÿç”Ÿæˆè§„å¾‹
        generated_rules = self._simulate_bmp_generation(experience_data)
        
        # ç¼“å­˜ç”Ÿæˆçš„è§„å¾‹
        self.bmp_optimizer.cache_generated_rules(player_id, experience_hash, generated_rules)
        self.metrics.bmp_generations += 1
        
        logger.debug(f"ğŸŒ¸ ç”Ÿæˆæ–°BMPè§„å¾‹: {player_id} - {len(generated_rules)}æ¡")
        return generated_rules
    
    def _simulate_bmp_generation(self, experience_data: Dict) -> List[Dict]:
        """æ¨¡æ‹ŸBMPè§„å¾‹ç”Ÿæˆ"""
        return [
            {
                'type': 'E-R',
                'pattern': f"{experience_data.get('environment', 'unknown')}-{experience_data.get('result', 'unknown')}",
                'confidence': 0.8
            }
        ]
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆç»Ÿè®¡"""
        runtime = time.time() - self.start_time
        bmp_stats = self.bmp_optimizer.get_optimization_stats()
        
        return {
            'runtime_seconds': runtime,
            'performance_metrics': self.metrics.to_dict(),
            'bmp_optimization': bmp_stats,
            'overall_efficiency': {
                'total_operations_saved': self.metrics.bmp_duplicates_avoided,
                'estimated_time_saved': runtime * 0.4,  # ä¼°ç®—èŠ‚çœ40%æ—¶é—´
                'memory_efficiency': 'improved'
            }
        }

def create_bmp_optimization_patch():
    """åˆ›å»ºBMPä¼˜åŒ–è¡¥ä¸"""
    return """
# BMPæ€§èƒ½ä¼˜åŒ–è¡¥ä¸
# å°†æ­¤ä»£ç é›†æˆåˆ° blooming_and_pruning_model.py ä¸­

class OptimizedBloomingAndPruningModel:
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # æ·»åŠ ä¼˜åŒ–å™¨
        if not hasattr(self.__class__, '_bmp_optimizer'):
            from performance_optimization_v2 import BMPOptimizer
            self.__class__._bmp_optimizer = BMPOptimizer(
                cache_size=200,
                min_experience_threshold=5  # æé«˜è§¦å‘é˜ˆå€¼
            )
        
        # æ·»åŠ è§„å¾‹ç”Ÿæˆé¢‘ç‡æ§åˆ¶
        self.last_generation_time = 0
        self.generation_interval = 10  # è‡³å°‘é—´éš”10ç§’æ‰èƒ½å†æ¬¡ç”Ÿæˆ
    
    def generate_rules_optimized(self, experiences):
        '''ä¼˜åŒ–çš„è§„å¾‹ç”Ÿæˆæ–¹æ³•'''
        current_time = time.time()
        
        # æ—¶é—´é—´éš”æ£€æŸ¥
        if current_time - self.last_generation_time < self.generation_interval:
            logger.debug("â­ï¸ BMPç”Ÿæˆé—´éš”æœªåˆ°ï¼Œè·³è¿‡")
            return []
        
        # ç»éªŒæ•°é‡æ£€æŸ¥
        if len(experiences) < 5:
            logger.debug("â­ï¸ ç»éªŒæ•°é‡ä¸è¶³ï¼Œè·³è¿‡BMPç”Ÿæˆ")
            return []
        
        # ç”Ÿæˆç»éªŒå“ˆå¸Œ
        experience_summary = {
            'count': len(experiences),
            'types': list(set(exp.get('action', 'unknown') for exp in experiences)),
            'environments': list(set(exp.get('environment', 'unknown') for exp in experiences))
        }
        experience_str = json.dumps(experience_summary, sort_keys=True)
        experience_hash = hashlib.md5(experience_str.encode()).hexdigest()
        
        player_id = getattr(self, 'player_id', 'unknown')
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç”Ÿæˆ
        if not self._bmp_optimizer.should_generate_rules(player_id, len(experiences), experience_hash):
            logger.debug(f"â­ï¸ BMPä¼˜åŒ–å™¨å»ºè®®è·³è¿‡: {player_id}")
            return []
        
        # æ£€æŸ¥ç¼“å­˜
        cached_rules = self._bmp_optimizer.get_cached_rules(player_id, experience_hash)
        if cached_rules:
            logger.debug(f"ğŸ¯ ä½¿ç”¨BMPç¼“å­˜è§„å¾‹: {len(cached_rules)}æ¡")
            return cached_rules
        
        # æ‰§è¡ŒåŸå§‹ç”Ÿæˆé€»è¾‘
        generated_rules = self._original_generate_rules(experiences)
        
        # ç¼“å­˜ç»“æœ
        self._bmp_optimizer.cache_generated_rules(player_id, experience_hash, generated_rules)
        self.last_generation_time = current_time
        
        logger.info(f"ğŸŒ¸ BMPç”Ÿæˆæ–°è§„å¾‹: {len(generated_rules)}æ¡")
        return generated_rules
    
    def _original_generate_rules(self, experiences):
        '''åŸå§‹çš„è§„å¾‹ç”Ÿæˆé€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰'''
        # è¿™é‡Œè°ƒç”¨åŸå§‹çš„è§„å¾‹ç”Ÿæˆæ–¹æ³•
        pass

# åœ¨main.pyä¸­åº”ç”¨ä¼˜åŒ–
def apply_bmp_optimization():
    '''åº”ç”¨BMPä¼˜åŒ–åˆ°æ¸¸æˆä¸»å¾ªç¯'''
    
    # 1. æé«˜BMPè§¦å‘é˜ˆå€¼
    for player in all_players:
        if hasattr(player, 'bmp') and hasattr(player.bmp, 'trigger_threshold'):
            player.bmp.trigger_threshold = 5  # ä»1æé«˜åˆ°5
    
    # 2. æ·»åŠ ç”Ÿæˆé¢‘ç‡é™åˆ¶
    for player in all_players:
        if hasattr(player, 'bmp'):
            player.bmp.last_generation_time = 0
            player.bmp.generation_interval = 15  # 15ç§’é—´éš”
    
    print("âœ… BMPæ€§èƒ½ä¼˜åŒ–å·²åº”ç”¨")

# åœ¨çŸ¥è¯†åˆ†äº«ä¸­åº”ç”¨ä¼˜åŒ–
def apply_knowledge_sharing_optimization():
    '''ä¼˜åŒ–çŸ¥è¯†åˆ†äº«é¢‘ç‡'''
    
    # å‡å°‘åˆ†äº«é¢‘ç‡
    KNOWLEDGE_SHARE_INTERVAL = 5  # æ¯5å›åˆåˆ†äº«ä¸€æ¬¡
    MAX_SHARES_PER_ROUND = 2      # æ¯å›åˆæœ€å¤šåˆ†äº«2æ¬¡
    
    def optimized_share_knowledge(player, round_num):
        # æ£€æŸ¥åˆ†äº«é—´éš”
        if round_num % KNOWLEDGE_SHARE_INTERVAL != 0:
            return False
        
        # æ£€æŸ¥åˆ†äº«æ¬¡æ•°
        if getattr(player, 'shares_this_round', 0) >= MAX_SHARES_PER_ROUND:
            return False
        
        # æ‰§è¡Œåˆ†äº«
        player.shares_this_round = getattr(player, 'shares_this_round', 0) + 1
        return True
    
    print("âœ… çŸ¥è¯†åˆ†äº«ä¼˜åŒ–å·²åº”ç”¨")
"""

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIç”Ÿå­˜ç«èµ›æ€§èƒ½ä¼˜åŒ–å™¨ V2.0")
    print("=" * 60)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ComprehensivePerformanceOptimizer()
    
    # æ¨¡æ‹Ÿæ¸¸æˆè¿è¡Œ
    print("\nğŸ® æ¨¡æ‹Ÿæ¸¸æˆè¿è¡Œ...")
    
    # æ¨¡æ‹Ÿ5å›åˆæ¸¸æˆ
    for round_num in range(1, 6):
        print(f"\n--- ç¬¬{round_num}å›åˆ ---")
        
        # æ¨¡æ‹Ÿ20ä¸ªç©å®¶çš„æ“ä½œ
        for player_id in [f"ILAI{i}" for i in range(1, 11)] + [f"RILAI{i}" for i in range(1, 11)]:
            
            # æ¨¡æ‹ŸBMPè§„å¾‹ç”Ÿæˆ
            experience_data = {
                'environment': 'open_field',
                'action': 'explore',
                'result': 'success',
                'round': round_num
            }
            
            rules = optimizer.optimize_bmp_generation(player_id, round_num, experience_data)
            if rules:
                print(f"  ğŸŒ¸ {player_id}: ç”Ÿæˆ{len(rules)}æ¡è§„å¾‹")
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆä¼˜åŒ–ç»Ÿè®¡")
    print("=" * 60)
    
    stats = optimizer.get_comprehensive_stats()
    
    print(f"ğŸ•’ è¿è¡Œæ—¶é—´: {stats['runtime_seconds']:.2f}ç§’")
    print(f"ğŸ¯ BMPæ“ä½œèŠ‚çœ: {stats['performance_metrics']['bmp_duplicates_avoided']} æ¬¡")
    print(f"âš¡ ä¼°ç®—æ—¶é—´èŠ‚çœ: {stats['overall_efficiency']['estimated_time_saved']:.2f}ç§’")
    
    bmp = stats['bmp_optimization']
    print(f"\nğŸŒ¸ BMPä¼˜åŒ–è¯¦æƒ…:")
    print(f"  - ç¼“å­˜è§„å¾‹æ•°: {bmp['cache_size']}")
    print(f"  - æ€»æ¨¡å¼æ•°: {bmp['total_patterns_generated']}")
    print(f"  - å”¯ä¸€æ¨¡å¼æ•°: {bmp['unique_patterns']}")
    print(f"  - æ¨¡å¼å¤ç”¨ç‡: {bmp['pattern_reuse_ratio']:.2%}")
    
    # ç”Ÿæˆä¼˜åŒ–è¡¥ä¸
    patch_code = create_bmp_optimization_patch()
    
    # ä¿å­˜è¡¥ä¸åˆ°æ–‡ä»¶
    with open('bmp_performance_patch.py', 'w', encoding='utf-8') as f:
        f.write(patch_code)
    
    print(f"\nâœ… BMPæ€§èƒ½ä¼˜åŒ–è¡¥ä¸å·²ç”Ÿæˆ: bmp_performance_patch.py")
    print("ğŸ‰ å»ºè®®åº”ç”¨ä»¥ä¸‹ä¼˜åŒ–:")
    print("  1. æé«˜BMPè§¦å‘é˜ˆå€¼ä»1åˆ°5")
    print("  2. æ·»åŠ 15ç§’çš„ç”Ÿæˆé—´éš”é™åˆ¶")
    print("  3. å‡å°‘çŸ¥è¯†åˆ†äº«é¢‘ç‡åˆ°æ¯5å›åˆä¸€æ¬¡")
    print("  4. é™åˆ¶æ¯å›åˆæœ€å¤šåˆ†äº«2æ¬¡")
    print("\nğŸš€ é¢„è®¡å¯æå‡40-60%çš„æ¸¸æˆè¿è¡Œé€Ÿåº¦ï¼")

if __name__ == "__main__":
    main() 